<html>
<head>
<title>How Computers Extract Meaningful Information From Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机如何从文本中提取有意义的信息</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/what-the-heck-is-tf-idf-69ead52c908b?source=collection_archive---------10-----------------------#2021-10-20">https://levelup.gitconnected.com/what-the-heck-is-tf-idf-69ead52c908b?source=collection_archive---------10-----------------------#2021-10-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f88" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">TF-IDF:理解搜索引擎和其他机器学习应用中使用的这种技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/45fe4a114230c6f25bb6015cd80a4a45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7YJ6e3quBYLAWleDeC9ZYQ.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1246674" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/anniespratt-4900708/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1246674" rel="noopener ugc nofollow" target="_blank">安妮·斯普拉特</a></figcaption></figure><p id="e856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你正在学习机器学习(ML)，特别是自然语言处理(NLP)，你可能会遇到这个缩写。<em class="lv">【TF-IDF】</em>。我一直在我阅读的每一篇关于自动文本摘要的研究论文中找到它。</p><p id="962b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> "TF-IDF..又来了！”</em>永远是我的思考。</p><p id="1d62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重述一个关键概念。在NLP中，文本术语/单词被转换成数值，因此算法可以执行计算并从中推断信息。</p><p id="326d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，在我关于<a class="ae ky" href="https://towardsdatascience.com/cosine-similarity-intuition-with-implementation-in-python-51eade2674f6" rel="noopener" target="_blank">余弦相似度</a>的文章中，我选择每个句子的数值(特征)为:</p><ul class=""><li id="88c7" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">字数</li><li id="9dd3" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">基础文本中包含的字数</li></ul><p id="972d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TF-IDF是我可以选择的另一个特性。</p><p id="f7e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它是一个属性，告诉你关于这个词或术语的一些有意义的东西。但是TF-IDF怎么算，TF-IDF等于0.23或者0.60或者0不代表什么？</p><p id="ecd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TF-IDF的目标是对文档中“术语”(如单词)的重要性进行评分。它通过比较单词在文档中的相关性和同一个单词在不同文档中的重要性来工作。</p><p id="575f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将“文档”视为一个通用术语。它可以指句子。</p><h1 id="19ba" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">术语频率(TF)</h1><p id="8212" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们先来看TF。</p><p id="74f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TF表示一个单词在其句子中的常见或罕见程度。它只看它的句子<em class="lv"/>。它不考虑其他的。我将用下面的句子来说明它是如何工作的。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="fc8b" class="nm ml it ni b gy nn no l np nq">Sentence 1: boy likes playing volleyball<br/>Sentence 2: girl likes playing basketball<br/>Sentence 3: Everyone likes playing</span></pre><p id="e351" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TF的公式如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/822641412c3490b14154cd59863f59e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Grt62bGzeCUPrbXMxkhSew.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图一。TF的公式。作者图片</figcaption></figure><p id="0a03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个句子中“男孩”这个词的TF值是多少？</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="5fe5" class="nm ml it ni b gy nn no l np nq"><strong class="ni iu">Sentence1; word "boy":</strong> 1/4 = 0.25 (It appears 1 time. the sentence has 4 words)<br/><strong class="ni iu">Sentence2; word "boy":</strong> 0/4 = 0<br/><strong class="ni iu">Sentence3; word "boy":</strong> 0/3 = 0</span></pre><p id="d70b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是所有的TF计算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/e9e8319d00280e839fd7626561454306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*Lo1CozLRCAHmUTsdLynAJA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图二。所有TF计算[2]。图片作者。</figcaption></figure><h1 id="067c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">反向文档频率(IDF)</h1><p id="1f37" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">另一方面，IDF从整个文档/句子集合的角度说明单词的重要性。</p><p id="ec38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">IDF显示一个单词在所有文档中的总体常见(或罕见)程度。</p><ul class=""><li id="3b80" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">IDF = 0(或接近0)，意味着这个词太常见了。</li><li id="5d22" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">IDF = 1，这个词很少见/不太常见。</li></ul><p id="7f49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这听起来可能很奇怪，但这是因为许多文档中的“common”意味着这个词与提取文档的关键信息无关。</p><p id="9e41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像<strong class="lb iu">“如何”、“什么”、“这个”这样的词以及其他常用词</strong>并不能告诉你关于特定文档的太多信息。</p><p id="20f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，考虑一下我在这篇文章中使用的句子。想象一下，每个句子都是关于一项运动的，而你正试图按它们给每个句子分类。</p><p id="f10d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据IDF值，篮球和排球将排名靠前。</p><p id="8fbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">换句话说</strong>——在文档X中常见的单词，但在其他文档Y和Z中不常见的<em class="lv">更能说明文档X的含义</em></p><p id="ad58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算IDF值的公式如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b3bac21242db361aee6e791a4b6a098a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*wU6whZL3l1-jWlmjVDW1CA.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图3。IDF公式。作者图片</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/d56e6e0c292ee11706e2828607049639.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*-hPPZygTzO8gE7PRiRpuVw.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图4。所有IDF计算[2]。图片作者。</figcaption></figure><h1 id="f632" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">把所有的放在一起</h1><p id="6d3f" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">一旦你有了TF和IDF，你就把它们相乘。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c0ffd26990f67b79bbff19cad4e1050d.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*XLd9SemlyGQPIHRDoXiIbg.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图5。TF-IDF公式。作者图片</figcaption></figure><p id="e7ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是了——考虑到所有其他句子，句子中每个单词的相关性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/79d30ab62aa37ef7936fa09bdb6c4739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*PAKVAqfqmNMgR9wMaIWcow.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">图6。TF-IDF最终结果[2]。作者图片</figcaption></figure><p id="bf80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">读取最终结果的方式是:</strong></p><ul class=""><li id="abae" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">“男孩”和“排球”是第一句中最相关的词。</li><li id="c85f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">“女孩”和“篮球”是第二句中最相关的词。</li><li id="4729" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">“每个人”是第三句中最相关的词。</li></ul><p id="1144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“likes”和“playing”在句子1中与“boy”具有相同的TF，但因为它们在其他句子中也太常见，所以它们在提供关于句子1的关键信息方面不太相关。</p><p id="c98a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括地说，在各种文档/句子中过于常见的术语可能与提取特定文档/句子的关键信息无关。而稀有术语更有可能泄露关键信息。</p><p id="8228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于Python中的实现，请查看Cory Maklin 的文章</p><h1 id="d86f" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">结论</h1><p id="4f55" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">TF-IDF是NLP中使用的一种流行的单词权重测量方法。它被用于搜索引擎，文本摘要系统和其他。这是一个有趣的方法来找出一个词/术语是如何相关的。</p><p id="f272" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理解起来没那么复杂，但是有点棘手。这会造成混乱。让我迷惑的一点是“逆文档频率”这个名字。“词频”很清楚，但“逆文档频……”就没那么多了。至少第一眼看不出来。</p><p id="207c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，现在阅读关于文本摘要和NLP的论文会感觉不那么费劲了。</p><p id="c8c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">渐渐地，所有的概念都很好地融合在一起了，我迫不及待地想深入研究一下“单值分解(SVD)”。大概是下一篇吧。</p><p id="6145" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读。</p><h1 id="c17c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参考</h1><p id="6cce" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">[1] <a class="ae ky" href="https://towardsdatascience.com/a-gentle-introduction-to-calculating-the-tf-idf-values-9e391f8a13e5" rel="noopener" target="_blank">计算TF-IDF值的简明介绍</a></p><p id="5fca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] <a class="ae ky" href="https://www.youtube.com/watch?v=D2V1okCEsiE" rel="noopener ugc nofollow" target="_blank">自然语言处理|TF-IDF直觉|文本预处理</a></p></div></div>    
</body>
</html>