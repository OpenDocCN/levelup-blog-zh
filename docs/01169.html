<html>
<head>
<title>3-Step Introduction to Machine Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中机器学习的3步介绍</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/3-step-introduction-to-machine-learning-in-python-6e16452b4551?source=collection_archive---------3-----------------------#2019-11-21">https://levelup.gitconnected.com/3-step-introduction-to-machine-learning-in-python-6e16452b4551?source=collection_archive---------3-----------------------#2019-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c890" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">简单是关键。</h2></div><p id="be26" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该练习由三个步骤组成<strong class="kk iu">:</strong></p><ol class=""><li id="f1bb" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">获取数据</li><li id="ecb7" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">制作ML模型</li><li id="c9e7" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">改进ML模型</li></ol><h1 id="d80c" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">目标</h1><p id="752a" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">我们有这个<a class="ae mp" href="https://openblender.io/#/dataset/explore/5db079199516296099c9fb1e/or/21" rel="noopener ugc nofollow" target="_blank">兽医数据集</a>，里面有2008年到2018年患者(狗、猫和雪貂)的模拟登记。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mq"><img src="../Images/dc1454d5650c96f53536a1c365423a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yhf_CzVl2pRXkcOw7Ni0_g.png"/></div></div></figure><p id="185b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每一行都是患者的就诊记录，包括<strong class="kk iu">体重</strong>公斤、<strong class="kk iu">流行病学</strong>水平以及患者是否出现<strong class="kk iu">李斯特菌病</strong>。(都是模拟的疾病)。</p><p id="506d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对<strong class="kk iu">流行病</strong>的测试是昂贵的，并且可能是有害的，所以<strong class="kk iu">的目标</strong>是制作一个ML模型来<strong class="kk iu">预测这个值</strong>，其余的<strong class="kk iu"> </strong>特征使用这个数据来训练&amp;测试模型，从而防止动物受到伤害，并在这个过程中节省资金。</p><h1 id="bc46" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">你需要什么</h1><ul class=""><li id="783e" class="le lf it kk b kl mk ko ml kr nc kv nd kz ne ld nf lk ll lm bi translated">任何版本的Python(<a class="ae mp" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank">https://www.python.org/downloads/</a>)</li><li id="ef01" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld nf lk ll lm bi translated">皮普(<a class="ae mp" href="https://www.makeuseof.com/tag/install-pip-for-python/" rel="noopener ugc nofollow" target="_blank">https://www.makeuseof.com/tag/install-pip-for-python/</a>)</li><li id="9339" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld nf lk ll lm bi translated">安装熊猫、sklearn和openblender(带pip)</li></ul><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="c0d2" class="nl lt it nh b gy nm nn l no np">$ pip install pandas OpenBlender scikit-learn</span></pre><ul class=""><li id="4a06" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld nf lk ll lm bi translated">(推荐)一个Python编辑器比如Jupyter Notebook(<a class="ae mp" href="https://jupyter.org/install" rel="noopener ugc nofollow" target="_blank">https://jupyter.org/install</a>)</li></ul><h1 id="32e7" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">第一步。获取数据</h1><p id="722e" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">现在您已经有了运行Python的地方，让我们导入将要使用的库:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="f697" class="nl lt it nh b gy nm nn l no np">import OpenBlender<br/>import pandas as pd<br/>import numpy as np<br/>import json<br/>import sklearn<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_squared_error</span></pre><p id="fb67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们<strong class="kk iu">通过<a class="ae mp" href="https://www.openblender.io/or/21" rel="noopener ugc nofollow" target="_blank"> OpenBlender </a> API <strong class="kk iu">拉数据</strong>。</strong>您需要在<a class="ae mp" href="https://www.openblender.io." rel="noopener ugc nofollow" target="_blank">https://www . open blender . io</a>中创建一个帐户，以获取令牌和user_id(这是免费的)。</p><p id="5a99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们将定义<strong class="kk iu">参数</strong>(在本例中，它只是数据集的id):</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="ce76" class="nl lt it nh b gy nm nn l no np"># It only contains the id, we'll add more parameters later.<br/>parameters = { <br/>    'token' : '<strong class="nh iu">YOUR_TOKEN</strong>',<br/>    'id_user' : '<strong class="nh iu">YOUR_USER_ID</strong>',  <br/>    'id_dataset':'5db079199516296099c9fb1e'<br/>}</span></pre><p id="00ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们将数据放入数据帧“df”中:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="57fb" class="nl lt it nh b gy nm nn l no np"># This function pulls the data and orders by timestamp</span><span id="d4d5" class="nl lt it nh b gy nq nn l no np">def pullObservationsToDF(parameters):<br/>    action = 'API_getObservationsFromDataset'<br/>    df = pd.read_json(json.dumps(OpenBlender.call(action,parameters)['sample']), convert_dates=False,convert_axes=False) .sort_values('timestamp', ascending=False)<br/>    df.reset_index(drop=True, inplace=True)<br/>    return df</span><span id="55c0" class="nl lt it nh b gy nq nn l no np">df_vet = pullObservationsToDF(parameters)</span></pre><p id="a720" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="15a9" class="nl lt it nh b gy nm nn l no np">print(df_vet.shape)<br/>df_vet.head()</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d1f74c282a693bc9417cd0187e4cec06.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*hsMx0eBVTSPlzUZScVeMmw.png"/></div></figure><p id="97af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有<strong class="kk iu"> 800个观察值</strong>和<strong class="kk iu"> 5个特性</strong>。</p><h1 id="649a" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">第二步。制作ML模型</h1><p id="953a" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">让我们观察相对于体重绘制的流行病水平:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="828e" class="nl lt it nh b gy nm nn l no np">%matplotlib inline<br/>df_vet.plot.scatter(‘epidermiology_level’, ‘weight_in_kg’)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ca48fde100b49ebdb7a5514263c9b72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*aL6c9wwvNdLz5HdT4EdWNQ.png"/></div></figure><p id="c977" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到流行病学水平与体重呈负相关。</p><p id="688c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数字数据的一个非常简单的模型是线性回归，它通过绘制的数据调整一条直线(姑且称之为'<strong class="kk iu"> y </strong>')，如下所示:</p><blockquote class="nt"><p id="ad41" class="nu nv it bd nw nx ny nz oa ob oc ld dk translated">y =a+bx</p></blockquote><p id="5480" class="pw-post-body-paragraph ki kj it kk b kl od ju kn ko oe jx kq kr of kt ku kv og kx ky kz oh lb lc ld im bi translated">直线到每个点之间的距离就是<strong class="kk iu">误差</strong>，我们希望<em class="oi">选择‘a’和‘b’的方式是</em> <strong class="kk iu"> <em class="oi">最小化</em> </strong>。</p><blockquote class="nt"><p id="badc" class="nu nv it bd nw nx ny nz oa ob oc ld dk translated">误差=真实值-y</p></blockquote><p id="91fc" class="pw-post-body-paragraph ki kj it kk b kl od ju kn ko oe jx kq kr of kt ku kv og kx ky kz oh lb lc ld im bi translated">让我们绘制回归图:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="890e" class="nl lt it nh b gy nm nn l no np"># First we declare it<br/>regr = LinearRegression()</span><span id="79f9" class="nl lt it nh b gy nq nn l no np"># Then we fit (or train) it to relate epidermiology with weight<br/>regr.fit(df_vet[['weight_in_kg']], df_vet[['epidermiology_level']])</span><span id="67c2" class="nl lt it nh b gy nq nn l no np"># Let's take a look at the intercpt (Our 'a')<br/>print(regr.intercept_)</span><span id="ab72" class="nl lt it nh b gy nq nn l no np"># And the slope (Our 'b')<br/>print(regr.coef_)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/858d98b85cdf5ad81c138558715acf78.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*SUecCdYqsgz9PHf6jZjxxw.png"/></div><figcaption class="ok ol gj gh gi om on bd b be z dk translated">截距和系数</figcaption></figure><p id="593f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们将<strong class="kk iu">添加到剧情</strong>中:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="464c" class="nl lt it nh b gy nm nn l no np">axes = df_vet.plot.scatter(‘epidermiology_level’, ‘weight_in_kg’)<br/>x_vals = np.array(axes.get_xlim())<br/>y_vals = 37.01155578 + -0.47164364 * x_vals<br/>axes.plot(x_vals, y_vals, ‘ — ‘)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/3c91c947582a190d6882e4cabdb427d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*sHcSrQY2fE7qHgLyLaN3nw.png"/></div></figure><p id="a4cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">定量测量的方法是用数据(训练集)的一部分进行<strong class="kk iu">训练，然后用剩余的</strong>(测试集)进行<strong class="kk iu">测试，这样我们可以看到它如何用“新”数据进行概括。</strong></p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="09a8" class="nl lt it nh b gy nm nn l no np"># First we define ‘X’ and ‘y’<br/>X = df_vet[[‘weight_in_kg’]]<br/>y = df_vet[[‘epidermiology_level’]]</span><span id="3027" class="nl lt it nh b gy nq nn l no np"># Then we separate 500 to train<br/>X_train = X[:500]<br/>y_train = y[:500]<br/>print(“Train X and y:”)<br/>print(X_train.shape)<br/>print(y_train.shape)</span><span id="ec9f" class="nl lt it nh b gy nq nn l no np"># And 300 to test<br/>X_test = X[500:]<br/>y_test = y[500:]<br/>print(“Test X and y:”)<br/>print(X_test.shape)<br/>print(y_test.shape)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/10b67282cc59e0bed2ff77615728fa21.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/format:webp/1*q_UjlNoyqg0blRHOusF2WA.png"/></div></figure><p id="2c70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们需要<strong class="kk iu">对这300个测试观测值进行预测</strong>，并且<strong class="kk iu">通过获得MSE ( <strong class="kk iu">均方误差</strong>)将</strong>与真实值进行比较:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/345b68f737e10125aba5b5b057ad0dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*ReIy9xMNbE-OTzspJ0ug3A.png"/></div></figure><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="7d62" class="nl lt it nh b gy nm nn l no np"># First we traqin the model with the Test Set<br/>lm = LinearRegression()<br/>lm.fit(X_test, y_test)</span><span id="f808" class="nl lt it nh b gy nq nn l no np"># Then we generate predictions and compare to ‘y’ test<br/>predictions = lm.predict(X_test)<br/>mean_squared_error(y_test, predictions)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bf3baa39887638124d3e6659245998ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/format:webp/1*ld6lpz5SXpB2Gu-gZwf7iA.png"/></div></figure><p id="d002" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的<strong class="kk iu"> MSE </strong>是<strong class="kk iu"> 97.43 </strong>，这是所有误差之和的平方平均值。我们来看看预测值和真实值。</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="8700" class="nl lt it nh b gy nm nn l no np">df_preds_res = pd.DataFrame({‘y_test’:y_test[‘epidermiology_level’], ‘y_pred’:pred[:,0]})<br/>df_preds_res.head(15)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/87df0ade20f1f7b89c240c816d547a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*SC9UI3-gW1cddW7vtaNBaQ.png"/></div></figure><p id="9b48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看是否可以通过增加其余的变量来改进它。</p><h1 id="d629" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">第三步。改进ML模型</h1><p id="1476" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">好了，我们有了下面的数据，但是我们可以<strong class="kk iu">只将数值特征</strong>输入到我们的LinearRegression中，所以我们要将'<em class="oi"> animal </em>和'<em class="oi"> has_listeriosis </em>特征转换成数值。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d1f74c282a693bc9417cd0187e4cec06.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*hsMx0eBVTSPlzUZScVeMmw.png"/></div></figure><p id="6b07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的做法是将该列的每个类别转换成另一个“虚拟”列。幸运的是，OpenBlender API可以为我们做到这一点:</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="c231" class="nl lt it nh b gy nm nn l no np">#We add the 'categorical_treatment' parameter and pull again.</span><span id="9c3e" class="nl lt it nh b gy nq nn l no np">parameters = { <br/>    'token' : 'YOUR_TOKEN',<br/>    'id_user' : 'YOUR_USER_ID',  <br/>    'id_dataset':'5db079199516296099c9fb1e',<br/><strong class="nh iu">    'categorical_treatment': </strong>{"treatment" : "convert_to_numeric", "exclude" : ["weight_in_kg"]}<br/>}</span><span id="06f1" class="nl lt it nh b gy nq nn l no np">df_vet_numerical = pullObservationsToDF(parameters)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ot"><img src="../Images/da2e283eeef3e018fc4582ba2b593d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVTT5RPFGy_-e9uecbA91A.png"/></div></div></figure><p id="6c6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了给<strong class="kk iu">添加更多有用的特性</strong>，让<strong class="kk iu">的日期分解</strong>拥有许多其他与时间相关的特性，如星期几、月份等。</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="53cd" class="nl lt it nh b gy nm nn l no np">parameters = {<br/>    'token' : 'YOUR_TOKEN',<br/>    'id_user' : 'YOUR_USER_ID', <br/>    'id_dataset':'5db079199516296099c9fb1e',<br/><strong class="nh iu">    </strong>'categorical_treatment'<strong class="nh iu">: </strong>{"treatment" : "convert_to_numeric",    <br/>    'exclude' : ["weight_in_kg"]},<br/> <strong class="nh iu">'date_treatment'</strong>:{"treatment":"breakdown"}<br/>}</span><span id="40fd" class="nl lt it nh b gy nq nn l no np">df_vet_numerical = pullObservationsToDF(parameters)<br/>df_vet_numerical.columns</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e3b4dca6f811004b6eb9c9031b03f10f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*2Rf-wY9e_50C0NRRnDYpSQ.png"/></div></figure><p id="a624" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，我们开始吧。</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="b593" class="nl lt it nh b gy nm nn l no np">target_variable = ‘epidermiology_level’</span><span id="3183" class="nl lt it nh b gy nq nn l no np"><strong class="nh iu"># First we define ‘X’ and ‘y’</strong><br/>X = df_vet_numerical.loc[:, df_vet_numerical.columns != target_variable].values<br/>y = df_vet_numerical.loc[:,[target_variable]].values</span><span id="e371" class="nl lt it nh b gy nq nn l no np"><strong class="nh iu"># Then we separate 500 to train</strong><br/>X_train = X[:500]<br/>y_train = y[:500]<br/>print(“Train X and y:”)<br/>print(X_train.shape)<br/>print(y_train.shape)</span><span id="31db" class="nl lt it nh b gy nq nn l no np"><strong class="nh iu"># And 300 to test</strong><br/>X_test = X[500:]<br/>y_test = y[500:]<br/>print(“Test X and y:”)<br/>print(X_test.shape)<br/>print(y_test.shape)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/80b937cc656f2538b61388a94109431f.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*eVgWhOLI7-vpwBJ31lhARw.png"/></div></figure><p id="a6c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们有了<strong class="kk iu"> 30个预测特征</strong>来馈入我们的线性模型。回归将增加其预测值特征，如下所示:</p><blockquote class="nt"><p id="00cf" class="nu nv it bd nw nx ny nz oa ob oc ld dk translated">y =a+b1x1 + b2x2 + … + bnxn</p></blockquote><p id="bec0" class="pw-post-body-paragraph ki kj it kk b kl od ju kn ko oe jx kq kr of kt ku kv og kx ky kz oh lb lc ld im bi translated">看看有没有进步。</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="2dcf" class="nl lt it nh b gy nm nn l no np"># First we traqin the model with the Test Set<br/>lm = LinearRegression()<br/>lm.fit(X_test, y_test)</span><span id="622e" class="nl lt it nh b gy nq nn l no np"># Then we generate predictions and compare to ‘y’ test<br/>pred = lm.predict(X_test)<br/>mean_squared_error(y_test, pred)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/0d7c6428f874015024bb8a4ad9951130.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*G7WR_q3bj6gqPGQ9GR1RHQ.png"/></div></figure><p id="52d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 59.93 </strong>当然是对<strong class="kk iu"> 97.42的<strong class="kk iu">改进</strong>。</strong>我们来看看预测的和真实的。</p><pre class="mr ms mt mu gt ng nh ni nj aw nk bi"><span id="a278" class="nl lt it nh b gy nm nn l no np">df_preds_res = pd.DataFrame({'y_test':y_test[:,0], 'y_pred':pred[:,0]})<br/>df_preds_res.head(15)</span></pre><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/27dfb774dbbbfdce41928f3a36d179d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:286/format:webp/1*gSXIAkk5HErcwqJD0JjThQ.png"/></div></figure></div></div>    
</body>
</html>