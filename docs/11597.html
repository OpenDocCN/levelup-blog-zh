<html>
<head>
<title>How do supercomputers work?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超级计算机是如何工作的？</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-do-supercomputers-work-39ab80eb90a3?source=collection_archive---------12-----------------------#2022-03-29">https://levelup.gitconnected.com/how-do-supercomputers-work-39ab80eb90a3?source=collection_archive---------12-----------------------#2022-03-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8c99" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">高性能计算简介</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/570cf8f606c760a38d6db4af5fdf10bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KZs7tbNcmyRH8JSK"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@chuttersnap?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> CHUTTERSNAP </a>拍摄</figcaption></figure><h2 id="a3f8" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="a26c" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">超级计算——现在称为高性能计算(HPC)——主要用于科学和工程目的，如物理模拟、密码分析、量子力学、天气预报、分子建模、空气动力学、核聚变研究等。虽然个人电脑的运算速度为数百千兆次(每秒浮点运算)到数十万亿次，但最近的超级计算机的速度达到了数百万亿次。为了帮助理解速度上的差异，一千万亿次浮点运算由一千万亿次浮点运算组成。这种巨大的加速使我们能够在几分钟和几小时内完成繁重的数据密集型计算，而不是几周或几个月。这听起来令人印象深刻，但是这些计算机怎么这么快呢？要回答这个问题，我们首先需要理解串行和并行执行之间的区别。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h2 id="cf62" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">串行与并行执行</h2><p id="7f86" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">传统上，具有一个核心的个人计算机以连续/串行的顺序工作，即使看起来事情是同时运行的。这种“假”并行化的效果之所以会发生，是因为操作系统的调度程序使CPU能够在程序/进程之间快速切换其处理能力。这种变化发生得如此之快，以至于人类大脑都没有注意到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3b91f1481672c8e3b0fde994e99f5397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*Bl7Vp38OWQIurefOsnO6Gw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">操作系统调度程序时间片(图片由作者提供)</figcaption></figure><p id="7608" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">然而，真正的并行化可以通过拥有多个CPUs内核来实现，这些CPUs内核可以独立运行，也可以承担相同的工作负载。我们不会深入线程和进程的细节，但正如下图所示，拥有多个CPUs内核允许计算机并行执行代码，从而提高速度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/ea35839e47c5b02db7001278e267fca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cG4UugedSxN41Ly_.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">并行与串行计算(<a class="ae kv" href="https://pythonnumericalmethods.berkeley.edu/notebooks/chapter13.01-Parallel-Computing-Basics.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h2 id="c5a9" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">高性能计算(HPC)集群</h2><p id="269b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">高性能计算集群由几十到几千个联网的计算机器/节点组成，其中每个节点包含大约8到128个CPUs核心。例如，在10个具有16个内核的节点上执行代码，我们可以并行运行160个进程，从而提高处理速度，实现高性能计算。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/210ff00ba79f434aa4abf3849bbe47e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*SuaVvSLmiotur0X0UHhmnA.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">高性能计算集群架构(<a class="ae kv" href="https://www.gdc-docs.ethz.ch/GeneticDiversityAnalysis/GDA20/site/biocomputing_Euler/" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="00aa" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">HPC集群通常还包括一个登录节点，用户可以从该节点使用自己的计算机通过<a class="ae kv" href="https://www.ssh.com/academy/ssh/protocol" rel="noopener ugc nofollow" target="_blank"> ssh </a>连接到集群。然后，使用特定的<a class="ae kv" href="https://slurm.schedmd.com/" rel="noopener ugc nofollow" target="_blank"> slurm </a>(用于资源管理的简单Linux实用程序)脚本命令，批处理作业可以提交给集群的调度程序来执行。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h2 id="fa3b" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">HPC标准和框架</h2><p id="d674" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本节中，我们将简要介绍最流行的HPC库和框架，从大多数并行处理框架使用的<a class="ae kv" href="https://www.openmp.org/" rel="noopener ugc nofollow" target="_blank"> OpenMP </a>开始。OpenMP代表开放多处理，它是一个用于C、C++和Fortran的跨平台共享内存多处理API。实际上，单独使用OpenMP可能是不够的，因为它只能在单个节点内并行化代码，而单个节点的处理能力可能不足以进行高要求的计算。另一方面，MPI(消息传递接口)允许跨多个节点并行化代码。最流行的MPI库是<a class="ae kv" href="https://www.open-mpi.org/" rel="noopener ugc nofollow" target="_blank"> OpenMPI </a>，它和OpenMP都是开源的，得到了业界和学术界的认可和标准化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/1dfeec3396ffae18b9fd17ac15ee9cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I-YxR3ZYN7lytMFycureCw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">HPC集群室(<a class="ae kv" href="https://www.ge.com/research/sites/default/files/inline-images/HPC_1.jpg" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="a503" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">即使使用多个节点，各种问题也需要更多的处理能力。具体而言，与矩阵变换相关的计算，如计算机图形渲染或神经网络训练，更适合在GPU(图形处理单元)上执行。幸运的是，有一些框架可以实现这种执行，如针对Nvidia GPUs的<a class="ae kv" href="https://developer.nvidia.com/cuda-toolkit" rel="noopener ugc nofollow" target="_blank"> CUDA </a>(计算统一设备架构)和为AMD和Nvidia显卡提供支持的<a class="ae kv" href="https://www.khronos.org/opencl/" rel="noopener ugc nofollow" target="_blank"> OpenCL </a>(开放计算语言)。通常，Cuda和MPI相结合，支持在多个节点的多个GPU上执行代码，从而最大化性能输出。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><h2 id="5c69" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">OpenMP演示</h2><p id="619b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本节中，我们将了解如何使用OpenMP对代码进行并行化，以及它的速度优势。下图中显示的代码没有语义含义，因为它仅用于演示目的。简而言之，它创建两个大小为50000的随机数组，并执行一些基本计算(乘法、除法和加法)，迭代500万次(2 x L x L)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/6fbdc339f25988362b1fb453c4d74c81.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*lS5gzlPjaKGvXB4W6YdMfA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">演示代码(图片由作者提供)</figcaption></figure><p id="cee7" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">OpenMP关键字“#pragma omp parallel for”用于跨多个线程并行化外部for循环。例如，我们可以用4个线程运行程序，而不是在单个线程上迭代100k次(2 x L ),这样它可以在每个线程上并行迭代25k (100k / 4)次。需要注意的是,“stop_watch”函数是用来计算执行并行区域(for循环内的代码)而不是整个程序所需的时间的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/ed8ded848c77bc561969c33976f7f25e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5Sp8IeXkqqpiVVnEREjJQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">演示程序以串行执行方式运行— 1个线程(图片由作者提供)</figcaption></figure><p id="1e13" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">如上图和下图所示，用1个线程执行程序需要大约41秒，而用8个线程执行需要大约6秒。这几乎快了7倍。它总是比我们预期的要慢(快8倍)，因为打开和关闭并行区域会消耗资源。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/cb77b35178a444273298cd390f484466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yib6V8yOnrSSAtAZuZPwAg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">演示程序并行运行— 8个线程(图片由作者提供)</figcaption></figure><p id="9f2e" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated">代码是在<a class="ae kv" href="https://hpcf.cyi.ac.cy/resources.html" rel="noopener ugc nofollow" target="_blank"> Cyclamen </a>上执行的，为此我被授权在塞浦路斯学院完成<a class="ae kv" href="https://www.cyi.ac.cy/index.php/education/masters-programs/simulation-and-data-sciences/sds-402-introduction-to-high-performance-computing.html" rel="noopener ugc nofollow" target="_blank">高性能计算入门</a>课程。</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><p id="7ecc" class="pw-post-body-paragraph ls lt iq lu b lv mt jr lx ly mu ju ma lf mv mc md lj mw mf mg ln mx mi mj mk ij bi translated"><em class="ne">感谢您的阅读，我希望这篇文章能激发您的好奇心，了解更多关于超级计算机这个神奇世界的知识。</em></p><h2 id="e87c" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">参考</h2><ol class=""><li id="04d0" class="nf ng iq lu b lv lw ly lz lf nh lj ni ln nj mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.suse.com/suse-defines/definition/supercomputer/" rel="noopener ugc nofollow" target="_blank">https://www.suse.com/suse-defines/definition/supercomputer/</a></li><li id="dd4b" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://pythonnumericalmethods.berkeley.edu/notebooks/chapter13.01-Parallel-Computing-Basics.html" rel="noopener ugc nofollow" target="_blank">https://python numerical methods . Berkeley . edu/notebooks/chapter 13.01-Parallel-Computing-basics . html</a></li><li id="941d" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.netapp.com/data-storage/high-performance-computing/what-is-hpc/" rel="noopener ugc nofollow" target="_blank">https://www . netapp . com/data-storage/高性能计算/what-is-hpc/ </a></li><li id="91b7" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.ssh.com/academy/ssh/protocol" rel="noopener ugc nofollow" target="_blank">https://www.ssh.com/academy/ssh/protocol</a></li><li id="79bd" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://slurm.schedmd.com/" rel="noopener ugc nofollow" target="_blank">https://slurm.schedmd.com/</a></li><li id="7d03" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.openmp.org/" rel="noopener ugc nofollow" target="_blank">https://www.openmp.org/</a></li><li id="b672" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.open-mpi.org/" rel="noopener ugc nofollow" target="_blank">https://www.open-mpi.org/</a></li><li id="eeb8" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://developer.nvidia.com/cuda-toolkit" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/cuda-toolkit</a></li><li id="8d51" class="nf ng iq lu b lv no ly np lf nq lj nr ln ns mk nk nl nm nn bi translated"><a class="ae kv" href="https://www.khronos.org/opencl/" rel="noopener ugc nofollow" target="_blank">https://www.khronos.org/opencl/</a></li></ol></div></div>    
</body>
</html>