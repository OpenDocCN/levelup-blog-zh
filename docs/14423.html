<html>
<head>
<title>Kaggle knowledge points: BERTâ€™s five pooling methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KaggleçŸ¥è¯†ç‚¹:ä¼¯ç‰¹çš„äº”ç§æ±‡é›†æ³•</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://levelup.gitconnected.com/kaggle-knowledge-points-berts-five-pooling-methods-b55d61dd9968?source=collection_archive---------6-----------------------#2022-11-27">https://levelup.gitconnected.com/kaggle-knowledge-points-berts-five-pooling-methods-b55d61dd9968?source=collection_archive---------6-----------------------#2022-11-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/45d92b12a51a100c689ba4433eebd147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-g3I0OWFtlwxNFPR.png"/></div></div></figure><p id="d447" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">BERTæ¨¡å‹å¯ä»¥ç”¨äºå¤šä¸ªä»»åŠ¡ï¼Œä¹Ÿæ˜¯å½“å‰NLPæ¨¡å‹çš„å¿…è¦æ–¹æ³•ã€‚åœ¨æ–‡æœ¬åˆ†ç±»ä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨<code class="fe kz la lb lc b">[CLS]</code>çš„ç›¸åº”è¾“å‡ºæ¥å®Œæˆæ–‡æœ¬åˆ†ç±»ï¼Œå½“ç„¶è¿˜æœ‰å…¶ä»–æ–¹æ³•ã€‚</p><p id="95db" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">è¿™å…è®¸æ¯ä¸ª<code class="fe kz la lb lc b">token</code>å¯¹åº”çš„è¾“å‡ºè¢«ä½¿ç”¨<code class="fe kz la lb lc b">pooling</code>ï¼Œç„¶ååœ¨é€šè¿‡åè¢«åˆ†ç±»ã€‚æœ¬æ–‡å°†ä»‹ç»å‡ ç§æ„å»ºå’Œä½¿ç”¨BERTçš„å¸¸ç”¨æ–¹æ³•ã€‚</p><h1 id="1cda" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ–¹æ³•1:å¹³å‡æ±‡é›†</h1><p id="3bb3" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated"><code class="fe kz la lb lc b">token</code>è®¡ç®—æ¯ä¸ªå¯¹åº”è¾“å‡ºçš„å¹³å‡å€¼ï¼Œè¿™é‡Œéœ€è¦è€ƒè™‘<code class="fe kz la lb lc b">attention_mask</code>ï¼Œå³éœ€è¦è€ƒè™‘æœ‰æ•ˆè¾“å…¥<code class="fe kz la lb lc b">token</code>ã€‚</p><pre class="mg mh mi mj gt mk lc ml bn mm mn bi"><span id="2587" class="mo le it lc b be mp mq l mr ms">class MeanPooling(nn.Module):<br/>    def __init__(self):<br/>        super(MeanPooling, self).__init__()<br/>        <br/>    def forward(self, last_hidden_state, attention_mask):<br/>        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()<br/>        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)<br/>        sum_mask = input_mask_expanded.sum(1)<br/>        sum_mask = torch.clamp(sum_mask, min = 1e-9)<br/>        mean_embeddings = sum_embeddings/sum_mask<br/>        return mean_embeddings</span></pre><h1 id="2eff" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ–¹æ³•2:æœ€å¤§æ± åŒ–</h1><p id="8da3" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">è®¡ç®—æ¯ä¸ª<code class="fe kz la lb lc b">token</code>å¯¹åº”è¾“å‡ºçš„æœ€å¤§å€¼ï¼Œè¿™é‡Œéœ€è¦è€ƒè™‘<code class="fe kz la lb lc b">attention_mask</code>ï¼Œä¹Ÿå°±æ˜¯æœ‰æ•ˆè¾“å…¥éœ€è¦è€ƒè™‘<code class="fe kz la lb lc b">token</code>ã€‚</p><pre class="mg mh mi mj gt mk lc ml bn mm mn bi"><span id="4d33" class="mo le it lc b be mp mq l mr ms">class MaxPooling(nn.Module):<br/>    def __init__(self):<br/>        super(MaxPooling, self).__init__()<br/>        <br/>    def forward(self, last_hidden_state, attention_mask):<br/>        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()<br/>        embeddings = last_hidden_state.clone()<br/>        embeddings[input_mask_expanded == 0] = -1e4<br/>        max_embeddings, _ = torch.max(embeddings, dim = 1)<br/>        return max_embeddings</span></pre><h1 id="0da9" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ–¹æ³•3:æœ€å°å…¬æ‘Š</h1><p id="2828" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">è®¡ç®—æ¯ä¸ª<code class="fe kz la lb lc b">token</code>å¯¹åº”è¾“å‡ºçš„æœ€å°å€¼ï¼Œè¿™é‡Œéœ€è¦è€ƒè™‘<code class="fe kz la lb lc b">attention_mask</code>ï¼Œå³éœ€è¦è€ƒè™‘æœ‰æ•ˆè¾“å…¥<code class="fe kz la lb lc b">token</code>ã€‚</p><pre class="mg mh mi mj gt mk lc ml bn mm mn bi"><span id="e888" class="mo le it lc b be mp mq l mr ms">class MinPooling(nn.Module):<br/>    def __init__(self):<br/>        super(MinPooling, self).__init__()<br/>        <br/>    def forward(self, last_hidden_state, attention_mask):<br/>        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()<br/>        embeddings = last_hidden_state.clone()<br/>        embeddings[input_mask_expanded == 0] = 1e-4<br/>        min_embeddings, _ = torch.min(embeddings, dim = 1)<br/>        return min_embeddings</span></pre><h1 id="14c0" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ–¹æ³•4:åŠ æƒæ± </h1><p id="becd" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">è®¡ç®—æ¯ä¸ª<code class="fe kz la lb lc b">token</code>å¯¹åº”è¾“å‡ºçš„é‡é‡ã€‚è¿™é‡Œçš„æƒé‡å¯ä»¥é€šè¿‡ç‰¹å¾è®¡ç®—ï¼Œä¹Ÿå¯ä»¥é€šè¿‡IDFè®¡ç®—ã€‚</p><pre class="mg mh mi mj gt mk lc ml bn mm mn bi"><span id="06e7" class="mo le it lc b be mp mq l mr ms">class WeightedLayerPooling(nn.Module):<br/>    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):<br/>        super(WeightedLayerPooling, self).__init__()<br/>        self.layer_start = layer_start<br/>        self.num_hidden_layers = num_hidden_layers<br/>        self.layer_weights = layer_weights if layer_weights is not None \<br/>            else nn.Parameter(<br/>                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)<br/>            )</span></pre><pre class="mt mk lc mu mv aw mw bi"><span id="9e0b" class="mx le it lc b gy my mz l na ms">    def forward(self, ft_all_layers):<br/>        all_layer_embedding = torch.stack(ft_all_layers)<br/>        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]</span><span id="0682" class="mx le it lc b gy nb mz l na ms">        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())<br/>        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()</span><span id="0700" class="mx le it lc b gy nb mz l na ms">        return weighted_average</span></pre><h1 id="a274" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ–¹æ³•5:é›†ä¸­æ³¨æ„åŠ›</h1><p id="ac0d" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">å°†æ¯ä¸ª<code class="fe kz la lb lc b">token</code>ç‰¹å¾å•ç‹¬æ·»åŠ åˆ°ä¸€ä¸ªå›¾å±‚ä¸­è¿›è¡Œå…³æ³¨åº¦è®¡ç®—ï¼Œå¢åŠ æ¨¡å‹çš„å»ºæ¨¡èƒ½åŠ›ã€‚</p><pre class="mg mh mi mj gt mk lc ml bn mm mn bi"><span id="81b5" class="mo le it lc b be mp mq l mr ms">class AttentionPooling(nn.Module):<br/>    def __init__(self, in_dim):<br/>        super().__init__()<br/>        self.attention = nn.Sequential(<br/>        nn.Linear(in_dim, in_dim),<br/>        nn.LayerNorm(in_dim),<br/>        nn.GELU(),<br/>        nn.Linear(in_dim, 1),<br/>        )</span></pre><pre class="mt mk lc mu mv aw mw bi"><span id="ad74" class="mx le it lc b gy my mz l na ms">    def forward(self, last_hidden_state, attention_mask):<br/>        w = self.attention(last_hidden_state).float()<br/>        w[attention_mask==0]=float('-inf')<br/>        w = torch.softmax(w,1)<br/>        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)<br/>        return attention_embeddings</span></pre><h1 id="9c76" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">æ€»ç»“</h1><p id="df0b" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">ä»æ¨¡å‹å¤æ‚åº¦æ¥çœ‹:attention pooling &gt; weighted layer pooling &gt; mean pooling/min pooling/max pooling</p><p id="e784" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ä»æ¨¡å‹ç²¾åº¦æ¥çœ‹:æ³¨æ„æ± &gt;åŠ æƒå±‚æ± &gt;å¹³å‡æ± &gt;æœ€å¤§æ± &gt;æœ€å°æ± </p><p id="4fef" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ä½¿ç”¨å¤šç§æ± çš„ç›®çš„æ˜¯å¢åŠ BERTæ¨¡å‹çš„å¤šæ ·æ€§ï¼Œå¹¶è€ƒè™‘åœ¨æ¨¡å‹é›†æˆä¸­ä½¿ç”¨å®ƒã€‚</p><p id="dc29" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿæˆä¸ºä¸€ä¸ªåª’ä»‹æˆå‘˜ï¼Œé€šè¿‡æ— é™åˆ¶çš„é˜…è¯»ç»§ç»­å­¦ä¹ ã€‚å¦‚æœä½ ä½¿ç”¨<a class="ae nc" href="https://machinelearningabc.medium.com/membership" rel="noopener">è¿™ä¸ªé“¾æ¥</a>æˆä¸ºä¼šå‘˜ï¼Œä½ å°†æ”¯æŒæˆ‘ï¼Œä¸éœ€è¦ä½ é¢å¤–ä»˜è´¹ã€‚æå‰æ„Ÿè°¢ï¼Œå†è§ï¼</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="e3bb" class="ld le it bd lf lg nk li lj lk nl lm ln lo nm lq lr ls nn lu lv lw no ly lz ma bi translated">åˆ†çº§ç¼–ç </h1><p id="df3f" class="pw-post-body-paragraph kb kc it kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:</p><ul class=""><li id="2c15" class="np nq it kd b ke kf ki kj km nr kq ns ku nt ky nu nv nw nx bi translated">ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰</li><li id="3268" class="np nq it kd b ke ny ki nz km oa kq ob ku oc ky nu nv nw nx bi translated">ğŸ“°æŸ¥çœ‹<a class="ae nc" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">å‡çº§ç¼–ç å‡ºç‰ˆç‰©</a>ä¸­çš„æ›´å¤šå†…å®¹</li><li id="d385" class="np nq it kd b ke ny ki nz km oa kq ob ku oc ky nu nv nw nx bi translated">ğŸ””å…³æ³¨æˆ‘ä»¬:<a class="ae nc" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae nc" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae nc" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">æ—¶äº‹é€šè®¯</a></li></ul><p id="dddf" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ğŸš€ğŸ‘‰<a class="ae nc" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu">åŠ å…¥å‡çº§è¾¾äººé›†ä½“ï¼Œæ‰¾åˆ°ä¸€ä»½æƒŠè‰³çš„å·¥ä½œ</strong> </a></p></div></div>    
</body>
</html>