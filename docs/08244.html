<html>
<head>
<title>Data Identification and Classification using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习的数据识别和分类</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/categorising-using-machine-learning-5601baf9a05e?source=collection_archive---------5-----------------------#2021-04-14">https://levelup.gitconnected.com/categorising-using-machine-learning-5601baf9a05e?source=collection_archive---------5-----------------------#2021-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ca1e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个关于如何给花分类的奇特的数据科学例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/390dfcb72d3b5505d100de5132c3228f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XO7oFpT6rutHcu9dvipQPw.jpeg"/></div></div></figure><p id="4d30" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我通过退休一直在哥伦比亚工程学习<a class="ae lq" href="https://online-exec.cvn.columbia.edu/applied-machine-learning" rel="noopener ugc nofollow" target="_blank">应用机器学习</a>。这是一个为期5个月的课程，我真的很喜欢，并会推荐。</p><p id="e9df" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">教练都很好，很有帮助，尤其是罗伯特·曼里克兹和普内特·萨拉斯瓦特。他们举办“办公时间”网络研讨会，帮助完成复杂的作业，同时也提供我们所学内容的实际演练。</p><p id="5246" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我之前的两篇文章《<a class="ae lq" rel="noopener ugc nofollow" target="_blank" href="/predicting-titanic-survivors-using-ml-8570ef4e89e8">使用ML </a>预测泰坦尼克号幸存者》和《<a class="ae lq" rel="noopener ugc nofollow" target="_blank" href="/predicting-house-sale-prices-using-ml-30b829fd9556">使用ML </a>预测房屋销售价格》中，我使用了一个伟大的数据科学和机器学习资源，名为<a class="ae lq" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。他们为数据科学家提供免费的数据集进行实践。还有比较机器学习的分析和建模的比赛。对于本教程，我将使用“<a class="ae lq" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>”提供的“<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>”。</p><p id="3365" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在一些“办公时间”网络研讨会中，Robert向我们介绍了几个数据集，这些数据集有不同的目标/需要解决的问题。在“<a class="ae lq" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank">泰坦尼克号——灾难中的机器学习</a>”数据集中，目标是预测谁在泰坦尼克号灾难中幸存。在"<a class="ae lq" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" rel="noopener ugc nofollow" target="_blank">房价-高级回归技术</a>"数据集中，目标是预测爱荷华州埃姆斯市的房屋销售价格。本教程将有一个分类目标/问题要解决。</p><p id="3128" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我将提供数据科学和机器学习的实用介绍，而不是深入幕后的数学(数学很复杂！).虽然这些名字听起来很花哨，但实际上它们分别是统计学家和统计学的现代名称。我们不要在这里自欺欺人，这主要是复杂的数学。</p><h2 id="33e5" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">步骤1:确定项目范围</h2><p id="453b" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">虹膜数据集对三种不同类型的花进行了各种测量:<strong class="kw iu"> Setosa </strong>、<strong class="kw iu"> Versicolor </strong>和<strong class="kw iu"> Virginica </strong>。这个项目的范围是试图确定允许我们对花卉进行分类的关键测量。</p><h2 id="673a" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">第二步:收集数据</h2><p id="faa5" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在这种特殊情况下，这是非常容易的。这些都在"<a class="ae lq" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>"库中提供给我们。我们将从那里加载“<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>”。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e437" class="lr ls it mq b gy mu mv l mw mx">from sklearn.datasets import load_iris</span><span id="2a12" class="lr ls it mq b gy my mv l mw mx">data = load_iris()<br/>df = pd.DataFrame(data=data.data, columns=data.feature_names)</span><span id="ef59" class="lr ls it mq b gy my mv l mw mx">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/f0e94468338fb0ca63504ab68559ced6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P2IERrCxoXCWD2FG_8VLzg.png"/></div></div></figure><h2 id="ce13" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">步骤3:清理数据</h2><p id="a363" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">第一步是加载我们的数据。我正在使用Python 3(带有<strong class="kw iu"> pandas </strong>、<strong class="kw iu"> numpy </strong>、<strong class="kw iu"> seaborn </strong>、<strong class="kw iu"> matplotlib </strong>和<strong class="kw iu"> sklearn </strong>库)和Jupyter notebooks "<strong class="kw iu">jupyterlab</strong>"如果你想继续的话。</p><p id="0b61" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">加载必要的库。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="711e" class="lr ls it mq b gy mu mv l mw mx">import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="4153" class="lr ls it mq b gy my mv l mw mx">from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split, GridSearchCV<br/>from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor</span><span id="405d" class="lr ls it mq b gy my mv l mw mx">from sklearn.datasets import load_iris<br/>from sklearn.cluster import KMeans</span></pre><p id="bc29" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Jupyter笔记本电脑的定制。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a1f6" class="lr ls it mq b gy mu mv l mw mx">sns.set_style('darkgrid')<br/>plt.rcParams.update({'font.size': 16})</span><span id="d78b" class="lr ls it mq b gy my mv l mw mx">%matplotlib inline</span></pre><p id="a055" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">数据集不会自动包含目标列。可以按如下方式添加。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="b3fb" class="lr ls it mq b gy mu mv l mw mx">data.target</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/e539be3d33814e4212d9567db134586f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zDLqsGlshAkUF8YkK2oJg.png"/></div></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="76aa" class="lr ls it mq b gy mu mv l mw mx">data.target_names</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/988367bea9d80bfeb958bda52afdc92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdObBAcFp_qhdMuLNxgAJQ.png"/></div></div></figure><p id="7869" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到Setosa是0，Versicolor是1，Virginica是2。我们应该使用“<strong class="kw iu">特征工程</strong>创建一个新特征，将“<strong class="kw iu"> id </strong>”映射到“<strong class="kw iu">友好名称</strong>”。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="6b75" class="lr ls it mq b gy mu mv l mw mx">def flower_map(x):<br/>    if x == 0:<br/>        return "Setosa"<br/>    elif x == 1:<br/>        return "Versicolor"<br/>    elif x == 2:<br/>        return "Virginica"</span><span id="3b46" class="lr ls it mq b gy my mv l mw mx">df['species'] = data.target<br/>df['species'] = df['species'].map(flower_map)</span></pre><p id="1275" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个看起来像这样。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a521" class="lr ls it mq b gy mu mv l mw mx">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/550b5c6a2bce476005fba4b20557260c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bO5sRodG7pLOYr327O3R1Q.png"/></div></div></figure><h2 id="8a7b" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">步骤4:探索性数据分析(EDA)</h2><p id="5670" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">除了我在课程中学到的东西，我还发现了这篇非常棒的文章，它向我展示了我以前从未见过的EDA技术。我推荐关注@pranshu453，因为他写得很好。他看起来像一个新的媒体作家，所以跟随他并给他一些支持会很好。</p><div class="nd ne gp gr nf ng"><a href="https://medium.com/analytics-vidhya/exploratory-data-analysis-iris-dataset-4df6f045cda" rel="noopener follow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd iu gy z fp nl fr fs nm fu fw is bi translated">探索性数据分析:Iris数据集</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">使用Pandas、Matplotlib和Seaborn库对鸢尾花数据集进行数据分析和可视化</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">medium.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu ks ng"/></div></div></a></div><p id="69e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些是探索数据的典型的第一步。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="ab9c" class="lr ls it mq b gy mu mv l mw mx">df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/a3c08caf313743f4e02e48dfd8251785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uSLhN-JUoyJWQIuWtspmmA.png"/></div></div></figure><p id="543d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一些重要的观察结果是，数据集中没有空值(好消息)，有四个包含测量值的列和两个分类列(包括我们刚刚创建的“<strong class="kw iu">物种</strong>”特征)。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="717e" class="lr ls it mq b gy mu mv l mw mx">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/5bc0a3e72d8f63ccc8c9bcc35b68836f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSfjtiVKOEGaYLamRknMyw.png"/></div></div></figure><p id="8b9b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这只是让我们对我们的数据有一个感觉。它显示了我们有多少非空行，平均值、标准偏差、最小值、最大值等等。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="c2cc" class="lr ls it mq b gy mu mv l mw mx">df[df.duplicated()]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/afd48357aca157c65223b7cc2bc0e5aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICTPkWTOvPWpMOJtCWwAww.png"/></div></div></figure><p id="bb68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有一个重复的行。现在我们要决定如何处理这个单一条目。有可能测量值是合法的复制品，并且两朵花具有相同的测量值。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="bc8b" class="lr ls it mq b gy mu mv l mw mx">df['species'].value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4521f4baa0511131d26d6fae3d988f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*x_NFtg7HX4-NSOssaGCpCw.png"/></div></figure><p id="f61c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们删除重复的Virginica，将导致我们的数据不平衡。目前每种类型有50朵花。我怀疑一个复制品可能只是一朵同样尺寸的花。在这种情况下，我们不应该删除它。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="6e32" class="lr ls it mq b gy mu mv l mw mx">sns.set(font_scale=1.5)<br/>plt.figure(figsize=(12,10))<br/>sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', hue='species', s=70)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/2ed95fac3eb156118410ab0e7924409c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5xwjn2S_sQq-ED3eqZ0xQ.png"/></div></div></figure><p id="8e7e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从视觉上看，使用散点图，似乎没有任何明显的方法来使用萼片长度和宽度测量来分类花。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="0fe3" class="lr ls it mq b gy mu mv l mw mx">sns.set(font_scale=1.5)<br/>plt.figure(figsize=(12,10))<br/>sns.scatterplot(x=df['petal length (cm)'], y=df['petal width (cm)'], hue=df['species'], s=70)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/d7682fa528a4d15119ac1f6f7bf019dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FFnri7ISn0GHGzhztZ9Ibg.png"/></div></div></figure><p id="c7f5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在这描绘了一幅完全不同的画面。例如，你可以看到，如果花瓣长度小于2厘米或花瓣宽度小于0.75，你肯定是在看一朵Setosa花。您可以将类似的规则应用于Versicolor和Virginia，但是您可以看到有一点重叠，这可能很难手动处理。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="6dce" class="lr ls it mq b gy mu mv l mw mx">sns.pairplot(df, hue='species', height=4)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/93b4e94088db5c7fe0feb414a473eb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qb-tiibNb4t0BAWCDaL_g.png"/></div></div></figure><p id="7acc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个配对图证实了我们已经知道的东西。这只是一个很好的方式来看看是否有任何其他功能可能对我们有用。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="3f05" class="lr ls it mq b gy mu mv l mw mx">plt.figure(figsize=(10,11))<br/>sns.heatmap(df.corr(), annot=True)<br/>plt.plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/b34b1beea4577494c51e84c878078953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UD5wvODBuuxBm-NGxZFgqw.png"/></div></div></figure><p id="a27a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这张热图也证实了我们已经知道的东西。我们对高于0.5或低于-0.5的强相关性感兴趣。我们可以看到我们的花瓣长度和宽度是高度相关的。萼片长度和花瓣长度和宽度之间似乎也有很强的相关性。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e599" class="lr ls it mq b gy mu mv l mw mx">df.groupby('species').agg(['mean', 'median'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/886f1d05ab1d09f37fa7d395dd69ab5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNaxWGhEs45Fix0yV6f2Uw.png"/></div></div></figure><p id="9f33" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是找到每朵花的平均值和中间值的简便方法。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="3e2d" class="lr ls it mq b gy mu mv l mw mx">fig, axes = plt.subplots(2, 2, figsize=(16,9))</span><span id="2e6d" class="lr ls it mq b gy my mv l mw mx">sns.boxplot(y='petal width (cm)', x='species', data=df, orient='v', ax=axes[0, 0])<br/>sns.boxplot(y='petal length (cm)', x='species', data=df, orient='v', ax=axes[0, 1])<br/>sns.boxplot(y='sepal length (cm)', x='species', data=df, orient='v', ax=axes[1, 0])<br/>sns.boxplot(y='sepal width (cm)', x='species', data=df, orient='v', ax=axes[1, 1])</span><span id="f4ec" class="lr ls it mq b gy my mv l mw mx">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/672c1ed93f8e5ba8d337f6774970326b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbNQLViKARUaLO9CefacBg.png"/></div></div></figure><p id="82dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个盒状图告诉我们，Setosa分布不广，特征集较小，Versicolor分布平均，特征集一般，Virginica分布高度，特征集较大。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="876c" class="lr ls it mq b gy mu mv l mw mx">fig, axes = plt.subplots(2, 2, figsize=(16,9))</span><span id="3daf" class="lr ls it mq b gy my mv l mw mx">sns.violinplot(y='petal width (cm)', x='species', data=df, orient='v', ax=axes[0, 0], inner='quartile')<br/>sns.violinplot(y='petal length (cm)', x='species', data=df, orient='v', ax=axes[0, 1], inner='quartile')<br/>sns.violinplot(y='sepal length (cm)', x='species', data=df, orient='v', ax=axes[1, 0], inner='quartile')<br/>sns.violinplot(y='sepal width (cm)', x='species', data=df, orient='v', ax=axes[1, 1], inner='quartile')</span><span id="cc00" class="lr ls it mq b gy my mv l mw mx">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/e708377f6fb73658226ec2f9d0ff9132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2NfIJTw8W8BAnyZA-C8ig.png"/></div></div></figure><p id="d70b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是可视化我们数据的另一个有用的方法。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e580" class="lr ls it mq b gy mu mv l mw mx">sns.FacetGrid(df, hue='species', height=5).map(sns.distplot, 'sepal length (cm)').add_legend()<br/>sns.FacetGrid(df, hue='species', height=5).map(sns.distplot, 'sepal width (cm)').add_legend()<br/>sns.FacetGrid(df, hue='species', height=5).map(sns.distplot, 'petal length (cm)').add_legend()<br/>sns.FacetGrid(df, hue='species', height=5).map(sns.distplot, 'petal width (cm)').add_legend()</span><span id="6f12" class="lr ls it mq b gy my mv l mw mx">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/7d85cdd68d939c51e0449d18caa7a985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jz-B_E0rhKjWGBiJTtytQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/35706924aa65263a2dcf3cdd7ed58334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtUHbHKP-QOHKbLW_TxW6A.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/e062467ed1f7f07d09684ce3d26ef077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HW7MoeTdiBdHwVyi2j3gQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/5e2d8f09da6be2fa5710bf6c55c223d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*597RUO18iMxkUhocPZ8Mew.png"/></div></div></figure><p id="3138" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们所看到的，Setosa在花瓣的宽度和长度方面是独立的。云芝和海滨锦鸡儿大部分是分开的，但有轻微的重叠。</p><h2 id="5b74" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">步骤5:建立数据模型</h2><p id="9e65" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated"><strong class="kw iu">基尼系数和熵值<br/> </strong>基尼系数和熵值是计算信息增益的标准。基尼系数和熵都是节点杂质的量度。换句话说，他们测量数据集的任何元素在被随机标记时被错误标记的频率。具有多个类的节点是不纯的，而只有一个类的节点是纯的。</p><p id="8fcb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">基尼指数的值介于0和0.5之间，熵值介于0和1之间。在计算上，熵更复杂，因为它使用对数，因此基尼系数的计算会更快。</p><p id="94fd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如上所述，基尼指数的最小值是0。当节点是纯的，并且节点中包含的所有元素都是一个唯一的类时，就会发生这种情况。因此，该节点不会被再次分割。最佳分割由具有较小基尼系数的特征选择。当两个类的概率相同时，它得到最大值。如果一组数据的分割相等，基尼系数将为0.25。</p><p id="4452" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">熵是信息的一种度量，它表示特征与目标之间的无序程度。类似于基尼指数，最佳分割由具有较少熵的特征选择。当两个类的概率相同时，它获得最大值，当熵具有最小值0时，节点是纯的。</p><p id="b5f8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们看一个例子…</p><p id="3c6d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，让我们把数据集分离出来，只包含两朵花。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="de26" class="lr ls it mq b gy mu mv l mw mx">df_two = df.loc[df.species != "Virginica", :].copy()</span><span id="7115" class="lr ls it mq b gy my mv l mw mx">df_two.species.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/527104e0ebf0a2e70d55cb6121a6fb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*PhWNik7gvdJl-ONeDNKTdQ.png"/></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="2c82" class="lr ls it mq b gy mu mv l mw mx">sns.set(font_scale=1.5)<br/>plt.figure(figsize=(9,7))<br/>sns.scatterplot(x=df_two['petal length (cm)'], y=df_two['petal width (cm)'], hue=df['species'], s=70)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/4afef4d6d2446101c2ee7892e5fe8817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4VRzaBxiUfDfEUfH8ljOQ.png"/></div></div></figure><p id="287e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在这里一个明显的分裂可能是说，如果花瓣宽度小于或等于0.75，那么它是Setosa，否则它是Versicolor。如果我们故意把它分成0.25。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="87ef" class="lr ls it mq b gy mu mv l mw mx">def gini_sum(p_list):<br/>    return np.sum([x * (1 - x) for x in p_list])</span><span id="cfca" class="lr ls it mq b gy my mv l mw mx">top_leaf = gini_sum([50/100, 50/100])<br/>print("Top Leaf Gini :", top_leaf, '\n')</span><span id="215a" class="lr ls it mq b gy my mv l mw mx">leaf_1 = df_two.loc[df_two['petal width (cm)'] &lt;= 0.25, 'species']<br/>leaf_2 = df_two.loc[df_two['petal width (cm)'] &gt; 0.25, 'species']</span><span id="0ea6" class="lr ls it mq b gy my mv l mw mx">print("Leaf 1 Contents:")<br/>print(leaf_1.value_counts(), '\n')<br/>print("Leaf 2 Contents:")<br/>print(leaf_2.value_counts(), '\n')</span><span id="1d0f" class="lr ls it mq b gy my mv l mw mx">leaf_1_gini = gini_sum([34/34])<br/>leaf_2_gini = gini_sum([50/66, 16/66])</span><span id="0712" class="lr ls it mq b gy my mv l mw mx">leaf_1_wt = 34/100<br/>leaf_2_wt = 66/100</span><span id="8467" class="lr ls it mq b gy my mv l mw mx">bot_leaf_total = (leaf_1_wt * leaf_1_gini) + (leaf_2_wt * leaf_2_gini)</span><span id="2077" class="lr ls it mq b gy my mv l mw mx">print("Bottom leaf total Gini :",  round(bot_leaf_total,4) )<br/>print("Information Gain =", round(top_leaf - bot_leaf_total,4) )</span><span id="00c2" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">Top Leaf Gini : 0.5 <br/><br/>Leaf 1 Contents:<br/>Setosa    34<br/>Name: species, dtype: int64 <br/><br/>Leaf 2 Contents:<br/>Versicolor    50<br/>Setosa        16<br/>Name: species, dtype: int64 <br/><br/>Bottom leaf total Gini : 0.2424<br/>Information Gain = 0.2576</strong></span></pre><p id="801f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到50朵Setosa花中有16朵被错误地分类了。如果我们使用正确的分割会怎样？</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="60a6" class="lr ls it mq b gy mu mv l mw mx">def gini_sum(p_list):<br/>    return np.sum([x * (1 - x) for x in p_list])</span><span id="b231" class="lr ls it mq b gy my mv l mw mx">top_leaf = gini_sum([50/100, 50/100])<br/>print("Top Leaf Gini :", top_leaf, '\n')</span><span id="0b6a" class="lr ls it mq b gy my mv l mw mx">leaf_1 = df_two.loc[df_two['petal width (cm)'] &lt;= 0.75, 'species']<br/>leaf_2 = df_two.loc[df_two['petal width (cm)'] &gt; 0.75, 'species']</span><span id="4645" class="lr ls it mq b gy my mv l mw mx">print("Leaf 1 Contents:")<br/>print(leaf_1.value_counts(), '\n')<br/>print("Leaf 2 Contents:")<br/>print(leaf_2.value_counts(), '\n')</span><span id="6555" class="lr ls it mq b gy my mv l mw mx">leaf_1_gini = gini_sum([34/34])<br/>leaf_2_gini = gini_sum([50/66, 16/66])</span><span id="c141" class="lr ls it mq b gy my mv l mw mx">leaf_1_wt = 34/100<br/>leaf_2_wt = 66/100</span><span id="574d" class="lr ls it mq b gy my mv l mw mx">bot_leaf_total = (leaf_1_wt * leaf_1_gini) + (leaf_2_wt * leaf_2_gini)</span><span id="7890" class="lr ls it mq b gy my mv l mw mx">print("Bottom leaf total Gini :",  round(bot_leaf_total,4) )<br/>print("Information Gain =", round(top_leaf - bot_leaf_total,4) )</span><span id="5b86" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">Top Leaf Gini : 0.5 <br/><br/>Leaf 1 Contents:<br/>Setosa    50<br/>Name: species, dtype: int64 <br/><br/>Leaf 2 Contents:<br/>Versicolor    50<br/>Name: species, dtype: int64 <br/><br/>Bottom leaf total Gini : 0.2424<br/>Information Gain = 0.2576</strong></span></pre><p id="f772" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到这两朵花被正确地分成两片叶子，50片是Setosa的，50片是Versicolor的，这是我们所期望的。我们是手动进行的，因为在这种情况下，我们自己进行分割在视觉上很容易。</p><p id="c120" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Sklearn库有办法为您完成这个手动过程。</p><h2 id="926b" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">决策树分类器</h2><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="80fd" class="lr ls it mq b gy mu mv l mw mx">features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']</span><span id="6293" class="lr ls it mq b gy my mv l mw mx">X = df_two.loc[:, features]<br/>y = df_two['species']</span><span id="a4f8" class="lr ls it mq b gy my mv l mw mx">dtc_model = DecisionTreeClassifier(random_state = 1)</span><span id="e6b7" class="lr ls it mq b gy my mv l mw mx">dtc_model.fit(X, y)</span><span id="45c3" class="lr ls it mq b gy my mv l mw mx">print("Training Accuracy : {}".format( dtc_model.score(X, y) ))<br/><strong class="mq iu">Training Accuracy : 1.0</strong></span><span id="7907" class="lr ls it mq b gy my mv l mw mx">pd.DataFrame({"feature" : features, "importance" : dtc_model.feature_importances_}).sort_values(by='importance')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1c027bd584695c8e2b45250310141d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*ZewAmR6RDdF59bF4Pmuqzw.png"/></div></figure><p id="84a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你所看到的，库已经确定了"<strong class="kw iu">花瓣宽度(cm) </strong>"是进行分割的最重要的特征。</p><p id="b7e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们先用两朵花试试这个…</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="532a" class="lr ls it mq b gy mu mv l mw mx">import graphviz<br/>from sklearn.tree import export_graphviz</span><span id="6d95" class="lr ls it mq b gy my mv l mw mx">def Plot_Tree(model, class_names, feature_names):<br/>    dot_data = export_graphviz(dtc_model, out_file=None,  <br/>                    filled=False, rounded=True,<br/>                    special_characters=True,<br/>                    class_names = class_names,<br/>                    feature_names= feature_names)<br/>    graph = graphviz.Source(dot_data)  <br/> <br/>    return graph</span><span id="824a" class="lr ls it mq b gy my mv l mw mx">Plot_Tree(dtc_model, class_names=['Setosa','Versicolour'], feature_names=features)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7f3248bf10725201f51f615ddcdacc38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2B8NNiff1ToNVoy9pHeJ7w.png"/></div></figure><p id="b5ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你在上面看到的，0.8被选为最佳分割点。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="0fdb" class="lr ls it mq b gy mu mv l mw mx">leaf_1 = df_two.loc[df_two['petal width (cm)'] &lt;= 0.8, 'species']<br/>leaf_2 = df_two.loc[df_two['petal width (cm)'] &gt; 0.8, 'species']<br/>print("Leaf 1 rows :", leaf_1.shape[0])<br/>print("Leaf 2 rows :", leaf_2.shape[0])</span><span id="d0de" class="lr ls it mq b gy my mv l mw mx">top_leaf = gini_sum([50/100, 50/100])<br/>print("Top Leaf Gini :", top_leaf)</span><span id="0eb0" class="lr ls it mq b gy my mv l mw mx">print(leaf_1.value_counts())<br/>print(' ')<br/>print(leaf_2.value_counts())</span><span id="c410" class="lr ls it mq b gy my mv l mw mx">bot_leaf = 50/100 * gini_sum([50/50]) + 50/100 * gini_sum([50/50, 50/50])</span><span id="07f6" class="lr ls it mq b gy my mv l mw mx">print("Next leaf total Gini :",  round(bot_leaf,2) )<br/>print("\nInformation Gain =", round(top_leaf - bot_leaf, 2) )</span><span id="40d3" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">Leaf 1 rows : 50<br/>Leaf 2 rows : 50<br/>Top Leaf Gini : 0.5<br/>Setosa    50<br/>Name: species, dtype: int64<br/> <br/>Versicolor    50<br/>Name: species, dtype: int64<br/>Next leaf total Gini : 0.0<br/><br/>Information Gain = 0.5</strong></span></pre><p id="44f3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们用三朵花来试试…</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="91ca" class="lr ls it mq b gy mu mv l mw mx">features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']</span><span id="2dfe" class="lr ls it mq b gy my mv l mw mx">X = df.loc[:, features]<br/>y = df['species']</span><span id="2cc0" class="lr ls it mq b gy my mv l mw mx">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)</span><span id="03a2" class="lr ls it mq b gy my mv l mw mx">dtc_model = DecisionTreeClassifier()</span><span id="9ba0" class="lr ls it mq b gy my mv l mw mx">dtc_model.fit(X_train, y_train)</span><span id="5ad3" class="lr ls it mq b gy my mv l mw mx">print("Training Accuracy : {}".format( dtc_model.score(X_train, y_train) ))<br/>print("Testing Accuracy : {}".format( dtc_model.score(X_test , y_test ) ))</span><span id="738e" class="lr ls it mq b gy my mv l mw mx">Plot_Tree(dtc_model, class_names=['Setosa', 'Versicolour', 'Virginica'], feature_names=features)</span><span id="2471" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">Training Accuracy : 1.0<br/>Testing Accuracy : 0.9555555555555556</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/2607176e518b4d4c5b84cd8d440fa95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0i6JZ7BXKaQYmhcCXi7PA.png"/></div></div></figure><p id="774e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">决策树分类器</strong>有很多配置选项。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/11988132ef2d99e9cfd8a0e7ff0fa93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fi81hzEr2LWGjwjVskN7og.png"/></div></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="676b" class="lr ls it mq b gy mu mv l mw mx">dtc_model = DecisionTreeClassifier()</span><span id="a64e" class="lr ls it mq b gy my mv l mw mx">params = {<br/>    "max_depth"         : [1,2,3,4,5,10],<br/>    "criterion"         : ['entropy', 'gini'],<br/>    "max_features"      : [0.5, 1],<br/>    "max_leaf_nodes"    : [2,3,5],<br/>    'min_samples_leaf'  : [2,3,5],<br/>    'min_samples_split' : [2,3,5]<br/>}</span><span id="43bd" class="lr ls it mq b gy my mv l mw mx">gs = GridSearchCV(dtc_model, params, cv=3)</span><span id="115e" class="lr ls it mq b gy my mv l mw mx">gs.fit(X_train, y_train)</span><span id="3727" class="lr ls it mq b gy my mv l mw mx">print("Training Accuracy : {}".format( gs.score(X_train, y_train) ))<br/>print("Testing Accuracy : {}".format( gs.score(X_test , y_test ) ))</span><span id="60d1" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">Training Accuracy : 0.9714285714285714<br/>Testing Accuracy : 0.9555555555555556</strong></span><span id="5c2a" class="lr ls it mq b gy my mv l mw mx">gs.best_params_</span><span id="bfaa" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">{'criterion': 'entropy',<br/> 'max_depth': 5,<br/> 'max_features': 0.5,<br/> 'max_leaf_nodes': 5,<br/> 'min_samples_leaf': 2,<br/> 'min_samples_split': 5}</strong></span></pre><p id="3808" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是它看起来的样子…</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="ff6e" class="lr ls it mq b gy mu mv l mw mx">Plot_Tree(gs.best_estimator_, class_names=['Setosa','Versicolour', 'Virginica'], feature_names=features)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/8962ead4f839392f7f9e05936c6b1558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OVcvmWjqKuy9glvoHvqWMQ.png"/></div></div></figure><h2 id="91f0" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">k均值</h2><p id="352a" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在我们的数据集中，我们知道我们的数据中有3个聚类(“<strong class="kw iu">花</strong>”)。我用下面的“<strong class="kw iu"> n_clusters </strong>”手动插入了这个。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e659" class="lr ls it mq b gy mu mv l mw mx">X = df.drop(columns='species')<br/>y = df['species']</span><span id="2f76" class="lr ls it mq b gy my mv l mw mx">kmeans = KMeans(n_clusters=3)<br/>kmeans.fit(X)</span><span id="0e26" class="lr ls it mq b gy my mv l mw mx">df['cluster_labels'] = kmeans.labels_<br/>df['cluster_labels'] = df['cluster_labels'].astype(str)</span><span id="ee29" class="lr ls it mq b gy my mv l mw mx">kmeans.cluster_centers_</span><span id="29bd" class="lr ls it mq b gy my mv l mw mx"><strong class="mq iu">array([[6.85      , 3.07368421, 5.74210526, 2.07105263],<br/>       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097],<br/>       [5.006     , 3.428     , 1.462     , 0.246     ]])</strong></span></pre><p id="920a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们不知道我们有多少个集群，有一种方法可以解决这个问题。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="47ef" class="lr ls it mq b gy mu mv l mw mx">interia_list = []<br/>for k in range(1, 15):<br/>    kmeans = KMeans(n_clusters=k)<br/>    kmeans.fit(X, y)<br/>    interia_list.append(kmeans.inertia_)</span><span id="37f0" class="lr ls it mq b gy my mv l mw mx">plt.plot(interia_list)<br/>plt.xticks(range(1, 15))<br/>plt.xlabel("n_clusters")<br/>plt.ylabel("Interia")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/d6d8a6784218b69458da92f7d012ee22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6y-jumrhai7I5-lrpNC6rg.png"/></div></div></figure><p id="4062" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们在这里寻找的是肘部的底部，在我们的例子中是3。</p><p id="9337" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">"<strong class="kw iu"> Intertia </strong>"是一个值，表示质心和它们各自的聚类成员的误差平方和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/4933ac4507782f61859b6f93a792b6d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5BxYi76JhdSAGxCBaqLb0A.png"/></div></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="debe" class="lr ls it mq b gy mu mv l mw mx">df.cluster_labels.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3450baea47d4c13be9cb6f986dff0840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*fXoBBRbuyRvcFXsdwfUCCg.png"/></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="41c8" class="lr ls it mq b gy mu mv l mw mx">df.groupby('cluster_labels').mean()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/8702d620de8a2b7e8f780337bafa3c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w9WfhPlV7BoZWQ_aCQiqtQ.png"/></div></div></figure><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="9041" class="lr ls it mq b gy mu mv l mw mx">plt.figure(figsize=(6,4))<br/>sns.scatterplot(data=df, x='petal length (cm)', y='petal width (cm)', hue='cluster_labels')<br/>plt.scatter(x = kmeans.cluster_centers_[:,2], y=kmeans.cluster_centers_[:,3], marker='X', s=80, color='black')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/97747e54fa87813cd9f650a890048914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cywx3RJ1llkXf0rNcyrkyA.png"/></div></div></figure><h2 id="0cf9" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">随机Forrest分类器与Ada Boost分类器</h2><p id="7aa7" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">通常我们会想要比较模型来评估哪一个给出最好的结果。我们可以这样做的方法如下。</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="cff2" class="lr ls it mq b gy mu mv l mw mx">from sklearn.metrics import classification_report<br/>from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier</span><span id="8308" class="lr ls it mq b gy my mv l mw mx">features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']</span><span id="0414" class="lr ls it mq b gy my mv l mw mx">X = df.loc[:, features]<br/>y = df['species']</span><span id="a3ef" class="lr ls it mq b gy my mv l mw mx">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)</span><span id="43b6" class="lr ls it mq b gy my mv l mw mx">RF = RandomForestClassifier(n_estimators=50)<br/>RF.fit(X_train, y_train)</span><span id="7a83" class="lr ls it mq b gy my mv l mw mx">print("Random Forest:\n")<br/>print(classification_report(y_test, RF.predict(X_test)))</span><span id="7b02" class="lr ls it mq b gy my mv l mw mx">ABC = AdaBoostClassifier(n_estimators=50)<br/>ABC.fit(X_train, y_train)<br/>print("\nAdaBoost:\n")<br/>print(classification_report(y_test, ABC.predict(X_test)))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/1f64b9f2b58e0c6be6450ee93c748011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JQnt9SKUIa4rOS5acp6uw.png"/></div></div></figure><p id="ff4b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我希望您对此感兴趣，并再次特别感谢Robert Manriquez的出色培训和课程支持。</p><p id="42d9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我希望你觉得这篇文章有趣并且有用。如果您想随时了解情况，请不要忘记关注我并注册我的<a class="ae lq" href="https://whittle.medium.com/subscribe" rel="noopener">电子邮件通知</a>。</p><h1 id="2d25" class="ow ls it bd lt ox oy oz lw pa pb pc lz jz pd ka mc kc pe kd mf kf pf kg mi pg bi translated">迈克尔·惠特尔</h1><ul class=""><li id="f832" class="ph pi it kw b kx mk la ml ld pj lh pk ll pl lp pm pn po pp bi translated"><strong class="kw iu"> <em class="pq">如果你喜欢这个，请</em> </strong> <a class="ae lq" href="https://whittle.medium.com/" rel="noopener"> <strong class="kw iu"> <em class="pq">跟我上媒</em> </strong> </a></li><li id="faa0" class="ph pi it kw b kx pr la ps ld pt lh pu ll pv lp pm pn po pp bi translated"><strong class="kw iu"> <em class="pq">更多有趣的文章，请</em> </strong> <a class="ae lq" href="https://medium.com/trading-data-analysis" rel="noopener"> <strong class="kw iu"> <em class="pq">关注我的刊物</em> </strong> </a></li><li id="b195" class="ph pi it kw b kx pr la ps ld pt lh pu ll pv lp pm pn po pp bi translated"><strong class="kw iu"> <em class="pq">有兴趣合作吗？</em> </strong> <a class="ae lq" href="https://www.linkedin.com/in/miwhittle/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="pq">我们上LinkedIn </em> </strong> </a>连线吧</li><li id="57cf" class="ph pi it kw b kx pr la ps ld pt lh pu ll pv lp pm pn po pp bi translated"><strong class="kw iu"> <em class="pq">支持我和其他媒体作者</em> </strong> <a class="ae lq" href="https://whittle.medium.com/membership" rel="noopener"> <strong class="kw iu"> <em class="pq">在此报名</em> </strong> </a></li><li id="872e" class="ph pi it kw b kx pr la ps ld pt lh pu ll pv lp pm pn po pp bi translated"><strong class="kw iu"> <em class="pq">请别忘了为文章鼓掌:)←谢谢！</em> </strong></li></ul></div></div>    
</body>
</html>