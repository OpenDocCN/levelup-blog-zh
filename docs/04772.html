<html>
<head>
<title>K-Nearest Neighbours (KNN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻(KNN)</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/knn-k-nearest-neighbours-d3ce76380e14?source=collection_archive---------3-----------------------#2020-07-14">https://levelup.gitconnected.com/knn-k-nearest-neighbours-d3ce76380e14?source=collection_archive---------3-----------------------#2020-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9aad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这一系列文章中，我们将详细了解K-最近邻(KNN)算法。</p><p id="b55b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，K-NN被归类为有监督的机器学习算法。对于想了解有监督和无监督机器学习算法的人来说，<a class="ae ko" href="https://en.wikipedia.org/wiki/Machine_learning#Supervised_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> <em class="kp">这里的</em> </strong> </a>同样是一个链接。简而言之，监督学习已经定义了类别标签。</p><p id="be7c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在深入KNN的细节之前，我们先来理解一下我们所说的分类问题v/s回归问题是什么意思。</p><p id="ae9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑泰坦尼克号数据集的例子。泰坦尼克号数据集被认为是“hello world！”机器学习领域的一个项目。这个问题的目标是根据某些特征对一个人是否在灾难中幸存进行分类。因此，给定一系列特征，如人的年龄、性别、他/她购买的头等舱机票等，我们应该预测这个人是否幸存。例如，如果一个人是女性或儿童，他们幸存的概率更高。因此，我们应该在两个类别标签之一之间进行分类，即存活与否。由于有两种可能的结果，它也被称为<strong class="js iu">二类分类</strong>问题或<strong class="js iu">二元分类</strong>问题。现在，假设你刚刚使用一个在线出租车聚合器乘坐了一辆出租车。游乐设施完成后，您可以选择对您的游乐设施体验进行评分。该评级系统有助于公司了解负责该游乐设备的司机的表现。现在，给你5个可能的选择，即非常差、差、一般、好、非常好。根据你的经验，从5个选项中选择一个。在这里，你正试图将你的乘坐体验分为5个可能的类别。由于可能的类别数大于2，称为<strong class="js iu">多类分类</strong>。</p><p id="7395" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们继续了解什么是回归问题？在上面的两个例子中，我的类别标签有一个有限的值集，如幸存与否或在5个可能的类别标签中对乘坐体验进行评级。但是在回归的情况下，我们没有这个有限的类别标签集。我举个例子来解释一下。给你一些特征，如一些学生的体重、年龄、性别，目标是预测学生的身高。在这种情况下，学生的身高不属于一个有限的班级标签集。它是一个实数值，可以取特定范围内的任何值。这种类别标签是实数的问题被称为<strong class="js iu">回归问题。</strong></p><p id="ffb3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">KNN既可用于分类问题，也可用于回归问题。我们将首先从分类的角度来理解KNN。</p><p id="621e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑下面的例子。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi kq"><img src="../Images/b162d7b48234f4ca17d443434ecc3ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*igIhJV6L620FAWNJltdV4Q.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated"><a class="ae ko" href="https://medium.com/@madanflies/k-nearest-neighbour-for-classification-on-breast-cancer-data-results-with-preprocessing-and-w-o-e21b0cc98a2f" rel="noopener">图像信用</a></figcaption></figure><p id="7f82" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有一组红绿点。我们观察到红色点属于类别标签A，绿色点属于类别标签b。给定这些点，我们现在得到另一个黄色点。任务/目标是将这个也被称为<strong class="js iu">查询点</strong>的黄色点分类到一个类别标签中。</p><h2 id="dec3" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">用通俗的语言给KNN下定义:</h2><p id="5c55" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">KNN代表K个最近邻居。其中K是指示要考虑的最近邻居的数量的整数值。k可以取1到n之间的任何整数值，其中n =数据集中的点数。因此，我们考虑查询点的K个最近邻居，并对这些最近邻居执行多数投票。具有最高投票的类别标签被分配给查询点。</p><p id="0b31" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">回到上面的例子。假设我的K=3，那么我们应该确定查询点的3个最近的邻居(我们如何确定这些邻居，我们将在本文的后面部分看到)。当我们考虑3个最近的邻居时，在这3个最近的邻居中，2个属于B类，1个属于a类。按照多数，我们将查询点分类为B类。现在，让我们考虑K=7。意味着，现在我们将考虑7个最近的邻居，而不是3个最近的邻居。当我们考虑7-NN时，我们得到属于类别A的4个最近邻和属于类别b的3个最近邻。现在，按照多数类别，我们将查询点分类为类别A。</p><p id="42e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可能想知道刚刚发生了什么？当我们选择K=3时，我们将查询点分类为B类，而当我们选择K=7时，分类标签变为a。这太令人困惑了。我如何确定选择什么样的K值？</p><p id="36df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不要担心，你所有的疑问都会很快得到解答。现在，我只想确保你理解KNN背后的直觉。我们很快就会明白如何确定最近的邻居，以及如何选择最佳的“K”值。</p><h2 id="ec76" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">如何找到最近的邻居？</h2><p id="5ba5" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">对上述问题的一个简单而直接的回答是计算两点之间的距离。我们将了解计算两点间距离的4种主要距离度量。</p><h2 id="12d9" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">1.欧几里得距离</h2><p id="4897" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">考虑下面的例子:</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/66b7a9e98ab5d4e8d8a9633f72b6e564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*uOj0usqbtBirj3OCC0K_WA.jpeg"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated"><a class="ae ko" href="https://hlab.stanford.edu/brian/making_measurements.html" rel="noopener ugc nofollow" target="_blank">形象信用</a></figcaption></figure><p id="8107" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">点A = (X_21，Y_21)</p><p id="5817" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">点B = (X_22，Y_22)</p><p id="8590" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">d =从A点到B点的最短直线的长度= A点和B点之间的欧几里德距离。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/f734d615bd644a889e9740288a223827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*6L0mbHjddFR71gjOWnFsSQ.png"/></div></figure><p id="5e5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">欧几里德距离是两点间距离平方之和的平方根。它也被称为L2规范。我们将在后面的文章中看到什么是L1和L2规范。</p><h2 id="3258" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">2.曼哈顿距离</h2><p id="ba94" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">曼哈顿距离是两点之间差异的绝对值之和</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/2260e95f158ad41a1b3017fe779173f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*7O7qagIPzK98-A3Wi6DQZA.png"/></div></figure><h2 id="8df2" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">3.汉明距离</h2><p id="2411" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">主要用于文本处理，当我们有一个二进制或布尔向量。简单来说，它告诉我们两个分类变量是否相同。考虑下面的例子，其中汉明距离在:</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/f9776b3bd1a89fa82d6025251fbba699.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*GW6uYVz4-melwH2QpgkdOA.png"/></div></figure><h2 id="a87d" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated">4.闵可夫斯基距离</h2><p id="fdf3" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">闵可夫斯基距离用于寻找两点之间的距离相似性。当p=1时，它变成曼哈顿距离，当p=2时，它变成欧几里德距离</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/fc83212423fffa695fe2400c53d77107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*7zts49drCoGASHRS97LYlg.png"/></div></figure><p id="605e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些是距离测量技术，主要用于计算点之间的距离，以确定最近的邻居。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="c637" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，你可能会想，还有别的吗？我的意思是，我理解距离测量的部分，但有没有其他方法也可以理解最近的邻居？答案是肯定的！</p><p id="a6d7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">到目前为止，我们用距离来衡量最近的邻居，我们用“角度”来衡量他们怎么样？</p><p id="ef80" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我给你介绍一下“<strong class="js iu">余弦相似度和余弦距离”</strong>的概念</p><p id="b078" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">余弦相似度考虑两点之间的角度(<strong class="js iu">θ</strong>)<strong class="js iu">T5)，等于<strong class="js iu"> cos( <em class="kp"> θ) </em> </strong>。考虑下面的例子:</strong></p><p id="b44a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">a和B是两个数据点，θ是它们之间的角度。可以肯定地说，如果两点之间的距离增加，则两点之间的角度将增加，并且随着两点之间的角度增加，<strong class="js iu"> cos( <em class="kp"> θ) </em> </strong>减小意味着它们的余弦相似性减小。</p><p id="9fb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑下面的例子:</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/a32ef823371d045df872407f9a4717ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a8dc-RS-fgpyOJ_ql3Mjeg.jpeg"/></div></div></figure><p id="fd97" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有3个向量——x1、x2和x3。</p><p id="017b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">余弦相似性(x1，x2)=<strong class="js iu">cos(<em class="kp">θ)<br/></em></strong>余弦相似性(x1，x3) = 1(自，θ = 0且cos(0) = 1) <br/>余弦距离(x1，x2) = 1 — cos(θ) <br/>余弦距离(x1，x3)= 1–1 = 0(自，cos(θ) = 1</p><p id="eddb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kp">所以观察结果是，就欧几里得距离而言，其清楚地表明距离d13&gt;d12</em>T26】</strong></p><p id="bb99" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kp">但是在比较余弦距离时，cos-dist (x1，x3) &lt; cos-dist (x1，x2) </em> </strong></p><p id="8737" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的观察中，很明显cos-sim或cos-dist使用向量之间的角度，而不是几何距离。</p><p id="2181" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">欧几里得和余弦相似性之间有关系吗？</p><p id="2853" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是的。有，具体如下:</p><p id="8304" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">x1和x2之间的平方欧氏距离= 2*(1 — cos( <em class="kp"> θ) </em> ) </strong></p><p id="c20a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要了解同样的详细数学证明请参考此<a class="ae ko" href="https://mc.ai/relationship-between-cosine-similarity-and-euclidean-distance/" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> <em class="kp">链接</em> </strong> </a></p><p id="cb1e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总之，我们非常详细地了解了K-NN。我们还讲述了各种距离度量和余弦相似性，以理解最近邻是如何计算的以及它们是如何相关的。</p><h2 id="1909" class="lc ld it bd le lf lg dn lh li lj dp lk kb ll lm ln kf lo lp lq kj lr ls lt lu bi translated"><strong class="ak">附加阅读材料</strong>:</h2><p id="48c0" class="pw-post-body-paragraph jq jr it js b jt lv jv jw jx lw jz ka kb lx kd ke kf ly kh ki kj lz kl km kn im bi translated">在我研究这个话题的时候，我看到了克里斯·埃米瑞的一篇精彩的文章。我会推荐你去一次这个<a class="ae ko" href="https://cmry.github.io/notes/euclidean-v-cosine" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> <em class="kp">链接</em> </strong> </a></p><p id="34f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kp">在下一篇文章中，我们将了解KNN的局限性，它的失败案例，如何挑选正确的“K”值。</em> </strong></p><p id="bed1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kp">直到那时，快乐学习</em> </strong></p></div></div>    
</body>
</html>