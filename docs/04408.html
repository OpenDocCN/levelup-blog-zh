<html>
<head>
<title>Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Keras中建立Seq2Seq LSTM用于时间序列预测</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=collection_archive---------0-----------------------#2020-06-25">https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb?source=collection_archive---------0-----------------------#2020-06-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="18f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了传统的回归，你想尝试一些其他的方法来解决你的预测问题吗？有许多常用于NLP领域的神经网络结构也可以用于时间序列。在这篇文章中，我们将在Keras中建立两个Seq2Seq模型，简单的Seq2Seq LSTM模型和Luong关注的Seq2Seq LSTM模型，并比较它们的预测精度。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><h1 id="362a" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">创建一些数据</h1><p id="b2e0" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">首先，我们来创建一些时间序列数据。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/569f4ae363f4ae15506b453650e02250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHNWPCwhLenodrQwlp7-Qw.png"/></div></div></figure><p id="f89c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们刚刚通过组合<em class="mc">正弦波</em>、<em class="mc">趋势</em>和<em class="mc">随机噪声</em>创建了两个序列<strong class="jp ir">、x1</strong>和<strong class="jp ir">T5】x2</strong>。接下来我们将预处理<strong class="jp ir"> <em class="mc"> x1 </em> </strong>和<strong class="jp ir"> <em class="mc"> x2 </em> </strong>。</p><h1 id="2b4c" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">预处理</h1><h2 id="7620" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">1.将序列分成80%的训练集和20%的测试集</h2><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mp"><img src="../Images/eddbd5f8d02ced6fcbdaaaf24acfc1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sk6zrtkTBVUNJuS3dc-qaA.png"/></div></div></figure><p id="df7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于序列长度为<em class="mc"> n_ = 1000 </em>，所以前800个数据点将作为我们的训练数据，其余的将作为我们的测试数据。</p><h2 id="93ca" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">2.去趋势</h2><p id="5432" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">去趋势时间序列不是必须的。然而，平稳的时间序列将使模型训练容易得多。时间序列去趋势的方法有很多，比如取序列与其lag1的差。这里为了简单起见，我们假设趋势的顺序是已知的，我们只是简单地将单独的趋势线拟合到<strong class="jp ir"> <em class="mc"> x1 </em> </strong>和<strong class="jp ir"> <em class="mc"> x2 </em> </strong>上，然后从相应的原始序列中减去趋势。</p><p id="b140" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将为序列中的每个位置创建索引号，以便于消除趋势和恢复趋势。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="ce46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们将使用np.polyfit来完成这个小任务。请注意，只有前800个数据点用于拟合趋势线，这是因为我们希望避免数据泄露。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mq"><img src="../Images/d9638f16e5e0e9a5b9b0bd49bcc232f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NuANtyj4JIl9TsWwE6XChQ.png"/></div></div></figure><p id="200c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于我们得到的上述值，我们现在可以得出<strong class="jp ir"> <em class="mc"> x1 </em> </strong>和<strong class="jp ir"> <em class="mc"> x2 </em> </strong>的趋势线。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="531d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们和<strong class="jp ir"> <em class="mc"> x1 </em> </strong>和<strong class="jp ir"> <em class="mc"> x2 </em> </strong>一起绘制趋势线，看看是否好看。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/5fcbf1a57a5779e6e7bea67935bf00b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCvMEh6gwoJFl2j6T6s2cA.png"/></div></div></figure><p id="8278" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的结果看起来不错，现在我们可以扣除趋势。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/2823c58c96b7ef5f3d1747a7df3d8bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUGOy76WMY9qBkusHyJ2dA.png"/></div></div></figure><p id="8265" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">去除趋势后，x1和x2变得稳定。</p><h2 id="68bb" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">3.组合序列</h2><p id="1489" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">为了在接下来的几个步骤中更容易地进行预处理，我们可以将序列及其相关信息组合到一个数组中。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mr"><img src="../Images/e9b27c7179d869b6598f8b3f81ef7249.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l8BWtiX5ReS28ThfEB_1oQ.png"/></div></div></figure><p id="abe2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在组合数组中，我们创建了<em class="mc"> x_lbl </em>:</p><ul class=""><li id="fb27" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated">第一列是<em class="mc"/><strong class="jp ir"><em class="mc">x1</em></strong></li><li id="70c7" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">第二列是<em class="mc"/><strong class="jp ir"><em class="mc">x2</em></strong></li><li id="ab28" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">第三列是<em class="mc">指标</em></li><li id="6e50" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">第四列是<em class="mc">标签</em> (1代表列车组，0代表测试组)</li></ul><h2 id="1bfc" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">4.使标准化</h2><p id="ffa9" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">归一化可以帮助模型避免偏向大特征而忽略非常小的特征。这里我们可以通过划分训练集中相应的最大值来简单地归一化<strong class="jp ir"> <em class="mc"> x1 </em> </strong>和<strong class="jp ir"> <em class="mc"> x2 </em> </strong>。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ng"><img src="../Images/d9fc5cbf8ee2cb83e10aaac4965ba8aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TOGkukzbih4iOnRLhC1zhQ.png"/></div></div></figure><p id="a560" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，上面的代码只计算第1列(<em class="mc">去趋势</em> <strong class="jp ir"> <em class="mc"> x1 </em> </strong>)和第2列(<em class="mc">去趋势</em> <strong class="jp ir"> <em class="mc"> x2 </em> </strong>)的最大值，第3列(<em class="mc">索引</em>)和第4列(<em class="mc">标签</em>)的分母都设置为1。这是因为我们没有将列3和列4输入到神经网络中，因此不需要对它们进行归一化。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nh"><img src="../Images/e5991bb7161cfa7ae5e93c343d93fcde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qD2kZHXxNh2dVwHEIWje7A.png"/></div></div></figure><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ni"><img src="../Images/f16cb08a3706b275f430e03b6cb2045c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQO38EcAih3J7YeLUCS5Jg.png"/></div></div></figure><p id="703b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标准化后，所有值或多或少都在-1到1的范围内。</p><h2 id="4a89" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">5.缩短</h2><p id="4875" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">接下来，我们将通过滑动输入窗口(长度= 200个时间步长)和输出窗口(长度= 20个时间步长)将序列切割成更小的片段，并将这些样本放入3d numpy数组中。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nh"><img src="../Images/038ccc8d1cfcfa057a5b798ae09e5c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYT9F6XDKTQKm8qgxC03Pw.png"/></div></div></figure><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nj"><img src="../Images/44cd28894b3664324ad6cac8f06a3b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0vH7rcm9dO1nolPbYSlfQg.png"/></div></div></figure><p id="7b02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">函数<em class="mc"> truncate </em>生成3个数组:</p><ul class=""><li id="533c" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated">输入到神经网络<strong class="jp ir"><em class="mc">X _ in</em></strong>:<strong class="jp ir"><em class="mc"/></strong>它包含781个样本，每个样本的长度为200个时间步长，每个样本包含3个特征:<em class="mc">去趋势和归一化的</em> <strong class="jp ir"> <em class="mc"> x1 </em> </strong>，<em class="mc">去趋势和归一化的</em> <strong class="jp ir"> <em class="mc"> x2 </em> </strong>和<em class="mc">原始赋值数据位置只有前两个特征将用于训练。</em></li><li id="60ab" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">神经网络中的目标<strong class="jp ir"><em class="mc">X _ out</em></strong>:<strong class="jp ir"><em class="mc"/></strong>它包含781个样本，每个样本的长度为20个时间步长，每个样本包含与<strong class="jp ir"> <em class="mc"> X_in </em> </strong>中相同的3个特征。只有前两个特征将被用作目标，第三个特征将仅被用于恢复预测的趋势。</li><li id="022d" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">标签<strong class="jp ir"> <em class="mc"> lbl </em> </strong> : 1代表列车组，0代表测试组。</li></ul><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nk"><img src="../Images/93cf87f77a90d9e1e4f2032d629ac426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OkBjPOalSKCEXUnIf0sJog.png"/></div></div></figure><p id="6cad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在数据已经可以输入神经网络了！</p><h1 id="f758" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型1:简单的Seq2Seq LSTM模型</h1><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nl"><img src="../Images/03b6eb2caca3307e4dac095cdf217e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w9hrrIEEIl5Uk3BiL4WFog.png"/></div></div></figure><p id="0da9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图表示Seq2Seq LSTM模型展开的单层:</p><ul class=""><li id="7754" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated"><strong class="jp ir"> <em class="mc">编码器LSTM单元</em> </strong>:将每个时间步长的值与前一个单元状态<strong class="jp ir"> c </strong>和隐藏状态<strong class="jp ir"> h </strong>一起输入编码器LSTM单元，重复该过程，直到生成最后一个单元状态<strong class="jp ir"> c </strong>和隐藏状态<strong class="jp ir"> h </strong>。</li><li id="5d50" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated"><strong class="jp ir"> <em class="mc">解码器LSTM单元</em> </strong>:我们使用来自编码器的最后一个单元状态<strong class="jp ir"> c </strong>和隐藏状态<strong class="jp ir"> h </strong>作为解码器LSTM单元的初始状态。编码器的最后一个隐藏状态也被复制20次，并且每个副本与先前的单元状态<strong class="jp ir"> c </strong>和隐藏状态<strong class="jp ir"> h </strong>一起被输入到解码器LSTM单元。解码器输出所有20个时间步长的隐藏状态，并将这些隐藏状态连接到密集层以输出最终结果。</li></ul><p id="d945" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">设置隐藏层数:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="06e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输入层</strong></p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nm"><img src="../Images/fd68df29e816c5542d4df2303597d9e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AJobq0uucY1ur8SeX4B93Q.png"/></div></div></figure><p id="d0c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">编码器LSTM </strong></p><p id="fb9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们需要注意2个导入参数<strong class="jp ir"><em class="mc">return _ sequences</em></strong>和<strong class="jp ir"> <em class="mc"> return_state </em> </strong>，因为它们决定LSTM返回什么。</p><ul class=""><li id="b90e" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated"><strong class="jp ir"><em class="mc">return _ sequences = False，return_state=False </em> </strong>:返回最后一个隐藏状态:state_h</li><li id="834e" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated"><strong class="jp ir"> <em class="mc"> return_sequences=True，return_state=False </em> </strong>:返回堆叠隐藏状态(<em class="mc">num _ time steps</em>*<em class="mc">num _ cells</em>):每个输入时间步长一个隐藏状态输出</li><li id="1936" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated"><strong class="jp ir"><em class="mc">return _ sequences = False，return_state=True </em> </strong>:返回3个数组:state_h，state_h，state_c</li><li id="66e5" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated"><strong class="jp ir"> <em class="mc"> return_sequences=True，return_state=True </em> </strong>:返回3个数组:堆栈隐藏状态，最后状态_h，最后状态_c</li></ul><p id="fd80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于简单的Seq2Seq模型，我们只需要最后的state_h和最后的state_c。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nn"><img src="../Images/d3efd1b79c38031900211c3fca2fc4f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tHrmLtdfLTYpgVPITC-bg.png"/></div></div></figure><p id="4326" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">添加批量标准化是因为我们希望避免编码器中激活功能<strong class="jp ir"> <em class="mc"> ELU </em> </strong>导致的梯度爆炸。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="5a73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们复制20份编码器的最后隐藏状态，并将其用作解码器的输入。编码器的最后一个单元状态和最后一个隐藏状态也被用作解码器的初始状态。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi no"><img src="../Images/a422767da01373b1e5d4e7ef24b289c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oKQIs8b3ZKIECkR0c8lqmQ.png"/></div></div></figure><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi np"><img src="../Images/d42c392f03961f2db8d077fbd030a578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SxUEGks34tSJyigW1APIRQ.png"/></div></div></figure><p id="0575" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们把所有东西放进模型，并编译它。这里我们简单地使用MSE作为损失函数，MAE作为评估指标。注意，我们为Adam优化器设置了<em class="mc"> clipnorm=1 </em>。这是为了归一化梯度，以避免反向传播过程中的梯度爆炸。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nq"><img src="../Images/b0618a1f50b81e6c8b6513b2361bacbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7DeNtv9VaPuxQRGQ3yYY2Q.png"/></div></div></figure><p id="14f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还可以绘制模型:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nr"><img src="../Images/dceb3cca934f49cbe21671a95cf6c4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-SwlPGD-A3kxiCSaK-2hXQ.png"/></div></div></figure><p id="90aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是培训:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ns"><img src="../Images/4f9358250c12f6e92d4eb81647d68a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mvhIqcO2lhfUu5vRKmKtuA.png"/></div></div></figure><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/5cf14cc863638f4459249274fdd70e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*dIlpZOA3dVYoxJrlLfNPsg.png"/></div></figure><h2 id="9c18" class="md kt iq bd ku me mf dn ky mg mh dp lc jy mi mj lg kc mk ml lk kg mm mn lo mo bi translated">预言；预测；预告</h2><p id="1007" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">模型预测和真实值未标准化:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nu"><img src="../Images/afe7013fc3320b8fb7e5257533c4b5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*klcy-ojhCUchJT2X6Yl-XQ.png"/></div></div></figure><p id="070c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们将非标准化的输出与它们相应的指数结合起来，这样我们就可以恢复趋势。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nv"><img src="../Images/2daaf6c4a6a5f7c0d0befb1faee1c50a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTWSBYIm_FZx6vnhJNmVJg.png"/></div></div></figure><p id="8e35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们将恢复趋势的所有输出放入一个字典<strong class="jp ir"> <em class="mc"> data_final </em> </strong>。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nw"><img src="../Images/ecc9259454d973d554522e17c7c8f895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O_fJU7gSmGNW-R2e9T7Giw.png"/></div></div></figure><p id="08ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只是快速检查一下预测值分布是否合理:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><div class="kl km kn ko gt ab cb"><figure class="nx kp ny nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/eb0bda10ffb0fda59a93a7f73539bef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*42ZOw7zhp0kKRKvy5xGZdw.png"/></div></figure><figure class="nx kp od nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/693794f53a1b3cbb09a4e6f7419a473e.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*V28XFfe5By2-5T3Bzp2qIw.png"/></div></figure></div><p id="b1dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">预测值和真值的数据分布几乎重叠，所以我们是好的。</p><p id="e2a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们也可以按时间顺序画出所有样本的MAE，看看是否有清晰的模式。理想的情况是当线是随机的时，否则它可能指示模型没有被充分训练。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><div class="kl km kn ko gt ab cb"><figure class="nx kp oe nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/1257a4acd9cc460bb8192afe6e7b16b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*bv8Zdrd1BpkixA2t-_Jh5A.png"/></div></figure><figure class="nx kp oe nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/75f5a0bd423347706f072aa742ad494a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*VUcwEvmyl08UlLF8voQe6Q.png"/></div></figure></div><p id="707f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据上述情况，我们可以说，在训练和测试MAE中仍然存在一定的周期性模式。更多时代的训练可能会带来更好的结果。</p><p id="4fba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们将检查一些随机样本，看看预测线和相应的真实线是否对齐。</p><div class="kl km kn ko gt ab cb"><figure class="nx kp of nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/3181e369adba79239b68f7ed75adb7f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*o2oIL4sRStvozfhw1fJvFg.png"/></div></figure><figure class="nx kp og nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/68ad48b46159937c79df638b69bf1a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*n4U0Xc556q0j2SBrgraj1A.png"/></div></figure></div><p id="df5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还可以检查每个时间步的第n次预测:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/d32c95377d9956d0284e5c032409fa4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*veNw3JnjiCs_fAewLX_4yA.png"/></div></div></figure><p id="3102" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">仔细看看测试集上的预测:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oh"><img src="../Images/3166776ef0949493b539cad8e745cd04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NI7MP5R75kN9GoBJ5foxqA.png"/></div></div></figure><h1 id="27da" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型二:关注度较高的Seq2Seq LSTM模型</h1><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oi"><img src="../Images/4cfc27d0f7e8b93559ba30efb1e9b38b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aJZsSIAx35n8-dU3IfvoIg.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">参见<a class="ae on" href="https://blog.floydhub.com/attention-mechanism/" rel="noopener ugc nofollow" target="_blank">https://blog.floydhub.com/attention-mechanism/</a></figcaption></figure><p id="9d9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简单Seq2Seq模型的限制之一是:只有编码器RNN的最后状态被用作解码器RNN的输入。如果序列很长，编码器对更早的时间步长的记忆会弱得多。注意机制可以解决这个问题。注意层将为编码器输出的每个隐藏状态分配适当的权重，并将它们映射到输出序列。</p><p id="f62d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来我们将在<strong class="jp ir"> <em class="mc">模型1 </em> </strong>之上构建<strong class="jp ir"> Luong Attention </strong>，并使用<em class="mc"> Dot </em>方法计算比对分数。</p><p id="2b1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"/><strong class="jp ir">输入图层</strong></p><p id="c438" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同<strong class="jp ir"> <em class="mc">模式1 </em> </strong>:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="ace7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">编码器LSTM </strong></p><p id="fa30" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这与<strong class="jp ir"> <em class="mc">模型1 </em> </strong>略有不同:除了返回最后一个隐藏状态和最后一个单元格状态，我们还需要返回堆叠的隐藏状态用于<strong class="jp ir"> <em class="mc">对齐分数</em> </strong>计算。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oo"><img src="../Images/695ea003470cf63e946227ce7002212a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y_fsKFOTuhwKfPb8S9RhGQ.png"/></div></div></figure><p id="990b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们应用批量标准化来避免梯度爆炸。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="34ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">解码器LSTM </strong></p><p id="9a2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们重复编码器的最后隐藏状态20次，并将它们用作解码器LSTM的输入。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi op"><img src="../Images/1196908099251c754a2e816dba5c1dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hJd4WVOcFeTWSYPX3jCTcA.png"/></div></div></figure><p id="71d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还需要得到de解码器的堆叠隐藏状态，用于<strong class="jp ir"> <em class="mc">对齐分数</em> </strong>的计算。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oq"><img src="../Images/eff74722807ae7016bd1395262e7d7cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*afWJIBBOqwuNgjU8pLox9w.png"/></div></div></figure><p id="f181" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">关注层</strong></p><p id="2071" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要构建关注层，首先要做的是计算比对分数，并对其应用softmax激活函数:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi or"><img src="../Images/de17a449321508b9a17a69f462477813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Gx4KdkRvfcLr6Fur0-DYw.png"/></div></div></figure><p id="4254" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们可以计算上下文向量，并在此基础上应用批量标准化:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi os"><img src="../Images/ea7a45d137d5e70eeb5103e8c76e5289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ye--X7H9g2mKwkRkGizVkg.png"/></div></div></figure><p id="3ed0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们连接解码器的上下文向量和堆叠隐藏状态，并将其用作最后一个密集层的输入。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ot"><img src="../Images/077b2d7f08897c31c9ca5aedff3bee6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5lUbjfgw8SUOdt3kAISulg.png"/></div></div></figure><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ou"><img src="../Images/ae8a2b0a05746cbd337eee2b4fd9ccd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WX7Yc0iGcsN2mtmtFii5RA.png"/></div></div></figure><p id="48e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们就可以编译模型了。参数与<strong class="jp ir"> <em class="mc">模型1 </em> </strong>中的参数相同，是为了比较2个模型的性能。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ov"><img src="../Images/bc0c0ca1b2d93198097de152da56774e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9X-fCAo4j4tmU1DkDpTGow.png"/></div></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ow"><img src="../Images/64e24c57df1391284727277f76c1723a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNxpULJVQsLCv8TaofIi9g.png"/></div></div></figure><p id="9df2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据如何在模型中流动:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ox"><img src="../Images/03490219d2dc4d8644fdf4acc5c9b023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vazomZ9K7a6RyHiVY3cVog.png"/></div></div></figure><p id="db46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">培训和评估过程与<strong class="jp ir"> <em class="mc">模型1 </em> </strong>中所示的相同。经过100个历元的训练(与<strong class="jp ir"> <em class="mc">模型1 </em> </strong>的训练历元数相同)，我们可以对结果进行评估。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/465f2912861878b7392c772aec12b254.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*-q16Pil2zkToGr5vPJEgkQ.png"/></div></figure><p id="7e29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是训练集和测试集的样品MAE与样品订单的<em class="mc">图。同样，模型没有得到充分的训练，因为我们仍然可以看到一些周期性的模式。但是为了更容易比较这两个模型，我们现在不打算训练它。请注意，与<strong class="jp ir"> <em class="mc">模型1 </em> </strong>相比，训练集和测试集的整体MAE略有提高。</em></p><p id="5159" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">添加关注层后:</p><ul class=""><li id="76d8" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated">训练集的平均误差从5.7851下降到5.7381</li><li id="b28b" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">测试集的平均误差从6.1495下降到5.9392</li></ul><div class="kl km kn ko gt ab cb"><figure class="nx kp oe nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/8e5565b000c7c9b16a504c7a278d7b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*8M6UK8v6lEuIM2aflnHNhg.png"/></div></figure><figure class="nx kp oe nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/6c55e86fe59ddb48a5d3d0bc8c8eddd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*IFWmUL01uN0-uu_yB7lpeA.png"/></div></figure></div><p id="f6e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随机抽样检查预测线与真实线:</p><div class="kl km kn ko gt ab cb"><figure class="nx kp of nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/5be5841761fc8b873fbecde74d2b37a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*Z_ge0jZuIbRnscmgpBWzaA.png"/></div></figure><figure class="nx kp og nz oa ob oc paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/95ef4ec0cfdaf69f74b5fe8033515556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*M78ues2A4ge67AKdIAuS3w.png"/></div></figure></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lv"><img src="../Images/3e731319db2985555704a7d372ec0f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nxgB3dGyYraVux9qbd6gEA.png"/></div></div></figure><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oh"><img src="../Images/db1c2dde9e60fc85eeade3092873a39a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1R4bJXooOesZ3kdwc5fcQ.png"/></div></div></figure></div></div>    
</body>
</html>