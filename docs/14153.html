<html>
<head>
<title>Scikit-Learn Cheat Sheet (2022), Python for Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">sci kit-å­¦ä¹ å¤‡å¿˜å•(2022)ï¼Œç”¨äºæ•°æ®ç§‘å­¦çš„Python</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://levelup.gitconnected.com/scikit-learn-cheat-sheet-2022-python-for-data-science-61c0a2e8517b?source=collection_archive---------3-----------------------#2022-11-06">https://levelup.gitconnected.com/scikit-learn-cheat-sheet-2022-python-for-data-science-61c0a2e8517b?source=collection_archive---------3-----------------------#2022-11-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6d7a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">åˆå­¦è€…å­¦ä¹ Scikitçš„ç»å¯¹åŸºç¡€â€”â€”2022å¹´å­¦ä¹ </h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5195f3ad25fdd2879e91539e0b231c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*odcj--poUP_QyVdOevDKaA.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">æ¥è‡ªUnsplashçš„ç…§ç‰‡ç”±<a class="ae ky" href="https://unsplash.com/photos/YFFGkE3y4F8" rel="noopener ugc nofollow" target="_blank"> Tim Stief </a>æ‹æ‘„</figcaption></figure><p id="4149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learnæ˜¯Pythonç¼–ç¨‹è¯­è¨€çš„å…è´¹è½¯ä»¶æœºå™¨å­¦ä¹ åº“ã€‚å®ƒå…·æœ‰å„ç§åˆ†ç±»ã€å›å½’ã€èšç±»ç®—æ³•ï¼Œä»¥åŠç”¨äºæ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æçš„é«˜æ•ˆå·¥å…·ã€‚å®ƒæ„å»ºåœ¨NumPyã€SciPyå’ŒMatplotlibä¹‹ä¸Šã€‚</p><blockquote class="lv lw lx"><p id="30a2" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">ç« èŠ‚:</em> </strong> <em class="it"> <br/> </em> 1ã€‚<a class="ae ky" href="#4e6d" rel="noopener ugc nofollow">åŸºæœ¬ç¤ºä¾‹</a> <br/> 2ã€‚<a class="ae ky" href="#cc46" rel="noopener ugc nofollow">åŠ è½½æ•°æ®</a> <br/> 3ã€‚<a class="ae ky" href="#aa8f" rel="noopener ugc nofollow">åŸ¹è®­å’Œæµ‹è¯•æ•°æ®</a> <br/> 4ã€‚<a class="ae ky" href="#3446" rel="noopener ugc nofollow">é¢„å¤„ç†æ•°æ®</a> <br/> 5ã€‚<a class="ae ky" href="#df83" rel="noopener ugc nofollow">åˆ›å»ºä½ çš„æ¨¡å‹</a> <br/> 6ã€‚<a class="ae ky" href="#8c18" rel="noopener ugc nofollow">æ¨¡å‹æ‹Ÿåˆ</a> <br/> 7ã€‚<a class="ae ky" href="#2ea8" rel="noopener ugc nofollow">é¢„æµ‹</a> <br/> 8ã€‚<a class="ae ky" href="#60b6" rel="noopener ugc nofollow">è¯„ä¼°ä½ æ¨¡ç‰¹çš„è¡¨ç°</a> <br/> 9ã€‚<a class="ae ky" href="#022d" rel="noopener ugc nofollow">è°ƒæ•´æ‚¨çš„æ¨¡å‹</a></p></blockquote><h1 id="4e6d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">åŸºæœ¬ç¤ºä¾‹:</h1><p id="a898" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">ä¸‹é¢çš„ä»£ç æ¼”ç¤ºäº†ä½¿ç”¨scikit-learnåœ¨ä¸€ç»„æ•°æ®ä¸Šåˆ›å»ºå’Œè¿è¡Œæ¨¡å‹çš„åŸºæœ¬æ­¥éª¤ã€‚</p><p id="b2e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä»£ç ä¸­çš„æ­¥éª¤åŒ…æ‹¬:åŠ è½½æ•°æ®ï¼Œåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç¼©æ”¾é›†ï¼Œåˆ›å»ºæ¨¡å‹ï¼Œæ ¹æ®æ•°æ®æ‹Ÿåˆæ¨¡å‹ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œæœ€åè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="ece9" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn import neighbors, datasets, preprocessing<br/>&gt;&gt;&gt; from sklearn.model_selection import train_test_split<br/>&gt;&gt;&gt; from sklearn.metrics import accuracy_score<br/>&gt;&gt;&gt; iris = datasets.load_iris()<br/>&gt;&gt;&gt; X,y = iris.data[:,:2], iris.target<br/>&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X,y)<br/>&gt;&gt;&gt; scaler = preprocessing_StandardScaler().fit(X_train)<br/>&gt;&gt;&gt; X_train = scaler.transform(X_train)<br/>&gt;&gt;&gt; X_test = scaler.transform(X_test)<br/>&gt;&gt;&gt; knn = neighbors.KNeighborsClassifier(n_neighbors = 5)<br/>&gt;&gt;&gt; knn.fit(X_train, y_train)<br/>&gt;&gt;&gt; y_pred = knn.predict(X_test)<br/>&gt;&gt;&gt; accuracy_score(y_test, y_pred)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="cc46" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">åŠ è½½æ•°æ®</h1><p id="bb49" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">æ‚¨çš„æ•°æ®éœ€è¦æ˜¯æ•°å­—ï¼Œå¹¶å­˜å‚¨ä¸ºNumPyæ•°ç»„æˆ–SciPyå¤‡ç”¨çŸ©é˜µã€‚è½¬æ¢æˆæ•°å­—æ•°ç»„çš„å…¶ä»–ç±»å‹ä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„ï¼Œæ¯”å¦‚Pandas DataFrameã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="b424" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; X = np.random.random((10,5))</span><span id="1c11" class="ne md it na b gy nv ng l nh ni">array([[0.21069686, 0.33457064],<br/>       [0.23887117, 0.6093155 ],<br/>       [0.48848537, 0.62649292]])</span><span id="a1d1" class="ne md it na b gy nv ng l nh ni">&gt;&gt;&gt; y = np.array(['A','B','A'])</span><span id="8955" class="ne md it na b gy nv ng l nh ni">array(['A', 'B', 'A'])</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="aa8f" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">åŸ¹è®­å’Œæµ‹è¯•æ•°æ®</h1><p id="3d49" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">å°†æ•°æ®é›†åˆ†ä¸ºXå’Œyå˜é‡çš„å®šå‹é›†å’Œæµ‹è¯•é›†ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="3287" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.model_selection import train_test_split<br/>&gt;&gt;&gt; X_train,X_test,y_train,y_test = train_test_split(X,y, random_state = 0)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="3446" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">é¢„å¤„ç†æ•°æ®</h1><p id="8e3b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">åœ¨æ¨¡å‹æ‹Ÿåˆä¹‹å‰å‡†å¤‡å¥½æ•°æ®ã€‚</p><h2 id="f88e" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">æ ‡å‡†åŒ–</h2><p id="1e56" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">é€šè¿‡ç§»é™¤å¹³å‡å€¼å¹¶ç¼©æ”¾è‡³å•ä½æ–¹å·®æ¥æ ‡å‡†åŒ–è¦ç´ ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="5c52" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler<br/>&gt;&gt;&gt; scaler = StandardScaler().fit(X_train)<br/>&gt;&gt;&gt; standarized_X = scaler.transform(X_train)<br/>&gt;&gt;&gt; standarized_X_test = scaler.transform(X_test)</span></pre><h2 id="7e2f" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">æ­£å¸¸åŒ–</h2><p id="6f01" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">å…·æœ‰è‡³å°‘ä¸€ä¸ªéé›¶åˆ†é‡çš„æ¯ä¸ªæ ·æœ¬(å³æ•°æ®çŸ©é˜µçš„æ¯ä¸€è¡Œ)ç‹¬ç«‹äºå…¶ä»–æ ·æœ¬è¢«é‡æ–°ç¼©æ”¾ï¼Œä½¿å¾—å…¶èŒƒæ•°ç­‰äº1ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="9f69" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.preprocessing import Normalizer<br/>&gt;&gt;&gt; scaler = Normalizer().fit(X_train)<br/>&gt;&gt;&gt; normalized_X = scaler.transform(X_train)<br/>&gt;&gt;&gt; normalized_X_test = scaler.transform(X_test)</span></pre><h2 id="3954" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">äºŒå€¼åŒ–</h2><p id="c45f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">æ ¹æ®é˜ˆå€¼å°†æ•°æ®äºŒå€¼åŒ–(å°†ç‰¹å¾å€¼è®¾ç½®ä¸º0æˆ–1)ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="4337" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.preprocessing import Binarizer<br/>&gt;&gt;&gt; binarizer = Binarizer(threshold = 0.0).fit(X)<br/>&gt;&gt;&gt; binary_X = binarizer.transform(X_test)</span></pre><h2 id="a22b" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">ç¼–ç åˆ†ç±»ç‰¹å¾</h2><p id="b7e4" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">ä½¿ç”¨ä»‹äº0å’Œn_classes-1ä¹‹é—´çš„å€¼å¯¹ç›®æ ‡æ ‡ç­¾è¿›è¡Œç¼–ç ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="7cea" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn import preprocessing<br/>&gt;&gt;&gt; le = preprocessing.LabelEncoder()<br/>&gt;&gt;&gt; le.fit_transform(X_train)</span></pre><h2 id="059b" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">è¾“å…¥ç¼ºå¤±å€¼</h2><p id="e2dc" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">å¡«è¡¥ç¼ºå¤±å€¼çš„æ’è¡¥è½¬æ¢å™¨ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="9d86" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.impute import SimpleImputer<br/>&gt;&gt;&gt; imp = SimpleImputer(missing_values = 0, strategy = 'mean')<br/>&gt;&gt;&gt; imp.fit_transform(X_train)</span></pre><h2 id="f5a0" class="ne md it bd me nw nx dn mi ny nz dp mm li oa ob mo lm oc od mq lq oe of ms og bi translated">ç”Ÿæˆå¤šé¡¹å¼è¦ç´ </h2><p id="a8a6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">ç”Ÿæˆç”±é˜¶æ•°å°äºæˆ–ç­‰äºæŒ‡å®šé˜¶æ•°çš„è¦ç´ çš„æ‰€æœ‰å¤šé¡¹å¼ç»„åˆç»„æˆçš„æ–°è¦ç´ çŸ©é˜µã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="692d" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.preprocessing import PolynomialFeatures<br/>&gt;&gt;&gt; poly = PolynomialFeatures(5)<br/>&gt;&gt;&gt; poly.fit_transform(X)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="df83" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">åˆ›å»ºæ‚¨çš„æ¨¡å‹</h1><p id="ea98" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">åˆ›å»ºå„ç§ç›‘ç£å’Œéç›‘ç£å­¦ä¹ æ¨¡å‹ã€‚</p><h1 id="1d4e" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">ç›‘ç£å­¦ä¹ æ¨¡å‹</h1><ul class=""><li id="7e68" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">çº¿æ€§å›å½’</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="1c85" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.linear_model import LinearRegression<br/>&gt;&gt;&gt; lr  = LinearRegression(normalize = True)</span></pre><ul class=""><li id="ba8a" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">æ”¯æŒå‘é‡æœº(SVM)</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="547c" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.svm import SVC<br/>&gt;&gt;&gt; svc = SVC(kernel = 'linear')</span></pre><ul class=""><li id="bb84" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">æœ´ç´ è´å¶æ–¯</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="8c54" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.naive_bayes import GaussianNB<br/>&gt;&gt;&gt; gnb = GaussianNB()</span></pre><ul class=""><li id="f6ae" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">KNN</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="2a76" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn import neighbors<br/>&gt;&gt;&gt; knn = neighbors.KNeighborsClassifier(n_neighbors = 5)</span></pre><h1 id="e65b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">æ— ç›‘ç£å­¦ä¹ æ¨¡å‹</h1><ul class=""><li id="eeec" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">ä¸»æˆåˆ†åˆ†æ</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="e42d" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.decomposition import PCA<br/>&gt;&gt;&gt; pca = PCA(n_components = 0.95)</span></pre><ul class=""><li id="c7dc" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">kè¡¨ç¤º</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="9d10" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.cluster import KMeans<br/>&gt;&gt;&gt; k_means = KMeans(n_clusters = 3, random_state = 0)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="8c18" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">æ¨¡å‹æ‹Ÿåˆ</h1><p id="d5e8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">å°†ç›‘ç£å’Œéç›‘ç£å­¦ä¹ æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ä¸Šã€‚</p><h1 id="8036" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">ç›‘ç£å­¦ä¹ </h1><ul class=""><li id="1205" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">ä½¿æ¨¡å‹ç¬¦åˆæ•°æ®</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="1868" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; lr.fit(X, y)<br/>&gt;&gt;&gt; knn.fit(X_train,y_train)<br/>&gt;&gt;&gt; svc.fit(X_train,y_train)</span></pre><h1 id="8c7f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">æ— ç›‘ç£å­¦ä¹ </h1><ul class=""><li id="fa05" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">ä½¿æ¨¡å‹ç¬¦åˆæ•°æ®</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="86b4" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; k_means.fit(X_train)</span></pre><ul class=""><li id="a926" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">é€‚åº”æ•°æ®ï¼Œç„¶åè½¬æ¢æ•°æ®</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="2f85" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; pca_model = pca.fit_transform(X_train)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="2ea8" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">é¢„è¨€ï¼›é¢„æµ‹ï¼›é¢„å‘Š</h1><p id="d9ef" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æµ‹è¯•é›†ã€‚</p><ul class=""><li id="7600" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">é¢„æµ‹æ ‡ç­¾</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="0396" class="ne md it na b gy nf ng l nh ni">#Supervised Estimators<br/>&gt;&gt;&gt; y_pred = lr.predict(X_test)#Unsupervised Estimators<br/>&gt;&gt;&gt; y_pred = k_means.predict(X_test)</span></pre><ul class=""><li id="4d30" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">ä¼°è®¡æ ‡ç­¾çš„æ¦‚ç‡</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="e7dc" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; y_pred = knn.predict_proba(X_test)</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="60b6" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">è¯„ä¼°æ‚¨çš„æ¨¡å‹çš„æ€§èƒ½</h1><p id="e275" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">ç¡®å®šæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°å¦‚ä½•çš„å„ç§å›å½’å’Œåˆ†ç±»æŒ‡æ ‡ã€‚</p><h1 id="bb3c" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">åˆ†ç±»æŒ‡æ ‡</h1><ul class=""><li id="e61a" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">å‡†ç¡®åº¦åˆ†æ•°</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="461b" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; knn.score(X_test,y_test)<br/>&gt;&gt;&gt; from sklearn.metrics import accuracy_score<br/>&gt;&gt;&gt; accuracy_score(y_test,y_pred)</span></pre><ul class=""><li id="05c9" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">åˆ†ç±»æŠ¥å‘Š</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="d0e1" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import classification_report<br/>&gt;&gt;&gt; print(classification_report(y_test,y_pred))</span></pre><ul class=""><li id="bb34" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">æ··æ·†çŸ©é˜µ</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="5473" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn .metrics import confusion_matrix<br/>&gt;&gt;&gt; print(confusion_matrix(y_test,y_pred))</span></pre><h1 id="fe64" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">å›å½’åº¦é‡</h1><ul class=""><li id="116a" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">ç»å¯¹å¹³å‡è¯¯å·®</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="550e" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import mean_absolute_error<br/>&gt;&gt;&gt; mean_absolute_error(y_test,y_pred)</span></pre><ul class=""><li id="8ddb" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">å‡æ–¹è¯¯å·®</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="ba9b" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import mean_squared_error<br/>&gt;&gt;&gt; mean_squared_error(y_test,y_pred)</span></pre><ul class=""><li id="73d5" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">råˆ†æ•°</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="82ff" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import r2_score<br/>&gt;&gt;&gt; r2_score(y_test, y_pred)</span></pre><h1 id="85cb" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">èšç±»åº¦é‡</h1><ul class=""><li id="67c9" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">è°ƒæ•´åçš„å…°å¾·æŒ‡æ•°</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="bd7f" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import adjusted_rand_score<br/>&gt;&gt;&gt; adjusted_rand_score(y_test,y_pred)</span></pre><ul class=""><li id="2cef" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">åŒç§</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="cdb1" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import homogeneity_score<br/>&gt;&gt;&gt; homogeneity_score(y_test,y_pred)</span></pre><ul class=""><li id="d668" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">å‚ç›´æµ‹é‡</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="191e" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.metrics import v_measure_score<br/>&gt;&gt;&gt; v_measure_score(y_test,y_pred)</span></pre><h1 id="d4ec" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">äº¤å‰éªŒè¯</h1><ul class=""><li id="3f47" class="oh oi it lb b lc mu lf mv li oj lm ok lq ol lu om on oo op bi translated">é€šè¿‡äº¤å‰éªŒè¯è¯„ä¼°åˆ†æ•°</li></ul><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="a160" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.model_selection import cross_val_score<br/>&gt;&gt;&gt; print(cross_val_score(knn, X_train, y_train, cv=4))</span></pre></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="022d" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">è°ƒæ•´æ‚¨çš„æ¨¡å‹</h1><p id="d477" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">æ‰¾åˆ°å°†æœ€å¤§åŒ–æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§çš„æ­£ç¡®å‚æ•°å€¼ã€‚</p><h1 id="25b6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">ç½‘æ ¼æœç´¢</h1><p id="771b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">å¯¹ä¼°è®¡é‡çš„ç‰¹å®šå‚æ•°å€¼çš„ç©·ä¸¾æœç´¢ã€‚ä¸‹é¢çš„ç¤ºä¾‹è¯•å›¾æ‰¾åˆ°ä¸ºknnæŒ‡å®šçš„æ­£ç¡®èšç±»æ•°é‡ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="a1aa" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.model_selection import GridSearchCV<br/>&gt;&gt;&gt; params = {'n_neighbors': np.arange(1,3), 'metric':['euclidean','cityblock']}<br/>&gt;&gt;&gt; grid = GridSearchCV(estimator = knn, param_grid = params)<br/>&gt;&gt;&gt; grid.fit(X_train, y_train)<br/>&gt;&gt;&gt; print(grid.best_score_)<br/>&gt;&gt;&gt; print(grid.best_estimator_.n_neighbors)</span></pre><h1 id="7a9c" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">éšæœºå‚æ•°ä¼˜åŒ–</h1><p id="d200" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">è¶…å‚æ•°çš„éšæœºæœç´¢ã€‚ä¸ç½‘æ ¼æœç´¢ç›¸åï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„å‚æ•°å€¼éƒ½è¢«å°è¯•ï¼Œè€Œæ˜¯ä»æŒ‡å®šçš„åˆ†å¸ƒä¸­é‡‡æ ·å›ºå®šæ•°é‡çš„å‚æ•°è®¾ç½®ã€‚å°è¯•çš„å‚æ•°è®¾ç½®çš„æ•°é‡ç”±n_iterç»™å‡ºã€‚</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="3ad6" class="ne md it na b gy nf ng l nh ni">&gt;&gt;&gt; from sklearn.model_selection import RandomizedSearchCV<br/>&gt;&gt;&gt; params = {'n_neighbors':range(1,5), 'weights':['uniform','distance']}<br/>&gt;&gt;&gt; rsearch = RandomizedSearchCV(estimator = knn, param_distributions = params, cv = 4, n_iter = 8, random_state = 5)<br/>&gt;&gt;&gt; rseach.fit(X_train, y_train)<br/>&gt;&gt;&gt; print(rsearch.best_score_)</span></pre><p id="c9fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learnå¯¹äºå„ç§æœºå™¨å­¦ä¹ æ¨¡å‹æ¥è¯´æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åº“ã€‚ä»¥ä¸Šéƒ¨åˆ†æä¾›äº†åœ¨ä¸åŒæ¨¡å‹ä¸Šæ‰§è¡Œåˆ†æçš„åŸºæœ¬åˆ†æ­¥è¿‡ç¨‹ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œè¯·æŸ¥é˜…<a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>çš„æ–‡æ¡£ï¼Œå› ä¸ºè¿˜æœ‰å¾ˆå¤šæœ‰ç”¨çš„å‡½æ•°å¯ä»¥å­¦ä¹ ã€‚</p><p id="e2c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://pages.christopherzita.com/python-cheat-sheet" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">ä¸5kä»¥ä¸Šçš„äººä¸€èµ·åŠ å…¥æˆ‘çš„ç”µå­é‚®ä»¶åˆ—è¡¨ï¼Œå…è´¹è·å¾—â€œå®Œæ•´çš„Pythonæ•°æ®ç§‘å­¦å°æŠ„æ‰‹å†Œâ€</strong> </a></p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="df12" class="mc md it bd me mf nq mh mi mj nr ml mm jz ns ka mo kc nt kd mq kf nu kg ms mt bi translated">åˆ†çº§ç¼–ç </h1><p id="95b2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:</p><ul class=""><li id="7522" class="oh oi it lb b lc ld lf lg li oq lm or lq os lu om on oo op bi translated">ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰</li><li id="8dcc" class="oh oi it lb b lc ot lf ou li ov lm ow lq ox lu om on oo op bi translated">ğŸ“°æŸ¥çœ‹<a class="ae ky" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">å‡çº§ç¼–ç å‡ºç‰ˆç‰©</a>ä¸­çš„æ›´å¤šå†…å®¹</li><li id="2e43" class="oh oi it lb b lc ot lf ou li ov lm ow lq ox lu om on oo op bi translated">ğŸ””å…³æ³¨æˆ‘ä»¬:<a class="ae ky" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae ky" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae ky" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">æ—¶äº‹é€šè®¯</a></li></ul><p id="b9ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ğŸš€ğŸ‘‰<a class="ae ky" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">å°†åƒä½ è¿™æ ·çš„å¼€å‘äººå‘˜å®‰ç½®åœ¨é¡¶çº§åˆ›ä¸šå…¬å¸å’Œç§‘æŠ€å…¬å¸</strong> </a></p></div></div>    
</body>
</html>