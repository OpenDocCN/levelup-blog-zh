# ç®¡ç†å’¨è¯¢ä¸­çš„æ•°æ®ç§‘å­¦å®¶:å¦‚ä½•è§£å†³æŠ€æœ¯ä½œä¸š

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/data-scientist-in-management-consulting-how-to-solve-the-technical-homework-3cc51115103>

## MBB å…¸å‹çš„æ•°æ®ç§‘å­¦å’Œå’¨è¯¢æŠ€æœ¯ä½œä¸š(éº¦è‚¯é”¡ã€è´æ©ã€BCG)æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Ÿè®©æˆ‘ä»¬å¼€å§‹ç€æ‰‹è§£å†³é—®é¢˜å§ã€‚

![](img/235689762e1e588f688455953485faed.png)

æ³¢ç½—çš„æµ·ç¾æ™¯(ä½œè€…æ‹æ‘„)

éº¦è‚¯é”¡ã€è´æ©æˆ–æ³¢å£«é¡¿å’¨è¯¢é›†å›¢ç­‰å…¬å¸æ˜¯è®¸å¤šæ±‚èŒè€…çš„æ¢¦æƒ³ã€‚ä»–ä»¬çš„æ‹›è˜è¿‡ç¨‹æ˜¯å‡ºäº†åçš„è‰°éš¾ã€æ¼«é•¿ï¼Œè€Œä¸”æˆåŠŸç‡å¾ˆä½ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æƒ³åˆ†äº«(å¹¶è§£ç­”)æˆ‘ä»ä¸€ä½ MBB é‚£é‡Œå¾—åˆ°çš„ä¸€ä»½è¯¾åä½œä¸šï¼Œå®ƒåŒ…å«åœ¨ä¸‰è½®æŠ€æœ¯é¢è¯•çš„ç¬¬ä¸€æ­¥ä¸­ã€‚ä½†äº‹ä¸å®œè¿Ÿï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼

å°æ³¨æ„:ç¬¬ä¸€æ­¥é€šè¿‡äº†æœ¬æ–‡ä¸­å…±äº«çš„è§£å†³æ–¹æ¡ˆ

# ç®€ä»‹:

å› ä¸ºä¸å¯èƒ½åˆ†äº«æœ€åˆçš„å®¶åº­ä½œä¸šï¼Œæ‰€ä»¥æˆ‘å‡†å¤‡äº†ä¸€ä»½æ€»ç»“ï¼Œå¹¶æ›´æ”¹äº†ä¸€äº›å˜é‡ã€‚

æˆ‘æ˜¯æ—¨åœ¨æé«˜ ABC Telco ARPU çš„è½¬å‹è®¡åˆ’çš„ä¸€éƒ¨åˆ†ã€‚åˆ†é…ç»™æˆ‘çš„ä»»åŠ¡æ˜¯é€šè¿‡é«˜çº§åˆ†ææé«˜ ABC Telco è¥é”€æ´»åŠ¨çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯ï¼Œåˆ†é…ç»™æˆ‘çš„æœ€ç»ˆç›®æ ‡æ˜¯ä»è¥é”€æ´»åŠ¨ä¸­è·å¾—æœ€å¤§åˆ©æ¶¦ï¼Œåˆ©æ¶¦å®šä¹‰ä¸º:

![](img/79dac5c702f359bb5a5a7546405f266e.png)

`pilot.csv`åŒ…å«è¿‡å»è¿›è¡Œçš„ä¸€é¡¹ç ”ç©¶çš„ä¿¡æ¯ï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€ä½å®¢æˆ·åŠå…¶ç‰¹å¾ï¼Œä»¥åŠè´­ä¹°/ä¸è´­ä¹°è¯¥æœåŠ¡çš„æœ€ç»ˆå†³å®šã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜è”ç³»äº† A/B æµ‹è¯•ï¼Œå¯è§äºåˆ—`treatment`ã€‚è¯¥æ–‡ä»¶å¯ç”¨ä½œç®—æ³•çš„è®­ç»ƒé›†ï¼Œè¯¥ç®—æ³•æ—¨åœ¨é¢„æµ‹åœ¨ç»™å®šä¸€ç»„ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œå“ªäº›æ¥è‡ª`CustomerBase.csv`çš„å®¢æˆ·å¯èƒ½ä¼šè´­ä¹°è¯¥æœåŠ¡ã€‚

# é™åˆ¶å’Œç»†å¾®å·®åˆ«:

*   è”ç³»ä¸€ä¸ªç”¨æˆ·çš„å¹³å‡ä»·æ ¼æ˜¯ 5 ä¸ªå•ä½
*   è¯¥ç®—æ³•çš„è¾“å‡ºæ˜¯æä¾›äºŒå…ƒå†³ç­–
*   è´­ä¹°è¯¥æœåŠ¡å°†äº§ç”Ÿ 100 ä¸ªå•ä½çš„å¢é‡æŠ˜æ‰£å®¢æˆ·ç»ˆèº«ä»·å€¼
*   å¤„ç†-> 0 ä»£è¡¨å¯¹ç…§ç»„ï¼Œ1 ä»£è¡¨æ¥è§¦äººç¾¤
*   é€šè¯æ¬¡æ•°è¢«é™åˆ¶åœ¨æ•´ä¸ªå®¢æˆ·ç¾¤çš„ 1/4

# ä»»åŠ¡:

*   ä»è¥é”€æ´»åŠ¨ä¸­è·å–æœ€å¤§åˆ©æ¶¦
*   å¼€å‘è‡³å°‘ä¸¤ä¸ªæ¨¡å‹(å…¶ä¸­ä¸€ä¸ªæ˜¯é›†åˆæ¨¡å‹),å¹¶æ ¹æ®æˆ‘é€‰æ‹©çš„æ ‡å‡†è¿›è¡Œæ¯”è¾ƒ

# æ”»å‡»è®¡åˆ’:

ä¸ºäº†æ‰§è¡Œè¿™é¡¹ä»»åŠ¡ï¼Œä½¿ç”¨äº†å…¸å‹çš„æ•°æ®ç§‘å­¦æ¡†æ¶ï¼Œæ•´ä¸ªåˆ†æåŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤:

*   1.0 æ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)
*   2.0 æ•°æ®å‡†å¤‡
*   3.0 å»ºæ¨¡å’Œè¯„ä¼°
*   4.0 ç»“è®º

# 1.0 æ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)

æœ¬èŠ‚æ—¨åœ¨ç†è§£`pilot`æ•°æ®é›†å’Œ`CustomerBase`ä¸­åŒ…å«çš„æ•°æ®ã€‚å®ƒé¦–å…ˆæ¢ç´¢ä»¥å‰çš„æ•°æ®é›†ï¼Œè¿›è¡Œä¸åŒçš„åŸºæœ¬ç»Ÿè®¡å’Œåˆ†æï¼Œè¯„ä¼° A/B æµ‹è¯•çš„å½±å“ï¼Œå¹¶æä¾›æ”¯æŒæ€§çš„å¯è§†åŒ–ã€‚

æ­¤å¤–ï¼Œç”±äºæ•°æ®é‡å…è®¸ï¼Œä½¿ç”¨`pandas_profiling`åŒ…ç”Ÿæˆäº†ä¸¤ä»½æŠ¥å‘Šï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åŒ…ï¼Œå¯ä»¥å¯¹ pandas æ•°æ®æ¡†æ¶è¿›è¡Œå¿«é€Ÿæ¢ç´¢æ€§æ•°æ®åˆ†æã€‚

```
pilot = pd.read_csv(â€˜../data/pilot.csvâ€™)
customer_base = pd.read_csv(â€˜../data/CustomerBase.csvâ€™)
```

![](img/33f8c613ea64482a3f9e675a1b0d25c6.png)

é£è¡Œå‘˜æ•°æ®é›†çš„è§†å›¾

![](img/97c590370a191ed6f9d8466773b6faf9.png)

customerBase æ•°æ®é›†çš„è§†å›¾

```
# Check for differences in purchase between control and treatment
control = pilot[pilot[â€˜treatmentâ€™] == 0]
treatment = pilot[pilot[â€˜treatmentâ€™] == 1]# Calculate total percentage (in relative terms) of customer who purchased for both groups
control_pct = (len(control[control[â€˜purchaseâ€™] == 1]) / len(control) * 100)treatment_pct = (
 len(treatment[treatment[â€˜purchaseâ€™] == 1]) / len(treatment) * 100)print(f'The pilot consists of {len(pilot)} customers')
print(
    f'The total amount of customers contacted in treatment is {len(treatment)} customers')
print(f'The total amount of customers in control is {len(control)} customers')
```

![](img/5973601b162c2a6773c1a0ecec182439.png)

```
print(
 fâ€™Absolute percentage of customer who purchased in pilot: {(len(pilot[pilot[â€œpurchaseâ€] == 1]) / len(pilot)) * 100}%â€™)
```

![](img/694c04a0a17f47eb5fa8f3fb8c738b65.png)

```
conversion_rates = pilot.groupby(â€˜treatmentâ€™)[â€˜purchaseâ€™]
# Std. deviation of the proportion
def std_p(x): return np.std(x, ddof=0)# Std. error of the proportion (std / sqrt(n))def se_p(x): return stats.sem(x, ddof=0)conversion_rates = conversion_rates.agg([np.mean, std_p, se_p])
conversion_rates.columns = [â€˜conversion_rateâ€™, â€˜std_deviationâ€™, â€˜std_errorâ€™]
conversion_rates.style.format(â€˜{:.3f}â€™)print(conversion_rates)plt.figure(figsize=(8, 6))
sns.barplot(x=pilot[â€˜treatmentâ€™], y=pilot[â€˜purchaseâ€™], ci=False)
plt.ylim(0, 0.17)
plt.title(â€˜Conversion rate by groupâ€™)
plt.xlabel(â€˜Groupâ€™)
plt.ylabel(â€˜Converted (proportion)â€™)
plt.show()
```

![](img/b32cf2c9fa639c62416fdf618fa4847e.png)

æ ¹æ®ä¸€äº›åŸºæœ¬ç»Ÿè®¡æ•°æ®ï¼Œåœ¨æ²»ç–—ç»„è´­ä¹°çš„å®¢æˆ·ä¼¼ä¹ç•¥æœ‰å¢åŠ ï¼Œä½†æ˜¯ï¼Œä¸ºäº†è¯å®è¿™ä¸€ç‚¹ï¼Œåº”è¿›è¡Œæ›´åˆé€‚çš„æµ‹è¯•ï¼Œå¦‚ Z-testã€‚

è¯•ç‚¹é¡¹ç›®çš„æ€»æˆæœ¬ã€æ”¶å…¥å’Œåˆ©æ¶¦:

```
# cost of contacting a customer:
total_costs = len(treatment) * 5# discounted (future) revenues for all customer who purchased
total_revenues = len(pilot[pilot[â€˜purchaseâ€™] == 1]) * 100profit = total_revenues â€” total_costsprint(fâ€™Total cost of contacting customer is {total_costs} unitsâ€™)
print(
 fâ€™Total revenues (incremental discounts) will be of {total_revenues} unitsâ€™)
print(
 fâ€™Total profit for pilot is: {profit} units, based on {len(pilot)} customers of which {len(pilot[pilot[â€œpurchaseâ€] == 1])} purchasedâ€™)
```

![](img/7d2e03738cfe011efa3bcb97b5f5ac31.png)

å¯¹äº`customerBase`ï¼Œè€ƒè™‘åˆ°çº¦æŸæ¡ä»¶ï¼Œæœ€å¤§å¯èƒ½æ€»åˆ©æ¶¦ä¸º:

```
max_amount_contactable_customers = (len(customer_base) * 0.25)
cost_of_contact = 5
profit = 100max_profit = max_amount_contactable_customers * \
 profit â€” (max_amount_contactable_customers * 5)
print(
 fâ€™Maximum possible profit (assuming 100% of contacted customers purchase): {max_profit} unitsâ€™)
```

![](img/d984f7fbd6b791c66aea737aecfc3e82.png)

æ¥ä¸‹æ¥ï¼Œä½¿ç”¨`pandas_profiling`åˆ›å»ºä¸€ä¸ªæŠ¥å‘Šï¼Œè¿™æœ‰åŠ©äºåœ¨æ•°æ®ä¸­å¯»æ‰¾æœ‰è¶£çš„æ¨¡å¼ã€‚

ä»æŠ¥å‘Šä¸­å¯è§çš„è¯Šæ–­ç»“æœæ¥çœ‹ï¼Œ`V19`åˆ—ä¸­çš„ä¸åŒå€¼å­˜åœ¨å·®å¼‚:

```
pilot[â€˜V19â€™].value_counts().sort_values(ascending=False).plot(kind=â€™barâ€™)
```

![](img/a914a20300842aab8c9b2794ab343ca1.png)

è¯•ç‚¹æ•°æ®é›†ä¸­çš„å¤§å¤šæ•°è§‚å¯Ÿå€¼å±äº V19 åˆ—çš„ A ç±»

```
customer_base[â€˜V19â€™].value_counts().sort_values(
 ascending=False).plot(kind=â€™barâ€™)
```

![](img/65029e4aaf580d97af5c79d5585e4d42.png)

å®¢æˆ·åŸºç¡€æ•°æ®é›†ä¹Ÿå­˜åœ¨éå¸¸ç›¸ä¼¼çš„æ¨¡å¼

è¿™ç§å·®å¼‚å¯èƒ½æ˜¯ç”±ä¸åŒçš„å› ç´ é€ æˆçš„ï¼Œä¾‹å¦‚ï¼Œè¯•ç‚¹ä»…é’ˆå¯¹ä¸€ç»„ç‰¹å®šçš„å®¢æˆ·(ä¾‹å¦‚ï¼Œæ‹¥æœ‰ç‰¹å®šè®¾å¤‡çš„å®¢æˆ·ç±»åˆ«ï¼Œæˆ–å±äºç‰¹å®šç±»åˆ«çš„å®¢æˆ·ç±»åˆ«)ã€‚

ä¸ºäº†äº†è§£å¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µï¼Œæœ‰å¿…è¦é‡åŒ–å®¢æˆ·ç¾¤ä¸­æœ‰å¤šå°‘è®°å½•å—åˆ°å½±å“:

```
print(fâ€™Customer base contains {len(customer_base)} records.â€™)affected_records = len(
 customer_base[customer_base[â€˜V19â€™].isin(pilot[â€˜V19â€™].unique())])print(fâ€™Number of record affected by category mismatch is: {affected_records}â€™)print(fâ€™{100 â€” (affected_records / len(customer_base) * 100)}%â€™)
print(fâ€™count of affected records: {len(customer_base) â€” affected_records}â€™)
```

![](img/d880d81f90693ec9d044288cff1ce757.png)

ç”±äºè¯¥ä»»åŠ¡ä¸­å—å½±å“çš„è®°å½•æ•°é‡å¾ˆå°‘(59 æ¡),æ˜¯å¦å†³å®šæ ¹æ®`V19`å˜é‡ä¸‹è¯•ç‚¹æ•°æ®é›†ä¸­çš„ç›¸åŒç±»åˆ«è·³è¿‡å¹¶è¿‡æ»¤å®¢æˆ·ç¾¤ã€‚

```
customer_base = customer_base[customer_base[â€˜V19â€™].isin(pilot[â€˜V19â€™].unique())]
```

ç†è§£æ•°æ®çš„å¦ä¸€ä¸ªé‡è¦æ­¥éª¤æ˜¯ç»˜åˆ¶æ¯ä¸ªå˜é‡çš„åˆ†å¸ƒå›¾ï¼Œè¿™æ¬¡æ˜¯é€šè¿‡é‡å ä¸¤ä¸ªå†³ç­–çš„æ•°æ®:

```
# distribution of features
features = sorted(
 [i for i in pilot.columns if pilot.dtypes[i] != â€˜objectâ€™])plt.figure(figsize=(12, 28*4))
gs = gridspec.GridSpec(28, 1)for i, cn in enumerate(pilot[features]):
 ax = plt.subplot(gs[i])
 sns.distplot(pilot[cn][pilot.purchase == 1], bins=50, label=â€™Purchasedâ€™)
 sns.distplot(pilot[cn][pilot.purchase == 0],
 bins=50, label=â€™Not purchasedâ€™)
 ax.set_xlabel(â€˜â€™)
 ax.legend()
 ax.set_title(â€˜histogram of feature: â€˜ + str(cn))
plt.show()
```

![](img/ba1d8088ebfe2724e2298c55c07f6e66.png)

ä½œè€…çš„å›¾è¡¨

æ ¹æ®å›¾è¡¨ï¼Œä¸€äº›å˜é‡ï¼Œå¦‚`V7`ã€`V20`ã€`V10`çœ‹èµ·æ¥æœ‰ç‚¹åƒé«˜æ–¯ï¼Œè¿™è¡¨æ˜äº†ä¸€ç§å¯èƒ½æ€§ï¼Œä¾‹å¦‚ï¼Œå°è¯•ä½¿ç”¨å…·æœ‰ RBF æ ¸çš„æ”¯æŒå‘é‡æœºå»ºæ¨¡ã€‚

æ­¤ä»»åŠ¡çš„ç›®æ ‡æ˜¯æ‹Ÿåˆä¸€ä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼Œè¿™æœ‰åŠ©äºæ£€æŸ¥ç›®æ ‡å˜é‡ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡:

```
pilot[â€˜purchaseâ€™].value_counts().plot(kind=â€™barâ€™)
print(pilot[â€˜purchaseâ€™].value_counts())
```

![](img/7ed0ea4007d480c71fe07c9282607bb3.png)

ç›®æ ‡å˜é‡å…·æœ‰éå¸¸å¼ºçš„ä¸å¹³è¡¡ï¼Œå¤§çº¦ä¸º 9:91ã€‚

# ç»“è®º:

æ ¹æ®è¿™ç§æ¢ç´¢æ€§çš„æ•°æ®åˆ†æï¼Œæœ‰å¯èƒ½å¾—å‡ºä»¥ä¸‹ç»“è®º:

*   åœ¨æ²»ç–—ç»„å’Œå¯¹ç…§ç»„ä¹‹é—´å­˜åœ¨çº¦ 2.3%çš„å·®å¼‚
*   é™¤äº†è¿ç»­å˜é‡å¤–ï¼Œæ•°æ®é›†è¿˜åŒ…å«ä¸¤ä¸ªåˆ†ç±»å˜é‡å’Œä¸€ä¸ªäºŒå…ƒå˜é‡ã€‚å‡ºäºå»ºæ¨¡ç›®çš„ï¼Œéœ€è¦è®°ä½è¿™ä¸€ç‚¹
*   æœ€å¤§(å¯è¡Œ)åˆ©æ¶¦ä¸º 2ï¼Œ256ï¼Œ250 å•ä½
*   ç›®æ ‡å˜é‡ä¸­å­˜åœ¨å¼ºçƒˆçš„ä¸å¹³è¡¡

 [## 5-bullet æ•°æ®ç§‘å­¦ä¸æŠ€æœ¯ğŸ“¡

### ç¼–è¾‘æè¿°

æ— æƒ…-åˆ›é€ è€…-2481.ck.page](https://relentless-creator-2481.ck.page/68d9def351) 

# 2.0 æ•°æ®å‡†å¤‡

æœ¬èŠ‚æ—¨åœ¨æ‹Ÿåˆç¬¬ä¸€ä¸ªæ¨¡å‹(éšæœºæ¢¯åº¦æ¨è¿›é›†åˆ)ä¹‹å‰å‡†å¤‡æ•°æ®ã€‚

å‡ºäºæ¨¡å‹æ‹Ÿåˆçš„ç›®çš„ï¼Œæ­£åœ¨ä½¿ç”¨é£è¡Œå‘˜æ•°æ®é›†ã€‚ç„¶è€Œï¼Œä¸ä¼šä½¿ç”¨`treatment`åˆ—ï¼Œå› ä¸ºå®ƒä¸æ˜¯ç»™å®šç”¨æˆ·çš„å›ºæœ‰ç‰¹æ€§ï¼Œè€Œæ˜¯éšæœºåˆ†é…çš„ç»„ã€‚

```
pilot = pilot.drop(â€˜treatmentâ€™, axis=1)
```

å¦‚å‰ä¸€èŠ‚æ‰€è¿°ï¼Œåœ¨ç›®æ ‡å˜é‡`purchase`ä¸­å¯ä»¥è§‚å¯Ÿåˆ°å¼ºçƒˆçš„é˜¶çº§ä¸å¹³è¡¡ã€‚æœ‰è®¸å¤šæ–¹æ³•æ¥å¤„ç†ç±»ä¸å¹³è¡¡(è¿‡é‡‡æ ·ã€æ¬ é‡‡æ ·ã€Tomek é“¾æ¥ã€SMOTE...)ï¼Œå¹¶ä¸”è€ƒè™‘äºŒè¿›åˆ¶åˆ†ç±»å™¨ï¼Œä»…ä»…é€šè¿‡é¢„æµ‹å¤šæ•°ç±»æ¥è·å¾—ç›¸å½“é«˜çš„å‡†ç¡®åº¦æ˜¯å¸¸è§çš„ï¼Œè€Œå®ƒæœªèƒ½æ•è·å°‘æ•°ç±»ï¼Œè¿™é€šå¸¸æ˜¯é¦–å…ˆåˆ›å»ºæ¨¡å‹çš„ç›®çš„ã€‚

æ­¤å¤–ï¼Œä»å•†ä¸šè§’åº¦æ¥çœ‹ï¼Œå…·æœ‰æ›´ä¿å®ˆçš„åˆ†ç±»å™¨å…·æœ‰ç»æµæ„ä¹‰ï¼Œè¿™æ„å‘³ç€ç›¸å¯¹äºå‡é˜´æ€§å…·æœ‰é«˜æ¯”ç‡çš„çœŸé˜³æ€§çš„åˆ†ç±»å™¨ã€‚è¿™ä¸€é€‰æ‹©èƒŒåçš„åŸºæœ¬åŸç†æ˜¯ï¼Œè”ç³»æ½œåœ¨å®¢æˆ·æ˜¯æœ‰æˆæœ¬çš„ï¼Œæˆ‘ä»¬åªå¯¹æœ‰é«˜è´­ä¹°æœºä¼šçš„æ½œåœ¨å®¢æˆ·æ„Ÿå…´è¶£ã€‚

å¯¹äºè¿™é¡¹ä»»åŠ¡ï¼Œä½¿ç”¨çš„é‡‡æ ·æŠ€æœ¯æ˜¯ SMOTEã€‚è¯¥æŠ€æœ¯çš„å·¥ä½œåŸç†æ˜¯ä»å°‘æ•°ç±»ä¸­éšæœºé€‰å–ç‚¹ï¼Œå¹¶è®¡ç®—è¯¥ç‚¹çš„ k-æœ€è¿‘é‚»ã€‚

ç„¶è€Œï¼Œä¸ºäº†å®ç°è¯¥ç®—æ³•ï¼Œåœ¨éœ€è¦å°†æ•°æ®é›†åˆ†å‰²æˆç‰¹å¾å’Œç›®æ ‡ï¼Œå¹¶é€šè¿‡è·å–è™šæ‹Ÿå˜é‡å¯¹åˆ†ç±»å˜é‡è¿›è¡Œç¼–ç ä¹‹å‰ï¼Œéœ€è¦ä½¿ç”¨`imblearn`åº“:

è¿™ç§é€‰æ‹©èƒŒåçš„åŸºæœ¬åŸç†æ˜¯ï¼Œè¿™ç§æ–¹æ³•ä¸ä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±(è¿‡é‡‡æ ·)ï¼Œä½†æ˜¯ï¼Œæœ‰å¿…è¦æ³¨æ„ï¼Œè¿‡é‡‡æ ·æˆ–æ¬ é‡‡æ ·å¹¶ä¸æ€»æ˜¯æœ€ä½³é€‰æ‹©:åœ¨å¤„ç†çœŸå®ä¸–ç•Œçš„æ•°æ®æ—¶ï¼Œä¸€äº›ç°è±¡æœ¬è´¨ä¸Šæ˜¯ä¸å¹³è¡¡çš„ï¼Œå› æ­¤ï¼Œæ“çºµç›®æ ‡ç±»ä¼šæ‰­æ›²æ•°æ®çš„çœŸå®æ€§è´¨(å³æ¬ºè¯ˆæ£€æµ‹ã€æµå¤±ã€ä¿¡ç”¨è¿çº¦â€¦â€¦)

```
# get dummies of categorical variables for both datasetspilot = pd.get_dummies(pilot, columns=[â€˜V2â€™, â€˜V19â€™], drop_first=True)customer_base = pd.get_dummies(customer_base, columns=[
 â€˜V2â€™, â€˜V19â€™], drop_first=True)# set aside 150 random records from pilot and remove them
test_set = pilot.groupby('purchase').apply(
    lambda x: x.sample(frac=0.035, random_state=42))
# get list of indices to drop
drop_indices = [i[1] for i in test_set.index]# reset index and shuffle
test_set = test_set.reset_index(drop=True)
test_set = test_set.sample(frac=1)# drop indices from original dataset (to avoid training on them)
pilot = pilot.drop(drop_indices)# shuffle data
pilot = pilot.sample(frac=1)# select all columns but purchase
features = pilot.loc[:, pilot.columns != 'purchase']
targets = pilot['purchase']# make sure input data has the same shape as customer baseassert len(features.columns) == len(customer_base.columns)
```

é¢„å¤„ç†ä¸­ä¸€ä¸ªå¸¸è§çš„ï¼Œä½†å¹¶ä¸æ€»æ˜¯å¿…è¦çš„æ­¥éª¤æ˜¯æ ‡å‡†åŒ–ï¼Œå½“æ“ä½œå†³ç­–æ ‘æ—¶ï¼Œå®ƒå¹¶ä¸æ€»æ˜¯å¿…è¦çš„ï¼Œä½†å®ƒç¡®å®æ˜¯æ”¯æŒå‘é‡æœºçš„æ¨èæ­¥éª¤

```
from sklearn.preprocessing import StandardScalerscaler = StandardScaler()
features_scaled = scaler.fit_transform(features.values)# get a list of categorical columns indexes to fit SMONTENC
cat_columns = [features.columns.get_loc(i)
               for i in features.columns if '_' in i]from imblearn.over_sampling import SMOTENCsm = SMOTENC(categorical_features=cat_columns, k_neighbors=10)
X, y = sm.fit_resample(features_scaled, targets)
```

# 3.0 å»ºæ¨¡å’Œè¯„ä¼°

ä¸ºäº†è®­ç»ƒ/éªŒè¯çš„ç›®çš„ï¼Œä½¿ç”¨ k-fold äº¤å‰éªŒè¯æ¥åˆ†å‰²æ•°æ®é›†ï¼Œæ­¤å¤–ï¼Œåº”ç”¨ç½‘æ ¼æœç´¢æ¥æœç´¢æœ€ä½³å‚æ•°ï¼Œè¿™äº›å‚æ•°ç„¶åç”¨äºåœ¨æ•´ä¸ªè®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆæ¨¡å‹ã€‚è¿™ä¸ªç­–ç•¥æ˜¯æ ¹æ®[è¿™ä¸ª](https://stats.stackexchange.com/questions/11602/training-on-the-full-dataset-after-cross-validation)é—®é¢˜å’Œå¼•ç”¨çš„è®ºæ–‡é€‰æ‹©çš„ã€‚

åœ¨æ²¡æœ‰åº”ç”¨ä»»ä½•è¿‡é‡‡æ ·(æˆ–æ¬ é‡‡æ ·)çš„æƒ…å†µä¸‹ï¼Œæ›´æœ‰æ„è¯†çš„é€‰æ‹©å°†è¢«åˆ†å±‚ k å€ã€‚

# 3.1 å»ºæ¨¡â€” SVM

```
# get test data (unseen by the algorithm)X_test = scaler.transform(test_set.drop([â€˜purchaseâ€™], axis=1).values)
y_test = test_set[â€˜purchaseâ€™].values
```

ä¸ºäº†ä¾¿äºæ‹Ÿåˆå¤šä¸ªæ¨¡å‹ï¼Œå¿«é€Ÿè¿­ä»£è¿”å›æœ€ä½³å‚æ•°çš„ä¸“ç”¨å‡½æ•°å˜å¾—éå¸¸æœ‰ç”¨:

```
def fit_gs_model_w_report(model, scores, param_grid, X_train, y_train, X_test, y_test, n_jobs):
 â€˜â€™â€™
 Fit a model, generate classification report, and return best model params.
 â€˜â€™â€™for score in scores:
 print(â€œ# Tuning hyper-parameters for %sâ€ % score)
 print()model = GridSearchCV(model, param_grid, scoring=score, n_jobs=n_jobs)
 model.fit(X_train, y_train)print(â€œBest parameters set found on development set:â€)
 print()
 print(model.best_params_)
 print()
 print(â€œGrid scores on development set:â€)
 print()
 means = model.cv_results_[â€œmean_test_scoreâ€]
 stds = model.cv_results_[â€œstd_test_scoreâ€]
 for mean, std, params in zip(means, stds, model.cv_results_[â€œparamsâ€]):
 print(â€œ%0.3f (+/-%0.03f) for %râ€ % (mean, std * 2, params))
 print()print(â€œDetailed classification report:â€)
 print()
 print(â€œThe model is trained on the full development set.â€)
 print(â€œThe scores are computed on the full evaluation set.â€)
 print()
 y_true, y_pred = y_test, model.predict(X_test)
 print(classification_report_imbalanced(y_true, y_pred,
 target_names=[â€˜Not purchasedâ€™, â€˜Purchasedâ€™]))
 print()return model.best_params_
```

è®©æˆ‘ä»¬ä½¿ç”¨ç½‘æ ¼æœç´¢æ‹Ÿåˆç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶è§£é‡Šè¾“å‡ºç»“æœ:

```
scores = [â€œroc_aucâ€]param_grid_svc = {â€œkernelâ€: [â€œrbfâ€],
 â€œgammaâ€: [1e-2, 1e-3, 1e-4],
 â€œCâ€: [1000, 10000],
 â€œclass_weightâ€: [â€˜balancedâ€™]
 }
svc_best_params = fit_gs_model_w_report(model=SVC(),
 scores=scores,
 param_grid=param_grid_svc,
 X_train=X,
 y_train=y,
 X_test=X_test,
 y_test=y_test,
 n_jobs=-1)
```

![](img/64cdf8e3a0f70b5de4581047740eb41e.png)

æ ¹æ®`Purchased`ç±»åˆ«çš„ç²¾ç¡®åº¦å’Œå¬å›åˆ†æ•°ï¼Œå½“æ¨¡å‹å£°ç§°è§‚å¯Ÿç¡®å®æ˜¯è´­ä¹°æ—¶ï¼Œå®ƒæœ‰ 29%çš„æ—¶é—´æ˜¯æ­£ç¡®çš„ï¼Œå¹¶ä¸”å®ƒèƒ½å¤Ÿæ£€æµ‹åˆ° 40%çš„è´­ä¹°ï¼Œä½†æ˜¯é‡è¦çš„æ˜¯è¦æ³¨æ„æµ‹è¯•é›†ä¸­æœ‰å¾ˆå¤§çš„ä¸å¹³è¡¡(160 ä¸ªé˜´æ€§æ ·æœ¬ï¼Œåªæœ‰ 15 ä¸ªé˜³æ€§æ ·æœ¬)

ç°åœ¨ï¼Œä½¿ç”¨æ•´ä¸ªæ•°æ®é›†æ‹Ÿåˆå…·æœ‰æœ€ä½³å‚æ•°çš„æœ€ç»ˆ SVC æ¨¡å‹:

```
best_svc = SVC(probability=True)
best_svc.set_params(**svc_best_params)best_svc.fit(X, y)y_scores_svc = cross_val_predict(
    best_svc, X, y, cv=10, method='predict_proba', n_jobs=-1)# since predict_proba returns predictions for each class, we need to focus on the positive class
y_scores_svc = y_scores_svc[:, 1]precisions_svc, recall_svc, thresholds_svc = precision_recall_curve(
    y, y_scores_svc)
```

ä¸ºäº†å°†è¯¥åˆ†ç±»å™¨ä¸å¦ä¸€ä¸ªæ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥ä½¿ç”¨ F1 åˆ†æ•°ï¼Œä½†æ˜¯ï¼ŒF1 åˆ†æ•°å€¾å‘äºå…·æœ‰ç›¸ä¼¼ç²¾åº¦å’Œå¬å›ç‡çš„åˆ†ç±»å™¨ã€‚

ç†æƒ³æƒ…å†µä¸‹ï¼Œå¯¹äºæ­¤ä»»åŠ¡ï¼Œæœ€å¥½ä½¿ç”¨å¬å›ç‡ç¨ä½ä½†ç²¾ç¡®åº¦è¾ƒé«˜çš„åˆ†ç±»å™¨ï¼Œè¿™æ„å‘³ç€ ABC Telco è”ç³»çš„å®¢æˆ·è´­ä¹°è¯¥è®¡åˆ’çš„å¯èƒ½æ€§è¾ƒé«˜ã€‚

ä¸ºäº†è¿›ä¸€æ­¥è°ƒæ•´è¿™ä¸€ç‚¹ï¼Œå¯ä»¥è®¿é—®æ¨¡å‹çš„å†³ç­–å¾—åˆ†ï¼Œç„¶åå¯ä»¥é€‰æ‹©é€‚å½“çš„é˜ˆå€¼:

```
def plot_precision_recall_vs_threshold(precisions, recall, thresholds):
 plt.plot(thresholds, precisions[:-1], â€œb â€” â€œ,
 label=â€Precisionâ€, linewidth=2)plt.plot(thresholds, recall[:-1], â€œg-â€, label=â€Recallâ€, linewidth=2)
 plt.xlabel(â€œThresholdâ€, fontsize=16)
 plt.legend(loc=â€upper leftâ€, fontsize=16)
 plt.ylim([0, 1])
 plt.grid()
 plt.legend()plot_precision_recall_vs_threshold(precisions_svc, recall_svc, thresholds_svc)
```

![](img/c619b16f771ed4893dcd2660975b74ed.png)

ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨é˜ˆå€¼çº¦ä¸º 0.70 æ—¶ï¼Œç²¾åº¦ä¼šä¸‹é™åˆ° 90%ä»¥ä¸‹ã€‚

å¦ä¸€ç§é€‰æ‹©æœ€åˆé€‚é˜ˆå€¼çš„å¸¸ç”¨æ–¹æ³•æ˜¯ç›´æ¥ç»˜åˆ¶ç²¾åº¦ä¸å¬å›ç‡çš„å…³ç³»å›¾:

```
plt.plot(precisions_svc, recall_svc)
plt.grid()
plt.xlabel(â€˜Precisionâ€™)
plt.ylabel(â€˜Recallâ€™)
```

![](img/248144d9be03c09ff398c9f8b29433ee.png)

ä»å›¾è¡¨ä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨å¤§çº¦ 90%çš„å¬å›ç‡æ—¶ï¼Œå‡†ç¡®ç‡å¼€å§‹æ€¥å‰§ä¸‹é™ã€‚è¿™æ„å‘³ç€ï¼Œå¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œå°†é€‰æ‹©åœ¨è¯¥æŠ•æ”¾ä¹‹å‰çš„ç²¾åº¦/å¬å›æŠ˜è¡·ã€‚

```
# get the threshold at which precision is 90%
threshold_90_precision_svc = thresholds_svc[np.argmax(precisions_svc >= 0.9)]ps_svc = precision_score(y, y_scores_svc > threshold_90_precision_svc)
print(fâ€™Precision: {ps_svc * 100}%â€™)
```

![](img/d5cbe8c5e64e4e8f72016c62575abf83.png)

ç„¶è€Œï¼Œå¬å›åˆ†æ•°å¤ªä½çš„åˆ†ç±»å™¨ä¹Ÿä¸æ˜¯å¾ˆæœ‰ç”¨ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨è°ƒæ•´ä¹‹åè¿˜éœ€è¦è¯„ä¼°å¬å›åˆ†æ•°çš„åŸå› :

```
rs_svc = recall_score(y, y_scores_svc > threshold_90_precision_svc)
print(fâ€™Recall: {rs_svc * 100}%â€™)
```

![](img/45aabc68c09ba36db6d23b91231c3d4d.png)

# 3.2 æ¢¯åº¦æå‡åˆ†ç±»å™¨

æœ¬èŠ‚è¯•å›¾æ‹Ÿåˆç¬¬äºŒä¸ª(ç†æƒ³æƒ…å†µä¸‹æ€§èƒ½æ›´å¥½çš„)æ¨¡å‹ã€‚æ‹Ÿåˆçš„æ¨¡å‹æ˜¯åŸºäº LightGBM åº“çš„æ¢¯åº¦æå‡åˆ†ç±»å™¨ã€‚æ­£åœ¨è¿›è¡Œç½‘æ ¼æœç´¢ï¼Œä»¥æ‰¾åˆ°æœ€ä½³å‚æ•°ï¼Œç‰¹åˆ«æ˜¯æ·»åŠ äº†`reg_alpha`ã€`reg_lambda`ã€`min_data_in_leaf`å’Œ`num_leaves`ï¼Œè¯•å›¾é˜²æ­¢è¿‡åº¦æ‹Ÿåˆ(åœ¨åŸºäºæ ‘çš„æ–¹æ³•ä¸­éå¸¸å¸¸è§)

```
scores = [â€œroc_aucâ€]param_grid_lgbm = {
 â€˜learning_rateâ€™: [0.5],
 â€˜n_estimatorsâ€™: [96],
 â€˜num_leavesâ€™: [64, 128],
 â€˜boosting_typeâ€™: [â€˜gbdtâ€™],
 â€˜objectiveâ€™: [â€˜binaryâ€™],
 â€˜max_binâ€™: [416],
 â€˜random_stateâ€™: [500],
 â€˜colsample_bytreeâ€™: [0.32],
 â€˜min_data_in_leafâ€™: [50],
 â€˜subsampleâ€™: [0.3],
 â€˜class_weightâ€™: [â€˜balancedâ€™],
 â€˜reg_alphaâ€™: [0.01, 0.05],
 â€˜reg_lambdaâ€™: [0.01],
 â€˜feature_fractionâ€™: [0.2, 0.4]
}lgbm_best_params = fit_gs_model_w_report(model=lgbm.LGBMClassifier(n_jobs=1), 
 scores=scores,
 param_grid=param_grid_lgbm, 
 X_train=X, 
 y_train=y,
 X_test=X_test, 
 y_test=y_test,
 n_jobs=-1)
```

![](img/bf8ec9269fc53d0982336272df8737b0.png)

åŒæ ·ï¼Œä½¿ç”¨æ¥è‡ªç½‘æ ¼æœç´¢çš„æœ€ä½³å‚æ•°æ¥æ‹Ÿåˆæœ€ç»ˆæ¨¡å‹:

```
best_lgbm = lgbm.LGBMClassifier()
best_lgbm.set_params(**lgbm_best_params)best_lgbm.fit(X, y)
```

æ ¹æ®ç²¾åº¦å’Œå¬å›æŒ‡æ ‡ï¼Œè¯¥æ¨¡å‹ä¼¼ä¹æ‰§è¡Œå¾—æ›´å¥½ï¼Œä½†æ˜¯ï¼Œå¿…é¡»è®°ä½ï¼Œä½¿ç”¨è¯¥ç®—æ³•å®¶æ—å¯èƒ½å¯¼è‡´ä¸¥é‡çš„è¿‡åº¦æ‹Ÿåˆã€‚

```
y_scores_lgbm = cross_val_predict(
 best_lgbm, X, y, cv=10, method=â€™predict_probaâ€™, n_jobs=-1)# since predict_proba returns predictions for each class, we need to focus on the positive class
y_scores_lgbm = y_scores_lgbm[:, 1]precisions_lgbm, recall_lgbm, thresholds_lgbm = precision_recall_curve(
 y, y_scores_lgbm)plot_precision_recall_vs_threshold(
    precisions_lgbm, recall_lgbm, thresholds_lgbm)
```

![](img/61f0ffa951a9cc60f3441819f23493c8.png)

```
plt.plot(precisions_lgbm, recall_lgbm)
plt.grid()
plt.xlabel(â€˜Precisionâ€™)
plt.ylabel(â€˜Recallâ€™)
```

![](img/a36f1e5bca5531fb3024d4a924aefad4.png)

ä½¿ç”¨ä¸ SVC ç›¸åŒçš„æ–¹æ³•é€‰æ‹©æ¨¡å‹çš„é˜ˆå€¼ã€‚

```
# get the threshold at which precision is 90%
threshold_90_precision_lgbm = thresholds_lgbm[np.argmax(
 precisions_lgbm >= 0.90)]ps_lgbm = precision_score(y, y_scores_lgbm > threshold_90_precision_lgbm)
print(fâ€™Precision lgbm model: {ps_lgbm * 100}%â€™)rs_lgbm = recall_score(y, y_scores_lgbm > threshold_90_precision_lgbm)
print(fâ€™Recall: {rs_lgbm * 100}%â€™)
```

![](img/5529b37320957c704a7380fbd477fc7c.png)

# 3.3 æ¨¡å‹è¯„ä¼°

æœ¬èŠ‚æ ¹æ®è¯„ä¼°é›†è¯„ä¼°è¿™ä¸¤ä¸ªæ¨¡å‹ï¼Œè®¨è®ºå®ƒä»¬ä¹‹é—´çš„å·®å¼‚å’Œç»†å¾®å·®åˆ«ï¼Œé€‰æ‹©æœ€ç»ˆæ¨¡å‹ï¼Œå¹¶æ ¹æ®å®¢æˆ·ç¾¤è®¡ç®—é¢„æµ‹ã€‚

# SVC:

```
# get test dataX_test = scaler.transform(test_set.drop([â€˜purchaseâ€™], axis=1).values)
y_test = test_set[â€˜purchaseâ€™].values# scale data in the customer base
customer_base_scaled = scaler.transform(customer_base)y_scores_svc = best_svc.predict_proba(X_test)# without threshold manipulation
evs_cm_svc = confusion_matrix(y_test, y_scores_svc[:, 1] > 0.5)
ConfusionMatrixDisplay(evs_cm_svc).plot()
```

![](img/6639aed1b4597de00c31f988f2267ce6.png)

```
evs_cmt_svc = confusion_matrix(
 y_test, y_scores_svc[:, 1] > threshold_90_precision_svc)
ConfusionMatrixDisplay(evs_cmt_svc).plot()
```

![](img/897484dc372560f1f3c507a3c531e88e.png)

ä»æ··æ·†çŸ©é˜µå¯ä»¥çœ‹å‡ºï¼Œæ ¹æ®æœŸæœ›çš„ç›®æ ‡è°ƒæ•´é˜ˆå€¼å¯ä»¥å‡å°‘å‡é˜³æ€§çš„æ•°é‡ï¼Œä»è€Œå¯¼è‡´æˆæœ¬çš„é™ä½ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è¿™äº›é¢„æµ‹æ˜¯å¦‚ä½•é’ˆå¯¹å®¢æˆ·ç¾¤çš„:

```
final_predictions_svc = best_svc.predict_proba(customer_base_scaled)constraint = int(len(customer_base) * 0.25)final_predictions_svc_df = pd.DataFrame(
    {'prediction': final_predictions_svc[:, 1] > threshold_90_precision_svc, 'probability': final_predictions_svc[:, 1]})# sort final prediction by score to then apply the 1/4 constraint in a safe way
final_predictions_svc_df = final_predictions_svc_df.sort_values(
    by='probability', ascending=False)final_predictions_svc_df = final_predictions_svc_df[final_predictions_svc_df['prediction'] == True]
print(
    f'The SVC model would decide to contact {len(final_predictions_svc_df)} customers out of a maximum of {constraint}')The SVC model would decide to contact 11618 customers out of a maximum of 23735
```

SVC æ¨¡å‹å°†å»ºè®®è”ç³»å‘¼å«ä¸­å¿ƒå¯è¡Œçš„å¤šä¸ªå®¢æˆ·ã€‚

ä¸ºäº†æ¨¡æ‹Ÿä¼°è®¡æœ‰å¤šå°‘å®¢æˆ·åœ¨æ¥è§¦åä¼šå®é™…è´­ä¹°è¯¥è®¡åˆ’ï¼Œå‡è®¾æ¦‚ç‡ä¸º 50%ï¼Œä»åˆ†å¸ƒä¸­æŠ½å–ä¸€ä¸ªäºŒé¡¹å¼éšæœºå˜é‡:

```
buy_decision_svc = binom.rvs(1, .5, size=len(final_predictions_svc_df))
final_predictions_svc_df[â€˜buy_decision_svcâ€™] = buy_decision_svc# cost of contacting a customer:
total_positive_predictions_svc = len(final_predictions_svc_df)total_buying_decisions_svc = len(
    final_predictions_svc_df[final_predictions_svc_df['buy_decision_svc'] == 1])total_costs_svc = total_positive_predictions_svc * 5# discounted revenues for all customer who purchased
total_revenues_svc = total_buying_decisions_svc * 100profit_svc = total_revenues_svc - total_costs_svcprint(
    f'Total total cost of contacting selected customers is {total_costs_svc} units')
print(
    f'Total revenues (incremental discounts) will be of {total_revenues_svc} units')
print(
    f'Total profit for this scenario is: {profit_svc} units, based on {len(final_predictions_svc_df)} customers of which {len(final_predictions_svc_df[final_predictions_svc_df["buy_decision_svc"] == 1])} purchased')
```

![](img/9e0e20b5b73a3d6c2075deccea5df8b2.png)

```
# save business result to a table
final_business_results = pd.DataFrame({
 â€˜modelâ€™: â€˜SVCâ€™,
 â€˜total_cost_contacting_customersâ€™: total_costs_svc,
 â€˜total_customer_baseâ€™: len(customer_base),
 â€˜contacted customersâ€™: len(final_predictions_svc_df),
 â€˜amount_of_customers_who_purchasedâ€™: len(final_predictions_svc_df[final_predictions_svc_df[â€œbuy_decision_svcâ€] == 1]),
 â€˜total_revenuesâ€™: total_revenues_svc,
 â€˜profitâ€™: profit_svc
}, index=[0])
```

![](img/07ab2f97cde0faaf853f53f91f2f91ae.png)

# LGBM:

```
# get test dataX_test = scaler.transform(test_set.drop([â€˜purchaseâ€™], axis=1).values)
y_test = test_set[â€˜purchaseâ€™].values# scale data in the customer base
customer_base = scaler.transform(customer_base)evs_pred_lgbm = best_lgbm.predict_proba(X_test)# without threshold manipulationevs_cm_lgbm = confusion_matrix(y_test, evs_pred_lgbm[:, 1] > 0.5)
ConfusionMatrixDisplay(evs_cm_lgbm).plot()
```

![](img/bc53ad2d15d33e4fb78e81efa3464dac.png)

```
evs_cmt_lgbm = confusion_matrix(
 y_test, evs_pred_lgbm[:, 1] > threshold_90_precision_lgbm)
ConfusionMatrixDisplay(evs_cmt_lgbm).plot()
```

![](img/2b844c4e3899f37b65fafb905062b48c.png)

æ¯”è¾ƒæœ€ç»ˆçš„ç²¾åº¦å’Œå¬å›æŒ‡æ ‡(è°ƒæ•´é˜ˆå€¼å)æ˜¾ç¤ºï¼Œç¬¬äºŒä¸ªæ¨¡å‹åœ¨å¬å›æ–¹é¢æ˜¾è‘—å¢åŠ ï¼Œè€Œç²¾åº¦ä¿æŒä¸å˜ã€‚å¦ä¸€æ–¹é¢ï¼Œåœ¨è¿™ä¸ªé˜¶æ®µï¼Œå°†ä¸¤ä¸ªæ¨¡å‹çš„æ··æ·†çŸ©é˜µæ”¾åœ¨ä¸€èµ·ç»˜å›¾å¯èƒ½æ˜¯æœ‰æ„ä¹‰çš„:

```
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18, 4))fig.suptitle(â€˜SVC VS LGBM â€” Confusion matrixâ€™)
ConfusionMatrixDisplay(evs_cmt_lgbm).plot(ax=axs[0])
axs[0].set_title(â€˜LGBMâ€™)ConfusionMatrixDisplay(evs_cmt_svc
 ).plot(ax=axs[1])
axs[1].set_title(â€˜SVCâ€™)
```

![](img/eccecd944b44021b27b3e623f1069bcb.png)

```
final_predictions_lgbm = best_lgbm.predict_proba(customer_base_scaled)
```

ä»å›¾ä¸­å¯ä»¥è§‚å¯Ÿåˆ°ï¼ŒLGBM æ¨¡å‹åœ¨æ•æ‰çœŸé˜³æ€§æ–¹é¢ç¡®å®æ›´å¥½ï¼Œè€Œå‡é˜´æ€§çš„æ•°é‡ä» 12 ä¸ªå‡å°‘åˆ°äº† 9 ä¸ªã€‚å¦ä¸€æ–¹é¢ï¼Œå‡é˜³æ€§çš„æ•°é‡ç•¥æœ‰å¢åŠ ã€‚ç„¶è€Œï¼Œä»å•†ä¸šè§’åº¦æ¥çœ‹ï¼Œè”ç³» 4 ä¸ªé¢å¤–çš„æ½œåœ¨å®¢æˆ·è‚¯å®šä¼šå¢åŠ  20 ä¸ªå•ä½çš„æˆæœ¬ï¼Œä½†ä»é•¿è¿œæ¥çœ‹ï¼Œç„å‡† 3 ä¸ªå®é™…è´­ä¹°è¯¥è®¡åˆ’çš„æ½œåœ¨å®¢æˆ·ä¼šå¸¦æ¥æ›´é«˜çš„åˆ©æ¶¦ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ LGB æ¨¡å‹è¢«ç”¨ä½œæœ€ç»ˆæ¨¡å‹ã€‚

```
final_predictions_lgbm_df = pd.DataFrame(
 {â€˜predictionâ€™: final_predictions_lgbm[:, 1] > threshold_90_precision_lgbm, â€˜probabilityâ€™: final_predictions_lgbm[:, 1]})# sort final prediction by score to then apply the 1/4 constraint in a safe way
final_predictions_lgbm_df = final_predictions_lgbm_df.sort_values(
 by=â€™probabilityâ€™, ascending=False)final_positive_predictions_lgbm_df = final_predictions_lgbm_df[
 final_predictions_lgbm_df[â€˜predictionâ€™] == True]
print(
 fâ€™The LGBM model would decide to contact {len(final_positive_predictions_lgbm_df)} customers out of a maximum of {constraint}â€™)
```

![](img/bd7e31bc94bb3189dc61f050246f133a.png)

æ˜¾ç„¶ï¼ŒLGBM æ¨¡å‹æ¯” SVC æ¨¡å‹æ›´æ…·æ…¨ã€‚

æ ¹æ®äºŒé¡¹å¼åˆ†å¸ƒæ¨¡æ‹Ÿæœ€ç»ˆå†³ç­–:

```
buy_decision_lgbm = binom.rvs(
 1, .5, size=len(final_positive_predictions_lgbm_df))
final_positive_predictions_lgbm_df[â€˜buy_decision_lgbmâ€™] = buy_decision_lgbm# cost of contacting a customer:
total_positive_predictions_lgbm = len(
 final_positive_predictions_lgbm_df[final_positive_predictions_lgbm_df[â€˜predictionâ€™] == True])total_buying_decisions_lgbm = len(
 final_positive_predictions_lgbm_df[final_positive_predictions_lgbm_df[â€˜buy_decision_lgbmâ€™] == True])total_costs_lgbm = total_positive_predictions_lgbm * 5# discounted revenues for all customer who purchased
total_revenues_lgbm = total_buying_decisions_lgbm * 100profit_lgbm = total_revenues_lgbm â€” total_costs_lgbmprint(
 fâ€™Total total cost of contacting selected customers is {total_costs_lgbm} unitsâ€™)
print(
 fâ€™Total revenues (incremental discounts) will be of {total_revenues_lgbm} unitsâ€™)
print(
 fâ€™Total profit for this scenario is: {profit_lgbm} units, based on {len(final_positive_predictions_lgbm_df)} customers of which {len(final_positive_predictions_lgbm_df[final_positive_predictions_lgbm_df[â€œbuy_decision_lgbmâ€] == 1])} purchasedâ€™)
```

![](img/356ea2785c44c5d377dc2ec319b798a8.png)

ç°åœ¨å¯ä»¥åˆ›å»ºä¸€ä¸ªæœ€ç»ˆè¡¨æ¥æ¯”è¾ƒä¸šåŠ¡ç›¸å…³æ•°æ®:

```
# save business result to a table
final_business_results = final_business_results.append({
 â€˜modelâ€™: â€˜LGBMâ€™,
 â€˜total_cost_contacting_customersâ€™: total_costs_lgbm,
 â€˜total_customer_baseâ€™: len(customer_base),
 â€˜contacted customersâ€™: len(final_positive_predictions_lgbm_df),
 â€˜amount_of_customers_who_purchasedâ€™: len(final_positive_predictions_lgbm_df[final_positive_predictions_lgbm_df[â€œbuy_decision_lgbmâ€] == 1]),
 â€˜total_revenuesâ€™: total_revenues_lgbm,
 â€˜profitâ€™: profit_lgbm
}, ignore_index=True)
```

é‡è¦çš„æ˜¯è¦çŸ¥é“ï¼Œç”±äºæœ€ç»ˆçš„è´­ä¹°å†³ç­–æ˜¯ç”±éšæœºå‡½æ•°æ¨¡æ‹Ÿçš„ï¼Œæ‰€ä»¥ä¸Šé¢çš„ä¼°è®¡å€¼å¯èƒ½ä¼šæœ‰ç»†å¾®çš„å˜åŒ–(å°½ç®¡å‡ºäºå†ç°æ€§ç›®çš„å£°æ˜äº†ä¸€ä¸ªç§å­)ã€‚

ä¸‹è¡¨åˆ—å‡ºäº†é¢„è®¡çš„æˆæœ¬ã€æ”¶å…¥å’Œåˆ©æ¶¦:

![](img/39cc365cfa4ed7c24137b769d2f65ebd.png)

è¿™ä¸ªä»»åŠ¡çš„ç›®æ ‡æ˜¯ä»è¿™ä¸ªæ´»åŠ¨ä¸­è·å¾—æœ€å¤§åˆ©æ¶¦ï¼Œå› æ­¤ LGBM æ¨¡å‹è¢«é€‰ä¸ºæœ€ç»ˆæ¨¡å‹ã€‚

# 4.0 ç»“è®º

è€ƒè™‘åˆ°è¿™ä¸ªä»»åŠ¡æ˜¯åœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šå®Œæˆçš„ï¼Œæˆ‘ä¸æƒ³ä½¿ç”¨ä»»ä½•è®¡ç®—é‡å¤ªå¤§çš„æŠ€æœ¯ï¼Œæ¯”å¦‚æ›´å¹¿æ³›çš„ç½‘æ ¼æœç´¢ã€‚æˆ‘ç›¸ä¿¡æé«˜è¿™ä¸ªæ¨¡å‹å‡†ç¡®æ€§çš„å…³é”®åœ¨äºæ›´é«˜çº§çš„æ•°æ®é¢„å¤„ç†ã€‚åœ¨è¿­ä»£ä¸åŒçš„é¢„å¤„ç†æŠ€æœ¯æ—¶ï¼Œæˆ‘å‡ ä¹ç«‹å³æ³¨æ„åˆ°äº†è§„èŒƒåŒ–æ˜¯å¦‚ä½•æé«˜æ¨¡å‹è¾“å‡ºçš„ã€‚

æ­¤å¤–ï¼Œè·å¾—æ›´å¤šæ•°æ®(+100K æ ‡è®°çš„è§‚å¯Ÿå€¼)å°†ä½¿å‰é¢æåˆ°çš„æŠ€æœ¯æ›´åŠ å¼ºå¤§ã€‚

æé«˜äº§é‡çš„å¯èƒ½æ–¹æ³•:

*   è·å¾—æ›´å¤šçš„è®¡ç®—èƒ½åŠ›å°†ä½¿è¶…å‚æ•°ä¼˜åŒ–æ›´å¿«ã€æ›´å®¹æ˜“å®ç°
*   äº†è§£ç‰¹æ€§çš„å•†ä¸šæ„ä¹‰å°†æœ‰åŠ©äºå˜é‡é€‰æ‹©/è§£é‡Š
*   æ›´å¹¿æ³›çš„é¢„å¤„ç†è¯•éªŒå’Œé”™è¯¯(ä»¥åŠå¿«é€Ÿè¿­ä»£çš„è®¡ç®—èƒ½åŠ›)
*   æ›´å¤šè®­ç»ƒæ•°æ®

```
**I have a newsletter ğŸ“©.** Every week Iâ€™ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe. *That means* ***a lot*** *for me.*
```

 [## 5-bullet æ•°æ®ç§‘å­¦ä¸æŠ€æœ¯ğŸ“¡

### ç¼–è¾‘æè¿°

æ— æƒ…-åˆ›é€ è€…-2481.ck.page](https://relentless-creator-2481.ck.page/68d9def351) 

# åˆ†çº§ç¼–ç 

æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:

*   ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰
*   ğŸ“°æŸ¥çœ‹[çº§ç¼–ç å‡ºç‰ˆç‰©](https://levelup.gitconnected.com/?utm_source=pub&utm_medium=post)ä¸­çš„æ›´å¤šå†…å®¹
*   ğŸ””å…³æ³¨æˆ‘ä»¬:[Twitter](https://twitter.com/gitconnected)|[LinkedIn](https://www.linkedin.com/company/gitconnected)|[æ—¶äº‹é€šè®¯](https://newsletter.levelup.dev)

ğŸš€ğŸ‘‰ [**åŠ å…¥å‡çº§è¾¾äººé›†ä½“ï¼Œæ‰¾åˆ°ä¸€ä»½æƒŠè‰³çš„å·¥ä½œ**](https://jobs.levelup.dev/talent/welcome?referral=true)