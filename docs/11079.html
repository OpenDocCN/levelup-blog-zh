<html>
<head>
<title>How To Use AI for Real-Time Speech Recognition with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过Python使用人工智能进行实时语音识别</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-use-ai-for-real-time-speech-recognition-with-python-73fe24c4f1ee?source=collection_archive---------10-----------------------#2022-02-13">https://levelup.gitconnected.com/how-to-use-ai-for-real-time-speech-recognition-with-python-73fe24c4f1ee?source=collection_archive---------10-----------------------#2022-02-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3c6d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用人工智能通过Python编程实时转录音频</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/85071800d9e079df96efd96507d2b7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JxKFZpTzc-EBZr1n"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@denisseleon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">丹尼斯·莱昂</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="ca2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为人类，我们发现很容易适应与他人的任何类型的对话，跟上不同类型的音调、口音和讲话的怪癖。然而，对于机器来说，理解和解码语言以及理解语音的变化是非常困难的。</p><p id="8d48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对机器来说，推断一个人正在说话的准确描述的任务被认为是一项相当复杂的任务。这个问题一直存在，直到现代AI接管语音识别和自然语言处理的兴起。在本文中，我们将借助Python编程和AssemblyAI平台开发一个实时语音识别项目，以获得整体的高性能。</p><p id="5b28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您通过麦克风说出的信息会被考虑在内，以便为用户提供实时的文本转录显示。除了信息的转录，人工智能还试图理解口语句子的大写、语言学和标点符号。</p><p id="67c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们之前的一篇文章中，我们已经讨论了如何使用Python编程部署您自己的优化的语音转文本web应用程序。我强烈建议查看之前的博客，了解转录音频数据对于现代应用的重要性。您可以通过下面提供的链接来完成。</p><div class="lv lw gp gr lx ly"><a href="https://towardsdatascience.com/how-to-deploy-your-own-optimized-speech-to-text-web-app-with-python-c956c7838ec8" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">如何使用Python部署您自己优化的语音转文本Web应用程序</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">一个详细的指南，告诉你如何构建自己的语音到文本的网络应用程序，以最佳的方式将音频转换成…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="86bc" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">构建实时语音识别项目；</h1><p id="445e" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">在这个项目中，我们将致力于实时转录音频，实现最佳效果。我们将每秒接收由您的麦克风捕捉并由AssemblyAI平台预测的单词到单词的结果。最后，当你说完话时，AI将通过添加标点符号以及所需的大写字母来优化实时语音识别，从而试图理解整个句子。在这个项目的下一部分，让我们从安装所有必需的依赖项开始。</p><h2 id="2407" class="nr mv it bd mw ns nt dn na nu nv dp ne li nw nx ng lm ny nz ni lq oa ob nk oc bi translated">安装必要的依赖项:</h2><p id="c6d5" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">为了开始实时语音识别项目，我们主要依赖pyaudio通过麦克风读取信息。和web sockets库安装，用于使用Python构建健壮的高性能web socket服务器和客户机。下面是提到的两个安装的列表。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="e863" class="nr mv it oe b gy oi oj l ok ol">pip install pyaudio<br/>pip install websockets</span></pre><p id="a841" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，MAC上的安装相对更简单，因为您可以在安装过程中继续使用命令“<em class="om"> brew install portaudio </em>”，并且您应该已经相应地设置了所有必需的依赖项。在Windows平台，我建议访问非官方的Python库<a class="ae ky" href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="noopener ugc nofollow" target="_blank">网站</a>，下载你需要的Pyaudio版本。轮式下载已经有了一些基本的细节，可以直接安装pyaudio。将它下载到所需的文件夹位置，并在该目录下运行安装程序，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/44c393ace1bf858e8184a538c8bd9c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*JmbVs1JrYzMpvJxFghrz_w.png"/></div></div></figure><p id="94de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们导入所有必要的需求，如下面的代码块所示。asyncio是Python的标准异步I/O框架，它提供了一个优雅的基于协程的API。我们还将使用base64库来解码一些需求，使用JSON库来准备JSON文件，并使用一个配置导入来存储我们的API密钥。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="242f" class="nr mv it oe b gy oi oj l ok ol">import websockets<br/>import asyncio<br/>import base64<br/>import json<br/>from configure import auth_key<br/>import pyaudio</span></pre><p id="ad82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们导入了所有需要的库，我们就可以在下一步中设置我们的配置文件，以建立与AssemblyAI平台的连接。</p><h2 id="122e" class="nr mv it bd mw ns nt dn na nu nv dp ne li nw nx ng lm ny nz ni lq oa ob nk oc bi translated">设置所需的配置:</h2><p id="aacd" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">既然我们已经成功地导入了所有必需的依赖项，我们可以继续创建一个配置文件。配置文件需要命名为configure.py，并且应该包含您的API密钥。你可以从AssemblyAI <a class="ae ky" href="https://www.assemblyai.com/" rel="noopener ugc nofollow" target="_blank">网站</a>获得你的API密匙。请注意，对于实时转录，您将需要他们提供的pro-plan，这相对便宜。输入在屏幕右侧找到的授权密钥，方法是将其复制并粘贴到下面显示的代码片段中。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="9192" class="nr mv it oe b gy oi oj l ok ol">auth_key = 'Enter your API key here'</span></pre><p id="a61a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们有了设置了认证密钥的配置文件，我们将继续处理主Python文件，在这里我们将完成通过麦克风解码输入语音的脚本的剩余部分。</p><h2 id="8521" class="nr mv it bd mw ns nt dn na nu nv dp ne li nw nx ng lm ny nz ni lq oa ob nk oc bi translated">设置所需的参数:</h2><p id="99bc" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">首先，让我们导入所有必要的参数，使我们能够从话筒接收最佳输入信号。可以相应地设置Pyaudio的帧、格式、通道和速率，如下面的代码片段所示。一旦我们根据需求设置了参数，我们还可以设置一个链接到assemblyAI网站的端点URL。</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="9731" class="nr mv it oe b gy oi oj l ok ol">FRAMES_PER_BUFFER = 3200<br/>FORMAT = pyaudio.paInt16<br/>CHANNELS = 1<br/>RATE = 16000<br/>p = pyaudio.PyAudio()<br/> <br/># starts recording<br/>stream = p.open(<br/> format=FORMAT,<br/> channels=CHANNELS,<br/> rate=RATE,<br/> input=True,<br/> frames_per_buffer=FRAMES_PER_BUFFER<br/>)<br/> <br/># the AssemblyAI endpoint we're going to hit<br/>URL = "wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000"</span></pre><p id="e071" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以注意到，我们在AssemblyAI端点中指定的采样率也是16000，这与我们在Pyaudio库中指定的采样率同步。有了这些基本参数的定义，我们应该能够构建一个函数来帮助我们发送输入音频数据和接收相同的转录文本数据。</p><h2 id="d5bb" class="nr mv it bd mw ns nt dn na nu nv dp ne li nw nx ng lm ny nz ni lq oa ob nk oc bi translated">创建发送和接收函数:</h2><p id="6aed" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">在本节中，我们将开发从输入麦克风信息向AssemblyAI端点发送和接收基本信息的完整代码，以便实时将音频数据转录为文本形式。因为我们的目标是实时转录音频数据，所以我们需要使用一些异步函数来执行这项任务。</p><p id="e800" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一个代码片段中，让我们快速浏览一下main函数，它将帮助我们创建从本地系统到AssemblyAI端点的异步连接。使用我们之前导入的WebSockets库，我们可以建立到AssemblyAI网站的连接，在那里我们的麦克风信息被中继，同时转录的信息每秒被发送回来。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="0d66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们描述了主要功能，我们就可以继续构造下一对异步功能，即发送和接收。首先，send()函数将使我们能够从麦克风接收音频流。然后，我们将通过一些解码将其转换为base64格式，并将其发送到已建立的端点连接。我们还将打印一些用户可能经常遇到的异常。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="8676" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将定义receive()函数，它将帮助我们接收发送的音频数据的转录测试结果。您可以选择返回部分结果，其中包含及时的逐秒审查，或者返回最终的完整结果，其中包含完整的精炼和语法正确的句子。参考AssemblyAI上的<a class="ae ky" href="https://docs.assemblyai.com/walkthroughs#realtime-streaming-transcription" rel="noopener ugc nofollow" target="_blank">文档</a>,了解实时转录可用的各种参数的更多信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="c7b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成这些步骤后，我们可以转到最后一部分，在这里我们将看到一些结果和执行实时语音识别的完整代码。</p><h2 id="bdec" class="nr mv it bd mw ns nt dn na nu nv dp ne li nw nx ng lm ny nz ni lq oa ob nk oc bi translated">最终代码:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/54f800977ee70ff006373e5e2d11c637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C7v76e8A5HJ2wGAhGDOkTA.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">作者运行测试的屏幕截图</figcaption></figure><p id="8e5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你说的每一个字每秒都被AssemblyAI端点转录，你会收到相应的响应。然而，一旦你说完这句话，AI就会自动大写、标点，并通过添加必要的更改来使所说的句子在语法上更加正确，如上图的最后一句所示。下面提供了运行该程序的完整最终代码，可以从命令终端使用“python speech_recognition.py”命令运行。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="3700" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你正在寻找这篇文章的视频指南，我建议你查看下面的<a class="ae ky" href="https://www.youtube.com/watch?v=5LJFK7eOC20" rel="noopener ugc nofollow" target="_blank">链接</a>以获得详细的解释。它还以web界面的形式介绍了该项目的设计。你也可以从下面的GitHub <a class="ae ky" href="https://github.com/misraturp/Real-time-transcription-from-microphone" rel="noopener ugc nofollow" target="_blank">链接</a>中查看大部分编码需求。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="422b" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">结论:</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/fd5ea3ad41903deea6a52d192a01c6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zwCayO5f9QKjWxLq"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ttcollect?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Troy T </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9bc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于最好的对话来说，理解参与对话的人用他们不同的语调、谈话风格、填充词、音调和整体语言技能在说什么是至关重要的。虽然人类大多可以感知这些品质和特征，但计算机很难做到这一点，直到现在，人工智能已经接管了这一领域。</p><p id="2bce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们了解了如何使用Python编程构建实时语音识别项目。我们学习了安装必要的依赖项、设置配置文件、加载所需的参数以及创建代码块功能，以便通过AssmeblyAI实时语音识别网站发送和接收适当的信息。</p><p id="1f0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想在我的文章发表后第一时间得到通知，请点击下面的<a class="ae ky" href="https://bharath-k1297.medium.com/membership" rel="noopener">链接</a>订阅邮件推荐。如果你希望支持其他作者和我，请订阅下面的链接。</p><div class="lv lw gp gr lx ly"><a href="https://bharath-k1297.medium.com/membership" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">通过我的推荐链接加入媒体</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">bharath-k1297.medium.com</p></div></div><div class="mh l"><div class="os l mj mk ml mh mm ks ly"/></div></div></a></div><p id="103e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看看我的一些与本文主题相关的文章，你可能也会喜欢阅读！</p><div class="lv lw gp gr lx ly"><a href="https://towardsdatascience.com/develop-your-own-calendar-to-track-important-dates-with-python-c1af9e98ffc3" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">使用Python开发您自己的日历来跟踪重要日期</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">开发一个日历GUI界面来管理您2022年及以后的计划</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ot l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a href="https://towardsdatascience.com/develop-your-weather-application-with-python-in-less-than-10-lines-6d092c6dcbc9" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">用Python开发不到10行的天气应用程序</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用Python构建我们的天气电视广播应用程序，以接收所需位置的更新</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ou l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a href="https://towardsdatascience.com/complete-python-starter-guide-for-data-science-for-2022-c1f880fa249d" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">2022年数据科学完整Python入门指南</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">涵盖了用代码启动数据科学所需的所有Python基础和基本概念…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ov l mj mk ml mh mm ks ly"/></div></div></a></div><p id="991d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢你们坚持到最后。我希望你们都喜欢这篇文章。祝大家有美好的一天！</p></div></div>    
</body>
</html>