<html>
<head>
<title>Multilingual Text Classification with Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨è½¬æ¢å™¨çš„å¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://levelup.gitconnected.com/multilingual-text-classification-with-transformers-2147fe179c6b?source=collection_archive---------7-----------------------#2022-12-09">https://levelup.gitconnected.com/multilingual-text-classification-with-transformers-2147fe179c6b?source=collection_archive---------7-----------------------#2022-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b7d0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">å¾®è°ƒçš„mBERT/distill mBERTå¹¶å¯¼å‡ºåˆ°ONNXè¿›è¡Œæ¨ç†</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/317e08e26430a1237ebea143e9b95e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oBoFfBkNxecb8AAP"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">æ¢æ°æ£®</a>åœ¨<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šæ‹ç…§</figcaption></figure><p id="ec90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä¹‹å‰ï¼Œæˆ‘å†™è¿‡ä¸€ç¯‡å…³äºä½¿ç”¨Python ä¸­çš„spaCyè¿›è¡Œ<a class="ae ky" href="https://towardsdatascience.com/sarcasm-text-classification-using-spacy-in-python-7cd39074f32e" rel="noopener" target="_blank">æ–‡æœ¬åˆ†ç±»çš„æ–‡ç« ã€‚spaCyèƒŒåçš„æ¶æ„å’Œæ¦‚å¿µå¾ˆç®€å•ï¼Œä½†å¯¹å¤§å¤šæ•°ç”¨ä¾‹æ¥è¯´å·²ç»è¶³å¤Ÿå¥½äº†ã€‚äº‹å®ä¸Šï¼Œæˆ‘å·²ç»åœ¨æˆ‘çš„ä¸€äº›é¡¹ç›®ä¸­å¹¿æ³›ä½¿ç”¨äº†å®ƒã€‚æ¯”å¦‚äºµæ¸å’Œå¹¿å‘Šåˆ†ç±»ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç©ºé—´æ¶æ„å­˜åœ¨ä»¥ä¸‹é—®é¢˜:</a></p><ul class=""><li id="02aa" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">æˆ‘å¿…é¡»ä¸ºæ¯ç§è¯­è¨€ç‹¬ç«‹è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹</li><li id="f674" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">æˆ‘å¿…é¡»ä¸ºæŸäº›è¯­è¨€(ä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€ä¿„æ–‡ã€è¶Šå—æ–‡ç­‰)è®¾ç½®å’Œå®‰è£…ä¸“é—¨çš„åˆ†è¯å™¨ã€‚)</li></ul><p id="09f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†è§£é‡Šå¦‚ä½•ä½¿ç”¨<code class="fe mj mk ml mm b">transformers</code>è®­ç»ƒå•ä¸ªå¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»æ¨¡å‹:</p><ul class=""><li id="1fec" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">å¾®è°ƒé¢„è®­ç»ƒçš„æ‹¥æŠ±è„¸çš„æ–‡æœ¬åˆ†ç±»çš„å˜å½¢é‡‘åˆš</li><li id="61da" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">åŸºäºDistilmBERTæ¶æ„(ä¹Ÿæ”¯æŒæ™®é€šçš„mBERTæ¶æ„)</li><li id="e9ab" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">å°†å¾®è°ƒæ¨¡å‹å¯¼å‡ºåˆ°ONNXè¿›è¡Œæ¨ç†</li></ul><p id="beee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">è®©æˆ‘ä»¬ç»§ç»­ä¸‹ä¸€éƒ¨åˆ†ï¼Œè®¾ç½®æ‰€æœ‰éœ€è¦çš„åŒ…ã€‚</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="e2fc" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">è®¾ç½®</h1><p id="d5a0" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">å¼ºçƒˆå»ºè®®åœ¨å®‰è£…ä¹‹å‰åˆ›å»ºä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒã€‚æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œå®‰è£…<code class="fe mj mk ml mm b">transformers</code>åŒ…ï¼Œå¦‚ä¸‹æ‰€ç¤º:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="458e" class="nv mv it mm b be nw nx l ny nz">pip install transformers</span></pre><blockquote class="oa ob oc"><p id="b6b7" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">è¯·æ³¨æ„ï¼Œå®˜æ–¹æ–‡æ¡£æ˜¯åŸºäºå…‹éš†æœ€æ–°çš„å­˜å‚¨åº“å¹¶å°†å…¶å®‰è£…åœ¨æœ¬åœ°ã€‚æœ¬æ–‡åŸºäºPyPIçš„æœ€æ–°ç¨³å®šç‰ˆæœ¬ã€‚</p></blockquote><p id="4f16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º<code class="fe mj mk ml mm b">requirements.txt</code>çš„æ–°æ–‡ä»¶ï¼Œå¹¶åœ¨å…¶ä¸­æ·»åŠ ä»¥ä¸‹æ–‡æœ¬:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="4e0d" class="nv mv it mm b be nw nx l oh nz">accelerate &gt;= 0.12.0<br/>datasets &gt;= 1.8.0<br/>sentencepiece != 0.1.92<br/>scipy<br/>scikit-learn<br/>protobuf<br/>torch &gt;= 1.3<br/>evaluate</span></pre><blockquote class="oa ob oc"><p id="9d39" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">è¯·æ³¨æ„ï¼Œæœ¬æ•™ç¨‹æ˜¯åŸºäºå˜å‹å™¨ç‰ˆæœ¬4.24.0ï¼Œè¯·å‚è€ƒæ›´æ–°çš„<a class="ae ky" href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/requirements.txt" rel="noopener ugc nofollow" target="_blank">éœ€æ±‚æ–‡ä»¶</a>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯æ›´æ–°çš„ç‰ˆæœ¬ã€‚</p></blockquote><p id="5962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…æ‰€æœ‰å¿…éœ€çš„è½¯ä»¶åŒ…:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="2ce3" class="nv mv it mm b be nw nx l ny nz">pip install -r requirements.txt</span></pre><p id="965b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">è½¬åˆ°ä¸‹é¢çš„<a class="ae ky" href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification" rel="noopener ugc nofollow" target="_blank">åº“</a>å¹¶å°†<a class="ae ky" href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py" rel="noopener ugc nofollow" target="_blank"> run_glue.py </a>æ–‡ä»¶ä¿å­˜åˆ°å·¥ä½œç›®å½•ã€‚æ˜¯å®˜æ–¹å¯¹ä¸€ä¸ª<code class="fe mj mk ml mm b">transformers</code>æ¨¡å‹è¿›è¡Œå¾®è°ƒçš„è®­ç»ƒè„šæœ¬ã€‚</p><blockquote class="oa ob oc"><p id="229d" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated"><code class="fe mj mk ml mm b">run_glue.py</code>æ˜¯ç”¨äºå•æœºå¾®è°ƒçš„æ ‡å‡†Pytorchç‰ˆæœ¬ã€‚è¿˜æœ‰å¦ä¸€ä¸ªåä¸º<code class="fe mj mk ml mm b">run_glue_no_trainer.py</code>çš„è®­ç»ƒè„šæœ¬ï¼Œå®ƒæ˜¯ä½¿ç”¨<code class="fe mj mk ml mm b">accelerate</code>åŒ…åœ¨å¤šå°æœºå™¨ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒçš„ã€‚</p></blockquote><p id="d5bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ‰“å¼€è®­ç»ƒè„šæœ¬å¹¶æ³¨é‡Šæ‰<code class="fe mj mk ml mm b">check_min_version</code>å‡½æ•°(è¿™æ˜¯é˜²æ­¢å¼‚å¸¸æ‰€å¿…éœ€çš„ï¼Œå› ä¸ºæœ¬æ•™ç¨‹æ˜¯åŸºäºPyPIçš„<code class="fe mj mk ml mm b">transformers</code>çš„æ—§ç¨³å®šç‰ˆæœ¬):</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="495c" class="nv mv it mm b be nw nx l ny nz"># Will error if the minimal version of Transformers is not installed. Remove at your own risks.<br/># check_min_version("4.26.0.dev0")</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="4846" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">æ•°æ®é›†</h1><p id="4a28" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">è®­ç»ƒè„šæœ¬æ¥å—CSVæˆ–JSONä½œä¸ºè®­ç»ƒ/éªŒè¯æ–‡ä»¶ã€‚æ¯ä¸ªæ–‡ä»¶éƒ½åº”è¯¥æœ‰ä»¥ä¸‹å¤´æˆ–é”®å€¼å¯¹:</p><ul class=""><li id="cb4d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">sentence</code> â€”ç¤ºä¾‹æ–‡æœ¬</li><li id="5cdd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">label</code>â€”ä»£è¡¨ç±»åˆ«çš„æ•°å­—ã€‚ä¾‹å¦‚ï¼Œ0è¡¨ç¤ºé˜´æ€§ï¼Œ1è¡¨ç¤ºé˜³æ€§ã€‚</li></ul><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="762f" class="nv mv it mm b be nw nx l oh nz">|------------|--------|<br/>|  sentence  | label  |<br/>|------------|--------|<br/>| bad movie  |   0    |<br/>|------------|--------|</span></pre><p id="82e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">å¯¹äºé‚£äº›æ²¡æœ‰è‡ªå·±è®­ç»ƒæ•°æ®çš„äººï¼Œä½ å¯ä»¥ä½¿ç”¨HuggingFaceçš„<a class="ae ky" href="https://huggingface.co/datasets/sst2" rel="noopener ugc nofollow" target="_blank">æ–¯å¦ç¦æƒ…æ„Ÿæ ‘åº“</a>æ•°æ®é›†(æƒ…æ„Ÿåˆ†æ)ã€‚</p><p id="69c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">å°†è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†æ”¾åœ¨ä¸<code class="fe mj mk ml mm b">run_glue.py</code>æ–‡ä»¶ç›¸åŒçš„å·¥ä½œç›®å½•ä¸­ã€‚å½“å‰çš„åŸ¹è®­è„šæœ¬åªæ¥å—ä¸€ä¸ªåŸ¹è®­æ–‡ä»¶å’Œä¸€ä¸ªéªŒè¯æ–‡ä»¶ã€‚</p><h1 id="d2f9" class="mu mv it bd mw mx oi mz na nb oj nd ne jz ok ka ng kc ol kd ni kf om kg nk nl bi translated">åŸ¹å…»</h1><p id="e5f5" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">è¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹åŸ¹è®­:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="3d2d" class="nv mv it mm b be nw nx l ny nz">python run_glue.py \<br/>  --model_name_or_path distilbert-base-multilingual-cased \<br/>  --train_file ./data/train.csv \<br/>  --validation_file ./data/eval.csv \<br/>  --do_train \<br/>  --do_eval \<br/>  --max_seq_length 128 \<br/>  --per_device_train_batch_size 16 \<br/>  --learning_rate 2e-5 \<br/>  --num_train_epochs 3 \<br/>  --output_dir ./output/</span></pre><ul class=""><li id="91e2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">ä½¿ç”¨<code class="fe mj mk ml mm b">bert-base-multilingual-cased</code>å¯¹mBERTè€Œä¸æ˜¯DistilmBERTè¿›è¡Œå¾®è°ƒã€‚ä¹Ÿå¯ä»¥åœ¨å…¶ä»–éå¤šè¯­è¨€<code class="fe mj mk ml mm b">transformers</code>è½¦å‹ä¸Šè¿›è¡ŒåŸ¹è®­ã€‚</li><li id="1143" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">å°†<code class="fe mj mk ml mm b">per_device_train_batch_size</code>çš„å€¼å¢åŠ æˆ–å‡å°‘åˆ°4/8/32/64/ç­‰ã€‚åŸºäºGPUçš„å†…å­˜ã€‚</li><li id="8e86" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">ç›¸åº”ä¿®æ”¹<code class="fe mj mk ml mm b">train_file</code>ã€<code class="fe mj mk ml mm b">validation_file</code>å’Œ<code class="fe mj mk ml mm b">output_dir</code>çš„è·¯å¾„ã€‚</li></ul><blockquote class="oa ob oc"><p id="a7aa" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">å½“æ‚¨ç¬¬ä¸€æ¬¡è¿è¡Œè¯¥å‘½ä»¤æ—¶ï¼Œå®ƒä¼šå°†æ‰€éœ€çš„æ¨¡å‹ä¸‹è½½åˆ°ç¼“å­˜ä¸­ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å°†å¯¹æ•°æ®é›†è¿›è¡Œä»¤ç‰ŒåŒ–ï¼Œå¹¶å­˜å‚¨åœ¨åŒä¸€æ–‡ä»¶å¤¹ä¸­ã€‚</p></blockquote><p id="6b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ­¤å¤–ï¼Œè¿˜æœ‰å…¶ä»–å¯¹åŸ¹è®­æœ‰ç”¨çš„è¾“å…¥å‚æ•°:</p><ul class=""><li id="8505" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">cache_dir</code> â€”é»˜è®¤æƒ…å†µä¸‹ï¼ŒHuggingFaceä¼šåœ¨<code class="fe mj mk ml mm b">.cache/huggingface/</code> (Linux)ä¸‹è½½å¹¶å­˜å‚¨æ¨¡å‹ã€‚æ­¤å‚æ•°ç¡®ä¿ç¼“å­˜å°†ä¿å­˜åœ¨æ‰€éœ€çš„ä½ç½®ã€‚</li><li id="1911" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">fp16</code> â€”ä»¥æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å‹ã€‚ä½¿ç”¨æ··åˆç²¾åº¦å¯ä»¥åœ¨ä¸é™ä½æ¨¡å‹æ€§èƒ½çš„æƒ…å†µä¸‹å°†è®­ç»ƒæ—¶é—´å‡å°‘ä¸€åŠã€‚</li><li id="13eb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">save_strategy</code> â€”ä¸æŒ‰ç‰¹å®šæ—¶é—´é—´éš”ä¿å­˜æ£€æŸ¥ç‚¹ã€‚è¯¥æ ‡å¿—å°†åœ¨æ¯ä¸ªæ—¶æœŸä¿å­˜ä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚</li></ul><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="107f" class="nv mv it mm b be nw nx l ny nz">CUDA_VISIBLE_DEVICES=2 python run_glue.py \<br/>  --model_name_or_path distilbert-base-multilingual-cased \<br/>  --train_file ./data/train.csv \<br/>  --validation_file ./data/eval.csv \<br/>  --do_train \<br/>  --do_eval \<br/>  --max_seq_length 128 \<br/>  --per_device_train_batch_size 16 \<br/>  --learning_rate 2e-5 \<br/>  --num_train_epochs 3 \<br/>  --output_dir ./output/ \<br/>  --save_strategy epoch \<br/>  --cache_dir models/ \<br/>  --fp16</span></pre><p id="1e7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ç¯å¢ƒå˜é‡<code class="fe mj mk ml mm b">CUDA_VISIBLE_DEVICES</code>å¯ç”¨äºåˆ†é…è®­ç»ƒæ‰€éœ€çš„GPUã€‚ä»¥ä¸‹å‘½ä»¤å°†ä½¿ç”¨ç¬¬ä¸‰ä¸ªGPUè®­ç»ƒæ¨¡å‹(ç´¢å¼•ä»0å¼€å§‹):</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="5c7f" class="nv mv it mm b be nw nx l ny nz">CUDA_VISIBLE_DEVICES=2 python run_glue.py ...</span></pre><p id="4bbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ ¹æ®æ•°æ®é›†çš„ä¸åŒï¼Œæ•´ä¸ªåŸ¹è®­å¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶ã€‚åœ¨åŸ¹è®­ç»“æŸæ—¶ï¼Œå®ƒå°†åœ¨<code class="fe mj mk ml mm b">output_dir</code>ä¸­ç”Ÿæˆä»¥ä¸‹é‡è¦æ–‡ä»¶:</p><ul class=""><li id="a079" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">é…ç½®. json</li><li id="71e1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">pytorch_model.bin</li><li id="699b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">special _ tokens _ map.json</li><li id="0513" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">tokenizer.json</li><li id="71fd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">tokenizer_config.json</li><li id="9cab" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">vocab.txt</li></ul><p id="4a3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä¸‹ä¸€èŠ‚å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="e53a" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">æ¨ç†</h1><p id="f5c0" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">åœ¨åŒä¸€ä¸ªå·¥ä½œç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º<code class="fe mj mk ml mm b">inference.py</code>çš„æ–°æ–‡ä»¶ã€‚åœ¨å…¶ä¸­è¿½åŠ ä»¥ä¸‹ä»£ç :</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="e110" class="nv mv it mm b be nw nx l ny nz">from transformers import AutoTokenizer, DistilBertForSequenceClassification, TextClassificationPipeline<br/><br/># tokenizer initialization<br/>tokenizer = AutoTokenizer.from_pretrained("./output/", local_files_only=True)<br/># model initialization, use BertForSequenceClassification for mBERT/BERT architecture<br/>model = DistilBertForSequenceClassification.from_pretrained("./output/", local_files_only=True)<br/># pipeline initialization<br/>pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer)<br/><br/>text_list = ["I love this movie!", "I hate this movie!"]<br/># inference<br/>result = pipe(text_list)<br/>print(result)</span></pre><p id="3424" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä¿å­˜æ–‡ä»¶å¹¶è¿è¡Œä»¥ä¸‹å‘½ä»¤:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="a75e" class="nv mv it mm b be nw nx l ny nz">python inference.py</span></pre><p id="052d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä»¥ä¸‹ç»“æœå°†æ‰“å°åœ¨ç»ˆç«¯ä¸Š:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="e977" class="nv mv it mm b be nw nx l ny nz">[{'label': 0, 'score': 0.9951834082603455}, {'label': 1, 'score': 0.9082725048065186}]</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="4804" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">ONNX</h1><p id="2211" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">æˆ‘ä»¬ä¸ç›´æ¥ç”¨Pytorchè¿›è¡Œæ¨ç†ï¼Œè€Œæ˜¯æ¢ç´¢å¦‚ä½•å°†æ¨¡å‹è½¬æ¢æˆONNXæ ¼å¼ï¼Œå¹¶ä½¿ç”¨ONNXè¿è¡Œæ—¶è¿›è¡Œæ¨ç†ã€‚</p><p id="1cef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ONNXè¿è¡Œæ—¶ç›¸æ¯”Pytorchå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿:</p><ul class=""><li id="1202" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">MLå‹å·çš„æ€§èƒ½åŠ é€Ÿ(é€‚ç”¨äºCPUå’ŒGPU)</li><li id="aa5f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">èƒ½å¤Ÿåœ¨ä¸åŒçš„ç¡¬ä»¶å’Œæ“ä½œç³»ç»Ÿä¸Šè¿è¡Œ</li><li id="c94e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">æ”¯æŒå…¶ä»–è¯­è¨€çš„æ¨ç†(C#/C++/Java)</li><li id="3aa8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">ç‹¬ç«‹äºåŸ¹è®­æ¡†æ¶(Pytorchã€TensorFlowç­‰ã€‚)</li></ul><p id="d670" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mj mk ml mm b">transformers</code>åº“è‡ªå¸¦äº†ç”¨äºONNXæ”¯æŒçš„<code class="fe mj mk ml mm b"><a class="ae ky" href="https://huggingface.co/docs/transformers/v4.24.0/en/serialization#export-to-onnx" rel="noopener ugc nofollow" target="_blank">transformers.onnx</a></code>åŒ…ã€‚æŒ‰ç…§ä»¥ä¸‹æ–¹å¼å®‰è£…:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="6727" class="nv mv it mm b be nw nx l ny nz">pip install transformers[onnx]</span></pre><p id="e26e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå°†æ–°å¾®è°ƒçš„æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="2003" class="nv mv it mm b be nw nx l ny nz">python -m transformers.onnx --model=output/ --feature=sequence-classification --framework=pt onnx_output/</span></pre><p id="2bfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ‰€æœ‰æ”¯æŒçš„åŠŸèƒ½åˆ—è¡¨å¦‚ä¸‹:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="6409" class="nv mv it mm b be nw nx l oh nz">|--------------------------------|-------------------------------------|<br/>|            Feature             |             Auto Class              |<br/>|--------------------------------|-------------------------------------|<br/>|causal-lm, causal-lm-with-past  |  AutoModelForCausalLM               |<br/>|default, default-with-past      |  AutoModel                          |<br/>|masked-lm                       |  AutoModelForMaskedLM               |<br/>|question-answering              |  AutoModelForQuestionAnswering      |<br/>|seq2seq-lm, seq2seq-lm-with-past|  AutoModelForSeq2SeqLM              |<br/>|sequence-classification         |  AutoModelForSequenceClassification |<br/>|token-classification            |  AutoModelForTokenClassification    |<br/>|--------------------------------|-------------------------------------|</span></pre><p id="4428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ç»ˆç«¯å°†æ˜¾ç¤ºä»¥ä¸‹è¾“å‡ºï¼Œè¡¨æ˜å¯¼å‡ºæˆåŠŸ:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="82c1" class="nv mv it mm b be nw nx l ny nz">Validating ONNX model...<br/>        -[âœ“] ONNX model output names match reference model ({'logits'})<br/>        - Validating ONNX Model output "logits":<br/>                -[âœ“] (2, 2) matches (2, 2)<br/>                -[âœ“] all values close (atol: 1e-05)<br/>All good, model saved at: onnx_output/model.onnx</span></pre><p id="4c76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">å®ƒå°†åœ¨<code class="fe mj mk ml mm b">onnx_ouput</code>æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶:</p><ul class=""><li id="98a3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">model.onnx</li></ul><p id="8061" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">åˆ›å»ºä¸€ä¸ªåä¸º<code class="fe mj mk ml mm b">inference_onnx.py</code>çš„æ–°è„šæœ¬ï¼Œå¹¶åœ¨å…¶ä¸­æ·»åŠ ä»¥ä¸‹ä»£ç :</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="43d2" class="nv mv it mm b be nw nx l ny nz">from transformers import AutoTokenizer<br/>from onnxruntime import InferenceSession<br/>import numpy as np<br/><br/><br/># utility function to calculate probabilities<br/>def softmax(vec):<br/>    exponential = np.exp(vec)<br/>    probabilities = exponential / np.sum(exponential)<br/>    return probabilities<br/><br/><br/># initialization<br/>sentiment_dict = {0: "positive", 1: "negative"}<br/>tokenizer = AutoTokenizer.from_pretrained("./output/", local_files_only=True)<br/>session = InferenceSession("onnx_output/model.onnx")<br/><br/>text_list = ["I love this movie!", "I hate this movie!"]<br/>result = []<br/><br/># loop over each item in text_list<br/>for text in text_list:<br/>    # ONNX accepts numpy as input<br/>    inputs = tokenizer(text, return_tensors="np")<br/><br/>    # inference, returns numpy array<br/>    outputs = session.run(output_names=["logits"], input_feed=dict(inputs))<br/>    # [array([[ 4.1819444, -2.2060142]], dtype=float32)]<br/><br/>    # convert to probability score (0 to 1)<br/>    probabilities = softmax(outputs[0][0])<br/>    # [0.9951833  0.00481664]<br/><br/>    # get the index with the highest probability<br/>    index = np.argmax(outputs)<br/>    # 0<br/><br/>    print({'label': sentiment_dict[index], 'score': probabilities[index]})<br/>    # {'label': positive, 'score': 0.9951833}</span></pre><p id="9939" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ä¿å­˜æ–‡ä»¶å¹¶è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨æ–­:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="1297" class="nv mv it mm b be nw nx l ny nz">python inference_onnx.py</span></pre><blockquote class="oa ob oc"><p id="5b04" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">ä¸ä½¿ç”¨Pytorchè¿›è¡Œæ¨ç†ç›¸æ¯”ï¼Œæ¨ç†é€Ÿåº¦åº”è¯¥æœ‰æ‰€æé«˜ã€‚</p></blockquote></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="6b79" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">ç»“è®º</h1><p id="7af7" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹æœ¬æ•™ç¨‹çš„å­¦ä¹ å†…å®¹ã€‚</p><p id="fa88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">é¦–å…ˆç®€è¦ä»‹ç»äº†ä½œä¸ºå¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»æ›¿ä»£æ¶æ„çš„<code class="fe mj mk ml mm b">transformers</code>ã€‚</p><p id="a717" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ç„¶åï¼Œæœ¬æ–‡ä»‹ç»äº†æ‰€æœ‰å¿…éœ€åŒ…çš„è®¾ç½®å’Œå®‰è£…ã€‚å®ƒè¿˜è§£é‡Šäº†æ•°æ®é›†çš„æ ¼å¼ï¼Œå¹¶é“¾æ¥åˆ°ä¸€ä¸ªå…è´¹ä½¿ç”¨çš„æƒ…æ„Ÿåˆ†ææ•°æ®é›†ã€‚</p><p id="1073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">éšåï¼Œå®ƒç»§ç»­ä½¿ç”¨Pytorchè¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚å®ƒè¿˜å¼ºè°ƒäº†ä¸€äº›é‡è¦çš„è®­ç»ƒå‚æ•°ï¼Œå¦‚æ··åˆç²¾åº¦è®­ç»ƒçš„fp16ã€‚</p><p id="4a5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æœ¬æ•™ç¨‹ç»§ç»­è¯¦ç»†è§£é‡ŠONNXä»¥åŠå¦‚ä½•å°†Pytorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ã€‚æœ€åä¸€èŠ‚å±•ç¤ºäº†ä½¿ç”¨è½¬æ¢åçš„ONNXæ¨¡å‹æ‰§è¡Œæ¨ç†çš„å®Œæ•´è„šæœ¬ã€‚</p><p id="1033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">æ„Ÿè°¢ä½ é˜…è¯»è¿™ç¯‡æ–‡ç« ã€‚ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="3163" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">å‚è€ƒ</h1><ol class=""><li id="ab40" class="lv lw it lb b lc nm lf nn li on lm oo lq op lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/distilbert-base-multilingual-cased" rel="noopener ugc nofollow" target="_blank">hugging faceâ€”distilbert-base-å¤šè¯­è¨€ç¯å¢ƒ</a></li><li id="d28c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/bert-base-multilingual-cased" rel="noopener ugc nofollow" target="_blank">æ‹¥æŠ±è„¸â€”Bert-base-å¤šè¯­è¨€ç¯å¢ƒ</a></li><li id="5373" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/docs/transformers/v4.24.0/en/serialization#export-to-onnx" rel="noopener ugc nofollow" target="_blank"> HuggingFaceåšå®¢â€”å¯¼å‡ºåˆ°ONNX </a></li><li id="5f3d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/datasets/sst2" rel="noopener ugc nofollow" target="_blank">æ‹¥æŠ±è„¸æ•°æ®é›†â€” SST </a> 2</li><li id="a984" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification" rel="noopener ugc nofollow" target="_blank"> Github â€” HuggingFaceæ–‡æœ¬åˆ†ç±»ç¤ºä¾‹</a></li></ol></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="9584" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">åˆ†çº§ç¼–ç </h1><p id="d43e" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:</p><ul class=""><li id="ac97" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰</li><li id="b64a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">ğŸ“°æŸ¥çœ‹<a class="ae ky" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">å‡çº§ç¼–ç å‡ºç‰ˆç‰©</a>ä¸­çš„æ›´å¤šå†…å®¹</li><li id="8e20" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">ğŸ””å…³æ³¨æˆ‘ä»¬:<a class="ae ky" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae ky" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae ky" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">æ—¶äº‹é€šè®¯</a></li></ul><p id="cc85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ğŸš€ğŸ‘‰<a class="ae ky" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">åŠ å…¥äººæ‰é›†ä½“ï¼Œæ‰¾åˆ°ä¸€ä»½ä»¤äººæƒŠå–œçš„å·¥ä½œ</strong> </a></p></div></div>    
</body>
</html>