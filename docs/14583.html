<html>
<head>
<title>Multilingual Text Classification with Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用转换器的多语言文本分类</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/multilingual-text-classification-with-transformers-2147fe179c6b?source=collection_archive---------7-----------------------#2022-12-09">https://levelup.gitconnected.com/multilingual-text-classification-with-transformers-2147fe179c6b?source=collection_archive---------7-----------------------#2022-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b7d0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">微调的mBERT/distill mBERT并导出到ONNX进行推理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/317e08e26430a1237ebea143e9b95e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oBoFfBkNxecb8AAP"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梁杰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="ec90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之前，我写过一篇关于使用Python 中的spaCy进行<a class="ae ky" href="https://towardsdatascience.com/sarcasm-text-classification-using-spacy-in-python-7cd39074f32e" rel="noopener" target="_blank">文本分类的文章。spaCy背后的架构和概念很简单，但对大多数用例来说已经足够好了。事实上，我已经在我的一些项目中广泛使用了它。比如亵渎和广告分类。然而，现有的空间架构存在以下问题:</a></p><ul class=""><li id="02aa" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我必须为每种语言独立训练一个新模型</li><li id="f674" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我必须为某些语言(中文、日文、韩文、俄文、越南文等)设置和安装专门的分词器。)</li></ul><p id="09f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我将解释如何使用<code class="fe mj mk ml mm b">transformers</code>训练单个多语言文本分类模型:</p><ul class=""><li id="1fec" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">微调预训练的拥抱脸的文本分类的变形金刚</li><li id="61da" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">基于DistilmBERT架构(也支持普通的mBERT架构)</li><li id="e9ab" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将微调模型导出到ONNX进行推理</li></ul><p id="beee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续下一部分，设置所有需要的包。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="e2fc" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">设置</h1><p id="d5a0" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">强烈建议在安装之前创建一个新的虚拟环境。激活虚拟环境，安装<code class="fe mj mk ml mm b">transformers</code>包，如下所示:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="458e" class="nv mv it mm b be nw nx l ny nz">pip install transformers</span></pre><blockquote class="oa ob oc"><p id="b6b7" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">请注意，官方文档是基于克隆最新的存储库并将其安装在本地。本文基于PyPI的最新稳定版本。</p></blockquote><p id="4f16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，创建一个名为<code class="fe mj mk ml mm b">requirements.txt</code>的新文件，并在其中添加以下文本:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="4e0d" class="nv mv it mm b be nw nx l oh nz">accelerate &gt;= 0.12.0<br/>datasets &gt;= 1.8.0<br/>sentencepiece != 0.1.92<br/>scipy<br/>scikit-learn<br/>protobuf<br/>torch &gt;= 1.3<br/>evaluate</span></pre><blockquote class="oa ob oc"><p id="9d39" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">请注意，本教程是基于变压器版本4.24.0，请参考更新的<a class="ae ky" href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/requirements.txt" rel="noopener ugc nofollow" target="_blank">需求文件</a>如果您使用的是更新的版本。</p></blockquote><p id="5962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行以下命令安装所有必需的软件包:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="2ce3" class="nv mv it mm b be nw nx l ny nz">pip install -r requirements.txt</span></pre><p id="965b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转到下面的<a class="ae ky" href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification" rel="noopener ugc nofollow" target="_blank">库</a>并将<a class="ae ky" href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py" rel="noopener ugc nofollow" target="_blank"> run_glue.py </a>文件保存到工作目录。是官方对一个<code class="fe mj mk ml mm b">transformers</code>模型进行微调的训练脚本。</p><blockquote class="oa ob oc"><p id="229d" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated"><code class="fe mj mk ml mm b">run_glue.py</code>是用于单机微调的标准Pytorch版本。还有另一个名为<code class="fe mj mk ml mm b">run_glue_no_trainer.py</code>的训练脚本，它是使用<code class="fe mj mk ml mm b">accelerate</code>包在多台机器上进行分布式训练的。</p></blockquote><p id="d5bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">打开训练脚本并注释掉<code class="fe mj mk ml mm b">check_min_version</code>函数(这是防止异常所必需的，因为本教程是基于PyPI的<code class="fe mj mk ml mm b">transformers</code>的旧稳定版本):</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="495c" class="nv mv it mm b be nw nx l ny nz"># Will error if the minimal version of Transformers is not installed. Remove at your own risks.<br/># check_min_version("4.26.0.dev0")</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="4846" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">数据集</h1><p id="4a28" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">训练脚本接受CSV或JSON作为训练/验证文件。每个文件都应该有以下头或键值对:</p><ul class=""><li id="cb4d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">sentence</code> —示例文本</li><li id="5cdd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">label</code>—代表类别的数字。例如，0表示阴性，1表示阳性。</li></ul><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="762f" class="nv mv it mm b be nw nx l oh nz">|------------|--------|<br/>|  sentence  | label  |<br/>|------------|--------|<br/>| bad movie  |   0    |<br/>|------------|--------|</span></pre><p id="82e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于那些没有自己训练数据的人，你可以使用HuggingFace的<a class="ae ky" href="https://huggingface.co/datasets/sst2" rel="noopener ugc nofollow" target="_blank">斯坦福情感树库</a>数据集(情感分析)。</p><p id="69c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将训练和验证数据集放在与<code class="fe mj mk ml mm b">run_glue.py</code>文件相同的工作目录中。当前的培训脚本只接受一个培训文件和一个验证文件。</p><h1 id="d2f9" class="mu mv it bd mw mx oi mz na nb oj nd ne jz ok ka ng kc ol kd ni kf om kg nk nl bi translated">培养</h1><p id="e5f5" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">运行以下命令开始培训:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="3d2d" class="nv mv it mm b be nw nx l ny nz">python run_glue.py \<br/>  --model_name_or_path distilbert-base-multilingual-cased \<br/>  --train_file ./data/train.csv \<br/>  --validation_file ./data/eval.csv \<br/>  --do_train \<br/>  --do_eval \<br/>  --max_seq_length 128 \<br/>  --per_device_train_batch_size 16 \<br/>  --learning_rate 2e-5 \<br/>  --num_train_epochs 3 \<br/>  --output_dir ./output/</span></pre><ul class=""><li id="91e2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用<code class="fe mj mk ml mm b">bert-base-multilingual-cased</code>对mBERT而不是DistilmBERT进行微调。也可以在其他非多语言<code class="fe mj mk ml mm b">transformers</code>车型上进行培训。</li><li id="1143" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将<code class="fe mj mk ml mm b">per_device_train_batch_size</code>的值增加或减少到4/8/32/64/等。基于GPU的内存。</li><li id="8e86" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">相应修改<code class="fe mj mk ml mm b">train_file</code>、<code class="fe mj mk ml mm b">validation_file</code>和<code class="fe mj mk ml mm b">output_dir</code>的路径。</li></ul><blockquote class="oa ob oc"><p id="a7aa" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">当您第一次运行该命令时，它会将所需的模型下载到缓存中。此外，它还将对数据集进行令牌化，并存储在同一文件夹中。</p></blockquote><p id="6b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还有其他对培训有用的输入参数:</p><ul class=""><li id="8505" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">cache_dir</code> —默认情况下，HuggingFace会在<code class="fe mj mk ml mm b">.cache/huggingface/</code> (Linux)下载并存储模型。此参数确保缓存将保存在所需的位置。</li><li id="1911" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">fp16</code> —以混合精度训练模型。使用混合精度可以在不降低模型性能的情况下将训练时间减少一半。</li><li id="13eb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe mj mk ml mm b">save_strategy</code> —不按特定时间间隔保存检查点。该标志将在每个时期保存一个检查点。</li></ul><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="107f" class="nv mv it mm b be nw nx l ny nz">CUDA_VISIBLE_DEVICES=2 python run_glue.py \<br/>  --model_name_or_path distilbert-base-multilingual-cased \<br/>  --train_file ./data/train.csv \<br/>  --validation_file ./data/eval.csv \<br/>  --do_train \<br/>  --do_eval \<br/>  --max_seq_length 128 \<br/>  --per_device_train_batch_size 16 \<br/>  --learning_rate 2e-5 \<br/>  --num_train_epochs 3 \<br/>  --output_dir ./output/ \<br/>  --save_strategy epoch \<br/>  --cache_dir models/ \<br/>  --fp16</span></pre><p id="1e7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">环境变量<code class="fe mj mk ml mm b">CUDA_VISIBLE_DEVICES</code>可用于分配训练所需的GPU。以下命令将使用第三个GPU训练模型(索引从0开始):</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="5c7f" class="nv mv it mm b be nw nx l ny nz">CUDA_VISIBLE_DEVICES=2 python run_glue.py ...</span></pre><p id="4bbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据数据集的不同，整个培训可能需要几个小时。在培训结束时，它将在<code class="fe mj mk ml mm b">output_dir</code>中生成以下重要文件:</p><ul class=""><li id="a079" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">配置. json</li><li id="71e1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">pytorch_model.bin</li><li id="699b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">special _ tokens _ map.json</li><li id="0513" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">tokenizer.json</li><li id="71fd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">tokenizer_config.json</li><li id="9cab" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">vocab.txt</li></ul><p id="4a3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一节将介绍如何使用新训练的模型进行推理。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="e53a" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">推理</h1><p id="f5c0" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">在同一个工作目录下创建一个名为<code class="fe mj mk ml mm b">inference.py</code>的新文件。在其中追加以下代码:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="e110" class="nv mv it mm b be nw nx l ny nz">from transformers import AutoTokenizer, DistilBertForSequenceClassification, TextClassificationPipeline<br/><br/># tokenizer initialization<br/>tokenizer = AutoTokenizer.from_pretrained("./output/", local_files_only=True)<br/># model initialization, use BertForSequenceClassification for mBERT/BERT architecture<br/>model = DistilBertForSequenceClassification.from_pretrained("./output/", local_files_only=True)<br/># pipeline initialization<br/>pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer)<br/><br/>text_list = ["I love this movie!", "I hate this movie!"]<br/># inference<br/>result = pipe(text_list)<br/>print(result)</span></pre><p id="3424" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保存文件并运行以下命令:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="a75e" class="nv mv it mm b be nw nx l ny nz">python inference.py</span></pre><p id="052d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下结果将打印在终端上:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="e977" class="nv mv it mm b be nw nx l ny nz">[{'label': 0, 'score': 0.9951834082603455}, {'label': 1, 'score': 0.9082725048065186}]</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="4804" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">ONNX</h1><p id="2211" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">我们不直接用Pytorch进行推理，而是探索如何将模型转换成ONNX格式，并使用ONNX运行时进行推理。</p><p id="1cef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ONNX运行时相比Pytorch具有以下优势:</p><ul class=""><li id="1202" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">ML型号的性能加速(适用于CPU和GPU)</li><li id="aa5f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">能够在不同的硬件和操作系统上运行</li><li id="c94e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">支持其他语言的推理(C#/C++/Java)</li><li id="3aa8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">独立于培训框架(Pytorch、TensorFlow等。)</li></ul><p id="d670" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mj mk ml mm b">transformers</code>库自带了用于ONNX支持的<code class="fe mj mk ml mm b"><a class="ae ky" href="https://huggingface.co/docs/transformers/v4.24.0/en/serialization#export-to-onnx" rel="noopener ugc nofollow" target="_blank">transformers.onnx</a></code>包。按照以下方式安装:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="6727" class="nv mv it mm b be nw nx l ny nz">pip install transformers[onnx]</span></pre><p id="e26e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行以下命令，将新微调的模型导出为ONNX格式:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="2003" class="nv mv it mm b be nw nx l ny nz">python -m transformers.onnx --model=output/ --feature=sequence-classification --framework=pt onnx_output/</span></pre><p id="2bfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有支持的功能列表如下:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="6409" class="nv mv it mm b be nw nx l oh nz">|--------------------------------|-------------------------------------|<br/>|            Feature             |             Auto Class              |<br/>|--------------------------------|-------------------------------------|<br/>|causal-lm, causal-lm-with-past  |  AutoModelForCausalLM               |<br/>|default, default-with-past      |  AutoModel                          |<br/>|masked-lm                       |  AutoModelForMaskedLM               |<br/>|question-answering              |  AutoModelForQuestionAnswering      |<br/>|seq2seq-lm, seq2seq-lm-with-past|  AutoModelForSeq2SeqLM              |<br/>|sequence-classification         |  AutoModelForSequenceClassification |<br/>|token-classification            |  AutoModelForTokenClassification    |<br/>|--------------------------------|-------------------------------------|</span></pre><p id="4428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">终端将显示以下输出，表明导出成功:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="82c1" class="nv mv it mm b be nw nx l ny nz">Validating ONNX model...<br/>        -[✓] ONNX model output names match reference model ({'logits'})<br/>        - Validating ONNX Model output "logits":<br/>                -[✓] (2, 2) matches (2, 2)<br/>                -[✓] all values close (atol: 1e-05)<br/>All good, model saved at: onnx_output/model.onnx</span></pre><p id="4c76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将在<code class="fe mj mk ml mm b">onnx_ouput</code>文件夹中生成以下文件:</p><ul class=""><li id="98a3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">model.onnx</li></ul><p id="8061" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建一个名为<code class="fe mj mk ml mm b">inference_onnx.py</code>的新脚本，并在其中添加以下代码:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="43d2" class="nv mv it mm b be nw nx l ny nz">from transformers import AutoTokenizer<br/>from onnxruntime import InferenceSession<br/>import numpy as np<br/><br/><br/># utility function to calculate probabilities<br/>def softmax(vec):<br/>    exponential = np.exp(vec)<br/>    probabilities = exponential / np.sum(exponential)<br/>    return probabilities<br/><br/><br/># initialization<br/>sentiment_dict = {0: "positive", 1: "negative"}<br/>tokenizer = AutoTokenizer.from_pretrained("./output/", local_files_only=True)<br/>session = InferenceSession("onnx_output/model.onnx")<br/><br/>text_list = ["I love this movie!", "I hate this movie!"]<br/>result = []<br/><br/># loop over each item in text_list<br/>for text in text_list:<br/>    # ONNX accepts numpy as input<br/>    inputs = tokenizer(text, return_tensors="np")<br/><br/>    # inference, returns numpy array<br/>    outputs = session.run(output_names=["logits"], input_feed=dict(inputs))<br/>    # [array([[ 4.1819444, -2.2060142]], dtype=float32)]<br/><br/>    # convert to probability score (0 to 1)<br/>    probabilities = softmax(outputs[0][0])<br/>    # [0.9951833  0.00481664]<br/><br/>    # get the index with the highest probability<br/>    index = np.argmax(outputs)<br/>    # 0<br/><br/>    print({'label': sentiment_dict[index], 'score': probabilities[index]})<br/>    # {'label': positive, 'score': 0.9951833}</span></pre><p id="9939" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保存文件并运行以下命令进行推断:</p><pre class="kj kk kl km gt nr mm ns bn nt nu bi"><span id="1297" class="nv mv it mm b be nw nx l ny nz">python inference_onnx.py</span></pre><blockquote class="oa ob oc"><p id="5b04" class="kz la od lb b lc ld ju le lf lg jx lh oe lj lk ll of ln lo lp og lr ls lt lu im bi translated">与使用Pytorch进行推理相比，推理速度应该有所提高。</p></blockquote></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="6b79" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">结论</h1><p id="7af7" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">让我们回顾一下本教程的学习内容。</p><p id="fa88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先简要介绍了作为多语言文本分类替代架构的<code class="fe mj mk ml mm b">transformers</code>。</p><p id="a717" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，本文介绍了所有必需包的设置和安装。它还解释了数据集的格式，并链接到一个免费使用的情感分析数据集。</p><p id="1073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随后，它继续使用Pytorch进行训练和推理。它还强调了一些重要的训练参数，如混合精度训练的fp16。</p><p id="4a5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程继续详细解释ONNX以及如何将Pytorch模型转换为ONNX格式。最后一节展示了使用转换后的ONNX模型执行推理的完整脚本。</p><p id="1033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你阅读这篇文章。祝你有美好的一天！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="3163" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">参考</h1><ol class=""><li id="ab40" class="lv lw it lb b lc nm lf nn li on lm oo lq op lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/distilbert-base-multilingual-cased" rel="noopener ugc nofollow" target="_blank">hugging face—distilbert-base-多语言环境</a></li><li id="d28c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/bert-base-multilingual-cased" rel="noopener ugc nofollow" target="_blank">拥抱脸—Bert-base-多语言环境</a></li><li id="5373" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/docs/transformers/v4.24.0/en/serialization#export-to-onnx" rel="noopener ugc nofollow" target="_blank"> HuggingFace博客—导出到ONNX </a></li><li id="5f3d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://huggingface.co/datasets/sst2" rel="noopener ugc nofollow" target="_blank">拥抱脸数据集— SST </a> 2</li><li id="a984" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oq mb mc md bi translated"><a class="ae ky" href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification" rel="noopener ugc nofollow" target="_blank"> Github — HuggingFace文本分类示例</a></li></ol></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="9584" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">分级编码</h1><p id="d43e" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li no lk ll lm np lo lp lq nq ls lt lu im bi translated">感谢您成为我们社区的一员！在你离开之前:</p><ul class=""><li id="ac97" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">👏为故事鼓掌，跟着作者走👉</li><li id="b64a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">📰查看<a class="ae ky" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">升级编码出版物</a>中的更多内容</li><li id="8e20" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">🔔关注我们:<a class="ae ky" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae ky" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae ky" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">时事通讯</a></li></ul><p id="cc85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">🚀👉<a class="ae ky" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">加入人才集体，找到一份令人惊喜的工作</strong> </a></p></div></div>    
</body>
</html>