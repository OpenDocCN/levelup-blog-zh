<html>
<head>
<title>The Art of Webscraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网络搜集的艺术</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/the-art-of-webscraping-716a69916c?source=collection_archive---------12-----------------------#2021-05-11">https://levelup.gitconnected.com/the-art-of-webscraping-716a69916c?source=collection_archive---------12-----------------------#2021-05-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9818" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如果数据是新的石油，那么网络搜集就是新的压裂法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/70290444c62b352cc12d9eb4029727f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*naaFM_MiRtog2TSV"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">雷蒙·克拉文斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="4639" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="474d" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">大约15年前<a class="ae kv" href="https://en.wikipedia.org/wiki/Clive_Humby#:~:text=In%202006%2C%20Humby%20coined%20the,it%20cannot%20really%20be%20used." rel="noopener ugc nofollow" target="_blank"> Clive Humby </a>创造了一个短语“数据是新的石油”。这句话后来被麦可尔·柏默进一步阐述，他说就像石油一样，数据只有在正确处理后才是有用的。而且，石油和数据的共性不止于此，因为就像石油一样，数据也有供应链。</p><p id="22e6" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这个供应链始于从给定来源获取数据。迄今为止，获取数据的最大来源是互联网。最近的计算估计，2020年互联网总容量为40兆字节。这么多零啊！</p><p id="5b15" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">为了释放这些海量数据的潜力，我们需要以一种可用于进一步分析的方式获取和格式化这些数据。这个过程通常被称为<strong class="lu ir">网络抓取</strong>。在本文中，我们将通过收集和格式化我不久前写的一篇名为；“机器学习需要懂数学吗”。</p><div class="mq mr gp gr ms mt"><a href="https://medium.com/analytics-vidhya/do-you-need-to-know-math-for-machine-learning-d51f0206f7e4" rel="noopener follow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">机器学习需要懂数学吗？</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">是啊！…不…这很复杂…</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">medium.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh kp mt"/></div></div></a></div></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h2 id="0534" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">获得所有需要的工具</h2><p id="8083" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">有许多方法可以使用从网站收集数据，但在本文中，我们将使用Python。Python是一种非常流行的编程语言，它有许多对网络抓取非常有用的库。本文中使用的库有:<a class="ae kv" href="https://pypi.org/project/beautifulsoup4/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>，<strong class="lu ir"> </strong>请求，json和re。</p><p id="9d9b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">默认情况下，Python环境中唯一可能不包含的库是BeautifulSoup。如果您想将这个库添加到您的环境中，只需使用<em class="np"> Python包安装程序</em>(又名pip)。如果您使用PyCharm(或任何其他IDE ),那么请遵循他们的软件包安装指南。</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="4417" class="kw kx iq nr b gy nv nw l nx ny">pip install beautifulsoup4</span></pre><p id="7366" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">安装完包之后，我们可以开始编写scraper了。这里唯一真正的需求是我们想要从中抓取数据的页面的URL(重申一下；我前面提到的文章)。您可以想象，对于大型webscrapers来说，为了收集某个域中的大量页面，可以将这个URL自动化，但是在这个例子中，我们将只使用一个页面。</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="6810" class="kw kx iq nr b gy nv nw l nx ny">from bs4 import BeautifulSoup<br/>import requests, json, re</span><span id="f5de" class="kw kx iq nr b gy nz nw l nx ny">url = "https://medium.com/analytics-vidhya/do-you-need-to-know-math-for-machine-learning-d51f0206f7e4"</span><span id="69c6" class="kw kx iq nr b gy nz nw l nx ny">page = requests.get(url)<br/>soup = BeautifulSoup(page.content, 'html.parser')</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h2 id="97e8" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">获取数据</h2><p id="227a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">安装并设置好您的环境后，您可以开始抓取URL。重要的是要记住，网站本质上是由浏览器翻译成网页的大量文本。要了解这篇文章的内容，只需在这篇文章上点击<code class="fe oa ob oc nr b">f12</code>。那是一大堆行话！</p><p id="f09b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在浏览所有这些文本时，需要记住的一条重要规则是，没有找到所需内容的黄金法则。网站存储数据的方式不同，如果你想抓取它们，你必须适应这一点。</p><p id="fe73" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这对于中等的文章也是一样的。经过一段时间的修补和搜索，我发现medium将其数据保存在html标签<code class="fe oa ob oc nr b">&lt;script data-rh="true" type="application/ld+json"&gt; </code>和<code class="fe oa ob oc nr b">&lt;/script&gt;</code>之间代码顶部的json字符串中。</p><p id="d819" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这是一个网络抓取的好机会，当你自己尝试这个过程时，认识到这一点是很重要的。为了将这个json字符串从代码的其余部分中分离出来，我们可以简单地使用字符串索引将其剪切出来。为此，请使用下面的代码片段。</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="2778" class="kw kx iq nr b gy nv nw l nx ny"><strong class="nr ir">def</strong> get_json(soup):<br/>    index_1 = soup.find('&lt;script data-rh="true" type="application/ld+json"&gt;')<br/>    index_2 = soup.find('&lt;/script&gt;', index_1)<br/>    json_string = soup[index_1 + 50:index_2]<br/>    <strong class="nr ir">return</strong> json.loads(json_string)</span><span id="63af" class="kw kx iq nr b gy nz nw l nx ny">soup = str(soup) # required to use string functions<br/>json = get_json(soup)<br/><strong class="nr ir">for</strong> item, value <strong class="nr ir">in</strong> json.items():<br/>    print(item, value, sep=' = ', end='<strong class="nr ir">\n\n</strong>')</span></pre><p id="399c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这输出了medium在这个json中提供的所有元数据(很多！).</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="dcd2" class="kw kx iq nr b gy nv nw l nx ny">@context = http://schema.org<br/><br/>@type = NewsArticle<br/><br/>image = ['https://miro.medium.com/max/1200/1*IHv0J-i2WvawIxU9MEAe8Q.png']<br/><br/>url = https://medium.com/analytics-vidhya/do-you-need-to-know-math-for-machine-learning-d51f0206f7e4<br/><br/>dateCreated = 2021-04-06T15:25:58.210Z<br/><br/>datePublished = 2021-04-06T15:25:58.210Z<br/><br/>dateModified = 2021-04-06T18:36:25.041Z<br/><br/>headline = Do You Need to Know Math for Machine Learning? - Analytics Vidhya - Medium<br/><br/>name = Do You Need to Know Math for Machine Learning? - Analytics Vidhya - Medium<br/><br/>description = Machine learning has become a popular field in the tech industry. Nowadays almost the exclusive majority of computer science related studies have a machine learning course in their curriculum. Most…<br/><br/>identifier = d51f0206f7e4<br/><br/>keywords = ['Lite:true', 'Tag:Machine Learning', 'Tag:Computer Science', 'Tag:Programming', 'Tag:Python', 'Tag:Math', 'Publication:analytics-vidhya', 'Elevated:false', 'LockedPostSource:LOCKED_POST_SOURCE_UGC', 'LayerCake:3']<br/><br/>author = {'@type': 'Person', 'name': 'Timo Kats', 'url': 'https://timokats.medium.com'}<br/><br/>creator = ['Timo Kats']<br/><br/>publisher = {'@type': 'Organization', 'name': 'Analytics Vidhya', 'url': 'https://medium.com/analytics-vidhya', 'logo': {'@type': 'ImageObject', 'width': 208, 'height': 60, 'url': 'https://miro.medium.com/max/416/1*66g0UGKgu4oopIC0ahQuXw.png'}}<br/><br/>mainEntityOfPage = https://medium.com/analytics-vidhya/do-you-need-to-know-math-for-machine-learning-d51f0206f7e4<br/><br/>isAccessibleForFree = False</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h2 id="e82d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">格式化数据</h2><p id="f8ce" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">既然已经获得了数据，我们可以开始格式化它了。由于数据是从json字符串中提取的，这实际上并不必要，因为json已经是一种很好的格式了。但是，在这个例子中，我们将数据重新格式化为一个csv文件，包含以下字段:标识符、发布日期、名称、创建者、发布。为此，我们首先需要从json文件中选择这些字段，然后将它们写入csv文件。让我们从第一部分开始。</p><p id="61e1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">当查看收集的json字符串中的字段时(参见上面的代码片段),很明显有些字段有多个值，而有些字段是单个的。因此，我们需要做一些定制的搜索来获得我们想要的值。此后，这些值被转换成字典。这最后一部分不是强制性的，但它确实使将数据写入csv文件变得容易多了。</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="3847" class="kw kx iq nr b gy nv nw l nx ny">selected_fields = [<strong class="nr ir">'identifier'</strong>, <strong class="nr ir">'datePublished'</strong>, <strong class="nr ir">'name'</strong>, <strong class="nr ir">'creator'</strong>, <strong class="nr ir">'publisher'</strong>]<br/>data = {}<br/><strong class="nr ir">for </strong>field <strong class="nr ir">in </strong>selected_fields:<br/>    <strong class="nr ir">if </strong>field == <strong class="nr ir">'creator'</strong>:<br/>        data[field] = json[field][0]<br/>    <strong class="nr ir">elif </strong>field == <strong class="nr ir">'publisher'</strong>:<br/>        data[field] = json[field][<strong class="nr ir">'name'</strong>]<br/>    <strong class="nr ir">else</strong>:<br/>        data[field] = json[field]</span></pre><p id="9f00" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">既然数据已经加载到字典中，我们最终可以将其导出到csv文件中。</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="1b2e" class="kw kx iq nr b gy nv nw l nx ny">csv = open(<strong class="nr ir">'medium_article.csv'</strong>, <strong class="nr ir">'a'</strong>, encoding=<strong class="nr ir">'utf-8'</strong>)<br/><strong class="nr ir">for </strong>key <strong class="nr ir">in </strong>data.keys():<br/>    csv.write(key + <strong class="nr ir">','</strong>)<br/>csv.write(<strong class="nr ir">'\n'</strong>)<br/><strong class="nr ir">for </strong>value <strong class="nr ir">in </strong>data.values():<br/>    csv.write(value + <strong class="nr ir">','</strong>)</span></pre><p id="d1d6" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">最后，我们有了一个包含前面提到的字段的csv文件！因为数据中只有一行，这可能看起来有点乏味，但是想象一下对给定出版物中的所有文章都这样做。对于许多与媒体文章相关的数据科学项目来说，这可能成为一个非常好的数据源！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/310ba62d9ebde89c89742af7be77a5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2SfDnQ6ItcFim-oYvadAVw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">excel中创建的csv文件的屏幕截图</figcaption></figure></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h2 id="6bbc" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">最后的话</h2><p id="59a6" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">这篇文章有望展示网络抓取是多么简单和有用。如果您想使用本文中提供的代码在您自己的webscraper上工作，请随意，下面给出了本文中使用的代码的完整版本。感谢您阅读本文！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oe of l"/></div></figure></div></div>    
</body>
</html>