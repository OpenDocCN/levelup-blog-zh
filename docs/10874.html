<html>
<head>
<title>Does Text Preprocessing Affect Natural Language Processing Performance?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本预处理是否影响自然语言处理性能？</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/does-text-preprocessing-affect-natural-language-processing-performance-ccadaaaab39b?source=collection_archive---------15-----------------------#2022-01-18">https://levelup.gitconnected.com/does-text-preprocessing-affect-natural-language-processing-performance-ccadaaaab39b?source=collection_archive---------15-----------------------#2022-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="db62" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用Tensorflow对各种文本预处理技术效果的实证研究。</p><p id="0a10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">说到自然语言处理，一个关键但经常被忽略的前置步骤是文本预处理。在将输入输入到模型中之前，有许多方法可以对其进行预处理。这篇博文实验并比较了各种文本预处理技术在情感分类任务中的效果。</p><p id="0836" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感情分类例子摘自<a class="ae ko" href="https://www.tensorflow.org/text/tutorials/text_classification_rnn" rel="noopener ugc nofollow" target="_blank"> Tensorflow教程网站</a>。我们将预测IMDB评论的正面和负面情绪。我们拥有的数据集是50000条高度极性的电影评论及其相应标签的列表——0或1，分为一半一半用于训练和测试。由于模型不是这篇文章的重点，并且在Tensorflow教程中已经有详细介绍，所以我们不会在它上面花太多时间。型号代码在文章末尾提供。它由一个文本矢量化层、一个嵌入层、一个双向LSTM层以及最后一个产生标签预测的密集层组成。需要注意的最重要的一点是，在文本矢量化层中，我们将参数<code class="fe kp kq kr ks b">standardize</code>设置为<code class="fe kp kq kr ks b">None</code>，因为我们将在预处理中进行自己的标准化。</p><p id="8851" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们首先在没有任何文本标准化的情况下训练模型。这是我们的基线。经过20个时期(后续测试也是如此)，我们获得了82.40%的验证准确率。注意，我们有一个<code class="fe kp kq kr ks b">preprocess</code>函数，它应用了给定的定制标准化。我们在这篇博文中使用了这个<code class="fe kp kq kr ks b">preprocess</code>函数。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">基线代码</figcaption></figure><p id="f151" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们简单地将文本转换成小写，我们获得了82.19%的验证准确率。小写减少了输入的稀疏性，但是有引入歧义的风险。例如，<code class="fe kp kq kr ks b">apple</code>和<code class="fe kp kq kr ks b">Apple</code>可能意味着不同的东西，一个是一种水果，另一个是一家公司。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">小写代码</figcaption></figure><p id="9ab9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，除了小写，我们删除标点符号。这一次，我们获得了85.73%的验证准确率。去掉标点符号减少了对句子部分末尾“新”字的不正确处理，例如<code class="fe kp kq kr ks b">“hello world,”</code>中的<code class="fe kp kq kr ks b">“world,”</code>而不是实际的<code class="fe kp kq kr ks b">“world”</code>。即使标点符号有时可能带有强烈的情感，如感叹号，但在这里删除它们似乎很有帮助。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">小写和无标点符号代码</figcaption></figure><p id="8e82" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">继续，我们尝试词干化和词汇化。词干化和词汇化都是一种将单词的形态变体简化为其基本/词根形式的处理。不同之处在于词干化仅基于简单的启发式字符规则，而词汇化内置了更多的语言知识。比如输入单词<code class="fe kp kq kr ks b">apples</code>、<code class="fe kp kq kr ks b">geese</code>、<code class="fe kp kq kr ks b">churches</code>，词干化产生<code class="fe kp kq kr ks b">appl</code>、<code class="fe kp kq kr ks b">gee</code>、<code class="fe kp kq kr ks b">churches</code>，而词条化产生<code class="fe kp kq kr ks b">apple</code>、<code class="fe kp kq kr ks b">goose</code>、<code class="fe kp kq kr ks b">church</code>。作为另一个例子，对于输入单词<code class="fe kp kq kr ks b">likes</code>、<code class="fe kp kq kr ks b">liking</code>、<code class="fe kp kq kr ks b">likely</code>、<code class="fe kp kq kr ks b">unlike</code>和<code class="fe kp kq kr ks b">liked</code>，词干化将它们全部简化为<code class="fe kp kq kr ks b">like</code>，而词汇化仅将<code class="fe kp kq kr ks b">likes</code>转换为<code class="fe kp kq kr ks b">like</code>，并保留所有其他变体，因为它们很可能根据上下文表示不同的意思。</p><p id="5a26" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">经过词干化和词元化后，我们获得了81.77%和84.69%的验证准确率，这与我们的直觉相符，即词元化优于词干化。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">词干化和词汇化代码</figcaption></figure><p id="bd9f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们试着去掉所有的停用词。停用词是指像<code class="fe kp kq kr ks b">i</code>、<code class="fe kp kq kr ks b">my</code>、<code class="fe kp kq kr ks b">you</code>、<code class="fe kp kq kr ks b">her</code>、<code class="fe kp kq kr ks b">be</code>、<code class="fe kp kq kr ks b">don’t</code>、<code class="fe kp kq kr ks b">can</code>、<code class="fe kp kq kr ks b">must</code>等词。停用词没有正式的定义。它们是传统自然语言处理为了简化而通常丢弃的那种单词。我们获得了84.01%的验证准确率。它稍微低一点的表现是意料之中的，因为停用词包含否定，比如<code class="fe kp kq kr ks b">don’t</code>，可以完全改变一篇评论的情绪。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">删除停用字词代码</figcaption></figure><p id="ee80" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，看起来简单的小写和删除标点符号效果最好。请参见下表进行概述，然后提供模型的代码片段。事实上，其他人也进行过<a class="ae ko" href="https://arxiv.org/abs/1707.01780#:~:text=version%2C%20v3)%5D-,On%20the%20Role%20of%20Text%20Preprocessing%20in%20Neural%20Network%20Architectures,Text%20Categorization%20and%20Sentiment%20Analysis&amp;text=While%20our%20experiments%20show%20that,of%20variability%20across%20preprocessing%20techniques." rel="noopener ugc nofollow" target="_blank">类似的调查</a>。对于哪个总体来说最好，是的，你猜对了。看情况。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi le"><img src="../Images/98c30d8f929fef6e5a29ad13854577f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gi5ZwSJ6G3L5fWgjK9v8w.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">结果概述</figcaption></figure><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi ll"><img src="../Images/5596f66c331fea4bbd0a826ed85be21c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p60BIudOOF0mZaOMxshWBw.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">训练图</figcaption></figure><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">模型和训练代码</figcaption></figure></div></div>    
</body>
</html>