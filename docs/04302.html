<html>
<head>
<title>Deploying Scalable, Production-Ready Airflow in 10 Easy Steps Using Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kubernetes，通过10个简单步骤部署可扩展的生产就绪型气流</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/deploying-scalable-production-ready-airflow-in-10-easy-steps-using-kubernetes-4f449d01f47a?source=collection_archive---------1-----------------------#2020-06-19">https://levelup.gitconnected.com/deploying-scalable-production-ready-airflow-in-10-easy-steps-using-kubernetes-4f449d01f47a?source=collection_archive---------1-----------------------#2020-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a5c6e9b42a3170705b6d6e1da9f93276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N1fzQcUTqiHIAKMG"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">图片来自《Kubernetes儿童图解指南》，点击<a class="ae kf" href="https://www.cncf.io/the-childrens-illustrated-guide-to-kubernetes/" rel="noopener ugc nofollow" target="_blank">查看</a>。</figcaption></figure><p id="131a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Airbnb的创意产品Airflow是一款开源数据编排工具，允许您以编程方式安排作业，以便提取、转换或加载(ETL)数据。由于Airflow的工作流是以Dag(有向无环图)的形式用Python编写的，因此它们允许复杂的计算、可伸缩性和可维护性，这与cron作业或其他调度工具不同。作为一名数据科学家和工程师，数据对我来说非常重要。我使用气流来确保我需要的所有数据都经过处理、清理并可用，这样我就可以轻松地运行我的模型。</p><p id="02e9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我一年前开始这段旅程时，我在网上搜寻资源，但是没有。我想要一个清晰的途径来部署可扩展版本的Airflow，但是我发现的许多文章都不完整，或者创建了无法处理我想要处理的数据量的小版本。我的目标是每天高效、可靠地运行数十万个以上的任务，同时不影响我的钱包。当时，KubernetesExecutor还没有向公众发布，但现在已经发布了。</p><p id="7f6c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我写这篇文章是希望防止你在许多不眠之夜思考气流的存在(以及我自己的),并对它产生不健康的痴迷。这就是我如何用10个简单的步骤用最新版本(1.10.10)创建一个可扩展的、生产就绪的气流。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="4788" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">先决条件:</h1><ul class=""><li id="6a07" class="mj mk it ki b kj ml kn mm kr mn kv mo kz mp ld mq mr ms mt bi translated">码头工人。如果你有Ubuntu系统，你可以在这里<a class="ae kf" href="https://docs.docker.com/engine/install/ubuntu/" rel="noopener ugc nofollow" target="_blank">使用他们令人敬畏的指令</a>或者你可以参考我做的这个<a class="ae kf" href="https://docs.google.com/document/d/e/2PACX-1vQjDiS49bEx4qhdsY7-YvuYAWo0F4_6FVlnKmnMplqvJ2jbkEONytEttu8anMUPEw/pub" rel="noopener ugc nofollow" target="_blank"> PDF </a>:</li><li id="bbd6" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld mq mr ms mt bi translated">名为“dags”的Git存储库，因此您可以存储您的工作流；这允许协作。</li><li id="d75c" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld mq mr ms mt bi translated">存储完整图像的容器存储库。</li><li id="869b" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld mq mr ms mt bi translated">Kubernetes集群(或minikube ),如果您想在生产中部署气流。</li></ul></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="d2da" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">第一步:Docker图像</h1><p id="b8f7" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">有很多选项，包括舵图(使用puckel图像)，但我发现Dockerfile是最直观、直接和可定制的版本。很少有好的图片——puck El很棒，如果你刚开始使用它——但是如果你打算使用KubernetesExecutor，我建议你使用Dockerfile创建自己的图片。你也可以用这个方法得到最新版本的Airflow (1.10.10)。</p><p id="9b17" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在您的linux环境中，键入:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="6a14" class="nl lm it nh b gy nm nn l no np">cd ~<br/>git clone <a class="ae kf" href="https://github.com/spanneerselvam/airflow-image.git" rel="noopener ugc nofollow" target="_blank">https://github.com/spanneerselvam/airflow-image.git</a><br/>cd airflow-image<br/>ls</span></pre><p id="adf9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您的config目录包含了您将从机器复制到Airflow的所有文件。打开docker文件。</p><p id="1470" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您应该在这里看到以下代码(这只是一个代码片段):</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="2849" class="nl lm it nh b gy nm nn l no np">FROM python:3.7<br/>RUN apt-get update &amp;&amp; apt-get install -y supervisor<br/>USER root<br/>RUN apt-get update &amp;&amp; apt-get install — yes \<br/>sudo \<br/>git \<br/>vim \<br/>cron \<br/>gcc<br/>RUN pip install apache-airflow[1.10.10]<br/>RUN cd /usr/local &amp;&amp; mkdir airflow &amp;&amp; chmod +x airflow &amp;&amp; cd airflow<br/>RUN useradd -ms /bin/bash airflow<br/>RUN usermod -a -G sudo airflow<br/>RUN chmod 666 -R /usr/local/airflow<br/>ARG AIRFLOW_USER_HOME=/usr/local/airflow<br/>ENV AIRFLOW_HOME=${AIRFLOW_USER_HOME}<br/>COPY config/airflow.cfg ${AIRFLOW_USER_HOME}/airflow.cfg<br/>EXPOSE 8080<br/>#Python Package Dependencies for Airflow<br/>RUN pip install pyodbc flask-bcrypt pymssql sqlalchemy psycopg2-binary pymysql</span></pre><p id="36d3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">告诉你一个有趣的事实(你对有趣的定义可能与我的非常不同):Docker的标志是这条非常可爱的鲸鱼——就像它是我见过的最可爱的标志(不相信我？去吧，去谷歌一下！)—因为它在一次logo大赛中以压倒性优势胜出，甚至打败了长颈鹿！Docker甚至收养了一头名叫Molly Dock的鲸鱼。她正在浩瀚的太平洋中游走。我为什么知道这个？当你很晚才醒来部署气流时，你最终会谷歌一些奇怪的东西…</p><h1 id="3bce" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第二步:DAGs</h1><p id="af3f" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">使用KubernetesExecutor在气流中设置DAGs是很棘手的，这是我完成的最后一块拼图。有几个选项，如在docker映像中嵌入DAG，但这种方法的问题是，每次更改DAG代码时，您都必须重建映像。</p><p id="f9e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我发现协作的最佳解决方案是使用GitHub(或BitBucket)来存储您的Dag。创建您自己的repo(克隆我的——稍后会有更多介绍),然后您和您的团队可以将您的所有工作放入存储库中。一旦你做到了这一点，你需要通过使用PV和PVC(持久卷和持久卷声明)和Azure文件共享(或EKS等同物)将Dag挂载到运行气流的pod。</p><p id="bf5d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">光伏和PVC是Kubernetes提供的服务。请将它们视为共享存储资源，可以连接到您部署的每个单元。为此，你需要创建一个Azure文件共享(这里的说明是<a class="ae kf" href="https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-create-file-share?tabs=azure-portal" rel="noopener ugc nofollow" target="_blank"/>)。确保你把文件共享挂载到你的电脑上(挂载说明可以在<a class="ae kf" href="https://docs.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux" rel="noopener ugc nofollow" target="_blank">这里</a>找到)，这样它就能从你的git repo中提取代码，并显示在Azure文件共享中。我使用了一个简单的cron作业，它每分钟运行一个名为git_sync.sh的shell脚本，从GitHub中提取代码。</p><p id="4be7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">crontab -e:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="d805" class="nl lm it nh b gy nm nn l no np">* * * * /home/git_sync.sh</span><span id="fd4a" class="nl lm it nh b gy nw nn l no np">#Mandatory Blank Line</span></pre><p id="b647" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">git_sync.sh(注意:我的远程名称是“DAGs”而不是origin):</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="09cb" class="nl lm it nh b gy nm nn l no np">cd ~<br/>git clone git@github.com:spanneerselvam/airflow-image.git<br/>cd airflow-image<br/>ls</span></pre><p id="6dcb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你做到了这一点(我建议为你的Azure文件共享使用至少5 Gi的存储)，你需要在Kubernetes中部署Azure文件共享。遵循以下步骤(它们也适用于EKS):</p><ol class=""><li id="2a0e" class="mj mk it ki b kj kk kn ko kr nx kv ny kz nz ld oa mr ms mt bi translated">为你的Azure文件共享创建一个Kubernetes秘密。阅读本指南，在这里安全地创建您的秘密<a class="ae kf" href="https://docs.microsoft.com/en-us/azure/aks/azure-files-volume" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="fa6f" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld oa mr ms mt bi translated">部署一个PVC(参见代码airflow-pvc.yaml)。你只需要做一次。</li><li id="287a" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld oa mr ms mt bi translated">部署一个PV(参见repo中的代码airflow-pv.yaml和airflow-pv-k8s.yaml)。您必须对每个名称空间都这样做(在我的例子中是“default”和“k8s-tasks”)。</li></ol><p id="f486" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">步骤2–3:要部署PV和PVC，需要运行以下代码行:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="07f8" class="nl lm it nh b gy nm nn l no np">kubectl create -f airflow-pvc.yaml<br/>kubectl get pvc<br/>kubectl create -f airflow-pv.yaml<br/>kubectl create -f airflow-pv-k8s.yaml<br/>kubectl get pv</span></pre><p id="3d5d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果PVs和PVC的状态是“已绑定”，那么就可以开始了！</p><p id="98f3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在Dag出现在Azure文件共享中，您需要调整气流设置。我将我的Dag存储在名为<em class="nq">"/usr/local/air flow/DAGs "</em>的文件夹中的pod中。此文件夹从文件共享安装在主窗格中，但为了正常工作，它也必须安装在每个工作窗格中。如果您查看airflow.cfg，请注意[kubernetes]部分下的这两个设置。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="2b99" class="nl lm it nh b gy nm nn l no np">dags_in_image = False #The worker will get the mount location for the dags<br/>#dags_volume_subpath = This line is commented out because the mount folder is the same as the dag folder<br/>dags_volume_claim = airflow-dags #put your claim name here (this must match your airflow-pvc.yaml file)</span></pre><p id="4d98" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">写达戈:</strong>也可以看看我写给“写达戈的艺术<a class="ae kf" href="https://docs.google.com/document/d/e/2PACX-1vRm5AqQD4aZ7fhQY2rDlD_wDho9RX48dTVCa9QQK_RFkpXciCdsCQ-Voa0Rt1LZIA/pub" rel="noopener ugc nofollow" target="_blank">的这个便捷指南。您可以克隆这个repo并下载两个dag，template_dag.py和gcp_dag.py </a><a class="ae kf" href="https://github.com/spanneerselvam/dags.git" rel="noopener ugc nofollow" target="_blank">在这里</a>。</p><h1 id="ba5b" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第三步:记录</h1><p id="fda6" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">对于每次任务运行，airflow都会创建一个日志来帮助用户调试。在这里，我们将日志存储在<em class="nq">"/usr/local/air flow/logs "</em>文件夹中。这是如此重要的一块。我在日志记录方面遇到了太多的问题——可怕的“***日志文件不存在”浮现在脑海中——我发誓每次我得到这个错误，我都会有点(实际上是很多)内心死亡，并感到心悸。但别担心，我会支持你的！说到Kubernetes有两种选择。</p><ol class=""><li id="1f70" class="mj mk it ki b kj kk kn ko kr nx kv ny kz nz ld oa mr ms mt bi translated">在Kubernetes集群上使用PVC(永久卷声明)</li><li id="0a83" class="mj mk it ki b kj mu kn mv kr mw kv mx kz my ld oa mr ms mt bi translated">远程日志记录</li></ol><p id="7e3b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们已经经历了使用PVC的过程，我将向您展示如何使用GCP(谷歌云平台)远程登录。使用Google控制台创建一个bucket，然后创建一个名为<em class="nq">“logs”</em>的文件夹。确保您打开了存储桶的权限；你可以点击查看<a class="ae kf" href="https://cloud.google.com/storage/docs/cloud-console" rel="noopener ugc nofollow" target="_blank">。你还需要创建一个服务帐户，也可以在这里找到(感谢上帝，GCP有惊人的说明！)下载json认证文件，并将内容复制到<em class="nq">“air flow-image/config/GCP . JSON”</em>文件中。</a></p><p id="b51a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您需要将bucket和文件夹的详细信息添加到airflow.cfg和Dockerfile的第72行。一旦你做到了这一点，你就成功了。我已经创建了一个名为“AirflowGCPKey”的日志连接ID。这个ID与GCP连接的敏感细节相关联。您可以在UI中创建这个ID，或者我个人喜欢做的是在UI中运行gcp_dag.py来自动创建这个连接(这里的代码是<a class="ae kf" href="https://github.com/spanneerselvam/dags/blob/master/gcp_dag.py" rel="noopener ugc nofollow" target="_blank">这里是</a>)。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="28c8" class="nl lm it nh b gy nm nn l no np">RUN pip install apache-airflow[gcp] apache-airflow[gcp-api]<br/>RUN echo “deb <a class="ae kf" href="http://packages.cloud.google.com/apt" rel="noopener ugc nofollow" target="_blank">http://packages.cloud.google.com/apt</a> cloud-sdk main” | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list<br/>RUN apt-get install gnupg -y<br/>RUN curl <a class="ae kf" href="https://packages.cloud.google.com/apt/doc/apt-key.gpg" rel="noopener ugc nofollow" target="_blank">https://packages.cloud.google.com/apt/doc/apt-key.gpg</a> | apt-key add -<br/>RUN apt-get update &amp;&amp; apt-get install google-cloud-sdk -y<br/>RUN gcloud auth activate-service-account &lt;insert your service account&gt; — key-file=/usr/local/airflow/gcp.json — project=&lt;your project name&gt;</span></pre><h1 id="adf7" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第四步:数据库</h1><p id="4577" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">这是让气流工作的基本要素。Airflow附带了一个默认的数据库(我不建议在生产中使用)。您可以创建一个postgresql数据库，并在airflow.cfg中添加以下格式的字符串:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="ef48" class="nl lm it nh b gy nm nn l no np">sql_alchemy_conn = postgresql+psycopg2://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:5432/&lt;db&gt;</span></pre><h1 id="86e5" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第五步:费尔内钥匙</h1><p id="7f0b" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">您需要进入Python shell(类型为“Python”)为您的数据库创建一个fernet键。然后在shell中，复制并粘贴以下代码行来生成您的密钥。确保复制fernet密钥并将其粘贴到airflow.cfg文件中(搜索“fernet_key”)。我还推荐使用旋转密钥来获得额外的安全性。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="7bbd" class="nl lm it nh b gy nm nn l no np">from cryptography.fernet import Fernet<br/>fernet_key= Fernet.generate_key()<br/>print(fernet_key.decode())</span></pre><h1 id="4d4b" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第六步:认证</h1><p id="958b" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我已经设置了UI来设置RBAC(基于角色的访问控制)(参见in airflow.cfg: <em class="nq"> rbac = True </em>)。您可以像这样创建用户(在您的docker文件或Airflow的后端):</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="bbe1" class="nl lm it nh b gy nm nn l no np">airflow create_user -r Admin -u sai -e saipanneerselvamcodes@gmail.com -f Sai -l Panneerselvam -p seahrsequeen</span></pre><p id="63b2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中:<em class="nq"> -r = roll，-u =用户名，-e =邮箱，-f =名字，-l =姓氏，-p =密码。</em></p><p id="84db" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是的，我是海马皇后。</p><p id="e529" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:RBAC有以下角色:管理员、公众、观众、用户和操作员。你可以在这里阅读更多关于他们的<a class="ae kf" href="https://airflow.apache.org/docs/stable/security.html?highlight=ldap" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="8823" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">步骤7:Airflow web服务器和调度程序</h1><p id="9281" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">要在启动时运行web服务器(如果您想在Kubernetes上运行您的映像，这一点至关重要，否则映像将无法运行)，请使用supervisord(参见<em class="nq">" air flow-image/config/super visor . conf "</em>)。这是运行长任务的一个很好的选择。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="5a3a" class="nl lm it nh b gy nm nn l no np">[supervisord]<br/>nondaemon=true</span><span id="de7c" class="nl lm it nh b gy nw nn l no np">[program:server]<br/>command=airflow webserver -p 8080<br/>stdout_logfile=/var/log/supervisor/%(program_name)s.log<br/>stderr_logfile=/var/log/supervisor/%(program_name)s.log<br/>autostart=true<br/>autorestart=true</span><span id="a097" class="nl lm it nh b gy nw nn l no np">[program:scheduler]<br/>command=airflow scheduler<br/>stdout_logfile=/var/log/supervisor/%(program_name)s.log<br/>stderr_logfile=/var/log/supervisor/%(program_name)s.log<br/>autostart=true<br/>autorestart=true</span></pre><h1 id="388d" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">第八步:KubernetesExecutor</h1><p id="9a14" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">为了实现这一奇迹，请在[kubernetes]部分下的airflow.cfg中设置这些特性。您需要添加worker_container_repository，以便从存储图像的位置提取数据，这样您就可以为每个任务启动多个pod。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="d4fe" class="nl lm it nh b gy nm nn l no np">worker_container_repository = &lt;your-docker-image-repository&gt;<br/>worker_container_tag = latest<br/>worker_container_image_pull_policy = IfNotPresent</span></pre><p id="f6e5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还需要在Kubernetes中创建一个名为“airflow-secrets”的秘密，它包含提取docker图像的信息。您可以使用这个简单的命令来完成:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="0efa" class="nl lm it nh b gy nm nn l no np">kubectl create secret docker-registry airflow-secrets — docker-server=&lt;your-host&gt; — docker-username=&lt;your-username&gt; — docker-password&lt;your-pwd&gt; — docker-email=&lt;your-email&gt;</span></pre><p id="499c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kubernetes API有一个观察超时，它会干扰气流调度程序，因此要绕过这个超时，请在docker文件中添加这一行:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="8d52" class="nl lm it nh b gy nm nn l no np">ENV AIRFLOW_KUBERNETES_ENVIRONMENT_VARIABLES_KUBE_CLIENT_REQUEST_TIMEOUT_SEC=50</span></pre><p id="87fc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">注意:</strong>在Dockerfile中有一堆设置好的环境变量。这些对于KubernetesExecutor与气流调度程序和远程日志记录一起工作是至关重要的。</p><h1 id="df33" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">步骤9:保存你的气流图像</h1><p id="ba78" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">一旦您修改了代码以适应您的需要，您就准备好构建您的映像了。从“airflow-image”文件夹向上移动一级，然后键入:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="3ae4" class="nl lm it nh b gy nm nn l no np">sudo docker build airflow-image</span></pre><p id="a3b9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你的形象建立起来的时候，拿些水，伸展一下，看着你所有的努力汇集在一起。构建完映像后，确保保存它，然后将映像放入容器注册表中。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="04df" class="nl lm it nh b gy nm nn l no np">docker tag &lt;image-id&gt; &lt;docker-repo&gt;<br/>docker push &lt;docker-repo&gt;</span></pre><h1 id="0bcc" class="ll lm it bd ln lo nr lq lr ls ns lu lv lw nt ly lz ma nu mc md me nv mg mh mi bi translated">步骤10:在Kubernetes部署气流</h1><p id="fcbf" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在Kubernetes中扩展气流的最简单方法是通过部署。首先创建一个名为k8s-tasks的新命名空间(参见in air flow . CFG:<em class="nq">namespace = k8s-tasks</em>)。这是运行每项任务的所有pod的创建位置。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="1874" class="nl lm it nh b gy nm nn l no np">kubectl create namespace k8s-tasks<br/>kubectl create clusterrolebinding default-admin — clusterrole cluster-admin — serviceaccount=default:default — namespace k8s-tasks</span></pre><p id="9b71" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用以下命令部署映像并创建NGINX入口(查看UI的网关)后:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="2d54" class="nl lm it nh b gy nm nn l no np">kubectl create -f airflow-deployment.yaml<br/>kubectl create -f airflow-ingress.yaml</span></pre><p id="2182" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，您需要创建一个服务:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="93e5" class="nl lm it nh b gy nm nn l no np">kubectl expose deployment/airflow-deploy</span></pre><p id="9b8e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用下面一行找到您的集群的IP地址:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="7cde" class="nl lm it nh b gy nm nn l no np">kubectl get service -l app=nginx-ingress — namespace ingress-basic</span></pre></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="3a3b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">转到您的IP地址，瞧！</p><figure class="nc nd ne nf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/499cbc0ec8adba394f93914367e155d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BbO2TvpiP0UrwaYr"/></div></div></figure><p id="1545" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你已经部署了最新版本的气流。在版本1.10.10中，您可以设置时区，这样您就不会在心里将UTC时间转换为您的时区(这很困难)。我把我的时区设为美洲/洛杉矶，因为我在阳光明媚的加利福尼亚州，但是你可以在这篇文章<a class="ae kf" href="https://airflow.apache.org/docs/stable/timezone.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到你的时区。</p><p id="6fa3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是你要的，伙计们！你刚刚在10个简单的步骤中创建了一个美丽的，工作的，可扩展的气流版本！触发您的模板DAG，进入k8s-tasks名称空间，高兴地看着pods随着每个任务的启动而旋转。漫威在你的工作和放松。你应得的！也随时感谢我；)</p></div></div>    
</body>
</html>