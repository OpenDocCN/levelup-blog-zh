# å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€:è’™ç‰¹å¡ç½—ç®—æ³•

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/fundamental-of-reinforcement-learning-monte-carlo-algorithm-85428dc77f76>

## ç¬¬ä¸‰éƒ¨åˆ†:é˜è¿°äº†æ— æ¨¡å‹ RL ç®—æ³•çš„åŸºæœ¬åŸç†:è’™ç‰¹å¡ç½—ç®—æ³•

![](img/855824dcb6ac9e253ecef07ab2a5d0a4.png)

å¢å¡æ–¯Â·æœ¬æ°æ˜åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

å›æƒ³ä¸€ä¸‹åœ¨[ç¬¬ä¸€éƒ¨åˆ†](/fundamental-of-reinforcement-learning-markov-decision-process-8ba98fa66060)ä¸­ä»‹ç»çš„æ™ºèƒ½ä½“-ç¯å¢ƒç•Œé¢ï¼Œè§‚å¯Ÿæ˜¯æ™ºèƒ½ä½“å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥ï¼Œè¡ŒåŠ¨å°†æ”¹å˜ç¯å¢ƒçš„çŠ¶æ€ï¼Œå¥–åŠ±æ˜¯ä¸€ä¸ªæ ‡é‡å€¼ï¼Œè¡¨ç¤ºæ™ºèƒ½ä½“åœ¨æ­¥éª¤ t åšå¾—æœ‰å¤šå¥½ï¼Œæ™ºèƒ½ä½“çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚

![](img/01b35c4888a5fd4a0229ebde859aaf60.png)

å›¾ 1:ä»£ç†-ç¯å¢ƒç•Œé¢ã€‚æ¥æºâ€”â€”æ–¯å¦ç¦å¤§å­¦ CME 241[è®²åº§](https://web.stanford.edu/class/cme241/lecture_slides/rich_sutton_slides/5-6-MDPs.pdf)ã€‚

å¼ºåŒ–å­¦ä¹ ä¸åŒäºå…¶ä»–æœºå™¨å­¦ä¹ èŒƒå¼æ˜¯å› ä¸ºä»£ç†çš„è¡Œä¸ºå½±å“äº†å®ƒæ¥æ”¶åˆ°çš„åç»­æ•°æ®ï¼Œæ²¡æœ‰ç›‘ç£(æ ‡ç­¾æ•°æ®)ï¼Œåªæœ‰å¥–åŠ±ä¿¡å·ã€‚

åœ¨[ç¬¬ 2 éƒ¨åˆ†](/fundamentals-of-reinforcement-learning-value-iteration-and-policy-iteration-with-tutorials-a7ad0049c84f)ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—äº†ä»·å€¼å‡½æ•°ï¼Œå¹¶æ‰¾åˆ°äº†è½¬ç§»æ¦‚ç‡å·²çŸ¥çš„æœ€ä¼˜ç­–ç•¥ã€‚ç„¶è€Œï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹**è½¬ç§»æ¦‚ç‡æ˜¯æœªçŸ¥çš„**ï¼Œæˆ‘ä»¬éœ€è¦**å­¦ä¹ **ä»·å€¼å‡½æ•°å¹¶ä»ç»éªŒä¸­æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥**ã€‚**

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨é‡‡æ ·æ–¹æ³•è§£é‡Šè’™ç‰¹å¡ç½—ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ— æ¨¡å‹ RL ç®—æ³•ã€‚

# è’™ç‰¹å¡æ´›

å…ˆè¯´ä»€ä¹ˆæ˜¯è’™ç‰¹å¡ç½—(MC)ï¼Ÿ
MC æ˜¯ä¸€ç§åˆ©ç”¨éšæœºæ€§è§£å†³é—®é¢˜çš„æ–¹æ³•ï¼Œå³é€šè¿‡ç”Ÿæˆåˆé€‚çš„éšæœºæ•°å¹¶è§‚å¯Ÿç¬¦åˆæŸäº›ç‰¹æ€§çš„æ•°å­—åˆ†æ•°æ¥è§£å†³é—®é¢˜ã€‚ä½¿ç”¨ MC è®¡ç®—Ï€çš„ç¤ºä¾‹:

![](img/cab9895f1fa908004591465c66d11a8b.png)

å›¾ 2:ä¸ºã€Šğ‘›=3000 æ—¶æŠ¥ã€‹åœ¨æ­£æ–¹å½¢ä¸Šéšæœºæ”¾ç½®åœ†ç‚¹

ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œç»™å®š r = 1ï¼Œçº¢è‰²é¢ç§¯= 1/4 Ï€rï¼Œæ­£æ–¹å½¢é¢ç§¯= rã€‚
âˆ´ Ï€ â‰ˆ 4 Ã—çº¢è‰²åŒºåŸŸçš„ç‚¹æ•°/æ€»ç‚¹æ•°

# æ³•å›½è’™ç‰¹å¡æ´›

åŒæ ·ï¼Œåœ¨ RL ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ MC å¯¹è®¸å¤šè½¨è¿¹è¿›è¡Œéšæœºé‡‡æ ·ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå°è¯•ä¼°è®¡ä¸åŒçŠ¶æ€çš„å€¼â€”â€”å›æƒ³ä¸€ä¸‹ï¼Œä»·å€¼å‡½æ•°æ˜¯ä» s: Vğœ‹(ğ‘ )=ğ”¼ğœ‹[ğºâ‚œ|ğ‘†â‚œ=ğ‘ ]å¼€å§‹çš„é¢„æœŸæ”¶ç›Šï¼Œè€Œ q å€¼å‡½æ•°æ˜¯ä»ğ‘ å¼€å§‹çš„é¢„æœŸæ”¶ç›Šï¼Œé‡‡å–è¡ŒåŠ¨ğ‘: ğ‘„ğœ‹(ğ‘ ,ğ‘)=ğ”¼ğœ‹[ğºâ‚œ|ğ‘†â‚œ=ğ‘ ï¼Œğ´â‚œ=ğ‘].è½¨è¿¹æ˜¯ä»å¼€å§‹çŠ¶æ€åˆ°ç»“æŸçŠ¶æ€çš„çŠ¶æ€åºåˆ—ã€‚ä¾‹å¦‚(sâ‚ï¼Œaâ‚ï¼Œrâ‚‚ï¼Œsâ‚‚ï¼Œaâ‚‚ï¼Œrâ‚ƒï¼Œâ€¦ï¼Œrâ‚œ).)

## é¦–æ¬¡è®¿é—®è’™ç‰¹å¡æ´›æ”¿ç­–è¯„ä¼°

![](img/190d4be16233ed3cdfcfc164eacfb63e.png)

å›¾ 3:é¦–æ¬¡è®¿é—®è’™ç‰¹å¡æ´›æ”¿ç­–è¯„ä¼°â€”ä¼ªä»£ç [3]

è¿™é‡Œæˆ‘ä»¬ç”¨ç»éªŒæ¥å­¦ä¹ ä¸€ä¸ªç»éªŒçŠ¶æ€å€¼å‡½æ•°:

![](img/80ce0f97166a6ab8671ee85210aa56ac.png)

å½“è®¡ç®—ä»·å€¼å‡½æ•°æ—¶ï¼Œå®ƒå¯¹è®¿é—®(ğ‘ ,ğ‘).)åè§‚å¯Ÿåˆ°çš„å›æŠ¥è¿›è¡Œå¹³å‡é¦–æ¬¡è®¿é—® MC æ„å‘³ç€å¹³å‡å›æŠ¥ç‡åªæœ‰ç¬¬ä¸€æ¬¡(ğ‘ ,ğ‘)è¢«è®¿é—®çš„è½¨è¿¹ã€‚

æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥äº†è§£ä¸€ä¸‹ã€‚å‡è®¾ä¸‹é¢æåˆ°çš„ä¸€ç»´ç½‘æ ¼ä¸–ç•Œç¯å¢ƒã€‚

![](img/320d4c4a56ad3edd6f80b53f6dc947ae.png)

å›¾ 4:ç¤ºä¾‹

ä»£ç†å¤„äº 1x4 ç½‘æ ¼ä¸–ç•Œä¸­ï¼ŒçŠ¶æ€ s âˆˆ {cellâ‚ã€cellâ‚‚ã€cellâ‚ƒã€cellâ‚„}ï¼ŒåŠ¨ä½œ a âˆˆ{å‘å·¦ç§»åŠ¨ï¼Œå‘å³ç§»åŠ¨)ã€‚åœ¨è¿™ç§ç¯å¢ƒä¸‹ï¼Œä»£ç†äººå¦‚æœåˆ°è¾¾ç›®çš„åœ°å°†è·å¾— 10 åˆ†å¥–åŠ±ï¼Œæ¯ä¸ªåŠ¨ä½œå°†èŠ±è´¹ 1 åˆ†ã€‚

å‡è®¾ä»¥ä¸‹æ˜¯ 3 ä¸ªè½¨è¿¹çš„è¡¨ç¤º:

![](img/02feb0ce8cdf2976dd76f7c157b24a45.png)

å›¾ 5:éšæœºé‡‡æ ·çš„ 3 æ¡è½¨è¿¹

ç»™å®šè¿™ 3 æ¡è½¨è¿¹ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æ‰€æœ‰éç»ˆç‚¹çŠ¶æ€çš„ä»·å€¼å‡½æ•°:cellâ‚ã€cellâ‚‚ã€cellâ‚ƒ.é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®—ğ›¾=0.9.æ¯é›†çš„å›æŠ¥

ç”±äºç¬¬ä¸€é›†å’Œç¬¬äºŒé›†æ²¡æœ‰æ¶‰åŠ cellâ‚ï¼Œ
**çš„ç»éªŒå€¼å‡½æ•°ä¸ºâˆ’1Ã—0.9â°âˆ’1Ã—0.9 +10Ã—0.9 = 6.2**

**ç¬¬ä¸€é›† cellâ‚‚:gâ‚œ=âˆ’1Ã—0.9â°+10Ã—0.9 = 8
ç¬¬äºŒé›† gâ‚œ=âˆ’1Ã—0.9â°âˆ’1Ã—0.9 1Ã—0.9+10Ã—0.9 = 4.58
ç¬¬ä¸‰é›† gâ‚œ=âˆ’1Ã—0.9â°âˆ’1Ã—0.9 1Ã—0.9+10Ã—0.9 = 4.58
cellâ‚‚**çš„ç»éªŒå€¼å‡½æ•°ä¸º(8+4.58+4.58)/3=5.72****

**ç¬¬ä¸€é›† cellâ‚ƒ:gâ‚œ=10Ã—0.9â°=10
ç¬¬äºŒé›† Gâ‚œ=âˆ’1Ã—0.9â°âˆ’1Ã—0.9 +10Ã—0.9 =6.2
ç¬¬ä¸‰é›† gâ‚œ=10Ã—0.9â°=10
cellâ‚ƒçš„ç»éªŒå€¼å‡½æ•°ä¸º(10+6.2+10)/3=8.73**

> **æˆ‘ä»¬å¯ä»¥ç”¨æ›´å¤šçš„æƒ…èŠ‚æˆ–è½¨è¿¹å¾—åˆ°æ›´ç²¾ç¡®çš„ä»·å€¼å‡½æ•°ã€‚**

## **è’™ç‰¹å¡ç½—æ§åˆ¶ç®—æ³•**

**![](img/3d64db351bb3958a8cc9020d7c59e860.png)**

**å›¾ 6:è’™ç‰¹å¡ç½—æ§åˆ¶ç®—æ³•â€”â€”ä¼ªä»£ç [3]**

**ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†ç»™å®šæ”¿ç­–çš„æ‰€æœ‰çŠ¶æ€çš„ä»·å€¼å‡½æ•°ã€‚æˆ‘ä»¬éœ€è¦æ”¹è¿›æ”¿ç­–ï¼Œä½¿ä¹‹æ›´å¥½ã€‚è¯„ä¼°å’Œæ”¹è¿›çš„è¿‡ç¨‹é‡å¤è¿›è¡Œï¼Œç›´åˆ°ç­–ç•¥æ²¡æœ‰æ”¹å˜æˆ–è¾¾åˆ°æœ€ä¼˜ç­–ç•¥ã€‚è¿™ä¸ªè¿‡ç¨‹ç±»ä¼¼äºæˆ‘ä»¬åœ¨ [**ç­–ç•¥è¿­ä»£**](/fundamentals-of-reinforcement-learning-value-iteration-and-policy-iteration-with-tutorials-a7ad0049c84f) ä¸­æ‰€åšçš„ã€‚ä½†æ˜¯ï¼Œå…‰æœ‰ä»·å€¼å‡½æ•°æ˜¯ä¸å¤Ÿçš„ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ä¸€ä¸ªåŠ¨ä½œåœç•™åœ¨ä¸€ä¸ªçŠ¶æ€ä¸‹æœ‰å¤šå¥½(Q å€¼)ã€‚ä½¿ç”¨ä¸Šé¢çš„ä¾‹å­ï¼Œè®©æˆ‘ä»¬ç»™å®šä¸€ä¸ªçŠ¶æ€å’Œä¸€ä¸ªåŠ¨ä½œæ¥å¡«å†™ Q è¡¨ã€‚ä¼°è®¡ Q å‡½æ•°ä¸ä¼°è®¡å€¼å‡½æ•°ç•¥æœ‰ä¸åŒã€‚å®ƒæ˜¯ä¸€é›†é‡Œå›½å®¶è¡ŒåŠ¨å¯¹(ğ‘ ,ğ‘)è¢«è®¿é—®çš„å¹³å‡å›æŠ¥ã€‚**

**ç”±äºç¬¬ä¸€é›†å’Œç¬¬äºŒé›†éƒ½æ²¡æœ‰(cellâ‚ï¼Œå³)
**(cellâ‚ï¼Œå³)**çš„ç»éªŒ q å€¼å‡½æ•°ä¸ºâˆ’1Ã—0.9â°âˆ’1Ã—0.9 +10Ã—0.9 = 6.2
ç”±äºæ‰€æœ‰é›†éƒ½æ²¡æœ‰(cellâ‚ï¼Œå·¦)
**(cellâ‚ï¼Œå·¦)**çš„ç»éªŒ q å€¼å‡½æ•°ä¸º 0**

**å¯¹äºç¬¬ä¸€é›†(cellâ‚‚ï¼Œå³)æ¥è¯´:Gâ‚œ =âˆ’1Ã—0.9â° +10Ã—0.9 =8
ç¬¬äºŒé›† gâ‚œ=âˆ’1Ã—0.9â°âˆ’1Ã—0.9 1Ã—0.9+10Ã—0.9 = 4.58
ç¬¬ä¸‰é›† Gâ‚œ=âˆ’1Ã—0.9â°+10Ã—0.9 =8
å¯¹äº **(cellâ‚‚ï¼Œå³)**çš„ç»éªŒ q å€¼å‡½æ•°ä¸º(8+4.58+8)/3=6.86
ç”±äºç¬¬ä¸€é›†å’Œç¬¬äºŒé›†éƒ½æœ‰ no(cellâ‚‚(å·¦)å‚ä¸ï¼Œ
ç»éªŒ q å€¼å‡½æ•°**

**å¯¹äº(cellâ‚ƒï¼Œå³)ç¬¬ä¸€é›†:Gâ‚œ =10Ã—0.9â°=10
ç¬¬äºŒé›† Gâ‚œ=10Ã—0.9â°=10
ç¬¬ä¸‰é›† gâ‚œ=10Ã—0.9â°=10
**(cellâ‚ƒï¼Œå³)**çš„ç»éªŒ q å€¼å‡½æ•°ä¸º(10+10+10)/3=10
ç”±äºç¬¬ä¸€é›†å’Œç¬¬ä¸‰é›†éƒ½æœ‰ no(cellâ‚ƒ(å·¦)
**(cellâ‚ƒï¼Œå·¦)**çš„ç»éªŒ q å€¼å‡½æ•°ä¸ºâˆ’1Ã—0.9â°âˆ’1Ã—0.9 +10Ã—0.9 =6.2**

**![](img/b848583d1e142bdbf520a1c33771dcdc.png)**

**å›¾ 7:å®Œæˆçš„é—®é¢˜è¡¨**

**æ¯ç§çŠ¶æ€ä¸‹çš„æœ€ä¼˜è¡ŒåŠ¨æ˜¯å…·æœ‰æœ€å¤§ Q(sï¼Œa)çš„è¡ŒåŠ¨ã€‚ä»ç»“æœæ¥çœ‹ï¼Œcellâ‚ã€cellâ‚‚ã€cellâ‚ƒçš„æœ€ä¼˜è¡ŒåŠ¨æ˜¯å‘å³ç§»åŠ¨ã€‚**

# **æ¨èé˜…è¯»**

**[](/fundamental-of-reinforcement-learning-markov-decision-process-8ba98fa66060) [## å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€:é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹

### ç¬¬ 1 éƒ¨åˆ†:è§£é‡Šé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’Œè´å°”æ›¼æ–¹ç¨‹çš„æ¦‚å¿µ

levelup.gitconnected.com](/fundamental-of-reinforcement-learning-markov-decision-process-8ba98fa66060) [](/fundamentals-of-reinforcement-learning-value-iteration-and-policy-iteration-with-tutorials-a7ad0049c84f) [## å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€:ä»·å€¼è¿­ä»£å’Œæ”¿ç­–è¿­ä»£æ•™ç¨‹

### ç¬¬äºŒéƒ¨åˆ†:è§£é‡Šç”¨äºè§£å†³ MDP é—®é¢˜çš„ä»·å€¼è¿­ä»£å’Œç­–ç•¥è¿­ä»£çš„æ¦‚å¿µã€‚

levelup.gitconnected.com](/fundamentals-of-reinforcement-learning-value-iteration-and-policy-iteration-with-tutorials-a7ad0049c84f) 

# å‚è€ƒ

[1] [æ–¯å¦ç¦å¤§å­¦ CME241 è®²åº§:é‡‘èä¸­éšæœºæ§åˆ¶é—®é¢˜çš„å¼ºåŒ–å­¦ä¹ ](https://web.stanford.edu/class/cme241/lecture_slides/rich_sutton_slides/5-6-MDPs.pdf)ï¼Œ2021

[2]â€œåœ†å‘¨ç‡çš„è’™ç‰¹å¡ç½—æ¨¡æ‹Ÿâ€”â€”å¥¥å°”ç™»å ¡å¤§å­¦ã€‚â€ã€åœ¨çº¿ã€‘ã€‚å¯ç”¨:[https://uol . de/en/LCS/probabilical-programming/web church-and-open bugs/pi-by-Monte-Carlo-simulation](https://uol.de/en/lcs/probabilistic-programming/webchurch-and-openbugs/pi-by-monte-carlo-simulation)

[3] R. S .è¨é¡¿å’Œ A. G .å·´å°”æ‰˜ï¼Œâ€œå¼ºåŒ–å­¦ä¹ :å¯¼è®ºï¼Œç¬¬äºŒç‰ˆï¼Œè¿›è¡Œä¸­ã€‚â€

# åˆ†çº§ç¼–ç 

æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼[è®¢é˜…æˆ‘ä»¬çš„ YouTube é¢‘é“](https://www.youtube.com/channel/UC3v9kBR_ab4UHXXdknz8Fbg?sub_confirmation=1)æˆ–è€…åŠ å…¥ [**Skilled.dev ç¼–ç é¢è¯•è¯¾ç¨‹**](https://skilled.dev/) ã€‚

[](https://skilled.dev) [## dreamus114.com

### The course to master the coding interview

skilled.dev](https://skilled.dev)**