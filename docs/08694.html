<html>
<head>
<title>Using Cycle-Generative Adversarial Network to Convert Between Map Views and Satellite Views</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用循环生成对抗网络在地图视图和卫星视图之间转换</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/using-cycle-generative-adversarial-network-to-convert-between-map-views-and-satellite-views-a75724068b6e?source=collection_archive---------13-----------------------#2021-05-25">https://levelup.gitconnected.com/using-cycle-generative-adversarial-network-to-convert-between-map-views-and-satellite-views-a75724068b6e?source=collection_archive---------13-----------------------#2021-05-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="aaf1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">及其核心架构的逐步介绍</strong></p><blockquote class="ko kp kq"><p id="b8c0" class="jq jr kr js b jt ju jv jw jx jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kn im bi translated"><strong class="js iu">背景</strong></p></blockquote><p id="c892" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个基于tensorflow <a class="ae kv" href="https://www.tensorflow.org/tutorials/generative/cyclegan" rel="noopener ugc nofollow" target="_blank">循环感知对抗网络(CycleGAN)教程</a>的简单实验。该教程在马和斑马图像之间进行转换。我试图复制它，以便在地图视图和卫星视图之间进行转换。方便的是，在tensorflow数据集目录下已经有一个准备好的数据集<a class="ae kv" href="https://www.tensorflow.org/datasets/catalog/cycle_gan#cycle_ganmaps" rel="noopener ugc nofollow" target="_blank"> cycle_gan/maps </a>。我们需要对tensorflow CycleGAN教程进行的唯一值得注意的代码更改是切换到加载cycle_gan/maps数据集。</p><blockquote class="ko kp kq"><p id="5e6e" class="jq jr kr js b jt ju jv jw jx jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kn im bi translated"><strong class="js iu"> CycleGAN核心架构</strong></p></blockquote><p id="2a4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深入探究CycleGAN背后的核心思想是值得的，因为我认为对它如何工作有更深的理解比制作一堆花哨的图像更令人满意。</p><p id="de22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CycleGAN可以学习映射来转换两个域的图像。与其他基于生成对抗网络的方法相比，它最显著的特点是CycleGAN不需要成对的图像。在CycleGAN之前，如果我们要将图像从一个域转换到另一个域，我们需要为域的图像收集成对的示例。然后，我们将通过一个生成器网络馈送源图像(带有噪声),并让一个鉴别器网络尝试区分真实的目标图像和生成的目标图像。更多细节请参考tensorflow <a class="ae kv" href="https://www.tensorflow.org/tutorials/generative/pix2pix" rel="noopener ugc nofollow" target="_blank"> Pix2Pix教程</a>为例。</p><p id="0ee5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CycleGAN如何克服配对样本的缺乏，主要取决于它设计损失的方式。我们都知道，在机器学习中，如果我们通过一个可微的过程构造一个损失函数，我们可以使用梯度下降来反向传播参数更新。下面是CycleGAN损失的定义。顺便说一下，我省略了一些超参数系数，这简化了图形演示。此外，我还故意忽略了一些情况下公式中张量的形状，也是为了简单。</p><p id="e813" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">前进路径</strong></p><p id="f2f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有两个生成器:地图到卫星视图(<code class="fe kw kx ky kz b">MV2SV</code>)和卫星到地图视图(<code class="fe kw kx ky kz b">SV2MV</code>)。还有两个鉴别器:一个鉴别真实与虚假的地图视图(<code class="fe kw kx ky kz b">DiscriminatorMV</code>)，另一个鉴别真实与虚假的卫星视图(<code class="fe kw kx ky kz b">DiscriminatorSV</code>)。输入包括一幅地图视图的实像(<code class="fe kw kx ky kz b">real_mv</code>)和一幅卫星视图的实像(<code class="fe kw kx ky kz b">real_sv</code>)。输入是从训练数据集中采样的。视图之间没有预定义的配对。</p><p id="1f5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们首先通过生成器传递真实图像以获得假(生成的)图像。参见图1中的图解。</p><pre class="la lb lc ld gt le kz lf lg aw lh bi"><span id="a22a" class="li lj it kz b gy lk ll l lm ln">fake_sv = MV2SV(real_mv)<br/>fake_mv = SV2MV(real_sv)</span></pre><figure class="la lb lc ld gt lp gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/6c2912f37b36bb6a845f54a9c663a4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*0nVabCnKb5eLZOZWrjeh0Q.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">图一</figcaption></figure><p id="565e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们将生成的假图像分别通过另一个生成器来创建循环图像。这里的想法是，当我们通过地图到卫星生成器传递地图视图时，我们会得到一个假的卫星视图，然后如果我们通过卫星到地图生成器传递假的卫星视图，我们应该会得到一个地图视图。它被称为循环图像，因为图像要经过往返转换。如果两个发生器都足够好，循环贴图视图应该看起来像原始贴图视图。对称路径也是如此。参见图2中的图解。</p><pre class="la lb lc ld gt le kz lf lg aw lh bi"><span id="a152" class="li lj it kz b gy lk ll l lm ln">cycled_sv = MV2SV(fake_mv)<br/>cycled_mv = SV2MV(fake_sv)</span></pre><figure class="la lb lc ld gt lp gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/6ee843118c6bc00f61702225b930cabe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*qcG_BUOgQjqvudgfiMNhDA.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">图2</figcaption></figure><p id="a651" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们将原始实像分别传递给位于同一图像域的生成器。这里的想法是，如果地图到卫星生成器足够好，它对已经是卫星的图像没有影响。对称路径也是如此。参见图3中的图解。</p><pre class="la lb lc ld gt le kz lf lg aw lh bi"><span id="3af9" class="li lj it kz b gy lk ll l lm ln">unchanged_mv = SV2MV(real_mv)<br/>unchanged_sv = MV2SV(real_sv)</span></pre><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi lx"><img src="../Images/3dd9faf2112e80e8c2c46aace61bb3a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2vxiaeVmKbRuO7d5ZPwmg.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">图3</figcaption></figure><p id="38c2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">亏损</strong></p><p id="35a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们准备计算损失。对于鉴别者来说，他们的损失是对真实和虚假图像的错误分类。参见图4中的图解。</p><pre class="la lb lc ld gt le kz lf lg aw lh bi"><span id="e9f8" class="li lj it kz b gy lk ll l lm ln">d_real_sv = DiscriminatorSV(real_sv)<br/>d_real_mv = DiscriminatorMV(real_mv)<br/>d_fake_sv = DiscriminatorSV(faked_sv)<br/>d_fake_mv = DiscriminatorMV(faked_mv)</span><span id="20e6" class="li lj it kz b gy mc ll l lm ln">d_mv_loss = BinaryCrossEntropyLoss(d_real_mv, 1) + <br/>    BinaryCrossEntropyLoss(d_fake_mv, 0)</span><span id="39b5" class="li lj it kz b gy mc ll l lm ln">d_sv_loss = BinaryCrossEntropyLoss(d_real_sv, 1) + <br/>    BinaryCrossEntropyLoss(d_fake_sv, 0)</span></pre><figure class="la lb lc ld gt lp gh gi paragraph-image"><div class="gh gi md"><img src="../Images/a5c21abc20b86089dffd7a10c50c4af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*vavmkYOSIeFd0iQOc9VR7w.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">图4</figcaption></figure><p id="a91d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于发电机来说，就有点复杂了。发电机的损耗有三个部分。</p><ol class=""><li id="81f6" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn mj mk ml mm bi translated">首先，生成器生成假图像，希望欺骗鉴别器。所以对于假图像，鉴别器的增益就是发生器的损耗。</li><li id="74b7" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">其次，回想一下，我们通过将原始图像传递给各自的生成器来生成未改变的图像，这些生成器被认为是没有效果的。因此，未改变的图像和真实图像之间的差值的范数是发电机损耗的一部分。</li><li id="b304" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">最后，回想一下我们通过往返转换生成的循环图像。循环图像应该看起来像原始图像。因此，循环图像和真实图像之间的差值的范数也是发生器损耗的一部分。请注意，我们使用了两个生成器来生成循环图像。所以两台发电机分担这个损耗。</li></ol><p id="b0f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">参见图5中的图解。</p><pre class="la lb lc ld gt le kz lf lg aw lh bi"><span id="1989" class="li lj it kz b gy lk ll l lm ln">cycle_loss = tf.reduce_mean(tf.abs(real_mv - cycled_mv)) + <br/>    tf.reduce_mean(tf.abs(real_sv - cycled_sv))</span><span id="405e" class="li lj it kz b gy mc ll l lm ln">mv2sv_loss = Loss(d_fake_sv, 1) + cycle_loss + <br/>    tf.reduce_mean(tf.abs(real_sv - unchanged_sv))</span><span id="9a8d" class="li lj it kz b gy mc ll l lm ln">sv2mv_loss = Loss(d_fake_mv, 1) + cycle_loss +    <br/>    tf.reduce_mean(tf.abs(real_mv - unchanged_mv))</span></pre><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ms"><img src="../Images/fa452343fb5e2ea5af7220d2222c6a0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4i4aWaZqZVUs8Tot86LIMQ.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">图5</figcaption></figure><p id="0e08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就是这样。我们现在可以开始训练了。</p><blockquote class="ko kp kq"><p id="3a0c" class="jq jr kr js b jt ju jv jw jx jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kn im bi translated"><strong class="js iu">实验</strong></p></blockquote><p id="e2e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该数据集包含2192个示例，地图视图和卫星视图各占一半。我训练了与tensorflow CycleGAN教程中相同的模型。为了加快训练速度，我使用了批量大小8而不是1(就像在教程中一样)。我在V100 GPU上运行训练，训练了200个epochss，每个epoch用时1分钟左右。我还尝试在2个GPU上使用MirrorStrategy。这导致了明显的加速，但跨副本聚合逻辑有点复杂，我没有时间来验证这一点，所以下面给出的最终结果来自单个GPU运行。以下是结果示例:</p><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mt"><img src="../Images/106432b016f3a1906d75dc8979e2af53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j43f0AgIDFbtmUDOSMd9nw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">示例图像:卫星视图到地图视图1</figcaption></figure><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mu"><img src="../Images/a5cc6cf54193ceeae8355f372812d016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VLcfVplcSy52mYPxK2WxRw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">示例图像:卫星视图到地图视图2</figcaption></figure><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mv"><img src="../Images/bb2e452c273076adea2610417f5dc427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hb_-BaIv7pbAzOFe_zt4Ow.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">示例图像:地图视图到卫星视图1</figcaption></figure><figure class="la lb lc ld gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mw"><img src="../Images/93d4c98cfc70badccece74d66cd43dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q9DnyBj64DnNxJ0jbnMonw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk translated">示例图像:地图视图到卫星视图2</figcaption></figure><p id="1737" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不完美，但也不差。再见，下次见…</p></div></div>    
</body>
</html>