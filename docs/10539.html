<html>
<head>
<title>Change Data Capture with Debezium Kafka and MySQL</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Debezium Kafka和MySQL改变数据捕获</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/change-data-capture-with-debezium-kafka-and-mysql-359f7bc6b29a?source=collection_archive---------6-----------------------#2021-12-19">https://levelup.gitconnected.com/change-data-capture-with-debezium-kafka-and-mysql-359f7bc6b29a?source=collection_archive---------6-----------------------#2021-12-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="8f9b" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是变更数据捕获？</h1><p id="6573" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将数据从应用程序数据库移动到另一个数据库，而对应用程序功能的影响可以忽略不计，这是使用移位数据捕获架构模式的主要灵感。</p><h2 id="db2a" class="lj jo iq bd jp lk ll dn jt lm ln dp jx kw lo lp kb la lq lr kf le ls lt kj lu bi translated">使用</h2><ol class=""><li id="d3a4" class="lv lw iq kn b ko kp ks kt kw lx la ly le lz li ma mb mc md bi translated">跟踪数据的变化，以馈入弹性搜索索引。</li><li id="1492" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">将数据更改从OLTP实时移动到OLAP</li><li id="94d9" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">创建审计日志等</li></ol><h1 id="2f03" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">项目概述</h1><p id="dd78" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将使用Mysql作为我们的数据库</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/50f0bde95a80dc753498dad339c06008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GZ6xYb6r_cv-ZibP.png"/></div></div></figure><p id="d771" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi">‍</p><h1 id="f235" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">成分</h1><h1 id="fa8c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">先决条件安装</h1><p id="95c6" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了跟进，你需要以下指定的工具</p><ol class=""><li id="8ae7" class="lv lw iq kn b ko mv ks mw kw na la nb le nc li ma mb mc md bi translated"><a class="ae nd" href="https://docs.docker.com/get-docker/" rel="noopener ugc nofollow" target="_blank">停靠</a>(首选)运行<code class="fe ne nf ng nh b">postgres, debezium and kafka</code></li><li id="6feb" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><a class="ae nd" href="https://github.com/dbcli/pgcli" rel="noopener ugc nofollow" target="_blank"> pgcli </a>连接到我们的<code class="fe ne nf ng nh b">postgres</code>实例</li></ol><h1 id="0b13" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">1.Postgres</h1><p id="c101" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这将作为我们的应用程序数据库。为了理解CDC(与<code class="fe ne nf ng nh b">debezium</code>一起)是如何工作的，我们需要理解当一个交易发生时会发生什么。当一个事务发生时，该事务被记录在磁盘中一个称为预写日志(WAL)的地方，然后处理数据更改、更新或删除。事务通常保存在缓存中，并批量刷新到磁盘，以保持较低的延迟。在数据库崩溃的情况下，我们可能会丢失缓存，但数据库可以使用磁盘中的日志进行恢复。使用WAL，只有日志被写入磁盘，这比将所有数据更改写入磁盘的成本更低，这是<code class="fe ne nf ng nh b">postgres</code>的开发人员不得不做出的折衷，以保持较低的事务延迟，并在崩溃时具有恢复能力(使用<code class="fe ne nf ng nh b">WAL</code>)。</p><p id="38ad" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">您可以将WAL看作是一个仅附加的日志，它包含了所有操作的顺序信息，时间戳表示事务的记录时间。WAL文件会被定期删除或存档，以便保持数据库较小。</p><p id="aa6a" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">我们将使用docker运行一个<code class="fe ne nf ng nh b">postgres</code>实例</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="6de3" class="lj jo iq nh b gy nm nn l no np">docker run -d --name postgres -p 5432:5432 -e POSTGRES_USER=start_data_engineer \<br/>-e POSTGRES_PASSWORD=password debezium/postgres:12</span></pre><p id="cd45" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">上面的docker命令启动了一个名为<code class="fe ne nf ng nh b">postgres</code>的<code class="fe ne nf ng nh b">postgres</code> docker容器。用户名设为<code class="fe ne nf ng nh b">start_data_engineer</code>，密码设为<code class="fe ne nf ng nh b">password</code>。如果你注意到你会看到我们已经使用了<code class="fe ne nf ng nh b">debezium/postgres:12</code>图像，使用debezium的docker of postgres的原因是为了启用postgres需要的设置来操作debezium。让我们来看看这些设置</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="2e60" class="lj jo iq nh b gy nm nn l no np">docker exec -ti postgres /bin/bash</span></pre><p id="fb9a" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">使用上面的命令以交互模式-it在postgres容器上执行/bin/bash命令。你现在在你的docker容器里面。输入</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="38a8" class="lj jo iq nh b gy nm nn l no np">cat /var/lib/postgresql/data/postgresql.conf</span></pre><p id="5f90" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">查看postgres的配置设置。</p><h2 id="fede" class="lj jo iq bd jp lk ll dn jt lm ln dp jx kw lo lp kb la lq lr kf le ls lt kj lu bi translated">postgresql.conf</h2><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nq"><img src="../Images/dbe21c314c84ca8b5cd7aa4d0711f212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FvM5tGp6-clj4oBk.png"/></div></div></figure><p id="53fe" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi">‍</p><p id="7e88" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">复制部分是我们设置数据库写入WAL的配置的地方。这</p><ol class=""><li id="fd04" class="lv lw iq kn b ko mv ks mw kw na la nb le nc li ma mb mc md bi translated"><code class="fe ne nf ng nh b">wal_level</code>具有最少的选项:从数据库崩溃中重启所需的最少信息，存档:使数据库引擎能够执行WAL存档，hot_standby:使数据库引擎能够创建我们的服务器的只读副本，逻辑:是我们的目的所需要的，它添加了所有必要的信息，使这个(WAL)数据可供其他系统使用。</li><li id="45b4" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">max_wal_senders</code>WAL发送者是在数据库上运行的进程，用于将WAL发送给接收者(其他副本或系统)。此配置表示允许的最大WAL发送方进程数。</li></ol><p id="16ce" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">让我们在postgres中创建数据。我们使用pgcli与postgres实例进行交互</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="e958" class="lj jo iq nh b gy nm nn l no np">pgcli -h localhost -p 5432 -U start_data_engineer<br/>#password is password</span><span id="2b03" class="lj jo iq nh b gy nr nn l no np">CREATE SCHEMA bank;<br/>SET search_path TO bank,public;<br/>CREATE TABLE bank.holding (<br/>    holding_id int,<br/>    user_id int,<br/>    holding_stock varchar(8),<br/>    holding_quantity int,<br/>    datetime_created timestamp,<br/>    datetime_updated timestamp,<br/>    primary key(holding_id)<br/>);<br/>ALTER TABLE bank.holding replica identity FULL;<br/>insert into bank.holding values (1000, 1, 'VFIAX', 10, now(), now());<br/>\q</span></pre><p id="a818" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">以上是标准sql，加上了<code class="fe ne nf ng nh b">replica identity</code>。该字段可选择设置为<code class="fe ne nf ng nh b">DEFAULT, NOTHING, FULL and INDEX</code>之一，决定写入WAL的详细信息量。我们选择full来获取我们的WAL中CRUD变更事件的所有前后数据，<code class="fe ne nf ng nh b">INDEX</code>选项与FULL相同，但它也包括对WAL中的索引所做的变更，这是我们的项目目标所不需要的。我们还在保存表中插入一行。</p><h1 id="8999" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">2.卡夫卡</h1><p id="6713" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">Kafka是一个至少有一次保证的消息队列系统。卡夫卡一些关键概念的快速概述</p><ol class=""><li id="c1e4" class="lv lw iq kn b ko mv ks mw kw na la nb le nc li ma mb mc md bi translated">卡夫卡是一个<code class="fe ne nf ng nh b">distributed message queue</code>系统。分布式集群管理由zookeeper提供。</li><li id="25eb" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">broker</code>处理消费者写、生产者请求和元数据配置。kafka集群中的一个服务器是一个kafka代理，一个kafka集群中可以有多个代理</li><li id="6d04" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">Topic</code>是一个特定的队列，生产者可以将数据推入其中，消费者可以从中读取数据。</li><li id="289a" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">Partitions</code>是在集群上分发主题内容的方式。</li><li id="54a9" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">您可以将<code class="fe ne nf ng nh b">offset</code>(特定于一个分区)看作是一个指针，当从那个主题分区读取消息时，它指向您所在的消息。</li></ol><p id="d8f4" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">在我们的项目中，kafka broker将用于将postgres数据库中的数据更改存储为消息。我们将在后面的小节中设置一个消费者来从代理读取数据。</p><p id="c355" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">让我们开始<code class="fe ne nf ng nh b">zookeeper</code>和一个卡夫卡式的经纪人</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="7805" class="lj jo iq nh b gy nm nn l no np">docker run -d --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 debezium/zookeeper:1.1<br/>docker run -d --name kafka -p 9092:9092 --link zookeeper:zookeeper debezium/kafka:1.1</span></pre><p id="7115" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">为了方便起见，我们再次使用debezium图像。您可以看到，对于动物园管理员，我们保持端口21821、2888、3888打开，这些是动物园管理员操作所必需的。同样，我们让9092对卡夫卡开放，我们可以通过这个端口与卡夫卡交流。</p><h1 id="9bf1" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">3.Debezium</h1><p id="5e10" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们使用一个叫做Connect的kafka工具来运行debezium。顾名思义，connect提供了一个框架，将输入数据源连接到kafka，并将kafka连接到输出接收器。它作为单独的服务运行。</p><p id="2fd4" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">Debezium负责从源数据系统(在我们的例子中是postgres)中读取数据，并以合适的格式将其推送到kafka主题(根据表自动命名)中。</p><p id="3c74" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">让我们开始一个kafka连接容器</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="c467" class="lj jo iq nh b gy nm nn l no np">docker run -d --name connect -p 8083:8083 --link kafka:kafka \<br/>--link postgres:postgres -e BOOTSTRAP_SERVERS=kafka:9092 \<br/>-e GROUP_ID=sde_group -e CONFIG_STORAGE_TOPIC=sde_storage_topic \<br/>-e OFFSET_STORAGE_TOPIC=sde_offset_topic debezium/connect:1.1</span></pre><p id="c392" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">注意，我们用BOOTSTRAP_SERVERS env变量指定了kafka主机和端点。这里的GROUP_ID表示这个连接服务所属的组。我们可以使用curl来检查已注册的连接服务。注意:在运行下面的curl命令之前，请等待几秒钟(至少10秒钟)</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="d82e" class="lj jo iq nh b gy nm nn l no np">curl -H "Accept:application/json" localhost:8083/connectors/<br/>[]</span></pre><p id="d3c8" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">我们可以使用curl命令在端口8083上注册一个debezium connect服务</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="cf52" class="lj jo iq nh b gy nm nn l no np">curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" \<br/>localhost:8083/connectors/ -d '{"name": "sde-connector", "config": {"connector.class": "io.debezium.connector.postgresql.PostgresConnector", "database.hostname": "postgres", "database.port": "5432", "database.user": "start_data_engineer", "database.password": "password", "database.dbname" : "start_data_engineer", "database.server.name": "bankserver1", "table.whitelist": "bank.holding"}}'</span></pre><p id="c054" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">让我们看看上面api调用的配置部分</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="36ea" class="lj jo iq nh b gy nm nn l no np">{<br/>  "name": "sde-connector",<br/>  "config": {<br/>    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",<br/>    "database.hostname": "postgres",<br/>    "database.port": "5432",<br/>    "database.user": "start_data_engineer",<br/>    "database.password": "password",<br/>    "database.dbname": "start_data_engineer",<br/>    "database.server.name": "bankserver1",<br/>    "table.whitelist": "bank.holding"<br/>  }<br/>}</span></pre><ol class=""><li id="b215" class="lv lw iq kn b ko mv ks mw kw na la nb le nc li ma mb mc md bi translated"><code class="fe ne nf ng nh b">The database.*</code>配置是我们postgres数据库的连接参数</li><li id="6876" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">database.server.name</code>是我们为数据库指定的名称</li><li id="9e89" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">table.whitelist</code>是一个字段，通知debezium连接器只从那个表中读取数据变更。同样，您可以将表或模式列入白名单或黑名单。默认情况下，debezium从模式中的所有表中读取数据。</li><li id="6154" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">connector.class</code>连接器是否用于连接我们的postgres数据库</li><li id="4a3d" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">name</code>我们为连接器指定的名称</li></ol><p id="5060" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">让我们检查连接器是否存在</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="304b" class="lj jo iq nh b gy nm nn l no np">curl -H "Accept:application/json" localhost:8083/connectors/<br/>["sde-connector"]%</span></pre><p id="524b" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">我们可以看到sde连接器已注册。</p><h1 id="8021" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">4.消费者</h1><p id="a23e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">既然我们已经有了将消息推入kafka代理的连接器，我们就可以使用消费者来消费消息了。让我们使用下面的命令，只看一下kafka主题bankserver1.bank.holding中的第一条消息</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="2c52" class="lj jo iq nh b gy nm nn l no np">docker run -it --rm --name consumer --link zookeeper:zookeeper --link kafka:kafka debezium/kafka:1.1 watch-topic -a bankserver1.bank.holding --max-messages 1 | grep '^{' | jq</span></pre><p id="ca40" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">在上面的例子中，我们启动了一个消费者容器来观察遵循格式<code class="fe ne nf ng nh b">{database.server.name}.{schema}.{table_name}</code>的主题<code class="fe ne nf ng nh b">bankserver1.bank.holding</code>，并且我们已经将这个消费者要读取的最大消息数设置为1。grep将过滤掉非JSON行，因为docker容器将打印出一些配置。<a class="ae nd" href="https://stedolan.github.io/jq/download/" rel="noopener ugc nofollow" target="_blank"> jq </a>(可选下载)是对json进行格式化。输出应该类似于下面所示的结构</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="c03b" class="lj jo iq nh b gy nm nn l no np">{<br/>  "schema": {<br/>    "type": "struct",<br/>    "fields": [<br/>      {<br/>        "type": "struct",<br/>        "fields": [<br/>          {<br/>            "type": "int32",<br/>            "optional": false,<br/>            "field": "holding_id"<br/>          },<br/>          {<br/>            "type": "int32",<br/>            "optional": true,<br/>            "field": "user_id"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": true,<br/>            "field": "holding_stock"<br/>          },<br/>          {<br/>            "type": "int32",<br/>            "optional": true,<br/>            "field": "holding_quantity"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "name": "io.debezium.time.MicroTimestamp",<br/>            "version": 1,<br/>            "field": "datetime_created"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "name": "io.debezium.time.MicroTimestamp",<br/>            "version": 1,<br/>            "field": "datetime_updated"<br/>          }<br/>        ],<br/>        "optional": true,<br/>        "name": "bankserver1.bank.holding.Value",<br/>        "field": "before"<br/>      },<br/>      {<br/>        "type": "struct",<br/>        "fields": [<br/>          {<br/>            "type": "int32",<br/>            "optional": false,<br/>            "field": "holding_id"<br/>          },<br/>          {<br/>            "type": "int32",<br/>            "optional": true,<br/>            "field": "user_id"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": true,<br/>            "field": "holding_stock"<br/>          },<br/>          {<br/>            "type": "int32",<br/>            "optional": true,<br/>            "field": "holding_quantity"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "name": "io.debezium.time.MicroTimestamp",<br/>            "version": 1,<br/>            "field": "datetime_created"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "name": "io.debezium.time.MicroTimestamp",<br/>            "version": 1,<br/>            "field": "datetime_updated"<br/>          }<br/>        ],<br/>        "optional": true,<br/>        "name": "bankserver1.bank.holding.Value",<br/>        "field": "after"<br/>      },<br/>      {<br/>        "type": "struct",<br/>        "fields": [<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "version"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "connector"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "name"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": false,<br/>            "field": "ts_ms"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": true,<br/>            "name": "io.debezium.data.Enum",<br/>            "version": 1,<br/>            "parameters": {<br/>              "allowed": "true,last,false"<br/>            },<br/>            "default": "false",<br/>            "field": "snapshot"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "db"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "schema"<br/>          },<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "table"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "field": "txId"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "field": "lsn"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": true,<br/>            "field": "xmin"<br/>          }<br/>        ],<br/>        "optional": false,<br/>        "name": "io.debezium.connector.postgresql.Source",<br/>        "field": "source"<br/>      },<br/>      {<br/>        "type": "string",<br/>        "optional": false,<br/>        "field": "op"<br/>      },<br/>      {<br/>        "type": "int64",<br/>        "optional": true,<br/>        "field": "ts_ms"<br/>      },<br/>      {<br/>        "type": "struct",<br/>        "fields": [<br/>          {<br/>            "type": "string",<br/>            "optional": false,<br/>            "field": "id"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": false,<br/>            "field": "total_order"<br/>          },<br/>          {<br/>            "type": "int64",<br/>            "optional": false,<br/>            "field": "data_collection_order"<br/>          }<br/>        ],<br/>        "optional": true,<br/>        "field": "transaction"<br/>      }<br/>    ],<br/>    "optional": false,<br/>    "name": "bankserver1.bank.holding.Envelope"<br/>  },<br/>  "payload": {<br/>    "before": null,<br/>    "after": {<br/>      "holding_id": 1000,<br/>      "user_id": 1,<br/>      "holding_stock": "VFIAX",<br/>      "holding_quantity": 10,<br/>      "datetime_created": 1589121006547486,<br/>      "datetime_updated": 1589121006547486<br/>    },<br/>    "source": {<br/>      "version": "1.1.1.Final",<br/>      "connector": "postgresql",<br/>      "name": "bankserver1",<br/>      "ts_ms": 1589121006548,<br/>      "snapshot": "false",<br/>      "db": "start_data_engineer",<br/>      "schema": "bank",<br/>      "table": "holding",<br/>      "txId": 492,<br/>      "lsn": 24563232,<br/>      "xmin": null<br/>    },<br/>    "op": "c",<br/>    "ts_ms": 1589121006813,<br/>    "transaction": null<br/>  }<br/>}</span></pre><p id="5e65" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">基本上有两个主要部分</p><ol class=""><li id="c5c3" class="lv lw iq kn b ko mv ks mw kw na la nb le nc li ma mb mc md bi translated"><code class="fe ne nf ng nh b">schema</code>:schema定义了<code class="fe ne nf ng nh b">before</code>、<code class="fe ne nf ng nh b">after</code>、<code class="fe ne nf ng nh b">source</code>、<code class="fe ne nf ng nh b">op</code>、<code class="fe ne nf ng nh b">ts_ms</code>和<code class="fe ne nf ng nh b">transaction</code>段的有效载荷的模式。消费者客户端程序可以使用这些数据来解析输入。</li><li id="a7bf" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated"><code class="fe ne nf ng nh b">payload</code>:包含实际数据，有前后两部分，分别显示持有、数据变更前后的栏目。数据更改由<code class="fe ne nf ng nh b">op</code>表示，它是c create (insert)、update、delete和r read(在快照时)之一。source部分显示了WAL配置，其中<code class="fe ne nf ng nh b">tx_id</code>表示事务id和<code class="fe ne nf ng nh b">lsn</code>日志序列号，用于存储每个WAL记录的日志文件的字节偏移量。</li></ol><p id="ce24" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">我们关心之前和之后的部分。我们将使用python将其格式化为我们在开始时定义的枢纽结构。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="0957" class="lj jo iq nh b gy nm nn l no np">#!/usr/bin/env python3 -u<br/># Note: the -u denotes unbuffered (i.e output straing to stdout without buffering data and then writing to stdout)</span><span id="a208" class="lj jo iq nh b gy nr nn l no np">import json<br/>import os<br/>import sys<br/>from datetime import datetime</span><span id="2942" class="lj jo iq nh b gy nr nn l no np">FIELDS_TO_PARSE = ['holding_stock', 'holding_quantity']</span><span id="b7b7" class="lj jo iq nh b gy nr nn l no np">def parse_create(payload_after, op_type):<br/>    current_ts = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')<br/>    out_tuples = []<br/>    for field_to_parse in FIELDS_TO_PARSE:<br/>        out_tuples.append(<br/>            (<br/>                payload_after.get('holding_id'),<br/>                payload_after.get('user_id'),<br/>                field_to_parse,<br/>                None,<br/>                payload_after.get(field_to_parse),<br/>                payload_after.get('datetime_created'),<br/>                None,<br/>                None,<br/>                current_ts,<br/>                op_type<br/>            )<br/>        )</span><span id="a95e" class="lj jo iq nh b gy nr nn l no np">return out_tuples</span><span id="ad6d" class="lj jo iq nh b gy nr nn l no np">def parse_delete(payload_before, ts_ms, op_type):<br/>    current_ts = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')<br/>    out_tuples = []<br/>    for field_to_parse in FIELDS_TO_PARSE:<br/>        out_tuples.append(<br/>            (<br/>                payload_before.get('holding_id'),<br/>                payload_before.get('user_id'),<br/>                field_to_parse,<br/>                payload_before.get(field_to_parse),<br/>                None,<br/>                None,<br/>                ts_ms,<br/>                current_ts,<br/>                op_type<br/>            )<br/>        )</span><span id="3cf7" class="lj jo iq nh b gy nr nn l no np">return out_tuples</span><span id="19ba" class="lj jo iq nh b gy nr nn l no np">def parse_update(payload, op_type):<br/>    current_ts = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')<br/>    out_tuples = []<br/>    for field_to_parse in FIELDS_TO_PARSE:<br/>        out_tuples.append(<br/>            (<br/>                payload.get('after', {}).get('holding_id'),<br/>                payload.get('after', {}).get('user_id'),<br/>                field_to_parse,<br/>                payload.get('before', {}).get(field_to_parse),<br/>                payload.get('after', {}).get(field_to_parse),<br/>                None,<br/>                payload.get('ts_ms'),<br/>                None,<br/>                current_ts,<br/>                op_type<br/>            )<br/>        )</span><span id="8d3c" class="lj jo iq nh b gy nr nn l no np">return out_tuples</span><span id="1301" class="lj jo iq nh b gy nr nn l no np">def parse_payload(input_raw_json):<br/>    input_json = json.loads(input_raw_json)<br/>    op_type = input_json.get('payload', {}).get('op')<br/>    if op_type == 'c':<br/>        return parse_create(<br/>            input_json.get('payload', {}).get('after', {}),<br/>            op_type<br/>        )<br/>    elif op_type == 'd':<br/>        return parse_delete(<br/>            input_json.get('payload', {}).get('before', {}),<br/>            input_json.get('payload', {}).get('ts_ms', None),<br/>            op_type<br/>        )<br/>    elif op_type == 'u':<br/>        return parse_update(<br/>            input_json.get('payload', {}),<br/>            op_type<br/>        )<br/>    # no need to log read events<br/>    return []</span><span id="e87d" class="lj jo iq nh b gy nr nn l no np">for line in sys.stdin:<br/>    # 1. reads line from unix pipe, assume only valid json come through<br/>    # 2. parse the payload into a format we can use<br/>    # 3. prints out the formatted data as a string to stdout<br/>    # 4. the string is of format<br/>    #    holding_id, user_id, change_field, old_value, new_value, datetime_created, datetime_updated, datetime_deleted, datetime_inserted<br/>    data = parse_payload(line)<br/>    for log in data:<br/>        log_str = ','.join([str(elt) for elt in log])<br/>        print(log_str, flush=True)</span></pre><p id="537d" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated"><strong class="kn ir">注</strong>:使用<a class="ae nd" href="https://github.com/tmux/tmux/wiki" rel="noopener ugc nofollow" target="_blank"> tmux </a>方便多终端查看。</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="76d8" class="lj jo iq nh b gy nm nn l no np">docker run -it --rm --name consumer --link zookeeper:zookeeper \<br/>--link kafka:kafka debezium/kafka:1.1 watch-topic \<br/>-a bankserver1.bank.holding | grep --line-buffered '^{' \<br/>| &lt;your-file-path&gt;/stream.py &gt; &lt;your-output-path&gt;/holding_pivot.txt</span></pre><p id="c25f" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">上面的命令启动一个消费者容器，<code class="fe ne nf ng nh b">grep</code>只允许以{表示一个json，line-buffered选项告诉grep一次输出一行而不进行缓冲(缓冲区大小取决于您的操作系统)，然后使用python脚本将消息转换成我们想要的格式，并将输出写入一个名为<code class="fe ne nf ng nh b">holding_pivot.txt</code>的文件。</p><p id="9668" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">在另一个终端中，执行以下操作</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="a161" class="lj jo iq nh b gy nm nn l no np">tail -f &lt;your-output-path&gt;/holding_pivot.txt</span></pre><p id="aef2" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">上面的命令打开holding_pivot.txt文件，然后继续执行，这样您就可以看到是否有新的行添加到文件中。在另一个终端中，使用</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="62f8" class="lj jo iq nh b gy nm nn l no np">pgcli -h localhost -p 5432 -U start_data_engineer<br/># the password is password</span></pre><p id="2584" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">尝试以下sql脚本，并确保您在holding_pivot.txt中看到的输出是准确的</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="bc9d" class="lj jo iq nh b gy nm nn l no np">-- C<br/>insert into bank.holding values (1001, 2, 'SP500', 1, now(), now());<br/>insert into bank.holding values (1002, 3, 'SP500', 1, now(), now());</span><span id="bca0" class="lj jo iq nh b gy nr nn l no np">-- U<br/>update bank.holding set holding_quantity = 100 where holding_id=1000;</span><span id="ef02" class="lj jo iq nh b gy nr nn l no np">-- d<br/>delete from bank.holding where user_id = 3;<br/>delete from bank.holding where user_id = 2;</span><span id="789a" class="lj jo iq nh b gy nr nn l no np">-- c<br/>insert into bank.holding values (1003, 3, 'VTSAX', 100, now(), now());</span><span id="e6e8" class="lj jo iq nh b gy nr nn l no np">-- u<br/>update bank.holding set holding_quantity = 10 where holding_id=1003;</span></pre><p id="6acf" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi translated">您的输出应该是</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="aa65" class="lj jo iq nh b gy nm nn l no np">1000,1,holding_stock,None,VFIAX,1589121006547486,None,None,2020-05-10-10-31-23,c<br/>1000,1,holding_quantity,None,10,1589121006547486,None,None,2020-05-10-10-31-23,c<br/>1001,2,holding_stock,None,SP500,1589121109691459,None,None,2020-05-10-10-31-50,c<br/>1001,2,holding_quantity,None,1,1589121109691459,None,None,2020-05-10-10-31-50,c<br/>1002,3,holding_stock,None,SP500,1589121109695248,None,None,2020-05-10-10-31-50,c<br/>1002,3,holding_quantity,None,1,1589121109695248,None,None,2020-05-10-10-31-50,c<br/>1000,1,holding_stock,VFIAX,VFIAX,None,1589121112732,None,2020-05-10-10-31-53,u<br/>1000,1,holding_quantity,10,100,None,1589121112732,None,2020-05-10-10-31-53,u<br/>1002,3,holding_stock,SP500,None,None,1589121116301,2020-05-10-10-31-56,d<br/>1002,3,holding_quantity,1,None,None,1589121116301,2020-05-10-10-31-56,d<br/>1001,2,holding_stock,SP500,None,None,1589121116303,2020-05-10-10-31-56,d<br/>1001,2,holding_quantity,1,None,None,1589121116303,2020-05-10-10-31-56,d<br/>1003,3,holding_stock,None,VTSAX,1589121119075024,None,None,2020-05-10-10-31-59,c<br/>1003,3,holding_quantity,None,100,1589121119075024,None,None,2020-05-10-10-31-59,c<br/>1003,3,holding_stock,VTSAX,VTSAX,None,1589121121916,None,2020-05-10-10-32-02,u<br/>1003,3,holding_quantity,100,10,None,1589121121916,None,2020-05-10-10-32-02,u</span></pre><h1 id="7a9a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">数据流</h1><p id="2fbb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这代表了我们如何使用CDC模式从应用程序数据库中捕获更改，将其转换为不同的格式，而不会影响应用程序性能或内存。</p><h2 id="444e" class="lj jo iq bd jp lk ll dn jt lm ln dp jx kw lo lp kb la lq lr kf le ls lt kj lu bi translated">设计数据流</h2><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/bc0f0b1bef8f150f761ced81425658d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5VPjC4QJxj6cABiD.png"/></div></div></figure><p id="3757" class="pw-post-body-paragraph kl km iq kn b ko mv kq kr ks mw ku kv kw mx ky kz la my lc ld le mz lg lh li ij bi">‍</p><h2 id="222a" class="lj jo iq bd jp lk ll dn jt lm ln dp jx kw lo lp kb la lq lr kf le ls lt kj lu bi translated">Docker命令</h2><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="7c76" class="lj jo iq nh b gy nm nn l no np"># starting a pg instance<br/>docker run -d --name postgres -p 5432:5432 -e POSTGRES_USER=start_data_engineer -e POSTGRES_PASSWORD=password debezium/postgres:12</span><span id="f8f0" class="lj jo iq nh b gy nr nn l no np"># bash into postgres instance<br/>docker exec -ti postgres /bin/bash</span><span id="b67a" class="lj jo iq nh b gy nr nn l no np"># zookeeper and kafka broker<br/>docker run -d --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 debezium/zookeeper:1.1<br/>docker run -d --name kafka -p 9092:9092 --link zookeeper:zookeeper debezium/kafka:1.1</span><span id="29ca" class="lj jo iq nh b gy nr nn l no np"># Kafka connect<br/>docker run -d --name connect -p 8083:8083 --link kafka:kafka --link postgres:postgres -e BOOTSTRAP_SERVERS=kafka:9092 -e GROUP_ID=sde_group -e CONFIG_STORAGE_TOPIC=sde_storage_topic -e OFFSET_STORAGE_TOPIC=sde_offset_topic debezium/connect:1.1</span><span id="f462" class="lj jo iq nh b gy nr nn l no np"># register debezium connector<br/>curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{"name": "sde-connector", "config": {"connector.class": "io.debezium.connector.postgresql.PostgresConnector", "database.hostname": "postgres", "database.port": "5432", "database.user": "start_data_engineer", "database.password": "password", "database.dbname" : "start_data_engineer", "database.server.name": "bankserver1", "table.whitelist": "bank.holding"}}'</span><span id="7af9" class="lj jo iq nh b gy nr nn l no np"># sample consumer<br/>docker run -it --rm --name consumer --link zookeeper:zookeeper --link kafka:kafka debezium/kafka:1.1 watch-topic -a bankserver1.bank.holding --max-messages 1 | grep '^{'</span><span id="68c4" class="lj jo iq nh b gy nr nn l no np"># stream consumer, parse it and write to file<br/>docker run -it --rm --name consumer --link zookeeper:zookeeper --link kafka:kafka debezium/kafka:1.1 watch-topic -a bankserver1.bank.holding | grep --line-buffered '^{' | &lt;your-file-path&gt;/stream.py &gt; &lt;your-output-path&gt;/holding_pivot.txt</span></pre><h1 id="b684" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">停靠码头集装箱</h1><p id="441a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">您可以使用以下命令停止并删除docker容器</p><pre class="mk ml mm mn gt ni nh nj nk aw nl bi"><span id="7958" class="lj jo iq nh b gy nm nn l no np">docker stop $(docker ps -aq)<br/>docker rm $(docker ps -aq)</span><span id="b83f" class="lj jo iq nh b gy nr nn l no np">docker stop &lt;your-container-name&gt; # to stop and remove specific container<br/>docker rm &lt;your-container-name&gt;</span></pre><h1 id="9675" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">需要注意的事项</h1><ol class=""><li id="11cb" class="lv lw iq kn b ko kp ks kt kw lx la ly le lz li ma mb mc md bi translated">我们看到数据发生了变化，但没有看到数据模式的变化，这取决于您的用例，这可能会变得非常棘手。</li><li id="19e6" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">你需要postgres或更高版本。</li><li id="a3a7" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">WAL配置需要仔细设置，以防止数据库过载。</li><li id="09a1" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">与大多数分布式系统一样，存在多个故障点，例如，数据库可能崩溃，kafka集群可能崩溃，您的用户可能崩溃，等等。始终为故障做好计划，并拥有处理这些问题的恢复机制。</li><li id="5de6" class="lv lw iq kn b ko me ks mf kw mg la mh le mi li ma mb mc md bi translated">kafka和debezium都提供至少一次事件交付保证。这很好，但是您的消费者或用户必须被设计为处理重复。一个好的方法是在消费者端使用基于upsert的数据摄取。</li></ol><h1 id="60ad" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="fa19" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">希望这篇文章能让你了解什么是变更数据捕获，什么时候使用它，如何使用debezium实现它，以及需要注意的常见陷阱。如果你有任何问题，请在下面的评论区告诉我。</p></div></div>    
</body>
</html>