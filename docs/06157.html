<html>
<head>
<title>How to Use Kafka Connect to Connect Two Data Sources on Heroku</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Kafka Connect连接Heroku上的两个数据源</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-use-kafka-connect-to-connect-two-data-sources-on-heroku-49104d693e4b?source=collection_archive---------13-----------------------#2020-10-30">https://levelup.gitconnected.com/how-to-use-kafka-connect-to-connect-two-data-sources-on-heroku-49104d693e4b?source=collection_archive---------13-----------------------#2020-10-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/0befd982dd9c7d0122cedce4da294515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V76ghc38RCCOXEr8"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">约书亚·内斯在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="1df6" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="e8bd" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">随着其他业务部门的需求不断增加，IT部门不得不不断寻找服务改进和成本节约的机会。这篇文章展示了正在研究或已经在使用Kafka的公司的几个具体用例，特别是Kafka Connect。</p><p id="4061" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Kafka Connect是一个企业级解决方案，用于集成大量应用程序，从传统数据库到Salesforce和SAP等业务应用程序。可能的集成场景包括从应用程序之间的连续流事件和数据到可用于替代手动数据传输的大规模可配置批处理作业。</p><h1 id="8a14" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">为什么是卡夫卡和赫罗库</h1><p id="d948" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae kf" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>最初是LinkedIn的一个内部项目，旨在取代多年来发展的各种排队和消息传递系统。目标是创建一个可横向扩展的系统，能够可靠地存储和处理每秒数百万条消息。今天，Kafka社区提供了一个完整的工具和功能生态系统，从简单的日志消息传递到执行基本的动态ETL任务，再到复杂的数据管道处理。Kafka的多功能性和健壮性以及可扩展性使其成为企业的绝佳选择。</p><p id="1f1a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Kafka的强大是有代价的:虽然从客户的角度来看使用Kafka很容易，但Kafka的设置和操作却是一项艰巨的任务。建立一个可靠的Kafka集群是一个需要经验的挑战。如果您的公司没有这方面的经验，可能需要几周甚至几个月的时间来设置和调整生产就绪型集群。这就是Heroku上Kafka的亮点:<a class="ae kf" href="https://devcenter.heroku.com/articles/kafka-on-heroku#provisioning-the-add-on" rel="noopener ugc nofollow" target="_blank">建立一个私有Kafka集群只需几分钟</a>，这使得it部门可以专注于他们想要提供的服务，而不是运营Kafka集群。</p><p id="50b6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦你在使用Kafka，添加Kafka Connect是合乎逻辑的下一步。但是Heroku上的Kafka Connect可以节省大量的时间，即使你不打算在你的应用程序中直接使用Kafka。Kafka Connect的运营开销很小，可以为任意数量的应用程序提供一个集成点。Kafka Connect为这些问题提供了一个统一的解决方案，而不是运行和维护用于重复数据传输、按需数据传输和系统间持续更新的不同解决方案。</p><p id="9fc1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在下一节中，您将了解一些典型的用例，并了解Kafka Connect能够集成哪些应用程序。</p><h1 id="946b" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">Kafka Connect的典型业务用例</h1><p id="b5d0" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">IT部门不断努力满足业务部门的需求，这些业务部门必须连接和集成各种定制和现成的应用程序。这些集成通常使用不太可靠的机制，比如循环批处理作业，而不是跨系统连续“流式”更新。Kafka Connect提供了一个可扩展的、可靠的解决方案，通常可以通过“流式”更新来取代缓慢的批处理作业。常见场景包括:</p><ol class=""><li id="f2f1" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">您的销售部门经常需要使用来自Salesforce的数据更新内部SQL数据库。使用Kafka Connect将更改从Salesforce连续传输到您的内部数据库。</li><li id="fde8" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">您的合规部门需要对某些数据库或应用程序的更新进行审计跟踪。使用Kafka Connect将相关更改传输到本地文件服务器，传输到S3进行异地存储，甚至传输到Elasticsearch进行快速检索。</li><li id="4803" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mm mn mo mp bi translated">用强大的解决方案取代不可靠、运行缓慢的ETL批处理作业。使用Kafka连接到</li></ol><ul class=""><li id="59db" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mv mn mo mp bi translated">跨多个应用程序更新数据，同时使它们更快、更可靠</li><li id="4b96" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">不断地从结构化文件(CSV、JSON、日志等)中传输变更。)到数据库和应用程序中</li><li id="a09e" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">在异构应用程序和数据库之间可靠、连续地传输更新</li></ul><p id="7d6e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">IT部门甚至可以创造新的自助服务机会，用自助服务流程取代手动或劳动密集型的数据传输或提取请求，从而减少IT部门的工作量，同时缩短业务部门的响应时间。假设有一个系统，贵公司的营销部门在您的服务台软件中创建一个票证，该票证会自动创建并触发数据传输，否则IT服务台将不得不手动处理。</p><h1 id="89d2" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">Kafka Connect可以集成的系统的(不完整)列表</h1><p id="649a" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Kafka Connect可以<a class="ae kf" href="https://docs.confluent.io/current/connect/managing/connectors.html" rel="noopener ugc nofollow" target="_blank">读取和写入</a>越来越多的应用和服务，包括企业应用，如SAP和Salesforce:</p><ul class=""><li id="fbd6" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mv mn mo mp bi translated">任何SQL数据库:Oracle、Microsoft SQL Server、IBM Db2、MySQL、PostgreSQL、MariaDB等等</li><li id="8acf" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">NoSQL数据库，如MongoDB、Redis、Cassandra、InfluxDB等</li><li id="1ce1" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">消息队列，如ActiveMQ、RabbitMQ、IBM MQ、亚马逊SQS、Azure Event Hub、Google Pub/Sub等</li><li id="34b2" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">IT服务台应用程序，如吉拉、ServiceNow和Zendesk</li><li id="96c7" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">日志和监控服务、应用程序和协议，如SNMP、Syslog、Elasticsearch、Amazon CloudWatch、Appdynamics、Metrics、Splunk等</li><li id="f14b" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">通用的“低级”数据源和协议，包括HTTP、SFTP、MQTT、JMS、文件系统等等</li><li id="3449" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">可以使用Java轻松编写健壮的定制连接器，充分利用可靠的Kafka Connect框架和底层基础设施</li><li id="1cdb" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">由于Kafka Connect使用Kafka作为底层基础设施，任何使用Kafka作为消息总线的应用程序都可以自动集成</li></ul><h1 id="db24" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">设置Kafka Connect集成既快速又简单</h1><p id="1aba" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们来举一个具体的例子。一个常见的集成场景是这样的:您有两个SQL数据库，您需要用另一个数据库中的信息更新其中一个数据库。例如，当订单的状态在您的履行系统中发生变化时，您可能需要更新内部CRM数据库来反映这一变化。下面是具体的场景:</p><ul class=""><li id="f7eb" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mv mn mo mp bi translated">每当完成数据库中的状态表改变时</li><li id="95c0" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">将更改写入CRM数据库中的ORDER_STATUS表</li></ul><p id="2bbd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">为简单起见，我们假设两者都是MySQL数据库。其他连接器的步骤是相同的，只是配置不同。</p><p id="69aa" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">假设您有一个带有Kafka Connect的工作Kafka集群，设置这种集成需要两个步骤:</p><ul class=""><li id="3f6f" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mv mn mo mp bi translated">创建“源-连接”以从履行数据库的状态表中读取数据</li><li id="4f7a" class="mh mi it lg b lh mq ll mr lp ms lt mt lx mu mb mv mn mo mp bi translated">创建“接收器连接”以将数据写入CRM数据库的ORDER_STATUS表</li></ul><p id="f82a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">下面是相应的cURL调用，以及对它们各自作用的解释。他们使用<a class="ae kf" href="https://docs.confluent.io/current/connect/references/restapi.html" rel="noopener ugc nofollow" target="_blank"> Kafka Connect REST API </a>来创建源和接收器。请注意，这些调用不是特定于Heroku的。它们可以与任何Kafka Connect安装一起使用:</p><ol class=""><li id="51b6" class="mh mi it lg b lh mc ll md lp mj lt mk lx ml mb mm mn mo mp bi translated">创建源连接。</li></ol><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="16de" class="nf kh it nb b gy ng nh l ni nj">curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d '{    <br/>  	"name": "jdbc_source_mysql_01",     <br/>  	"config": {       <br/>  		"connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",       <br/>  		"connection.url": "jdbc:mysql://fulfillmentdbhost:3306/fulfillmentdb",       <br/>  		"connection.user": "fullfilment_user",       <br/>  		"connection.password": "&lt;password&gt;",       <br/>  		"topic.prefix": "order-status-update-",       <br/>  		"mode":"timestamp",       <br/>  		"table.whitelist" : "fulfullmentdb.status",       <br/>  		"timestamp.column.name": "LAST_UPDATED",       <br/>  		"validate.non.null": false     <br/>  	}   <br/>}'</span></pre><p id="92c6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">2.创建接收器连接。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="b96a" class="nf kh it nb b gy ng nh l ni nj">curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d '{    <br/>	"name": "jdbc_sink_mysql_01",     <br/>	"config": {       <br/>		"connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",       <br/>		"connection.url": "jdbc:mysql://crmdbhost:3306/crmdb",       <br/>		"connection.user": "crm_user",       <br/>		"connection.password": "&lt;password&gt;",       <br/>		"topics": "order-status-update-status",       <br/>		"table.name.format" : "crmdb.order_status"    <br/>	}   <br/>}'</span></pre><p id="1dd6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">你完了！从这一点开始，履行数据库的状态表中的任何新条目都将自动写入CRM数据库的ORDER_STATUS表中。让我们稍微深入一下每个调用都在做什么。</p><h2 id="414c" class="nf kh it bd ki nk nl dn km nm nn dp kq lp no np ku lt nq nr ky lx ns nt lc nu bi translated">cURL呼叫1:连接信号源</h2><p id="55d8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">第一个cURL命令告诉Kafka Connect使用特定类型的源连接器，即JdbcSourceConnector，使用提供的凭证连接到位于fulfillmentdbhost:3306/fulfillmentdb的MySQL数据库。它还配置这个连接器，根据“LAST_UPDATED”列中的时间戳监视数据库中名为“status”的表中的新条目因此，每当向表中写入一个新行时，Kafka Connect都会为每个新行自动向Kafka主题“order-status-update-status”中写入一条新消息。</p><p id="626e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">接下来，我们需要一个sink连接器来监控Kafka主题的变化。这就是第二个cURL调用的作用。</p><h2 id="1f68" class="nf kh it bd ki nk nl dn km nm nn dp kq lp no np ku lt nq nr ky lx ns nt lc nu bi translated">cURL呼叫2:连接水槽</h2><p id="9020" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">第二个cURL命令创建一个接收器连接器(JdbcSinkConnector ),它连接到另一个数据库，即crmdbhost:3306/crmdb。该连接器将监视主题“order-status-update-status”中的新消息，并将任何新消息写入crmdb-database中的表“order_status”。</p><p id="ad46" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">此示例使用JdbcSourceConnector和JdbcSinkConnector连接两个关系数据库。可以安装其他类型的连接器，然后以相同的方式使用。每个连接器都有自己的文档和一组选项。在<a class="ae kf" href="https://www.confluent.io/hub/" rel="noopener ugc nofollow" target="_blank">汇合网站</a>上可以找到可用连接器的非正式列表及其文档链接。</p><h1 id="e339" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">更上一层楼</h1><p id="8966" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">您已经看到了如何只用两个命令在两个SQL数据库之间建立连续的流集成。以类似的方式，您可以集成Kafka Connect为其提供连接器的任何应用程序，甚至可以编写自己的应用程序。只需设置一个源连接器和一个接收器连接器，就可以开始更新了。</p><p id="ad29" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">但这还不是全部。一旦设置了源连接器，就可以使用同一个源来更新多个目标(“接收器”)。在我们的示例中，您可以运行第三个cURL命令，将所有订单状态更新写入另一个数据库。</p><h1 id="3612" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="2f91" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果您的团队面临本文中描述的任何问题，您应该尝试Kafka Connect。Kafka Connect为现有的Kafka集群添加了一套全新的功能，从长远来看，这将使您的团队生活更加轻松。如果您目前没有运行Kafka集群，本文将向您展示如何在几分钟内完成设置。一旦Kafka Connect启动并运行，您的团队就可以专注于解决实际的业务问题。</p><p id="389c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦您的团队掌握了本文中描述的基本工作流，您可能还想了解Kafka Connect动态转换<a class="ae kf" href="https://docs.confluent.io/current/connect/transforms/index.html" rel="noopener ugc nofollow" target="_blank">数据的能力，这可用于解决一系列全新的问题。</a></p></div></div>    
</body>
</html>