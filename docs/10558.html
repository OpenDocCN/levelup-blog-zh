<html>
<head>
<title>Standard Deviation MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">标准偏差MNIST</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/standard-deviation-mnist-6fc6b5e0830e?source=collection_archive---------25-----------------------#2021-12-19">https://levelup.gitconnected.com/standard-deviation-mnist-6fc6b5e0830e?source=collection_archive---------25-----------------------#2021-12-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/21de423984458b1f68caeac5c9fc37b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*DQSLKyHw2eAkM385mG-29g.png"/></div><figcaption class="iy iz gj gh gi ja jb bd b be z dk translated"><a class="ae jc" href="https://commons.wikimedia.org/wiki/File:MnistExamples.png" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:MnistExamples.png</a></figcaption></figure><div class=""/><h1 id="de4f" class="kc kd jf bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">量子启发的算法</h1><p id="85ce" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在使用密集角度编码的<a class="ae jc" href="https://towardsdatascience.com/quantum-mnist-f2c765bdd478" rel="noopener" target="_blank">量子MNIST </a>和使用<a class="ae jc" rel="noopener ugc nofollow" target="_blank" href="/amplitude-encoding-dd89dc84170d">振幅编码的</a><a class="ae jc" href="https://towardsdatascience.com/784-dimensional-quantum-mnist-f0adcf1a938c" rel="noopener" target="_blank"> 784维量子MNIST </a>之后，我使用经典解释的<a class="ae jc" rel="noopener ugc nofollow" target="_blank" href="/comparing-quantum-states-c6445e1e46fd">量子算法</a>对<a class="ae jc" href="https://bsiegelwax.medium.com/quantum-inspired-mnist-6e33466d991b" rel="noopener">量子启发的MNIST </a>进行了实验，该算法可用于量子机器学习(QML)任务，如<a class="ae jc" href="https://medium.com/swlh/quantum-classification-cecbc7831be" rel="noopener">量子分类</a>和<a class="ae jc" rel="noopener ugc nofollow" target="_blank" href="/quantum-clustering-c498b089b88e">量子聚类</a>。只使用加法和减法，该方法达到了72%的准确率，这比猜测好得多，比一些卷积神经网络(CNN)学生的尝试好，但明显比Kaggle提交的结果差。</p><p id="4186" class="pw-post-body-paragraph la lb jf lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">这是我第一次尝试提高量子启发的MNIST的准确性，同时希望保留量子启发的MNIST的相对简单性。</p><h2 id="fc99" class="md kd jf bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">MNIST数据集</h2><p id="aec5" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这就引出了一个问题，“MNIST是什么？”对于那些不熟悉它的人来说，MNIST是一个流行的手写数字数据集，数字0到9。它之所以受欢迎，是因为它经过了彻底的测试，并且非常干净，这使得学生可以专注于构建和训练他们的图像分类模型，而不是他们的数据。</p><p id="7d1d" class="pw-post-body-paragraph la lb jf lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">MNIST数据集中的每个数字由大约6000幅图像表示。每个图像包含排列在28×28网格中的784个像素。每个像素都有一个从0到254的值，代表其强度。我曾经取了每一个数字，并计算了它的784个像素的平均亮度值，结果是平均0，平均1，等等。</p><p id="eee7" class="pw-post-body-paragraph la lb jf lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在我最初的量子MNIST实验中，我将784个像素压缩成16个值，只映射到8个量子位，我担心所有10个数字会模糊在一起。我对784维的量子MNIST也有类似的担忧，但由于振幅值很小，只有1024，它们的平方必须等于1。但是，有了量子激发的MNIST，除了计算手段之外，不需要经典的预处理。测试数字的值保持不变。而且，很快。因此，如果我要用平均值以外的任何东西来表示训练数字，现在似乎是一个尝试的好时机。</p><h2 id="d256" class="md kd jf bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">标准偏差</h2><p id="8e04" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">自从我最初的量子MNIST实验以来，我一直在考虑的两个选项是标准差和宁滨。宁滨非常广泛，有多种方法，所以我用标准差作为一种简单、温和的数字表示法。</p><p id="f54e" class="pw-post-body-paragraph la lb jf lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">该算法总体上只增加了两个主要步骤:计算每个数字每个像素的标准偏差，然后增加每个像素的两次比较。对于量子启发的MNIST，我将每个测试像素值与每个训练数字对应的平均像素值进行了比较。对于这个实验，我还将每个测试像素值与相应的平均像素值减去标准偏差，以及相应的平均像素值加上标准偏差进行了比较。因此，将每个测试数字与更广泛的零表示、更广泛的一表示等进行比较。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="1c49" class="md kd jf mu b gy my mz l na nb">.<br/>.<br/>.</span><span id="0f30" class="md kd jf mu b gy nc mz l na nb">Target: 9<br/>Actual: 9<br/><br/>Correct: 50%</span></pre><h2 id="a68f" class="md kd jf bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">结果</h2><p id="2b72" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">仅使用平均值，并使用前100个测试数字，量子MNIST的准确率为72%。保持一切完全相同，只增加这些标准差比较，准确率下降到50%。正如我在最初的量子MNIST实验中所担心的那样，这些数字似乎变得模糊了。然而，值得注意的是，猜测的准确率只有10%，一些传统的MNIST方法表现更差。因此，这仍然不是解决MNIST问题的最糟糕的方法，但它正朝着错误的方向前进。</p><h2 id="92aa" class="md kd jf bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">反馈请求</h2><p id="35a7" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我为什么要写落后的进步？因为我在分享数据和代码，实际上，数据在代码中，在<a class="ae jc" href="https://cb.run/L9vp" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。也许有人能发现ID10T错误。或者，也许有人可以建议一种不同的方法。无论哪种方式，量子启发的MNIST消除了模型、权重、激活函数、优化器…你通常用来分类图像的一切。归根结底，这仍然是基于简单的加法和减法。基本算术能打败猜测；它能和经典机器学习抗衡吗？我希望得到反馈。</p><h2 id="bb96" class="md kd jf bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">下一步</h2><p id="a7a0" class="pw-post-body-paragraph la lb jf lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">正如我在量子启发的MNIST文章中所写的，传统的MNIST不做像素与像素的比较。卷积神经网络(CNN)使用像素组和多层比较。也有Kaggle提交达到超过99%的准确率。因此，在等待关于标准偏差的使用和/或误用的反馈时，我可以努力使量子启发的MNIST更像CNN，也许更像Kaggle，同时仍然保持它相对简单。</p></div></div>    
</body>
</html>