<html>
<head>
<title>Building a Decision Tree from Scratch in Python | Machine Learning from Scratch (Part III)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python从零开始构建决策树|从零开始机器学习(第三部分)</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-a-decision-tree-from-scratch-in-python-machine-learning-from-scratch-part-ii-6e2e56265b19?source=collection_archive---------2-----------------------#2019-04-03">https://levelup.gitconnected.com/building-a-decision-tree-from-scratch-in-python-machine-learning-from-scratch-part-ii-6e2e56265b19?source=collection_archive---------2-----------------------#2019-04-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d52a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用决策树建立更好的房价预测模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/29cb8bab4471c28886f58fdcf2d9e346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H9sFR6s-dmxtJpmV5m-SKw.jpeg"/></div></div></figure><blockquote class="kr"><p id="8f01" class="ks kt iq bd ku kv kw kx ky kz la lb dk translated">TL；DR使用Python从头开始构建决策树回归模型。将您的模型与Scikit-learn模型的性能进行比较。决策树用于预测房屋销售价格，并将结果发送给Kaggle。</p></blockquote><h2 id="df00" class="lc ld iq bd le lf lg dn lh li lj dp lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">从零开始的机器学习系列:</h2><ol class=""><li id="a1e9" class="ly lz iq ma b mb mc md me ll mf lp mg lt mh lb mi mj mk ml bi translated"><a class="ae mm" href="https://towardsdatascience.com/smart-discounts-with-logistic-regression-machine-learning-from-scratch-part-i-3c242f4ded0" rel="noopener" target="_blank">采用逻辑回归的智能折扣</a></li><li id="0cb0" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1" rel="noopener">用线性回归预测房价</a></li><li id="b577" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><strong class="ma ir">用Python从头开始构建决策树</strong></li><li id="0b6a" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/color-palette-extraction-with-k-means-clustering-machine-learning-from-scratch-part-iv-55e807407e53" rel="noopener">利用K均值聚类进行调色板提取</a></li><li id="bd93" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/movie-review-sentiment-analysis-with-naive-bayes-machine-learning-from-scratch-part-v-7bb869391bab" rel="noopener">基于朴素贝叶斯的电影评论情感分析</a></li><li id="8fe1" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/music-artist-recommender-system-using-stochastic-gradient-descent-machine-learning-from-scratch-5f2f1aae972c" rel="noopener">使用随机梯度下降的音乐艺术家推荐系统</a></li><li id="8177" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/fashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661" rel="noopener">利用神经网络进行时尚产品图像分类</a></li><li id="aefc" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/build-a-taxi-driving-agent-in-a-post-apocalyptic-world-using-reinforcement-learning-machine-175b1edd8f69" rel="noopener">使用强化学习在后启示录世界中构建一个出租车驾驶代理</a></li></ol><p id="7df5" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">对不起，你可能会失眠。在内心深处，你知道你的线性回归模型不会削减它。住房市场的主导地位还在进一步发展。</p><p id="4763" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们能改进它吗？我们能有一个能做出更好预测的模型吗？</p><p id="890e" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><strong class="ma ir"> <em class="nh">完整源代码笔记本</em> </strong>(谷歌合作实验室):</p><div class="ni nj gp gr nk nl"><a href="https://www.patreon.com/curiousily" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">维尼林·瓦尔科夫正在创建机器学习教程</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">大家好，我叫维尼林，我很高兴邀请你们踏上神奇的机器世界之旅…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">www.patreon.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz kp nl"/></div></div></a></div><h1 id="aab0" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">数据</h1><p id="18e6" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">我们将再次使用Kaggle数据:“<a class="ae mm" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">房价:高级回归技术</a>”。它包含<em class="nh"> 1460 </em>个训练数据点和80个可能帮助我们预测房屋售价的特征。</p><h1 id="16b5" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">决策树</h1><p id="85d9" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">决策树模型构建这样的结构:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/43d71324a3f37cd696daae183e173307.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*JAEY3KP7TU2Q6HN6LasMrw.png"/></div><figcaption class="op oq gj gh gi or os bd b be z dk translated">来源:<a class="ae mm" href="https://www.xoriant.com/" rel="noopener ugc nofollow" target="_blank">https://www.xoriant.com</a></figcaption></figure><p id="a578" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">用于构建树的算法将数据集分解成越来越小的子集，同时相关的决策树被递增地开发。最终结果是一个有决策节点和叶节点的树。决策节点有两个或多个分支。叶节点代表一个分类或决策(用于回归)。对应于最佳预测器(最重要的特征)的树中最顶端的决策节点被称为根节点。</p><p id="9ae5" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">决策树可以处理分类数据和数值数据。它们用于分类和回归问题。他们也可以很好地处理丢失的数据！</p><h1 id="2697" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">数据预处理</h1><p id="71a0" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">我们将使用与线性回归模型相同的数据。然而，我们不会做任何扩展，只是因为我们懒(或者不需要):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><h1 id="c42b" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">价值函数</h1><p id="d358" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">我们将使用一个新的成本函数——均方根误差(RMSE)。它是数据点离回归线有多远的标准差。换句话说，它告诉你数据在最佳拟合线周围的集中程度。</p><p id="4d0e" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">RMSE由公式给出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/da1269b77b02e31809d30de4db4407e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*JrFKHRIHbCuhVJDdiODG5Q.png"/></div></figure><p id="039d" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们在前面的部分已经实现了MSE，所以我们要在这里导入一个实现，以可读性的名义(或者神圣的懒惰？):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><h1 id="83f0" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">使用预先构建的决策树模型</h1><p id="c19b" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">让我们使用<a class="ae mm" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>库中的决策树回归器来快速了解该模型:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="1587" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们使用带有1个评估器的<code class="fe ow ox oy oz b">RandomForestRegressor</code>,这基本上意味着我们使用决策树模型。这是我们模型的树形结构:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/5f0a938bc733d4e322df5e4f2f5b2bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KrxGq-6rjEjCvZaCBYiNEg.png"/></div></div></figure><p id="cb7e" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">您应该收到完全相同的模型(如果您正在运行代码),因为我们正在设置随机状态。模型使用了多少功能？</p><p id="d6be" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">现在这个模型已经可以使用了，让我们来评估它的<em class="nh"> R </em>分数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="f8de" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><code class="fe ow ox oy oz b">0.6336246655552089</code></p><p id="9d2b" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><em class="nh"> R </em>统计量为我们提供了关于模型拟合优度的信息。<code class="fe ow ox oy oz b">1</code>的分数表示完全适合。让我们来看看RMSE:</p><p id="d307" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><code class="fe ow ox oy oz b">48069.23940764968</code></p><h1 id="eb56" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">构建自己的决策树</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="36e2" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">让我们开始实现我们的<code class="fe ow ox oy oz b">Node</code>助手类:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0139" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">树是递归数据结构，我们将充分利用这一点。我们的<code class="fe ow ox oy oz b">Node</code>类代表了模型中的一个决策点。在寻找解决方案时，模型中的每个部分都有两种可能的结果——向左或向右。该决策点也将我们的数据分为两组。</p><p id="cc84" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">属性<code class="fe ow ox oy oz b">idxs</code>存储该节点正在处理的数据子集的索引。</p><p id="dd77" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">决策(预测)是基于<code class="fe ow ox oy oz b">Node</code>持有的<code class="fe ow ox oy oz b">value</code>。为了做出预测，我们只需取这个<code class="fe ow ox oy oz b">Node</code>因变量数据的平均值。</p><p id="41ad" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">方法<code class="fe ow ox oy oz b">find_varsplit</code>发现我们应该在哪里分割数据。让我们来看看:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="2a6b" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">首先，我们试图找到一个更好的特征来分割。如果没有找到这样的特征(我们在叶节点)，我们什么也不做。然后，我们使用由<code class="fe ow ox oy oz b">find_better_split</code>找到的分割值，为左右节点创建数据，并使用数据的子集创建每个节点。</p><p id="38ad" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">下面是<code class="fe ow ox oy oz b">split_col</code>和<code class="fe ow ox oy oz b">is_leaf</code>的实现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="1983" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">是时候实现我们算法的主力<code class="fe ow ox oy oz b">find_better_split</code>方法了:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="77d4" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们试图在每个数据点上进行分割，让最佳分割胜出。</p><p id="3e6e" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们将创建我们的分割，使其具有尽可能低的标准差。我们找到了使标准偏差的加权平均值最小化的分割，这相当于使RMSE最小化。</p><p id="781e" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">如果我们找到一个更好的分割，我们存储以下信息:变量的索引、分割分数和分割值。</p><p id="23ff" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">分数是一个度量，它告诉我们分割的效果如何(注意，叶节点没有分数，所以它将是无穷大)。方法<code class="fe ow ox oy oz b">find_score</code>计算数据的加权平均值。如果得分低于前一次，我们有一个更好的分裂。注意，分数最初被设置为无穷大- &gt;只有叶子节点和非常浅的树(以及灭霸)的分数为无穷大。</p><p id="9f55" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">最后，让我们看看我们如何使用所有这些来进行预测:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="bf7b" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们再一次利用了生命的递归性。从树根开始，<code class="fe ow ox oy oz b">predict_row</code>检查我们是否需要根据找到的分割值向左或向右移动节点。一旦我们到达一个叶节点，递归就结束了。此时，答案/预测存储在<code class="fe ow ox oy oz b">val</code>属性中。</p><p id="7934" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">下面是我们的<code class="fe ow ox oy oz b">Node</code>类的完整源代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><h1 id="a263" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">估价</h1><p id="46de" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">让我们看看您的决策树回归器在训练数据上的表现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="3f4a" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">以下是分数:</p><p id="ce78" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><code class="fe ow ox oy oz b">0.8504381072711565</code></p><p id="dcd9" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">我们的<em class="nh"> scikit-learn </em>模型给了我们<code class="fe ow ox oy oz b">0.6336246655552089</code>的分数</p><p id="f807" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">RMSE的分数是:</p><p id="dab9" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated"><code class="fe ow ox oy oz b">30712.460628635836</code></p><p id="1520" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">这个<em class="nh"> scikit-learn </em>回归器给了我们<code class="fe ow ox oy oz b">48069.23940764968</code></p><p id="143b" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">看起来你的模特做得很好，是吧？我们对测试数据做个预测，发给Kaggle。</p><h1 id="011c" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">将你的预测发送给Kaggle</h1><p id="75b9" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">让我们根据<a class="ae mm" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques#evaluation" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上的要求进行预测并格式化数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="c0af" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">请随意向Kaggle提交您的<code class="fe ow ox oy oz b">csv</code>文件。还有，怎么才能提高？</p><h1 id="6b63" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">结论</h1><p id="c832" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">犒劳一下自己，您刚刚实现了一个决策树回归器！</p><p id="f826" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">有可能在你的模型上实现随机森林回归器吗？这对你的卡格尔分数有什么影响？</p><p id="c8a0" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">在下一部分中，您将使用k均值进行一些无监督学习！</p><h1 id="369e" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx lo jz oi ka ls kc oj kd lw ok bi translated">感谢</h1><p id="1ead" class="pw-post-body-paragraph ms mt iq ma b mb mc jr mv md me ju mx ll ol mz na lp om nc nd lt on nf ng lb ij bi translated">本部分呈现的源代码很大程度上受到了<a class="ae mm" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a> — <a class="ae mm" href="http://course18.fast.ai/ml" rel="noopener ugc nofollow" target="_blank">程序员机器学习入门</a>精品课程的启发</p></div><div class="ab cl pb pc hu pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="ij ik il im in"><h2 id="d30e" class="lc ld iq bd le lf pi dn lh li pj dp lk ll pk ln lo lp pl lr ls lt pm lv lw lx bi translated">从零开始的机器学习系列:</h2><ol class=""><li id="6e52" class="ly lz iq ma b mb mc md me ll mf lp mg lt mh lb mi mj mk ml bi translated"><a class="ae mm" href="https://towardsdatascience.com/smart-discounts-with-logistic-regression-machine-learning-from-scratch-part-i-3c242f4ded0" rel="noopener" target="_blank">逻辑回归智能折扣</a></li><li id="22dd" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1" rel="noopener">用线性回归预测房价</a></li><li id="f579" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><strong class="ma ir">用Python从头开始构建决策树</strong></li><li id="3a62" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/color-palette-extraction-with-k-means-clustering-machine-learning-from-scratch-part-iv-55e807407e53" rel="noopener">用K均值聚类提取调色板</a></li><li id="9b1b" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/movie-review-sentiment-analysis-with-naive-bayes-machine-learning-from-scratch-part-v-7bb869391bab" rel="noopener">用朴素贝叶斯进行电影评论情感分析</a></li><li id="8cc4" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/music-artist-recommender-system-using-stochastic-gradient-descent-machine-learning-from-scratch-5f2f1aae972c" rel="noopener">使用随机梯度下降的音乐艺术家推荐系统</a></li><li id="548c" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/fashion-product-image-classification-using-neural-networks-machine-learning-from-scratch-part-e9fda9e47661" rel="noopener">利用神经网络进行时尚产品图像分类</a></li><li id="3728" class="ly lz iq ma b mb mn md mo ll mp lp mq lt mr lb mi mj mk ml bi translated"><a class="ae mm" href="https://medium.com/@curiousily/build-a-taxi-driving-agent-in-a-post-apocalyptic-world-using-reinforcement-learning-machine-175b1edd8f69" rel="noopener">使用强化学习在后启示录世界中构建一个出租车驾驶代理</a></li></ol></div><div class="ab cl pb pc hu pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pn ou l"/></div></figure></div><div class="ab cl pb pc hu pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="ij ik il im in"><p id="7da3" class="pw-post-body-paragraph ms mt iq ma b mb mu jr mv md mw ju mx ll my mz na lp nb nc nd lt ne nf ng lb ij bi translated">喜欢你读的吗？你想了解更多关于机器学习的知识吗？</p><div class="ni nj gp gr nk nl"><a href="https://leanpub.com/hmls" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">从零开始实践机器学习</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">“我不能创造的东西，我不理解”——理查德·费曼这本书将引导你走向更深的…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">leanpub.com</p></div></div><div class="nu l"><div class="po l nw nx ny nu nz kp nl"/></div></div></a></div></div></div>    
</body>
</html>