<html>
<head>
<title>How to Actually Speed Up Your AI Predictions: Asynchronous Advantage Actor Critic (A3C)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何实际加速你的人工智能预测:异步优势演员评论家(A3C)</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-actually-speed-up-your-ai-predictions-asynchronous-advantage-actor-critic-a3c-94b3be26235d?source=collection_archive---------5-----------------------#2022-08-07">https://levelup.gitconnected.com/how-to-actually-speed-up-your-ai-predictions-asynchronous-advantage-actor-critic-a3c-94b3be26235d?source=collection_archive---------5-----------------------#2022-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="7fa6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最重要的A3C基础，简单解释:用例，真实世界的应用，以及它是如何工作的</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f89678cd3e97418c66e3323ff2564414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8CO6VQNrBVsInznz-wWxQ.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的罗伯特·林德</figcaption></figure><p id="d51d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">还记得《T2毁灭战士》这款游戏吗？如果你把这两者联系起来(A3C + Doom)，这个算法很可能会成为你记忆犹新的东西。</p><p id="f914" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">异步优势行动者评价(A3C)是一种强化学习算法，使用行动者评价神经网络架构[12]。该算法由谷歌的DeepMind研究团队提出；它已经被用来训练游戏实现的代理，包括第一人称游戏《毁灭战士》[13][14]。</p><p id="e297" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">A3C算法是广泛使用的A2C算法的扩展[15]。像A2C一样，它由相似的部分组成:演员和评论家[12]。然而，与A2C不同，它使用单个代理从经验中学习，并使用这些知识将这些更新应用到其他代理，A3C算法并行地使用多个代理，以独立和异步地从他们的经验中学习[16]。这意味着每个代理可以更新其政策梯度，可能更经常或更频繁，也可能导致更快地收敛到最优政策[17]。此外，使用多个代理还提供了更多的探索，因为每个代理将识别新的数据连接，并发现它们对应的(数据连接)环境的不同部分。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lf"><img src="../Images/dc0a024249db03944be50e8c77f7e479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hb_lcrOn49MKdB4j41xJEA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的斯蒂芬·莱昂纳迪</figcaption></figure><h1 id="a015" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">引擎盖下</strong></h1><p id="6830" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">A3C算法已经被证明能够在许多不同的强化学习任务上实现最先进的性能，包括3D虚拟环境。在许多情况下，它可以远远超过其他算法[18]。例如，在流行的第一人称游戏Doom中，与训练其他算法(尤其是最先进的one算法)所需的时间相比，训练A3C算法可以在更少的训练时间内获得更高的平均分数。</p><p id="09b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">A3C算法赢得声誉有几个原因。首先，它使用多个代理允许潜在的更有效的探索和更快的收敛到最优策略。其次，它的演员-评论家架构使它能够学习如何采取行动(演员)，以及这些行动如何影响未来的回报(评论家)。强调后一种方法很重要，因为强化学习系统通常需要在探索和利用之间进行权衡，比如尝试新事物与使用已知的好策略，能够学习这两个方面可能会导致更好的整体性能。最后，更新的异步特性意味着每个代理都可能取得进展，即使其他代理没有取得进展，这是由于时间的使用和应用(在用于训练和输出管理的系统内)而可能加速学习的机会。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mj"><img src="../Images/4c105d87ced531e2435e306c66256e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kHKPLLVLksLwtOMj3FIKVA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的Joshua Hoehne</figcaption></figure><h1 id="4436" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">其效力</strong></h1><p id="a944" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">A3C是一种强化学习算法，结合了基于值和基于策略的方法。作为学习选择行动的行动者网络和学习评估每个行动的预期回报的评论家网络之间的关系的一部分，算法被设计为多个代理与环境异步交互(而每个代理都有自己的行动者和评论家网络的副本[1])。</p><p id="0325" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与传统的强化学习算法(如Q-learning)相比，使用A3C有许多优势。首先，A3C更新是在代理人采取的每一步之后完成的[19]，而不是Q-learning [20]的情节实施方法。在这种情况下，优化A3C的机会在于它如何能够潜在地(在时间上，潜在地更快地)收敛于期望的解决方案，因为我们在整个培训过程中获得了关于我们的解决方案的反馈(而不是处理剧集依赖性)。</p><h1 id="8a35" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">在机器学习的背景下</strong></h1><p id="3ba6" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">A3C对于深度学习来说是实用的，因为它使用了共享的全局模型[21]，这使得网络能够从各种经验和数据源中学习，帮助网络更好地概括，并增加潜在做出更准确预测的可能性。此外，A3C采用异步更新方案，允许在多个内核或设备上进行并行训练，这可能会加快训练时间(无论CPU/GPU配置如何，算法优化都是影响训练时间的关键)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mk"><img src="../Images/4c61130a91a19f1e996f826a58e770bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yf5Xm9ULPWjkDbwZ7CTekw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的Todd Diemer</figcaption></figure><h1 id="7a49" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">为什么自然语言处理是用例的一部分</strong></h1><p id="1205" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">自然语言处理中的神经网络是实现流水线的基本方法。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/fa894f0876d578941de265b964881aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*4YsF2crEMw31toFVmCUl2A.png"/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">输入、隐藏层和输出(示例)[23]</figcaption></figure><p id="97b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在A3C和由输入层、隐藏层和输出层[2]组成的三层结构的背景下，这些层中的每一层都有自己的一组相互连接的神经元，这些神经元将信息从一个神经元传递到下一个神经元。输入层作为A3C算法与外界的接口；它接收环境中正在发生的事情的信息，并将这些信息传递给隐藏层。隐藏层处理这些信息并产生一个传递给输出层的表示。然后，输出层获取这种表示，并将其映射到代理为实现其目标而可以采取的意义或动作上。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mm"><img src="../Images/12f4e7965ed8c9108b292595d402cb68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VaIn-BGzIcPrmHefgtqPEw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的paolo candelo</figcaption></figure><h1 id="40b2" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">A3C的真实实施</strong></h1><p id="c9d2" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">A3C是一种有效的机器学习算法，因为它使用多个代理来探索环境，可能更有效地探索状态空间(尤其是帮助代理学习)。此外，A3C使用代理之间的共享网络[22]，允许每个代理从网络上其他代理的经验中受益。</p><p id="c277" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">A3C已经被一些可识别的人工智能实现所采用。举例来说，它可以用来开发一种算法，可以更准确地识别图像中的对象。另一个应用涉及使用A3C使机器人能够通过障碍管理回避技术在环境中导航。它在整个金融行业也有应用，特别是在金融工程领域:A3C可能会在定价方面进行预测分析。</p><p id="4b68" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人工智能中A3C的其他一些现实世界的例子包括面部识别和计算机视觉。面部识别用于识别数字图像或视频中的某些人或物体，计算机视觉使用允许计算机解释图像细节的算法，包括光照、姿势和纹理。</p><h1 id="f7cb" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak">离别的思念</strong></h1><p id="2365" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">如果你对这篇文章的编辑有任何建议，或者对进一步扩展这个主题领域有什么建议，请和我分享你的想法。</p><p id="1111" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另外，请考虑<a class="ae le" href="https://pventures.substack.com" rel="noopener ugc nofollow" target="_blank">订阅我的每周简讯:</a></p><p id="8cf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">根据我写的文章，其中一些你可能会感兴趣:</strong></p><h2 id="ee3a" class="mn lh it bd li mo mp dn lm mq mr dp lq kb ms mt lu kf mu mv ly kj mw mx mc my bi translated">金融工程的学习方法:你需要知道的一切</h2><div class="mz na gp gr nb nc"><a href="https://medium.datadriveninvestor.com/q-learning-methods-for-financial-engineering-all-you-need-to-know-ae730ae8b0b" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">金融工程的学习方法:你需要知道的一切</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">如何开发和部署Q-learning方法，包括强化学习中的应用程序、用例、最佳实践…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq ky nc"/></div></div></a></div><h2 id="5e11" class="mn lh it bd li mo mp dn lm mq mr dp lq kb ms mt lu kf mu mv ly kj mw mx mc my bi translated">金融工程十大基本深度学习模型</h2><div class="mz na gp gr nb nc"><a href="https://medium.datadriveninvestor.com/top-10-essential-deep-learning-models-for-financial-engineering-ca550fcff91" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">金融工程十大基本深度学习模型</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">金融工程中这些方法的10个基本深度学习(DL)模型和用例。</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq ky nc"/></div></div></a></div><h2 id="351f" class="mn lh it bd li mo mp dn lm mq mr dp lq kb ms mt lu kf mu mv ly kj mw mx mc my bi translated">金融工程的5大基本机器学习库</h2><div class="mz na gp gr nb nc"><a href="https://pub.towardsai.net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad6d7a8195" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">金融工程的5大基本机器学习库</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">五个机器学习库，其中一个是最重要的库，用于金融工程用例</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">pub.towardsai.net</p></div></div><div class="nl l"><div class="ns l nn no np nl nq ky nc"/></div></div></a></div><h2 id="f0ad" class="mn lh it bd li mo mp dn lm mq mr dp lq kb ms mt lu kf mu mv ly kj mw mx mc my bi translated">金融工程的10大基本NLP模型</h2><div class="mz na gp gr nb nc"><a href="https://medium.com/mlearning-ai/top-10-essential-nlp-models-for-financial-engineering-f78f2536a2a9" rel="noopener follow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">金融工程的10大基本NLP模型</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">金融工程中这些方法的10个基本NLP模型和用例。</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">medium.com</p></div></div><div class="nl l"><div class="nt l nn no np nl nq ky nc"/></div></div></a></div></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><p id="b143" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob">参考文献</em>:</p><p id="e282" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 1。</em> <em class="ob">强化学习——人工智能栈交换。</em><a class="ae le" href="https://ai.stackexchange.com/questions/12103/do-we-need-to-use-the-experience-replay-buffer-with-the-a3c-algorithm" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://ai . stack exchange . com/questions/12103/do-we-need-to-use-the-experience-replay-buffer-with-the-the-a3c-algorithm</em></a></p><p id="e007" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 2。</em>人工神经网络基础。<a class="ae le" href="http://uc-r.github.io/ann_fundamentals" rel="noopener ugc nofollow" target="_blank">http://uc-r.github.io/ann_fundamentals</a></p><p id="9c73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.神经系统Webquest-study lib。<a class="ae le" href="https://studylib.net/doc/8588418/nervous-system-webquest" rel="noopener ugc nofollow" target="_blank">https://studylib.net/doc/8588418/nervous-system-webquest</a></p><p id="e8f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 4。</em> <em class="ob">面向认知网络安全的异步优势行动者-批评家(A3C)学习。(未注明)。IEEE Xplore。检索到2022年8月6日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/document/9750264" rel="noopener ugc nofollow" target="_blank">【https://ieeexplore.ieee.org/document/9750264】T21</a></p><p id="fe6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 5。</em> <em class="ob"> Mnih，v .，Badia，A. P .，Mirza，m .，Graves，a .，Lillicrap，T. P .，Harley，t .，Silver，d .，&amp;# 38；k . kavukcuoglu(2016年2月4日)。深度强化学习的异步方法。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/1602.01783" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://arxiv.org/abs/1602.01783</em></a></p><p id="50a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 6。</em> <em class="ob">蒂尔贝，阿尼尔。(2022年8月3日)。金融工程顶级q-learning深度学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/q-learning-methods-for-financial-engineering-all-you-need-to-know-ae730ae8b0b" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://medium . datadriveninvestor . com/q-learning-methods-for-financial-engineering-all-you-need-to-know-a e730 AE 8 b 0b</em></a></p><p id="0f90" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">7 .<em class="ob">。</em> <em class="ob">蒂尔贝，安尼尔。(2022年8月3日)。金融三大基本无监督学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/top-3-essential-unsupervised-learning-methods-for-financial-engineering-fb5356a7a401" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://medium . datadriveninvestor . com/top-3-essential-unsupervised-learning-methods-for-financial-engineering-FB 5356 a7a 401</em></a></p><p id="5a43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 8。</em> <em class="ob">蒂尔贝，阿尼尔。(2022年7月28日)。金融工程中10个必不可少的深度学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/top-10-essential-deep-learning-models-for-financial-engineering-ca550fcff91" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://medium . datadriveninvestor . com/top-10-essential-deep-learning-models-for-financial-engineering-ca 550 fcff 91</em></a></p><p id="39eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 9。</em> <em class="ob">蒂尔贝，阿尼尔。(2022年7月26日)。金融工程5大AI ML库。走向AI。</em><a class="ae le" href="https://pub.towardsai.net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad6d7a8195" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://pub . toward sai . net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad 6d 7a 8195</em></a></p><p id="0875" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">10。 <em class="ob">蒂尔贝，阿尼尔。(2022年7月27日)。金融工程的10个基本NLP模型。</em><a class="ae le" href="https://medium.com/mlearning-ai/top-10-essential-nlp-models-for-financial-engineering-f78f2536a2a9" rel="noopener"><em class="ob">https://medium . com/mlearning-ai/top-10-essential-NLP-models-for-financial-engineering-f78f 2536 a 2 a 9</em></a></p><p id="f733" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 11。</em><em class="ob">&amp;# 38:j . kautz(2016年11月18日)。在GPU上通过异步优势行动者-批评家进行强化学习。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/1611.06256" rel="noopener ugc nofollow" target="_blank"><em class="ob"/></a></p><p id="c2d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 12。</em>孙、杜、段、&amp;# 38；李。(2019).基于异步优势行动者-批评家学习方法的自适应PID控制器的设计与应用。无线网络，27(5)，3537–3547。<a class="ae le" href="https://doi.org/10.1007/s11276-019-02225-x" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://doi.org/10.1007/s11276-019-02225-x</em></a></p><p id="52bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 13。</em> <em class="ob"> awjuliani。(未注明)。DeepRL-Agents/A3C-doom . ipynb at master awjuliani/DeepRL-Agents。GitHub。2022年8月6日检索，来自</em><a class="ae le" href="https://github.com/awjuliani/DeepRL-Agents/blob/master/A3C-Doom.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://github . com/awjuliani/DeepRL-Agents/blob/master/A3C-doom . ipynb</em></a></p><p id="7a42" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 14。</em> <em class="ob">可汗，纳伊姆，卡塔克，阿斯加尔，&amp;# 38；马利克。(2021年1月1日)。使用深度强化学习和vizdoom游戏人工智能研究平台与基于预期者a3c的代理一起玩Doom。斯普林格国际出版公司。</em><a class="ae le" href="https://link.springer.com/chapter/10.1007/978-3-030-77939-9_15" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://link . springer . com/chapter/10.1007/978-3-030-77939-9 _ 15</em></a></p><p id="71b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 15。</em> <em class="ob">使用具有时间上下文的优势行动者评价器的用于自主纵向控制的端到端强化学习。(未注明)。IEEE Xplore。检索到2022年8月6日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/8917387" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://ieeexplore.ieee.org/abstract/document/8917387</em></a></p><p id="2abd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 16。</em> <em class="ob"> M-A3C:双足机器人实时步态规划的均值-异步优势行动者-批评者强化学习方法。(未注明)。IEEE Xplore。检索到2022年8月6日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/9779214" rel="noopener ugc nofollow" target="_blank">【https://ieeexplore.ieee.org/abstract/document/9779214】T21</a></p><p id="cf66" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">17。 <em class="ob">车联网视频分析的边缘计算与区块链。(未注明)。美国计算机学会会议。检索到2022年8月6日，转自</em><a class="ae le" href="https://dl.acm.org/doi/abs/10.1145/3416014.3424582" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://dl.acm.org/doi/abs/10.1145/3416014.3424582</em></a></p><p id="01e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">18岁。 <em class="ob">古普塔，叶戈罗夫，&amp;# 38；科森德弗。(2017年1月1日)。使用深度强化学习的协作多智能体控制。斯普林格国际出版公司。</em><a class="ae le" href="https://link.springer.com/chapter/10.1007/978-3-319-71682-4_5" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://link . springer . com/chapter/10.1007/978-3-319-71682-4 _ 5</em></a></p><p id="61fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 19。</em>T42【Sewak】。(2019年1月1日)。演员评论家模型和A3C。新加坡斯普林格。<a class="ae le" href="https://link.springer.com/chapter/10.1007/978-981-13-8285-7_11" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://link . springer . com/chapter/10.1007/978-981-13-8285-7 _ 11</em></a></p><p id="1c5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 20。</em> <em class="ob">沃特金斯，&amp;# 38；大雁。(未注明)。q-学习。机器学习，8(3)，279–292页。</em><a class="ae le" href="https://doi.org/10.1007/BF00992698" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://doi.org/10.1007/BF00992698</em></a></p><p id="60df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 21。</em> <em class="ob">西瓦克。(2019年1月1日)。代码中的A3C。新加坡斯普林格。</em><a class="ae le" href="https://link.springer.com/chapter/10.1007/978-981-13-8285-7_12" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://link . springer . com/chapter/10.1007/978-981-13-8285-7 _ 12</em></a></p><p id="f29b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 22。</em> <em class="ob">面向认知网络安全的异步优势行动者-批评家(A3C)学习。(未注明)。IEEE Xplore。检索到2022年8月6日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/9750264" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://ieeexplore.ieee.org/abstract/document/9750264</em></a></p><p id="999f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ob"> 23。甘尼山，美国(未标明)。A3C异步优势演员-评论家代理。检索2022年8月6日，来自</em><a class="ae le" href="https://bardofcodes.github.io/DRL_in_CV//posts/2017-11-28-A3C" rel="noopener ugc nofollow" target="_blank"><em class="ob">https://bardofcodes . github . io/DRL _ in _ CV//posts/2017-11-28-A3C</em></a></p></div></div>    
</body>
</html>