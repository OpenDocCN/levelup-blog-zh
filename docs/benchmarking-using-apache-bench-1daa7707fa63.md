# 使用 Apache Bench 进行基准测试。

> 原文：<https://levelup.gitconnected.com/benchmarking-using-apache-bench-1daa7707fa63>

## 想知道您的应用程序的性能如何吗？

## 熟悉绩效评估的流程。

![](img/294490716fcc837194bca6bb1c25c627.png)

[凯利拍摄的照片](https://www.pexels.com/photo/fully-loaded-cargo-ship-sailing-on-sea-12530465/)

最近，我在咨询一个正在创建一组公共 API 的产品。这就要求 API 应该是[高性能的](https://medium.com/technogise/journey-of-a-quality-analyst-part-ii-9c6271748153)等等。我们还没有上线，我们的理论是，这是业务的核心产品之一，它将有很高的使用率。因此，我提议在管道中进行性能测试，这个提议很受欢迎。

在 SDLC 早期，我们需要将我们的系统与性能标准进行比较。我们还需要一个参考点(基准)——从一开始就能看出我们的系统性能如何。

在团队内部讨论了我们的目标之后，我想出了一些工具。我们讨论了这些选项，并同意从 [Apache Bench](https://httpd.apache.org/docs/2.4/programs/ab.html) (AB)和 Ruby & Shell 脚本开始。

## 应用架构:

*   我们的是基于微服务的架构，使用包括 Lambda 在内的 AWS 基础设施。随之而来的是通常需要考虑的问题，如控制冷启动时间、配置合适的内存、提供并发性(PC)等。
*   我们的服务与其他一些内部服务进行通信(通过 API 调用),我们还必须忍受它们的冷启动时间。
*   我们的申请是针对美国公民的，因此基础设施在美国。

## 测试的设计:

*   我们调用 APIs 50 次，并发数为 5。这样做了 3 次，这样我们就能了解当天的表现。
*   正在分析我们所有的 GET & POST 端点。我们没有分析补丁(AB 缺乏对它的支持)和删除终点。
*   我们在美国地区运行测试 Github Actions(我们的管道)的虚拟机通过 Azure 托管在美国。
*   在测试运行之前，我们确保所有的 Lambdas(包括我们的依赖项)都是热的。我们确实对 cold Lambdas 进行了单独的测试，并通过从我们以外的地区访问服务器来进行更深入的分析。
*   我们断言应该有 0 个非 2XX 响应。在失败的情况下，我们在空闲信道中得到一个警报。在这种情况下，我们通常会检查 AWS 日志、AWS insights、AWS X 射线，以便更好地了解问题。
*   我们最初的目标是在不提供并发性的情况下观察我们的应用程序的行为。因此，我们在没有配置 PC 的较低环境中运行它。
*   在插入资源时，我将填充有效载荷中的所有属性。在获取资源时，我会确保获取最大的资源。最初，我没有删除测试过程中创建的测试数据，除非它因为任何原因被破坏。

我们的第一个请求是获取所有端点的身份验证令牌。然后存储响应中的令牌以备将来使用。如果我们因为任何原因没有成功，测试会因失败而中止。

**获取要存储的身份验证令牌。**

**对我们终点的考验。**

**断言请求没有失败。**

调用以下 shell 脚本来启动上述测试:

```
ruby tests/generate-auth-token.rb
sh tests/test.sh
ruby verifier/check-failed-requests.rb
```

## 运行频率:

我们使用 Github 动作来运行测试。最终产品可供下载和分析 90 天。

最初，我们每天运行测试来观察我们的集成系统。后来，我们选择了每周运行，因为我们的迭代每周结束。这个想法是我们在每次迭代结束时分析我们的应用程序的行为。

## 该报告:

[AB 报告](https://www.tutorialspoint.com/apache_bench/apache_bench_quick_guide.htm)有几个关键要素有助于理解系统的性能:

*   连接时间的标准偏差。
*   平均每秒处理的请求数。
*   99%请求的解决时间。

## 我们拥有的优势:

甚至在我们的报告出来之前，我们就开始想办法优化我们的冷启动时间。团队还启用了分布式跟踪(AWS X 射线)。此外，我们遇到了一个问题(如下所述)。

经过几天的测试，我们发现了系统中的一个瓶颈。

为了读取特定的资源，一个端点会超时。

为了在该资源内创建子资源，另一个端点将抛出内部服务器错误。

在进一步调查后，我们意识到测试产生了非常大的数据(不删除测试数据有助于突出这种行为)。

解决这个问题的一个方法是调试并找出是哪部分代码造成了这个问题。另一种方法是了解业务。后者是一个更好的方法——我们同意子资源创建应该有一个 5 的限制。

这有助于我们使我们的系统变得健壮——甚至在我们上线之前——防止我们的端点被潜在误用和/或滥用。

看到这一切，所有其他项目也开始努力测试他们的微服务的性能！

## 所用工具背后的推理:

我们想要:

*   一个轻量级的开源工具。
*   整个过程几乎零成本。
*   很容易在团队中采用。团队应该能够在本地或任何其他环境中运行它。
*   设置需要的投资可以忽略不计。

对我们来说，Apache Bench 和 Ruby 正符合要求。
随着用例的发展，我们对将来迁移到不同工具的可能性持开放态度。

## 未来计划:

我计划对所有涉及的微服务使用不同的供应并发性(PC)来运行测试。这将有助于了解所需电脑的正确数量。

我的另一个目的是验证分配给 lambda 的 2048 内存是否足够。我们还使用了 DynamoDB，所以我想验证 5 的读/写容量是否足够。

希望这有助于您对所有微服务进行定期性能测试！