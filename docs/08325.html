<html>
<head>
<title>Document Similarity with Synset and Path Similarity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有同义词集和路径相似性的文档相似性</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/document-similarity-with-synset-and-path-similarity-predictive-hacks-73f0dccfa642?source=collection_archive---------8-----------------------#2021-04-21">https://levelup.gitconnected.com/document-similarity-with-synset-and-path-similarity-predictive-hacks-73f0dccfa642?source=collection_archive---------8-----------------------#2021-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bead" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个如何使用NLTK中的wordnet找到路径相似的相似文档的例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9ba00a6a0ae78d103754c2bb1c6e4c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qUJfmtZmunUNKlKK.png"/></div></div></figure><div class="ku kv gp gr kw kx"><a href="https://jorgepit-14189.medium.com/membership" rel="noopener follow" target="_blank"><div class="ky ab fo"><div class="kz ab la cl cj lb"><h2 class="bd iu gy z fp lc fr fs ld fu fw is bi translated">用我的推荐链接加入媒体-乔治皮皮斯</h2><div class="le l"><h3 class="bd b gy z fp lc fr fs ld fu fw dk translated">阅读乔治·皮皮斯(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="lf l"><p class="bd b dl z fp lc fr fs ld fu fw dk translated">jorgepit-14189.medium.com</p></div></div><div class="lg l"><div class="lh l li lj lk lg ll ks kx"/></div></div></a></div><p id="ec76" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将提供一个例子，说明如何使用<a class="ae mi" href="https://www.geeksforgeeks.org/nlp-synsets-for-a-word-in-wordnet/#:~:text=Synset%20is%20a%20special%20kind,Synset%20and%20some%20have%20several." rel="noopener ugc nofollow" target="_blank">synset</a>和<a class="ae mi" href="https://www.nltk.org/howto/wordnet.html" rel="noopener ugc nofollow" target="_blank">路径相似度</a>来定义相似的文档。我们将创建以下函数:</p><ul class=""><li id="60cd" class="mj mk it lo b lp lq ls lt lv ml lz mm md mn mh mo mp mq mr bi translated"><code class="fe ms mt mu mv b"><strong class="lo iu">convert_tag:</strong></code>将<code class="fe ms mt mu mv b">nltk.pos_tag</code>给出的标签转换成<code class="fe ms mt mu mv b">wordnet.synsets</code>使用的标签。您需要在<code class="fe ms mt mu mv b">doc_to_synsets</code>中使用该功能。</li><li id="62c1" class="mj mk it lo b lp mw ls mx lv my lz mz md na mh mo mp mq mr bi translated"><code class="fe ms mt mu mv b"><strong class="lo iu">document_path_similarity:</strong></code>使用<code class="fe ms mt mu mv b">doc_to_synsets</code>查找每个文档中的同义词集，然后使用<code class="fe ms mt mu mv b">similarity_score</code>计算相似度，从而计算两个文档之间的对称路径相似度。</li><li id="9f92" class="mj mk it lo b lp mw ls mx lv my lz mz md na mh mo mp mq mr bi translated"><code class="fe ms mt mu mv b"><strong class="lo iu">doc_to_synsets:</strong></code>返回文档中的同义词集列表。这个函数应该首先使用<code class="fe ms mt mu mv b">nltk.word_tokenize</code>和<code class="fe ms mt mu mv b">nltk.pos_tag</code>对文档进行分词和词性标注。然后它应该使用<code class="fe ms mt mu mv b">wn.synsets(token, wordnet_tag)</code>找到每个令牌对应的synset。应该使用第一个synset匹配。如果不匹配，则跳过该令牌。</li><li id="69b3" class="mj mk it lo b lp mw ls mx lv my lz mz md na mh mo mp mq mr bi translated"><code class="fe ms mt mu mv b"><strong class="lo iu">similarity_score:</strong></code>将一个synset列表(s1)的规范化相似性得分返回到第二个synset列表(s2)上。对于s1中的每个同义词集，找出s2中具有最大相似度值的同义词集。将所有最大相似性值加在一起，并通过将其除以找到的最大相似性值的数量来归一化该值。小心数据类型，应该是浮点数。应该忽略缺失值。</li></ul><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="8b11" class="nf ng it mv b gy nh ni l nj nk">import numpy as np<br/>import nltk<br/>from nltk.corpus import wordnet as wn<br/>import pandas as pd</span><span id="2344" class="nf ng it mv b gy nl ni l nj nk">def convert_tag(tag):<br/>    """Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets"""<br/>    <br/>    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}<br/>    try:<br/>        return tag_dict[tag[0]]<br/>    except KeyError:<br/>        return None</span><span id="78e6" class="nf ng it mv b gy nl ni l nj nk">def doc_to_synsets(doc):<br/>    """<br/>    Returns a list of synsets in document.</span><span id="1385" class="nf ng it mv b gy nl ni l nj nk">Tokenizes and tags the words in the document doc.<br/>    Then finds the first synset for each word/tag combination.<br/>    If a synset is not found for that combination it is skipped.</span><span id="8470" class="nf ng it mv b gy nl ni l nj nk">Args:<br/>        doc: string to be converted</span><span id="19f0" class="nf ng it mv b gy nl ni l nj nk">Returns:<br/>        list of synsets</span><span id="f2ba" class="nf ng it mv b gy nl ni l nj nk">Example:<br/>        doc_to_synsets('Fish are nvqjp friends.')<br/>        Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]<br/>    """<br/>    tokens = nltk.word_tokenize(doc)<br/>    pos = nltk.pos_tag(tokens)<br/>    tags = [tag[1] for tag in pos]<br/>    wntag = [convert_tag(tag) for tag in tags]<br/>    ans = list(zip(tokens,wntag))<br/>    sets = [wn.synsets(x,y) for x,y in ans]<br/>    final = [val[0] for val in sets if len(val) &gt; 0]<br/>    <br/>    return final</span><span id="12e9" class="nf ng it mv b gy nl ni l nj nk">def similarity_score(s1, s2):<br/>    """<br/>    Calculate the normalized similarity score of s1 onto s2</span><span id="a8ac" class="nf ng it mv b gy nl ni l nj nk">For each synset in s1, finds the synset in s2 with the largest similarity value.<br/>    Sum of all of the largest similarity values and normalize this value by dividing it by the<br/>    number of largest similarity values found.</span><span id="ad56" class="nf ng it mv b gy nl ni l nj nk">Args:<br/>        s1, s2: list of synsets from doc_to_synsets</span><span id="123f" class="nf ng it mv b gy nl ni l nj nk">Returns:<br/>        normalized similarity score of s1 onto s2</span><span id="98fc" class="nf ng it mv b gy nl ni l nj nk">Example:<br/>        synsets1 = doc_to_synsets('I like cats')<br/>        synsets2 = doc_to_synsets('I like dogs')<br/>        similarity_score(synsets1, synsets2)<br/>        Out: 0.73333333333333339<br/>    """<br/>    s =[]<br/>    for i1 in s1:<br/>        r = []<br/>        scores = [x for x in [i1.path_similarity(i2) for i2 in s2] if x is not None]<br/>        if scores:<br/>            s.append(max(scores))<br/>    return sum(s)/len(s)</span><span id="d67d" class="nf ng it mv b gy nl ni l nj nk">def document_path_similarity(doc1, doc2):<br/>    """Finds the symmetrical similarity between doc1 and doc2"""</span><span id="d97a" class="nf ng it mv b gy nl ni l nj nk">synsets1 = doc_to_synsets(doc1)<br/>    synsets2 = doc_to_synsets(doc2)</span><span id="4766" class="nf ng it mv b gy nl ni l nj nk">return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2</span></pre><p id="ab67" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">测试其工作情况:</p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="666d" class="nf ng it mv b gy nh ni l nj nk">def test_document_path_similarity():<br/>    doc1 = 'This is a function to test document_path_similarity.'<br/>    doc2 = 'Use this function to see if your code in doc_to_synsets \<br/>    and similarity_score is correct!'<br/>    return document_path_similarity(doc1, doc2)</span></pre><p id="3ee6" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><code class="fe ms mt mu mv b"><a class="ae mi" href="https://drive.google.com/file/d/1r5qgK0QB6Md0NWB2s9-dMNnBAS40Nfz9/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">paraphrases</a></code>是包含以下列的数据帧:<code class="fe ms mt mu mv b">Quality</code>、<code class="fe ms mt mu mv b">D1</code>和<code class="fe ms mt mu mv b">D2</code>。<code class="fe ms mt mu mv b">Quality</code>是指示变量，指示两个文档<code class="fe ms mt mu mv b">D1</code>和<code class="fe ms mt mu mv b">D2</code>是否是彼此的释义(1表示释义，0表示不释义)。</p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="dfb7" class="nf ng it mv b gy nh ni l nj nk"># Use this dataframe for questions most_similar_docs <br/># and label_accuracy</span><span id="9f76" class="nf ng it mv b gy nl ni l nj nk">paraphrases = pd.read_csv('paraphrases.csv')<br/>paraphrases.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/27e87dfe05aed274580893ee2d0a0ae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CTgKywk7xxR2FPYm.png"/></div></div></figure><h1 id="5d6f" class="nn ng it bd no np nq nr ns nt nu nv nw jz nx ka ny kc nz kd oa kf ob kg oc od bi translated">最相似的文档</h1><p id="9c24" class="pw-post-body-paragraph lm ln it lo b lp oe ju lr ls of jx lu lv og lx ly lz oh mb mc md oi mf mg mh im bi translated">使用<code class="fe ms mt mu mv b">document_path_similarity</code>，我们将在释义中找到具有最大相似性得分的文档对。<em class="oj">这个函数应该返回一个元组</em> <code class="fe ms mt mu mv b"><em class="oj">(D1, D2, similarity_score)</em></code></p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="c7f3" class="nf ng it mv b gy nh ni l nj nk">def most_similar_docs():<br/>    paraphrases['similarity_score'] = paraphrases.apply(lambda x:document_path_similarity(x['D1'], x['D2']), axis=1)<br/>    return (paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['D1'], paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['D2'], paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['similarity_score'])</span><span id="9edb" class="nf ng it mv b gy nl ni l nj nk">most_similar_docs()</span></pre><p id="5287" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">输出:</p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="c5c5" class="nf ng it mv b gy nh ni l nj nk">('"Indeed, Iran should be put on notice that efforts to try to remake Iraq in their image will be aggressively put down," he said.', '"Iran should be on notice that attempts to remake Iraq in Iran\'s image will be aggressively put down," he said.\n', 0.97530864197530864)</span></pre><h1 id="cfca" class="nn ng it bd no np nq nr ns nt nu nv nw jz nx ka ny kc nz kd oa kf ob kg oc od bi translated">标签准确性</h1><p id="f237" class="pw-post-body-paragraph lm ln it lo b lp oe ju lr ls of jx lu lv og lx ly lz oh mb mc md oi mf mg mh im bi translated">通过使用<code class="fe ms mt mu mv b">document_path_similarity</code>计算每对文档的相似度，为二十对文档提供标签。设分类器规则为:如果得分大于0.75，标签为释义(1)，否则标签不为释义(0)。使用scikit-learn的accuracy_score报告分类器的准确性。</p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="9ddc" class="nf ng it mv b gy nh ni l nj nk">def label_accuracy():<br/>    from sklearn.metrics import accuracy_score</span><span id="0773" class="nf ng it mv b gy nl ni l nj nk">paraphrases['similarity_score'] = paraphrases.apply(lambda x:document_path_similarity(x['D1'], x['D2']), axis=1)<br/>    paraphrases['predicted'] = np.where(paraphrases['similarity_score'] &gt; 0.75, 1, 0)<br/>    <br/>    return accuracy_score(paraphrases['Quality'], paraphrases['predicted'])</span><span id="d387" class="nf ng it mv b gy nl ni l nj nk">label_accuracy()</span></pre><p id="8113" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">输出:</p><pre class="kj kk kl km gt nb mv nc nd aw ne bi"><span id="14f5" class="nf ng it mv b gy nh ni l nj nk">0.80</span></pre><h1 id="b3c1" class="nn ng it bd no np nq nr ns nt nu nv nw jz nx ka ny kc nz kd oa kf ob kg oc od bi translated">参考</h1><p id="3621" class="pw-post-body-paragraph lm ln it lo b lp oe ju lr ls of jx lu lv og lx ly lz oh mb mc md oi mf mg mh im bi translated">[1] <a class="ae mi" href="https://click.linksynergy.com/fs-bin/click?id=ZHrx*LMoSUs&amp;offerid=759505.571&amp;subid=0&amp;type=4" rel="noopener ugc nofollow" target="_blank"> Coursera </a>(附属链接)</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="2f49" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><em class="oj">原载于</em><a class="ae mi" href="https://predictivehacks.com/document-similarity-with-synset-and-path-similarity/" rel="noopener ugc nofollow" target="_blank"><em class="oj">https://predictivehacks.com</em></a><em class="oj">。</em></p></div></div>    
</body>
</html>