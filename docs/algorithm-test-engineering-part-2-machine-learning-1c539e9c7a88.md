# 算法测试工程，第 2 部分:机器学习

> 原文：<https://levelup.gitconnected.com/algorithm-test-engineering-part-2-machine-learning-1c539e9c7a88>

## 如果我们不确切地知道我们在测试什么，我们如何测试？

![](img/53e08b727be0503b07353073547a877b.png)

让我们探测一下这台机器，看看它学到了什么。[Zoltan·塔斯](https://unsplash.com/@zoltantasi?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

在[我之前的算法测试工程文章](/algorithm-test-engineering-exploratory-job-analysis-1048b4344e21)中，我讨论了更经典算法的测试和分析，比如二分搜索法。虽然算法的整体测试可能很复杂，但大多数经典算法都可以被描述为具有非常清晰定义的输入、输出及其关系。

在这篇后续文章中，我将讨论与不同类型的算法相关的测试和分析，其中输入-输出关系更复杂，更难定义，并且结果有时是主观的。通常这些都是基于机器学习(ML)的。例如，同一组互联网搜索结果在某个时间对一个人可能是好的，但对(另一个)人或在不同的时间就不那么好了。同样的情况也可能适用于其他属性，例如基于相同的传感器输入，电子鼻试图区分葡萄酒与威士忌，或者基于生物特征的个人压力水平。环境和有时个人的“感觉”会造成不同。

在本文中，我将探讨测试这些类型的系统意味着什么。我从作为 ML 模型训练过程的一部分的测试开始，延伸到训练后测试。为了更具体一点，我查看了一些行业示例，并回顾了几年前我使用定制的自然语言处理(NLP)算法构建的一个搜索引擎项目的经历。

# 训练、验证和测试过程

与机器学习相关的基本测试过程是在 ML 模型训练过程中的测试和验证。下图说明了这一点:

![](img/e51ca705f44b614b9b36b929720cff07.png)

训练和测试回路。图片作者。

这使用了三个数据集:

*   **训练集**:ML 模型在此基础上被训练，算法调整模型以更好地概括该集中的所有项目。
*   **验证集**:在这个单独的数据集上评估训练好的模型性能。只要验证分数提高，或者满足其他结束标准，就用训练集重复训练。
*   **测试集**:一个最终的、独立的数据集，用于执行结果的最终测试，独立于整个训练循环及其验证。

上述过程旨在建立一个模型，该模型根据训练数据上的给定标准(例如，精度或预测误差)尽可能好地进行概括。通常，这可以优化给定数据集上的模型，但不会区分哪些特定数据项的性能仍然很差。

接下来，*训练后测试*是指在上述过程完全完成后，与完全训练好的模型相关的测试。让我们更详细地看看这种类型的测试。

# 培训后测试

我在写这篇文章的时候碰到了这个术语，来自杰瑞米·乔登的一篇文章。他将其描述为调查“最终”算法(训练好的模型)背后的逻辑。我喜欢术语*调查*，因为我认为这是探索不同输入和输入转换的模型行为。这非常类似于我之前写的[变形测试(MMT)方法，更侧重于探索部分。提醒一下，MMT 对输入进行修改，并观察对输出的影响。这些修改被称为变形转换。](https://towardsdatascience.com/metamorphic-testing-of-machine-learning-based-systems-e1fe13baf048)

Jordan [文章](https://www.jeremyjordan.me/testing-ml/)将训练后测试分为三种类型:

*   *不变性测试*:用类似的输入测试 ML 算法，人们期望得到类似的输出。给出的例子是两个不同的(红色)苹果。想想变形转化。
*   *方向测试*:测试给定方向上的小输入修改，以查看算法输出是否以预期的方式反应。例如，房价会随着房子面积的增加而上涨吗？变形转化的另一种形式。
*   最小功能测试:用特定的输入实例测试最大似然算法，我们知道我们期望的结果。例如，同一个苹果是否总是给出相同的结果(例如，分类百分比)。

我在我之前的文章中[讨论了许多与测试传统算法相关的类似方面，我认为上述测试类型可以应用于一般的测试。然而，在测试 ML 算法时，我发现探索具有更大的作用，因为模型(算法)更像是一个黑盒，具有复杂的内部结构，例如大量的权重和连接。](/algorithm-test-engineering-exploratory-job-analysis-1048b4344e21)

我相信上述测试类型的应用程度取决于手头的数据、模型和领域。例如，当对苹果的图像进行分类时，我发现定义一个苹果的变体，或者如何转换这样的图像是非常直观的。有时候事情会变得更复杂。让我们看一些例子。

**评估复杂性的例子**

例如，在我的[变形测试文章](https://towardsdatascience.com/metamorphic-testing-of-machine-learning-based-systems-e1fe13baf048)中，我讨论了无人驾驶汽车的用例。现在想象一下，ML 算法将转向角反馈给驱动系统。如果对于相同的场景，这个角度随着时间的推移漂移了几分之一的百分比(对于不同的模型版本)，那么它在什么时候是输出的相关变化？或者，如果它使用来自真实世界的多个摄像头输入，并且我们将真实世界生活环境的所有复杂性都视为输入，那么输入的哪个变化是相关的？数据空间可能非常大。在时序数据中(如驾驶)，数据关系和随时间的变化也需要考虑。

Jordan 的文章给出了另一个定义不变量并将它们用于调查/测试的有趣例子:房地产价格估计。特别是期望更高的浴室数量不会降低房价，或者减少房子的面积不会增加奖金。这些在某种程度上是*逆不变量*，描述了人们可能期望的反面。也许我期望价格保持不变或上涨，但不是下降。一个有趣的角度来看待数据和预期。

在乔丹的例子中，他们注意到他们的小户型公寓的数据集大多来自公寓更贵的大城市。一般来说，这使模型偏向于较小的公寓面积。我发现这是一个有趣的例子，如果不深入研究(或*调查*)培训后的结果，很容易忽略这些发现。

# 运营领域与数据领域

在高层次上考虑[变形关系](https://towardsdatascience.com/metamorphic-testing-of-machine-learning-based-systems-e1fe13baf048)，人们可能会考虑在*操作域*(例如，天气、驾驶环境、角度、汽车)中人们可能会观察到什么样的变化。这些是描述人类可理解概念的高层次变化。此外，输入*数据域*本身也有变化(例如，传感器损坏、干扰、信号干扰、环境影响)。

这两个领域在 Daniel Angilov 的文章中有很好的描述。虽然没有使用变形测试术语，但它很好地总结了如何在更高的级别(操作级别)为测试 ML 构建输入转换，以及如何将它们映射到更低的级别表示(数据级别)。自然，data domain 的范围要大得多，因为它包括所有可能的输入值。对于操作领域，其中许多可能是不相关的(例如，随机数据的图像)。插图:

![](img/cf99b39c3886ac21176abf074057811b.png)

运营领域 vs 数据领域，改编自此处的。

操作领域处理更直观、高级和人类可理解的概念和转换。例如，在自动驾驶汽车场景中，有雾的场景，相机角度，或雨天与晴天。这些映射到数据域，在那里发生实际的数据转换。我们可以应用操作域转换来为确定的测试场景产生高级别的修改。以及针对较低级别的变化的较低级别的数据转换(例如，添加噪声)。

下面是我的[变形测试文章](https://towardsdatascience.com/metamorphic-testing-of-machine-learning-based-systems-e1fe13baf048)中的一个例子，我认为它说明了操作领域中的(领域)转换:

![](img/b655b3df4704490408eb8dae76e00c40.png)

操作域转换示例。图片作者。

在这种情况下，假想汽车的摄像机角度被转动了，好像汽车本身是倾斜的。嗯，前面的另一辆车也开得更远了:)。我为了我的变形测试纸穿过街道时拍了这些照片，这解释了它。例如，更面向数据域的转换可以是向图像添加静态噪声。

我们不可能涵盖数据域中所有可能的值，或者为所有这些值找出一个通用的测试 oracle。类似地，对于操作领域，期望为所有可能的输入组合构建详尽的测试集是不可行的。相反，我们需要努力找出与这两个领域最相关的。并且挑选一个合适的测试集，探索它的变化，以及随时间的演化。不幸的是，对此我没有一个通用的方法(目前)。

# 整个 ML 流程中的测试

考虑到整体的 ML 训练、测试、运营流程，可能我见过的最简洁、充满 ML 测试细节的论文是来自 [2016 可靠机器学习野外工作坊](https://sites.google.com/site/wildml2016nips/schedule)的 [Google 论文](https://research.google/pubs/pub45742/)。因为整篇论文只是一个测试类型列表和它们非常简洁的描述，所以我列出了我觉得最有趣的那些。这些都与持续测试有关:

*   特征假设。例如值范围和最常见的值，因为这些值可能随时间漂移。检查假设是否有效。
*   与目标变量以及彼此之间的特征关系。为了更好地理解您的数据，并检查关系是否成立。
*   每个功能的计算成本与收益。为了计算成本而包含所有特性值得吗？它会进化吗？
*   由于复制粘贴类型错误，不需要的特征泄漏到模型中。如果使用了不需要的功能，持续监控应该会发出警报。
*   如果持续进行再培训，模型评估分数随时间的变化。比如日常用新数据训练的效果。
*   模型偏差对于特定类型的数据，一些新的数据或数据类型是否会带来新的偏差，应该加以考虑。
*   训练的可重复性，对同一数据的多次训练的漂移有多大。
*   不断监视训练数据中的不变量如何随着时间的推移适用于操作数据。

我认为最重要的主题是不断监控和观察变化和影响。

这只是我找到的与本文最相关的一个简短列表。还有许多与从 ML 代码审查到操作监控的整个过程相关的问题。我推荐阅读[的谷歌论文](https://sites.google.com/site/wildml2016nips/schedule)，获得非常有见地的列表。

# 一些真实世界的例子

大量的词汇是好的，但是真实世界的例子有助于使它具体化。尤其是来自业界的真实的。最近，我听了一些 ACM ByteCast 剧集，其中一些提供了有趣的行业见解。

## Spotify

其中之一是讨论 Spotify 的推荐算法研究。更具体地说，Spotify 的推荐系统和围绕它的一切。使用的术语是 [*对 m1 结果的评估*](https://research.atspotify.com/evaluation/) 。

这就区分了线下和线上两种形式的评价。离线是传统的 ML 评估方法，使用训练/测试分割和诸如准确度、精确度和召回率的度量。在线是指从用户行为评估算法性能，比如点击网页，或者在 Spotify 的情况下，我猜是音乐播放列表上的选择。他们讨论了用户参与度的代表概念，以及应用程序中的某些特定交互是否是实现目标的良好衡量标准，或者回访用户是否是满意度和成功的标志。一个有趣的观点是定义一个 ML 测试预言，并不断研究 ML 算法的行为。

他们与 Spotify 讨论的另一个方面是让用户能够发现新内容。与简单地依赖基于当前用户简档的算法推荐不同，它可以帮助人们发现新内容。在 Spotify 案例中，这被讨论为选择大约 10%的选项呈现给用户作为这些“新”类型的选择。当测试/研究作为系统一部分的 ML 算法时，这是考虑整体用户体验和目标的一个很好的例子。它确保用户不会被锁定在算法沙箱中，支持他们寻找新的想法(音乐，搜索结果，..)去探索。

## 多林戈

关于这个话题，我发现另一个有趣的字节播集是 DuoLingo 上的[。DuoLingo 是一款旨在帮助人们学习语言的应用和服务。他们将](https://learning.acm.org/bytecast/ep14-luis-von-ahn)[机器学习用于他们系统](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/)的许多部分，包括[为学生创建根据他们的学习历史定制的任务](https://venturebeat.com/2020/04/30/duolingos-english-test-ai-serve-and-score-questions/)，[根据用户在某些单词和语言结构上的表现定制内容，以及对类似用户整体起作用的内容](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/)，以及我确定我在这里错过的许多其他方式。但总的来说，这是一个非常成功的应用。

DuoLingo 根据用户所学的个人资料，与专家团队一起为用户量身定制测验。通过这种方式，它将算法的评估游戏化，并让用户通过回答定制的测验以及使用 [A/B 测试](https://en.wikipedia.org/wiki/A/B_testing)等方法来提供反馈。我发现这是一个非常有趣的想法和方法，通过用户的算法反馈来进行“在线”算法测试和进化。通过诱使用户作为服务使用过程的一部分，从事有助于算法学习更好地为他们服务的任务。

# 我自己的一个例子:ValtuustoPilvi

几年前，我建立了一个名为 *Valtuustopilvi* (芬兰语为 CouncilCloud)的搜索引擎，作为由芬兰[城市奥卢](https://www.ouka.fi/oulu/english)主办的[基于开放数据的服务竞赛](https://www.ouka.fi/oulu/oulu-tietoa/oac)的一部分。它在这个(小)比赛中排名第一，所以我在接下来的两年里也把它作为城市的一项服务。结果，我熟悉了各种 NLP 算法，并使用它们构建了我的第一个服务，包括我测试 ML 和 NLP 的第一次经历。

## 服务概述

ValtuustoPilvi 是为人们交互式搜索市议会会议文件而设计的。对于搜索算法，我使用了各种现有的自然语言处理(NLP)库，构建了一些我自己的定制算法，并改编了一些众所周知且广泛使用的算法。

因为只有我在这个项目上工作，所以我做了开发、测试、分析和其他一切事情。不确定这对这个案子是好是坏，但事实就是如此。几年前我打包了代码，所以这次没有具体的代码度量和执行，而是关于我如何测试、分析和设计它的例子和反思。希望它能让事情变得更加具体和有趣。

为了将服务具体化一点，下面是搜索 UI 的截图:

![](img/414816341d6a3c5275854d937c8b0d59.png)

交互式搜索界面。图片作者。

用户可以通过选择其中的单词来改进搜索，或者在上图底部显示的框中键入查询词来与单词云进行交互。该系统(实时)构建与修改后的搜索查询的搜索结果相匹配的新词云，并且用户可以使用持续更新的 UI /词云来迭代地继续精炼他们的搜索。

我设计了几种算法来构建不同层次的词云。整个文档集变化不是很快，因此我使用了一个预先计算的数据模型，每天晚上更新。当第一次到达所有文件的主搜索页面时，或者对于理事会会议的特定预定义子类别(例如，建筑许可)，应用这种类型的数据模型。它基于一个[主题模型](https://en.wikipedia.org/wiki/Topic_model)。基于这个主题模型，选择了一组单词，每个单词根据主题模型在其发现的主题中的排名进行加权。这可以从上面的单词云中的单词大小看出。稍后将提供更多详细信息。首先说几句预处理。

## 计算复杂性示例:用 Voikko 进行预处理

在我的[之前的算法测试文章](/algorithm-test-engineering-exploratory-job-analysis-1048b4344e21)中，我讨论了算法计算复杂度的评估。在 ValtuustoPilvi 的例子中，一个相关的例子来自于使用第三方库，以及它的计算复杂性是如何变得重要的，因为我的使用不同于它以前的用例。

在 ML 中，尤其是在 NLP 中，一个非常常见的任务是对提供给算法的数据进行预处理。在单词云构建算法的情况下，一个基本需求是将不同形式的单词统一成单个表示(单词)。在 NLP 中，这被称为[变元化](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)(即基本形式转换，例如*汽车* - > *汽车*)。

为此，我使用了芬兰的 NLP 库。Voikko 早期主要用于较短的文本，如拼写检查中的句子和单词。然而，我使用 Voikko 处理整个文档，其中最长的文档长达数百页。使用如此大量的输入，处理时间呈指数增长。报告该问题后，已在 4.0.1 版本中修复(可见于 [Voikko 发行说明](https://voikko.puimula.org/releases.html))。

与本文和我上一篇文章的主题相关，这说明了算法的不同需求在不同的场景中是如何相关的，以及这将如何随着时间的推移而演变。现在， [Voikko 网页](https://voikko.puimula.org/)实际上列出了在芬兰语文本的机器学习管道中通常用作 t [工具的库](https://github.com/voikko/voikko-sklearn)，说明了它在这个方向上更一般的用例漂移。

## 连续数据分析:测试预处理

像 Voikko 这样的词汇化工具对于处理写得好、结构好的文本非常有用。然而，真实世界的文本通常包含拼写错误、特定领域的单词、缩写和其他类似的异常。对于这些，像 Voikko 这样的工具将无法处理它们，因为它们不在标准字典中。

对于任何合理大小的输入集，阅读所有文档并手动修复所有文本都不是一项可行的任务。相反，我收集了所有 Voikko 不认识的单词/标记。通过将这些未识别的单词和标记按照它们出现的频率进行排序，我可以很容易地找到经常出现但未被识别的单词，根据需要创建自定义规则对它们进行词汇化，从而不断地监控、测试和改进预处理。即使文档集以及它们所涵盖的主题会随着时间的推移而发展。每次文档集和主题模型更新时(每晚)都会运行这个过程。我大约一周检查一次结果，当新的和频繁的拼写错误或新单词出现时，更新词汇化规则。

## 算法定制:词云的 LDA

我[之前讨论过的另一个话题](/algorithm-test-engineering-exploratory-job-analysis-1048b4344e21)是理解所用算法的重要性。在这种情况下，我使用的主题模型算法产生的内部表示通常不作为输出的一部分。然而，在详细学习算法之后，我能够使用这些内部属性作为服务特性的基础。当然，理解你在测试什么也不会伤害到测试。

我用来构建词云的主题建模算法是[潜在狄利克雷分配](https://dl.acm.org/doi/10.5555/944919.944937) (LDA)。这是一种将文档和文本映射到一组“主题”的 NLP 算法。发现的主题通常用作应用程序中进一步步骤的输入。首先，简单介绍一下 LDA。

LDA 将单词映射到称为主题的簇中。具体来说，这里有一个例子，我用 LDA 在一个 [Kaggle 新冠肺炎研究论文数据集](https://www.kaggle.com/donkeys/covid-nlp-preprocess)(代码和笔记本[这里](https://www.kaggle.com/donkeys/summarizing-topic-models-with-transformers))上构建了四个主题(词簇):

![](img/bc6b197a0711fdad71dbcb3af0a274d2.png)

基于 LDA 的主题模型，有四个主题，显示单词权重。图片作者。

使用 LDA，解释这些主题/集群是留给用户的。在这种情况下，我认为上述主题似乎与患者治疗(主题 1)、病毒分析(主题 2)、病毒结构(主题 3)以及可能的感染机制(主题 4)有关。

在 Valtuustopilvi 的例子中，主题的确切含义是不相关的，只是捕获了一组有代表性的单词及其权重，并且它们代表了文档集中一组高级的和不同的概念。最终的想法是帮助用户探索文档集中不同的、有趣的高级概念。在测试一个系统时，无论是否基于 ML，记住这个最终用户目标总是好的。

主题本身从来不会向用户显示，只有后端代码使用它们作为构建高级单词云的基础。以不同的方式合计权重提供了为云选择单词的基础，并对它们的大小进行加权。

当我自己测试和使用这项服务时，我也意识到以算法给出的权重最高的单词的形式给用户提供完全确定的结果是令人厌烦的，并且不能很好地为用户服务。因为这样做将始终为文档集提供完全相同的单词云。随着时间的推移，这不会帮助他们探索和发现新的信息，并且在几次看到我已经互动过的完全相同的单词云后，会感到无聊。所以类似于 Spotify 试图避免算法沙箱的例子，我添加了一些随机化来降低一些词的权重，或者添加一些随机性来确定每个主题中的哪些热门词包含在词云计算中，以及每个词的权重。

## ValtuustoPilvi 的测试、分析和开发

上面的 LDA 示例仅用于顶级搜索，在顶级搜索中，人们搜索所有文档或特定的预定义会议类别。它需要预先计算，在汇总较大的集合时最有用。对于使用动态文档集的更深层次的搜索查询，我使用了一种更快的算法，它能适应不断变化的搜索结果。关于这个算法和我使用的其他算法的更多细节，请参考我写的关于这个主题的[论文草稿](http://www.kanstren.net/valtuustopilvi.pdf)...)回到过去。

其中一个基本测试的例子是检查是否使用了正确的算法。这些基础测试通常很简单，写起来很直观，对系统如何工作有一些基本的了解。但是如何测试单词云对用户来说是实际主题的良好表示呢？这更加主观，也更难测试。

回过头来看，我看到了我对此进行的不同级别的测试:

![](img/4bd60a7b259f57a966516272dfa2384d.png)

在 Valtuustopilvi 项目中测试大小和 oracle 级别。图片作者。

首先，我查看了一个类别的一组文档，以及算法提供的结果对我来说是否有意义。这就是位于上述金字塔底部的*我*。测试先知是我自己，所以非常有限的观点，但也非常中肯，并且容易检查(我确切地知道我在想什么，至少通常是:)。

接下来是*测试组*，比如竞赛评审员和他们给出的反馈。这种反馈更一般，没有算法的详细知识，但仍然具体地给出了他们对服务的不同部分的感觉的反馈。它实际上是转换成用户呈现形式的算法输出。

第三个层次是*一般用户人群*。它的样本量很大，有可能覆盖该服务的所有用户。然而，测试 oracle 是非常通用的，因为它只能依赖于从用户与服务的交互中收集的一些间接线索。这类似于 Spotify(例如，[评估](https://research.atspotify.com/evaluation/)和[搜索](https://research.atspotify.com/search-recommendations/))和 [DuoLingo](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/) 关于分析用户交互和执行调谐算法实验的例子。这同样适用于一般的搜索引擎，例如基于[聚合和匿名交互](https://www.google.com/search/howsearchworks/algorithms/)的谷歌搜索结果优化(2022 年 2 月链接)。

在 Valtuustopilvi 的案例中，该服务没有互联网规模的用户数量，所以在所有用户的顶层没有太多可分析的。我还在 UI 中加入了一个反馈机制，但是除了一些基本的评论之外，并没有太多的收获。然而，一旦一项服务达到足够大的规模，我相信普通用户群是一个非常有用的机会，可以用来获取评估数据和想法。如 [Spotify](https://research.atspotify.com/evaluation/) 、 [DuoLingo](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/) 和 [Google](https://www.google.com/search/howsearchworks/algorithms/) 的例子所示。当然，记住所有的隐私和类似的方面。

# 结论

回顾这篇文章，在我看来，测试基于 ML 的算法与传统算法的最大区别是 ML 模型的黑盒性质。它们嵌入了复杂的内部结构，比如大量的权重、节点和连接。其中每一项都因应用程序、模型配置、培训课程和所用数据的不同而不同。因此，没有单一的方法来测试一个特定的 ML 算法，但这个过程涉及许多调查和探索。这是一个持续的过程，因为数据、模型和基于它的理解通常会随着时间而发展。

我从中收集了一些具体的要点:

*   数据进化，并持续监控它，
*   训练模型进化，并持续监控它，
*   识别重要的操作和数据不变量，
*   培训后测试类型和变形测试，
*   不同的观点，例如相反的假设/不变量，
*   调查和探索作为一个中心概念，
*   用户(系统)反馈及其在不同等级评估中的代理，
*   牢记整个 ML 运营流程和相关质量，
*   最终(用户)目标的广度，例如避免算法沙箱，

综上所述，另一个常见的主题是关注*持续测试、监控和分析*，而不是传统测试中常见的时间点。

总的来说，我发现在测试 ML 算法和围绕它们构建的系统时，有许多方面需要考虑。许多相同的概念适用于传统测试，但希望本文有助于提供一些关于 ML 测试细节的见解。

目前就这些。干杯:)