<html>
<head>
<title>Understanding Decision Trees In Machine Learning and How To Implement It In Python Using sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解机器学习中的决策树以及如何使用sklearn在Python中实现它</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/what-are-decision-trees-4bfac0fbb179?source=collection_archive---------6-----------------------#2019-11-07">https://levelup.gitconnected.com/what-are-decision-trees-4bfac0fbb179?source=collection_archive---------6-----------------------#2019-11-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4fa1de4bd28d2632b536f8fc109328dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ifguo45Dj72h9zHAstUq5w.gif"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图片由r2d3.us提供</figcaption></figure><div class=""/><p id="3e91" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">决策树是一种监督学习，用于分类(是/否)和回归(连续数据)，其中数据根据某个参数连续分割。预测类别是从数据的特征中导出的。以下文章从3.11项目的<a class="ae ld" href="https://medium.com/@FhelDimaano/the-311-on-3-11-bbb05716e1c7" rel="noopener"> 311创建了一个决策树。在这个项目中，预测的是正面或负面的解决结果。决定这一点的特征是:</a></p><blockquote class="le lf lg"><p id="8984" class="kf kg lh kh b ki kj kk kl km kn ko kp li kr ks kt lj kv kw kx lk kz la lb lc im bi translated"><strong class="kh jj"> <em class="ji">机构</em> </strong> <em class="ji"> : NYPD、交通部、卫生部&amp;精神卫生、环境卫生、住房保护和发展部、公园和娱乐部等<br/> </em> <strong class="kh jj"> <em class="ji">区</em> </strong> <em class="ji">:布鲁克林、皇后区、曼哈顿、布朗克斯、斯塔滕岛<br/> </em> <strong class="kh jj"> <em class="ji">地点</em> </strong> <em class="ji">:经度/纬度、十字路口、 十字路口<br/> </em> <strong class="kh jj"> <em class="ji">创建/关闭日期</em></strong><em class="ji"><br/></em><strong class="kh jj"><em class="ji">投诉</em> </strong> <em class="ji"> </em> <strong class="kh jj"> <em class="ji">类型</em> </strong> <em class="ji">:高温/热水、啮齿动物、噪音、街道状况、违章停车、不卫生状况、车道堵塞等等。 <br/> </em> <strong class="kh jj"> <em class="ji">解决方案</em> </strong> <em class="ji"> </em> <strong class="kh jj"> <em class="ji">描述</em> </strong> <em class="ji">:描述响应311服务请求所做的事情。</em></p></blockquote><p id="fd30" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">使用决策树的最大好处之一就是它的可解释性。这不是一个黑盒模型，它吐出一个答案，你不知道为什么或如何得出这个结论。在这个决策树中，它考虑了哪个机构处理了311呼叫，以预测是否有正面或负面的解决方案。决策树拆分的其他功能是显示投诉类型(啮齿动物、噪音、暖气/热水)以及311投诉发生在哪个区。</p><p id="c1e6" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该树是根据基尼指数分割的。<strong class="kh jj">基尼指数</strong>的程度在0和1之间变化，其中0表示所有要素都属于某个阶层，1表示要素随机分布在各个阶层。0.5的基尼指数表示在某些阶层中的要素分布均等。</p><h1 id="b765" class="ll lm ji bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">如何使用sklearn在Python中制作决策树</h1><p id="c242" class="pw-post-body-paragraph kf kg ji kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc im bi translated">我们在熊猫数据库中有我们的数据。我们将所有特征设为X，并移除<code class="fe mo mp mq mr b">resolution_outcome</code>,因为这就是我们所预测的。我们设Y为<code class="fe mo mp mq mr b">resolution_outcome</code>。</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="d1df" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后我们训练分类器并进行预测:</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/6c6ec56776aada08ab4d0b8ad6bbede5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OCVTLVibgZ7yRqbLZXP2lQ.gif"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">图片由r2d3.us提供</figcaption></figure><h1 id="852e" class="ll lm ji bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">超参数调整和优化</h1><p id="a561" class="pw-post-body-paragraph kf kg ji kh b ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc im bi translated">超参数调整和优化对决策树的预测能力有很大影响。决策树的深度是一个非常重要的考虑因素。非常深的树容易过拟合训练数据，而深度不够的树可能过拟合。使用<strong class="kh jj"> GridSearch </strong>是确定理想的超参数集的一个很好的解决方案。GridSearch将使用不同的超参数集运行决策树，并返回产生最高分数的最佳参数。</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="a4e3" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在那里，我们使用graphviz和pydotplus创建一个可视化:</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/9f2d778f432ae6c84e00de81015980c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r_Xp3uiMOqNb0yNGbP-SQ.png"/></div></div></figure></div></div>    
</body>
</html>