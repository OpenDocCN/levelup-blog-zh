<html>
<head>
<title>Creating an iOS AR App using RealityKit's Video Materials</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用RealityKit的视频材料创建iOS AR应用程序</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/creating-an-ios-ar-app-using-realitykits-video-materials-978d49000aad?source=collection_archive---------4-----------------------#2022-01-26">https://levelup.gitconnected.com/creating-an-ios-ar-app-using-realitykits-video-materials-978d49000aad?source=collection_archive---------4-----------------------#2022-01-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f1e23e89eb54015ebd9a6b9163fae804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SqKDhBBRNxZ0dc2R1eh0-g.png"/></div></div></figure><p id="6758" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在iOS / iPadOS设备上运行的增强现实(AR)应用程序中，使用视频图像作为虚拟对象的表面材料可以应用于将移动的场景融入到AR体验中，并可视化时间序列数据。使用iOS SDK的ARKit和RealityKit，这可以通过几行Swift代码来实现。在本文中，我们将以NASA地球天文台的视频图像(基于卫星数据的全球环境变化可视化图像)为例，来看看视频在AR显示中的应用。</p><h1 id="796c" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">机制</h1><p id="5faa" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">使用RealityKit的VideoMaterial功能，可以将视频图像作为AR空间中虚拟对象的素材进行播放。视频材料是在WWDC20上推出的RealityKit功能。视频播放由AVFoundation控制。</p><h1 id="c2ef" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">创建三维模型</h1><p id="cbfd" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">NASA地球观测站允许你下载电影文件(mov格式),它结合了几种类型的数据。这是两种数据组合的一个例子。</p><ul class=""><li id="1347" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated">NASA地球天文台，全球地图:<a class="ae mi" href="https://earthobservatory.nasa.gov/global-maps" rel="noopener ugc nofollow" target="_blank">https://earthobservatory.nasa.gov/global-maps</a></li><li id="fe73" class="lz ma iq ka b kb mj kf mk kj ml kn mm kr mn kv me mf mg mh bi translated">选定数据:<strong class="ka ir">净辐射</strong>和<strong class="ka ir">一氧化碳</strong></li></ul><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/77145f9014c6eb1f2a021b44e20a8d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*OxzkGLXFn1bwTBx276HhDg.jpeg"/></div></figure><p id="cfa9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">两个世界地图上都出现了数据变化的时间序列。日期和标签也是视频图像的一部分。为了将这些信息投射到虚拟对象上，我们为日期和标签创建了两个半球对象和一个普通对象。我们使用DCC(数字内容创建)工具，如Blender来创建3D模型。通过编辑材质的UV贴图来指定视频图像中每个对象和区域之间的对应关系。将每个半球对象映射到世界地图，并将每个普通对象映射到日期/标签区域。</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/c345ea5114e51694ccdd095b79420d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7CF_9A84INTqM8Ax7EvzjQ.jpeg"/></div></div></figure><p id="9785" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从DCC工具以glTF格式输出，并使用Apple Reality Converter转换为USDZ格式。</p><h1 id="1a47" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">创建AR iOS应用程序</h1><p id="c739" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">使用创建的3D模型和下载的视频文件创建一个提供AR体验的应用程序。</p><ul class=""><li id="2ea3" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv me mf mg mh bi translated">iOS部署目标:14.0</li><li id="f8a6" class="lz ma iq ka b kb mj kf mk kj ml kn mm kr mn kv me mf mg mh bi translated">Xcode 13.2</li></ul><p id="6a81" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以从Xcode中的<em class="mt">目标</em> - <em class="mt">构建阶段</em>选项卡- <em class="mt">复制捆绑资源</em>添加视频文件。可以通过拖放将3D模型USDZ文件添加到项目中。</p><p id="50b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">AVFoundation用于播放视频。对于无限循环播放，使用<em class="mt"> AVPlayerItem </em>、<em class="mt"> AVQueuePlayer </em>和<em class="mt"> AVPlayerLooper </em>，并且必须保留一个<em class="mt"> AVPlayerLooper </em>的实例。将<em class="mt"> AVQueuePlayer </em>实例传递给<em class="mt">VideoMaterial(av player:)</em>来创建一个video material。通过将这个VideoMaterial设置为从USDZ文件加载的ModelEntity的材质，视频将被分配给3D模型的材质。<em class="mt"> play() </em>将播放3D模型表面素材的视频。<br/>使用SwiftUI时，使用<em class="mt">UIViewControllerRepresentable</em>。</p><figure class="mp mq mr ms gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h1 id="7c35" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h1><p id="6b7d" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">使用RealityKit的视频材料，我们可以在任意形状的3D物体表面播放视频。要将视频图像的任意区域映射到给定的虚拟对象，请使用3D模型材质的UV贴图。同样的方法可以用来在多个不同形状的3D模型上播放视频。</p><p id="8c89" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">到目前为止描述的Xcode项目可以在GitHub上获得。包括视频文件和3D模型文件，因此您可以立即试用。你可以尝试自己改变NASA数据集和3D模型形状。</p><div class="mw mx gp gr my mz"><a href="https://github.com/ynagatomo/AREarthObservatory" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">GitHub-ynagatomo/arearthhobservatory:一个最小的iOS AR应用程序，可以可视化…</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">一个最小的iOS AR应用程序，基于来自NASA卫星的数据可视化全球环境中的时间序列变化…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">github.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn jw mz"/></div></div></a></div><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/7f80bcf172fa49e29b0288ebd23399c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*FfuX4wCPXAjhUZY__LDXdA.jpeg"/></div></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/ee8d2ed418a3476eb54e7357c40f04c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*Dlth-_vs_S3yLeJ43HNiAQ.gif"/></div></figure><p id="4181" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过将视频素材应用到围绕用户的球体的内表面，用户可以在球体内部360度体验视频所播放的世界。GitHub上有一个样本Xcode项目。这是伦敦塔桥的景色。也可以听听城市的声音。</p><div class="mw mx gp gr my mz"><a href="https://github.com/ynagatomo/ARVideoPortal" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">GitHub - ynagatomo/ARVideoPortal:一个最小的iOS AR应用程序，用于在球体空间中显示360 /视频。</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">一个最小的iOS AR应用程序，可以在球体空间中显示360 /视频。Xcode 13.2.1目标:iOS / iPadOS 14.0+ SwiftUI，ARKit…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">github.com</p></div></div><div class="ni l"><div class="no l nk nl nm ni nn jw mz"/></div></div></a></div><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/347a8584be8b5f8029d40e6507459d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*p0A0Max1RWqB2N4azNJxCA.jpeg"/></div></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/b62f07f3350317e72da90cac0e4a1ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*5WrFfewIThdoHblBN81p4w.gif"/></div></figure><p id="25f1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">参考</p><ol class=""><li id="591b" class="lz ma iq ka b kb kc kf kg kj mb kn mc kr md kv np mf mg mh bi translated">苹果WWDC20视频，RealityKit中的新内容:<a class="ae mi" href="https://developer.apple.com/videos/play/wwdc2020/10612/" rel="noopener ugc nofollow" target="_blank">https://developer.apple.com/videos/play/wwdc2020/10612/</a></li><li id="c815" class="lz ma iq ka b kb mj kf mk kj ml kn mm kr mn kv np mf mg mh bi translated">Apple Documentation，Struct video material:<a class="ae mi" href="https://developer.apple.com/documentation/realitykit/videomaterial" rel="noopener ugc nofollow" target="_blank">https://developer . apple . com/Documentation/reality kit/video material</a></li><li id="ae15" class="lz ma iq ka b kb mj kf mk kj ml kn mm kr mn kv np mf mg mh bi translated">文章- Max Cobb，RealityKit入门:视频资料:<a class="ae mi" href="https://maxxfrazer.medium.com/realitykit-videomaterials-66ad05f396f4" rel="noopener">https://maxx frazer . medium . com/reality kit-Video Materials-66ad 05 f 396 f 4</a></li></ol></div></div>    
</body>
</html>