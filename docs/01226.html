<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-a-smarter-global-accelerator-7ce156ca05fa?source=collection_archive---------6-----------------------#2019-12-01">https://levelup.gitconnected.com/building-a-smarter-global-accelerator-7ce156ca05fa?source=collection_archive---------6-----------------------#2019-12-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0503b3de2e3ddcaf75beb42d1e95bfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*um_lCAxGCd44YlNe"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">尤利娅·布查茨卡娅在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><blockquote class="je jf jg"><p id="dfee" class="jh ji jj jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf ij bi translated"><strong class="jk kg"> <em class="kh">本文原载于我的个人博客</em></strong><a class="ae jd" href="https://toonk.io/" rel="noopener ugc nofollow" target="_blank"><strong class="jk kg"><em class="kh">toonk . io</em></strong></a></p></blockquote><h1 id="0905" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">构建<strong class="ak">更智能的AWS全球加速器</strong></h1><p id="23ac" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">在我的上一篇博文中，我们看到了由AWS提供的全局负载平衡器<a class="ae jd" href="https://medium.com/faun/building-a-high-available-anycast-service-using-aws-global-accelerator-450fc8c4fd1e" rel="noopener">全局加速器</a>。我认为Global Accelerator对于在AWS中构建全球应用程序的人来说是一个非常好的工具，因为它将帮助他们将流量导向正确的源位置或服务器。这对于大容量应用程序来说非常好，并且提供了改进的可用性。</p><p id="183a" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">在这篇博文中，我们将看看如何在之前的博文基础上构建我们自己的全球加速器。我对Global Accelerator想了很多，虽然它提供了一个强大的数据平面，但我认为它将受益于一个更智能的控制平面。通过考虑容量、负载和到每个起点的往返时间，提供更智能的负载平衡的控制平面。在这篇博客文章中，我们将评估并演示通过我们自己实现一个<em class="jj">更智能的全球加速器</em>会是什么样子。</p><h1 id="1f6f" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak">典型建筑</strong></h1><p id="871b" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">如今，许多应用程序都是使用下面的架构交付的。客户端总是命中最近的边节点之一(蓝色菱形)。哪个边缘节点取决于流量被定向到边缘节点的方式，通常使用基于DNS的负载平衡或直接任播，这是AWS全局加速器所使用的。</p><figure class="lp lq lr ls gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lo"><img src="../Images/82ae7a2ce0fdcfb2a0a1594cf0b29191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YI0T8iXatDz57M-7eHDvZw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">典型的应用交付架构</figcaption></figure><p id="b725" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">然后，边缘节点需要确定将请求发送到哪个源服务器(假设没有缓存或缓存缺失)。这是典型的CDN的工作方式，也是谷歌和脸书交付应用的方式。在简单CDN的情况下，可以有一个或多个源服务器。在脸书的例子中，更多的选择是将请求发送到他们的“核心”或“更大”的数据中心。</p><p id="1879" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">使用AWS Global Accelerator，您可以在一个区域中配置侦听器(菱形)，以将一定比例的流量发送到一个原始组，即AWS所说的“端点组”。这是静态配置，不太理想。此外，如果一个源(图中的绿框)达到其容量，您将需要更新配置。这是我们要做得更聪明的部分。</p><p id="cc37" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">在理想情况下，每个边缘节点(菱形)根据边缘节点和起点之间的延迟将请求路由到最近的起点。它还应该知道原点承受的总负载，以及原点可以处理多少负载。单个边节点不知道有多少其他边节点，也不知道每个边节点向每个原点发送了多少。所以我们需要一个集中的大脑和一个反馈回路。</p><h1 id="224e" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">构建闭环系统</h1><p id="3160" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">为了让系统不断适应不断变化的环境，我们需要访问几个操作指标。我们需要知道每个边缘节点(负载平衡器)正在接收多少请求，这样我们就可以推断出每秒传入请求的总数。我们还需要知道每个源的容量，因为我们希望确保我们不会向一个源发送超过其处理能力的流量。最后，我们需要知道每个边缘节点和每个原点之间的健康状况和延迟。这些指标大多是动态的，因此我们需要持续发布(或轮询)健康信息和每秒请求信息。</p><p id="3e75" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">现在我们有了所有的输入数据，我们可以把它输入到我们的软件中。该软件本质上是一个调度程序，解决基于约束的分配问题。输出是具有所有边节点和每个原点的每个边节点的权重分配的列表。一个简单的例子如下:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="ad42" class="ly kj kh lu b gy lz ma l mb mc">-Listener 192.0.2.10:443 <br/> - Edge node Amsterdam:<br/>    - Origin EU DC:  90%<br/>    - Origin US-WEST DC:  0%<br/>    - Origin US-EAST DC:  10%<br/>    - Origin Asia DC:  0%<br/> - Edge node New York:<br/>    - Origin EU DC: 0%<br/>    - Origin US-WEST DC:  0%<br/>    - Origin US-EAST DC:  100%<br/>    - Origin Asia DC:  0%</span></pre><p id="1817" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">在监听方<em class="jj">192.0.2.10:443</em>的上述示例中，Amsterdam edge节点将把90%的请求发送到欧盟起点，而剩余的10%被定向到下一个最近的美国东部DC。这意味着欧盟数据中心已满负荷，正在将流量卸载到下一个最近的起点。</p><p id="9da3" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">纽约边缘节点将所有流量发送到EU-东部数据中心，因为此时有足够的容量，不需要卸载流量。</p><p id="73a4" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">我们的闭环系统将每隔几秒钟重新计算并发布结果，以便我们能够快速应对变化。</p><h1 id="3770" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak">让我们开始建造</strong></h1><p id="6d93" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">我将重复使用我们之前构建的大部分内容，在这个实验中，我将再次使用<a class="ae jd" href="https://medium.com/@atoonk/building-a-high-available-anycast-application-in-5-minutes-on-packet-198c82eaabc" rel="noopener">Packet.net和他们的BGP选播支持</a>来构建边缘节点。详情请看这个<a class="ae jd" href="https://medium.com/@atoonk/building-a-high-available-anycast-application-in-5-minutes-on-packet-198c82eaabc" rel="noopener">的博客</a>。我使用Linux LVS作为这个设置的负载平衡器。每个边缘节点每隔15秒向时序数据库<a class="ae jd" href="https://prometheus.io/" rel="noopener ugc nofollow" target="_blank">普罗米修斯</a>发布所需的指标。这样，我们现在就有了一些完全任意播放的边缘节点，并且可以在一个集中式系统中访问每个边缘节点所需的所有指标。</p><figure class="lp lq lr ls gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi md"><img src="../Images/0407aa060adf9320820db6f402c7c09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXsxBwPZsGxrGXEOVtXiCg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">Swagger文件，使用Flask-RESTPlus构建</figcaption></figure><p id="3e80" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">另一件事是需要一个集中的真相来源。为此，我编写了一个基于Flask的REST API。这个API允许我们创建新的负载平衡器，添加源，等等。我们还可以向所有负载平衡器询问相同的API、它的来源以及健康和操作指标。</p><p id="e126" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">接下来我们需要的是一个脚本，它每隔几秒钟就与API对话以检索最新的配置。有了这些信息，每个边缘节点可以更新负载平衡器配置，例如创建新的负载平衡器监听器，并更新源细节，例如每个源的权重。我们现在一切就绪，可以开始测试了。</p><figure class="lp lq lr ls gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/f92f83c49ca2192caad0f51f6bcf3bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PbSBDEjF_1mYGVH4snMhTQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">每个负载平衡器的JSON定义</figcaption></figure><h1 id="9197" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak">观察和调整</strong></h1><p id="22a2" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">我通过向一个监听器生成许多get请求开始测试，这个监听器有两个来源，一个在美国的<a class="ae jd" href="https://www.digitalocean.com/" rel="noopener ugc nofollow" target="_blank"> digitalocean </a> VM，一个在欧洲。由于所有测试都是从一个位置执行的，因此它涉及一个边缘数据中心，该数据中心有两个边缘节点。这些边缘节点会将流量发送到最近的起点，即美国起点。现在想象一下，这个源服务器达到了它的最大容量，我想保护它免于过载，并开始向另一个源发送一些流量。为此，我将美国源的最大负载数设置为每秒200个请求(参见上面的JSON)。</p><p id="7279" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">下面你会看到一个有趣的可视化测量。在t=0时，两个源的总流量负载为0，根本没有流量进入，这也意味着两个源都远低于其最大容量。这意味着US负载平衡器被配置为将所有请求发送到US源，因为它们具有最低延迟并且低于最大阈值。</p><p id="f367" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">在我们生成流量之后，所有的请求都被发送到美国源来启动。随着指标开始传入，系统检测到传入请求的总数超过200，因此，负载平衡器配置将被更新以开始向两个源服务器发送流量，目的是每秒向美国源发送的请求不超过200个。</p><figure class="lp lq lr ls gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mf"><img src="../Images/627d487986805bcf05f1d5e4d78bc335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_rh2VgUAN2w45QQXnpuzg.png"/></div></div></figure><h2 id="6891" class="ly kj kh bd kk mg mh dn ko mi mj dp ks li mk ml kw lk mm mn la lm mo mp le mq bi translated">速度与准确性。</h2><p id="1140" class="pw-post-body-paragraph jh ji kh jk b jl lg jn jo jp lh jr js li lj jv jw lk ll jz ka lm ln kd ke kf ij bi translated">我们想要防止的事情之一是交通的突然大波动。为了实现这一点，我内置了一个阻尼因子来限制负载转移(即负载平衡器配置)更改为每15秒间隔每个原点2%。注意；如果你有两个原点，这意味着每个原点有2%的变化，所以每15秒钟周期有4%的摆动。这意味着系统对重大变化的反应时间会稍长一些，但会给我们带来更大的稳定性，意味着原点之间的振荡会更小，并允许系统稳定下来。在我的初始版本中，我没有阻尼，系统从未稳定过，并显示出明显的不必要的突然流量波动。</p><p id="ca28" class="pw-post-body-paragraph jh ji kh jk b jl jm jn jo jp jq jr js li ju jv jw lk jy jz ka lm kc kd ke kf ij bi translated">该图显示了我的测试设置的一个有趣的副作用。由于我在美国西海岸进行测试，并开始将越来越多的请求卸载到欧盟原产地，这意味着平均而言，由于往返时间的增加，单个curl将需要更长的时间。结果，请求的总数下降了。这很有趣，因为这意味着软件需要不断适应。每次我们稍微改变源权重，请求的总数就会稍微改变。这会导致一些振荡，但这也正是闭环系统设计的振荡，只要我们有一个阻尼因子，它就能很好地工作。它还显示，在某些情况下，如果您的网站(或任何应用程序)响应更快，入站请求的总数会增加。虽然我不确定这是否代表真实世界的情况。不过，这是一个有趣的副作用，给软件增加了一点额外的压力。</p><h1 id="b00d" class="ki kj kh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">结束语</h1><blockquote class="je jf jg"><p id="2d7b" class="jh ji jj jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf ij bi translated">这个项目很有趣，因为它让我结合了我的几个兴趣。其中一个是全球流量工程，即。我们如何让流量到达我们想要处理的地方。我们还将重复使用从以前的几篇博客文章中获得的经验和教训，特别是如何使用Packet构建anycasted应用程序，并深入研究AWS全球加速器。我通过在Flask中构建一个Restful API来提高我的Python技能，并确保使用OpenAPI规范对它进行了适当的文档化。</p><p id="6856" class="jh ji jj jk b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf ij bi translated">最后，构建实际的调度程序是一个有趣的挑战，在我对结果真正满意之前，我花了一段时间来找出如何最好地解决分配问题。其结果可能是一个更智能的全球加速器。</p></blockquote></div></div>    
</body>
</html>