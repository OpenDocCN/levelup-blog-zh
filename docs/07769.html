<html>
<head>
<title>Deployment: Computer Vision in Practice</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">部署:实践中的计算机视觉</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/deployment-computer-vision-in-practice-99b7bbb6aa7c?source=collection_archive---------10-----------------------#2021-03-08">https://levelup.gitconnected.com/deployment-computer-vision-in-practice-99b7bbb6aa7c?source=collection_archive---------10-----------------------#2021-03-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="18cf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">计算机视觉导论，第七部分</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/cb95c6bb828888bf09bface8758b5b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mn8VKKEW-3rv6opELKZl8A.jpeg"/></div></div></figure><p id="96a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在过去的六周里，我们学到了很多关于如何教一个模型去检测图像的知识。我们从计算机如何读取和存储图像的基础知识开始。然后过渡到算法如何通过使用Haar-like特征来定义图像中的对象。我们讨论了积分图像如何减少计算图像中成千上万个可能特征的时间和必要资源。从那以后，我们讨论了模型是如何被训练的，既有直觉层面的，也有数学层面的，特别是当它与Adaboost相关的时候。最后，我们看到了模型训练的作用。今天，我们将采用上次构建的“训练过的”模型，并应用我们所学的所有知识来理解对象检测如何实时工作。</p><blockquote class="ln lo lp"><p id="4076" class="kr ks lq kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated">注意:这段时间，我们所有的知识都是基于Viola-Jones算法，利用Viola和Jones 20年前研究的Haar类的基本特性。虽然深度学习神经网络正在慢慢成为新的标准，但Viola-Jones算法仍然是一个强大的工具，可以作为建立一个人对计算机视觉的理解的伟大基础。</p><p id="7dc1" class="kr ks lq kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated">虽然Viola-Jones算法被用于人脸检测，但其核心是一种<strong class="kt ir">物体检测</strong>算法，这种算法是在人脸上经过<strong class="kt ir">训练</strong>的。因此，我们可以很容易地将相同的过程应用到我们的场景中。</p></blockquote><h1 id="e312" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">从静止图像到实时图像</h1><p id="4510" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">从静态图像分类到实时图像分类的转变实际上是相当不稳定的。请记住，我们所说的“视频”只不过是快速连续拍摄的一系列静态照片。该模型将这些图像作为输入，就像在训练期间一样，并针对这些图像测试现在“训练的”(或“拟合的”)方程。为了让模型跟上实时提要，需要在提要的分辨率、可用的处理能力和每秒捕获的帧数(又名:每秒帧数，或“FPS”)之间建立平衡。当这些元素都正确排列时，您将获得如下结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/83dc30b41b33a002ad3da13ba6a1f1f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*MOTqoMEnVYaOJgAp823wxg.gif"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">图片来源:【PyImageSearch.com T4】</figcaption></figure><p id="ebb1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如你所看到的，勾勒这对夫妇个人面部轮廓的框架能够实时缩放、计算和跟踪。如果电脑的处理能力太低，或者FPS或分辨率设置太高，您会看到帧滞后。这在中低端数码相机中很常见。</p><p id="347c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">实时对象检测之所以可用，主要是因为通过使用Integral Image和Adaboost进行了优化。相对平滑的过渡的另一个原因是，一旦模型被训练、测试和部署，模型等式中保留的权重和特征(例如，<em class="lq">f</em>(<em class="lq">x</em>)=<em class="lq">α</em>₀<em class="lq">f</em>₀(<em class="lq">x</em>)+<em class="lq">α</em>₁<em class="lq">f</em>₁(<em class="lq">x</em>)+<em class="lq">α</em>₂<em class="lq">这意味着权重(<em class="lq"> αₙ </em>)和特征(<em class="lq"> fₙ) </em>不能改变，除非你打算重新训练模型。</em></p><p id="3455" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在某种程度上，您可以将训练好的模型视为清单。如果最小数量的特征出现在预定义空间的一侧，则它是目标对象的概率非常高。我说的预定义空间是什么意思？简单地说，就是你在上面看到的每个面周围的缩放框！它可以缩放以补偿不同的面部尺寸和强制透视(当对象根据与相机的距离看起来更小或更大时)。该模型在图像上滑动该框，直到它检测到所有必要的特征都在该框内。一旦找到这些特征，它就开始计算。</p><p id="e18d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在继续之前，让我们最后一次仔细看看那张GIF。你可能会注意到每个方框右上角的波动数字。这表示<em class="lq"> </em>轮廓物体成为目标物体的<em class="lq">概率</em>。让我们最后再看一遍模型后面的方程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7b9743f844dd3c2872392e5fa8885a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/0*F6zp7kl22wtXDYQ1.png"/></div></figure><p id="4efc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">上次我们说<em class="lq"> F </em> ( <em class="lq"> x </em>)代表的是分类器。虽然这是事实，但这不是全部的真相。记住，所有这些都是一个大的数学方程式。因此，当你把所有的项(<em class="lq"> αₙ fₙ </em> ( <em class="lq"> x </em>))加起来时，结果将是一个数字。这个数字是模型找到目标对象的可能性。因此，<em class="lq"> F </em> ( <em class="lq"> x </em>)是在该帧内检测到目标对象的<em class="lq">概率</em>。</p><p id="8b21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有这些问题都解决了，让我们向前看，看看我们的模型是如何工作的。</p><h1 id="a93e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">检测沃尔玛</h1><p id="f20b" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">所以上次我们假装训练了一个可以检测沃尔玛的图像分类器。因此，我们可以说，在我们的实时提要中捕获的图像之一是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e56472bfc886057e47adb0102824e93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aQx-QH4XiMSqp3V0.jpeg"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">图片来源:<a class="ae mw" href="https://www.ttnews.com/articles/walmart-fights-54-million-lawsuit-verdict-awarding-drivers-sleeper-berth-pay" rel="noopener ugc nofollow" target="_blank">TTNews.com</a></figcaption></figure><p id="1b6f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们的屏幕上，我们看到了这个图像，但是请记住，在本系列的第一部分中，图像实际上是一个分布在三个通道上的数组，这三个通道对应于像素的红色、绿色和蓝色通道。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/ae21e48f567b0d6fa6f5069e7a577a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mSfHCmDorqR2hMY9.png"/></div></div></figure><p id="603e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">阵列的尺寸等于图像的分辨率，因为每个单元代表一个像素。每个通道的单元表示该像素通道的强度(或亮度)。因此，当我们看到沃尔玛的图片时，计算机将其视为数字和渠道的集合。</p><h2 id="89b1" class="mz lv iq bd lw na nb dn ma nc nd dp me la ne nf mg le ng nh mi li ni nj mk nk bi translated">转换</h2><p id="a3b2" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">接下来，模型在后台执行两个转换。这两种变换您以前都见过:将图像转换为灰度，并缩放数值(不是分辨率)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4ce92755186322eb33127445eef19af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gw3AipH9VijdxXms.jpeg"/></div></div></figure><p id="8403" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">独立通道中的每个单元格都被转换为灰度。这使得数学更简单，有助于降低任务的复杂性。</p><p id="fc41" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第二个转换是缩放每个单元格中的值。通常，亮度在0到255之间，255是最亮的。然而，为了简单起见，这些值被缩放，以便它们在0和1之间(0表示没有光，1表示最亮)。</p><p id="bf40" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，你可能还记得，在训练过程中，图像的分辨率也被缩小了。嗯，这不会在模型部署后发生。相反，所有的特征都被放大以匹配图像分辨率的比例！所以只要记住:在训练期间，<em class="lq">形象</em>被缩小<strong class="kt ir"/>。实际上，<em class="lq">的特征</em>被放大<strong class="kt ir">到</strong>。</p><h2 id="0834" class="mz lv iq bd lw na nb dn ma nc nd dp me la ne nf mg le ng nh mi li ni nj mk nk bi translated">检测特征</h2><p id="502c" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">有了正确格式的图像阵列、通道和数字，模型就开始寻找目标的特征。它计算出所有必要的<em class="lq">类似Haar的特征。你可能记得这张图片:</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/1e40f91f14f29273b293cd6fd011a3d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/0*g9hPV1QDmFbFcOs8.png"/></div></figure><p id="46ea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该模型想要确定图像的轮廓部分是否包含边缘特征。这是通过创建一个完整的图像来实现的，如下图所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/2d6dcf41a9dfc8a15c551b7aba018656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*JGkTkZZA1lluVVC3.png"/></div></figure><p id="ae62" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它使用积分图像来定位它需要的4个神奇数字，以快速找到总和并计算较亮和较暗部分的平均值:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/91fd3a7871f89a3de99b7c59e6c1f78c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*Zho9nAcZtexGZfMh.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">较轻的那一半的数字</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/af334ce3c464f07da7f407c2c4bf6630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*gx4BZ_bRzTRkvfHB.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">黑暗一半的数字</figcaption></figure><h2 id="8148" class="mz lv iq bd lw na nb dn ma nc nd dp me la ne nf mg le ng nh mi li ni nj mk nk bi translated">级联:另一个出色的优化</h2><p id="610e" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">这一切听起来非常熟悉，但这次有些不同。我之前提到过，它正在计算<em class="lq">必要的</em>特性。请记住，在培训期间，我们删除了所有不必要的功能，并将等式简化为如下形式:</p><p id="0aac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="lq">f</em>(<em class="lq">x</em>)=<em class="lq">α</em>₀<em class="lq">f</em>₀(<em class="lq">x</em>)+<em class="lq">α</em>₁<em class="lq">f</em>₁(<em class="lq">x</em>)+<em class="lq">α</em>₂<em class="lq">f</em>₂(<em class="lq">x</em>)+…+<em class="lq">α</em>₅</p><p id="708d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果围绕图像平移的帧(像这对夫妇的GIF中的帧)没有找到第一个特征，<em class="lq"> f </em> ₀，它简单地停止计算，移动一个像素并再次尝试。如果它找到了<em class="lq"> f </em> ₀，但没有找到<em class="lq"> f </em> ₁，它再次停止并移动一个像素。它将这样做，直到₀到₅都在盒子里面。这种节省时间的方法叫做“层叠”。这使得模型不必浪费时间来计算类似Haar的特征等。如果所有的重要特征都不存在。在我们的模型中，这些特征对应于下面看到的特征:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b63be9355908eb25c1526a3d85f500ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nLIcdLc6qdIahu5o.jpeg"/></div></div></figure><p id="eedd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们的模型移动一个框架，直到上面的所有六个特征都在其中找到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/75c5571c7326994e8968b2fc2b21331c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4DmZxvAK3IVqZ7xORGmU0A.jpeg"/></div></div></figure><h2 id="5da4" class="mz lv iq bd lw na nb dn ma nc nd dp me la ne nf mg le ng nh mi li ni nj mk nk bi translated">预测</h2><p id="e494" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">此时，模型采用先前计算的值(以确定它们是否是类哈尔特征)，并将它们代入<em class="lq"> </em>方程中对应的<em class="lq"> fₙ </em>项。它将它们乘以各自的权重(<em class="lq"> αₙ </em>)。结果是检测到的物体是目标的概率。</p><p id="c557" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们这种情况下，概率非常高，我们的直播提要突出了这一点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/3c95cbcf18bc798a55a1a451612b5da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mO7wZAMfzD6yLozZ8mbFwQ.jpeg"/></div></div></figure><p id="22cf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，这里有一个问题！看这个盒子！我们想要一个检测沃尔玛商店的模型，但是我们的模型只检测到沃尔玛的标志！幸运的是，有一些方法可以纠正这一点。然而，在目前的状态下，该模型很擅长告诉我们沃尔玛是否出现在实时画面中，但在勾勒物体本身方面表现不佳。</p><h1 id="8adc" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">摘要</h1><p id="74c9" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">在这个系列中，我们讨论了计算机视觉基础的复杂发展。它们是如此的基础，以至于即使深度学习神经网络，在抛弃像Haar-like特征等概念的同时。仍然遵循类似的模式，例如在图像内定义边缘。它们也非常强大，以至于这些算法今天仍在许多模型中使用！</p></div></div>    
</body>
</html>