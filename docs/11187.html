<html>
<head>
<title>Huggingface Transformers Interpretability with Captum</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Captum的Huggingface Transformers解释性</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/huggingface-transformers-interpretability-with-captum-28e4ff4df234?source=collection_archive---------3-----------------------#2022-02-24">https://levelup.gitconnected.com/huggingface-transformers-interpretability-with-captum-28e4ff4df234?source=collection_archive---------3-----------------------#2022-02-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1f2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">审查由Meta(脸书)开发的一个有前途的框架</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/f83c9bcd13569a88f903aeb679b1acfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SsCJVZqh_dcOV7wg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">布雷特·乔丹在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="2497" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">复杂的NLP模型的可解释性仍然是一项困难的、经常是主观的任务，但肯定是市场所需要的。Captum是由Meta(脸书)工程师开发的一个软件包，封装了几十种广泛接受的解释技术。在本帖中，我将为您提供一个围绕Hugginface情感分类器构建的活生生的例子</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="4f22" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">环境准备</h1><p id="61ff" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">要完成本教程，您需要安装几个软件包。像往常一样，我将为您提供一组终端命令来使它自动发生:</p><pre class="km kn ko kp gt mm mn mo mp aw mq bi"><span id="1ec2" class="mr lk iq mn b gy ms mt l mu mv">$ python3 -m virtualenv venv<br/>$ source ./venv/bin/activate<br/>$ pip install -r requirements.txt</span></pre><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="98d3" class="lj lk iq bd ll lm my lo lp lq mz ls lt lu na lw lx ly nb ma mb mc nc me mf mg bi translated">模型准备</h1><p id="0718" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">在本教程中，我想跳过模型开发的忙乱，更多地关注可解释性。出于这个原因，我决定使用Huggingface情绪分析管道，因为它为您提供了只有两行代码的SOTA模型:</p><pre class="km kn ko kp gt mm mn mo mp aw mq bi"><span id="8c1b" class="mr lk iq mn b gy ms mt l mu mv">from transformers import pipeline</span><span id="ac6e" class="mr lk iq mn b gy nd mt l mu mv">clf = pipeline(“sentiment-analysis”)</span></pre><p id="40ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型能够分析文本的积极或消极情绪，并返回如下预测:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/56cda34468de120d9e1b3959b871a82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*_ZRYlcrhLbjhiUGT4xXeLg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">图片#1。拥抱表面管道执行</figcaption></figure><p id="fc2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经典的ML任务！</p><h1 id="a6a3" class="lj lk iq bd ll lm my lo lp lq mz ls lt lu na lw lx ly nb ma mb mc nc me mf mg bi translated">该算法</h1><p id="2787" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">在这一部分中，我将解释一下用于生成要素重要性的算法——图层集成梯度。首先，我不打算向你解释它背后所有沉重的数学，因为它已经由Mukund Sundararajan等人在名为<a class="ae lb" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank">“深度网络的公理化属性”</a>的论文中完美地实现了。我在这篇文章的这一部分的目标是向你解释编程逻辑，因为我们将使用一个高级框架，在那里这个算法已经被实现了。</p><ol class=""><li id="1fe5" class="nf ng iq jp b jq jr ju jv jy nh kc ni kg nj kk nk nl nm nn bi translated">生成基线输入。对于图像，基线代表全黑图片或随机像素矩阵。对于文本，采用一系列填充标记。例如，当使用基于BERT的分类器时，在Image #2上传递类似伪代码的东西是很方便的。请注意，序列的中间部分等于填充标记列表乘以seq_len-2。基线应该与输入的大小相同，所以这个技巧允许我们实现它。</li></ol><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi no"><img src="../Images/10f5cdbdbc0f2361197e4ef7ea53057e.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*G-yqzRdReXs67qp7v7Kp6A.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">图片#2。伪代码</figcaption></figure><p id="3f1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.生成从基线到输入序列的线性变换。这一步可以通过以下一组图像很好地可视化:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi np"><img src="../Images/fe89ad100619d6f03172fbf7c9c3ecb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5TxIrIWQdPB5-T-n.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">原图取自<a class="ae lb" href="https://towardsdatascience.com/understanding-deep-learning-models-with-integrated-gradients-24ddce643dbf" rel="noopener" target="_blank">本帖</a></figcaption></figure><p id="1faa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在文本用例中，您将逐渐用输入向量中的标记替换填充标记。</p><p id="a65e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.计算一组梯度以测量每一步的变化，其中一步是引入关于基线输入的越来越多的信息的过程。</p><p id="97f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.通过将每个步长向量除以其步长总和来归一化梯度。在文本的情况下，您将拥有一个多维数组，其形状类似于<strong class="jp ir"> [1，seq_len，emb_len] </strong>，并且您将通过列<em class="nq">(伪代码:np.sum(-1)) </em>进行求和</p><h1 id="40ab" class="lj lk iq bd ll lm my lo lp lq mz ls lt lu na lw lx ly nb ma mb mc nc me mf mg bi translated">在Captum中实现</h1><p id="e5a5" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">在这一节中，让我为您提供一个久经考验的类，它包含了Captum解释所需的所有主要步骤的功能。请通读方法描述，以便更详细地理解这段代码的作用。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="a4b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用包装器也很简单，只需几行代码:</p><pre class="km kn ko kp gt mm mn mo mp aw mq bi"><span id="cb35" class="mr lk iq mn b gy ms mt l mu mv"><br/>device = ‘cpu’<br/>sample = “I am very excited about this project”</span><span id="291d" class="mr lk iq mn b gy nd mt l mu mv">exp_model = ExplainableTransformerPipeline(‘distilbert’, clf, device)<br/>exp_model.explain(sample)</span></pre><p id="d525" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出应该如下所示:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/71a7009aac9189677f9899345272cb1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*L9pqnodViQDR2lFqR3KwBQ.png"/></div></figure><p id="1d3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意,“兴奋”一词是模型总体结果的最大“驱动因素”,因为pipeline预测了该样本的“阳性”标签，而Captum正在计算关于目标类别的梯度。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="0ed9" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">结论</h1><p id="466f" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">虽然Captum仍处于测试版，但它似乎已经相当稳固了。这个框架不是一个“开箱即用”的解决方案，所以您需要一点耐心来浏览文档和教程。我自己的目标是更深入地探索它，开发一个python包来涵盖大多数常见场景，这样最终用户就可以用几行代码调用Captum算法。</p><p id="1a9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你对这个包感兴趣，请在评论区告诉我！</p></div></div>    
</body>
</html>