# 一致散列有什么帮助

> 原文：<https://levelup.gitconnected.com/how-does-consistent-hashing-help-df9d969735b4>

## BD 76935874 Fe 98 fc 72 c 3a 6 DC 4 bace af 6

![](img/e5d9c392c4d0dd1873a14e51418d7419.png)

马库斯·斯皮斯克在 [Unsplash](https://unsplash.com/) 上拍摄的照片

让我们从理解一些术语和一些与本文相关的事实开始，并找到共同点。

*   `Hashing`是采用字符串或输入键(为存储叙述性数据而创建的变量)并用哈希值表示它的做法，哈希值通常由算法确定，并构成比原始字符串短得多的字符串。
*   `Web caching`是存储数据以供重用的活动，例如由 web 服务器提供的网页副本。用户第一次访问该页面时，缓存或存储该副本，下次用户请求同一页面时，缓存将提供该副本，这有助于防止源服务器过载。想象一下访问电子商务，页面被一次又一次地请求，重复地从服务器下载页面是一种浪费。一个显而易见的想法是使用 Web 缓存，它存储最近访问过的页面的本地副本。如果已经存在本地副本，则无需攻击服务器，本地副本的响应会更快，从而为所有人创造双赢局面。
*   `Distributed System`所称的`Andrew Tanenbaum`是:

> 一组独立的计算机，对用户来说就像一台计算机。

*   分布式系统由多台计算机组成，这些计算机同时运行，独立发生故障，并且不共享一个公共时钟。它们必须同步才能保持一致。

> 一致散列(1997 年)的最初动机是 Web 缓存。这个想法有实际用途。一致散列法诞生了 Akamai，直到今天，Akamai 仍是互联网的主要参与者，管理着数以吨计的大公司的网站。(从数量上来说，Akamai 服务于所有互联网流量的 10-30%)。
> 
> ~CS168 斯坦福大学
> 
> Teradata 在 1986 年发布的分布式数据库中使用了这种技术，尽管他们没有使用这个术语。Teradata 仍然使用哈希表的概念来实现这个目的。
> 
> ~维基百科

让我们假设在一个组织中有一台服务器来呈现所有的请求。所有读取和写入操作都是在同一上执行的。假设产品是`read intensive`。过了一段时间，用户群增长了，为了继续呈现读请求，首先想到的是创建单个的`Master server`。现在，写操作寻址到主服务器，读请求寻址到副本服务器。

现在，假设随着时间的推移，写操作的流量会增加。也许现在是节日，每个人都忙着给朋友和家人写祝福。写操作溢出。我想到的一个想法是创建`shards`。结果，创建了五个碎片。如果这是一个关系数据库，这里可能会变得混乱，因为很难维护连接操作。`Referential integrity`，通常由 RDBMS 维护的表之间的父/子关系，如果父行和子行在不同的片上，则不会自动维护。一种方法是反规范化，但这也会变得很糟糕。

类似地，假设在一个组织中，我们计划为在该组织中工作的人缓存数据。现在，单个机器渲染的数据可能会非常庞大。假设我们维护 5 台机器 M0、M1、M2、M3、M4 来呈现结果。我们所做的是散列请求并生成一个唯一的数字。通常，不会生成唯一的编号。我们使用像`MD5`这样的算法来生成比如说`32 bit hashes`。但是在这里，让我们考虑在散列后生成一个唯一的数。一个 RequestId 为 1 的请求传入，我们对此进行哈希处理以获得唯一的数字 21。现在，假设我们使用一个模运算符来查找服务器号地址。

```
requestId = 1
h(requestId) = h(1) = 21 //let's suppose
h(requestId) % 5 = 21 % 5 = 1
```

![](img/dd315dd96339081d1dd67ae3f8285bbd.png)

图 1

这将非常好地工作，并将负载均匀地分布在机器上。但这种情况是非常理想的。负载会随着时间的推移而增加，任何现有的机器都可能出现故障。在这种情况下，总会有一个问题。假设负载增加，组织决定再添加一个资源。在这种情况下，

```
requestId = 1
h(requestId) = h(1) = 21 //let's suppose
h(requestId) % 6 = 21 % 6 = 3
```

该资源将在 M3 查看，但在存储时，我们有 5 台机器，因此我们将其存储在 M1。一个糟糕的解决方案是在所有 6 台机器上重新分配资源，但这可能是一个非常昂贵的操作。如果一个节点爆炸了。现在将有 4 个节点，请求将指向错误的机器。因为这里我们考虑的是创建缓存的情况，如果没有找到资源，请求将转到原始资源服务器，并在机器上创建一个本地副本。这将导致数据不一致。因为相同的数据现在将出现在两个节点上，如果用户在一个节点上更新数据，则相同的键在两个节点上会出现数据不匹配。因此，这种解决方案并不可取。

救世主始终如一地出现在画面中。上面讨论的两个案例都是为了在一个广阔的框架内提供对问题的正确理解。

## 一致性哈希有什么帮助？

我们需要的是对象保持在相同的位置，不管机器或服务器的数量是多少。

这里我们散列密钥和服务器。假设我们对一个对象的密钥或 id 执行 32 位 MD5，对一个服务器的 IP 执行类似的 32 位 MD5。这给了我们可以从`0 to 2³²-1`中选择的数字。所以我们有机器 m0 → m2 -1。让我们考虑一个小的子集，并创建一个平面数组来更好地理解。

![](img/da199d6c10cf1ecf7e551b17dbcbb9eb.png)

图:2

考虑对象 x0、x1、x2、x4 以及机器 m1、m2 和 m3。每个对象都被分配给它右边的下一台机器。x0 →m2，x2 →m1，x1 & x4 → m3。在这里，我们已经散列了所有的机器和对象，并分别推送到这种扁平的类似数组的结构。我们得到一个对象，散列它，找到并开始查找它的右边，以找到下一个机器散列 h(m)，并将这个对象分配给这台机器。数组的第一个元素被认为是在数组的最后一个元素的右边。因此，这可以被视为一个循环节点连接，类似于下面的`Figure: 3`。机器和对象的定位是通过散列输出来实现的。据说这是为了创建一个可视化的工作原理。

![](img/7cb368054bed92bcaa90f19aaefa3ea4.png)

图:3

缓存和对象都散列到这个圆上的点，一个对象存储在离`clockwise direction`最近的缓存服务器上。假设合理的散列函数，根据对称性，n 个缓存服务器中的每一个上的预期负载正好是一个`1/n fraction of the objects`。现在，假设有这样一种情况，随着负载的增加，我们必须再添加一个缓存服务器，我们可以轻松地添加它，并且只需要移动对象总数的 1/n，因为机器是均匀分布的。

![](img/690fb938b48fe3573c6ba78ee00bc36a.png)

图 4

在`Figure 4`这里，机器 m4 被添加在 m1 和 x2 之间。以前，对象 x2 在 m1 处被引用，现在查找将改变。m1 的所有数据将被移动到 m4，当 x2 向右或顺时针方向看时，它将向服务器 m4 查询结果。在这个 web 缓存的例子中，这很简单，因为请求会发送到 m4，它不会找到资源。这将是一次缓存未命中，将从资源的原始服务器中获取数据，并在 m4 创建一个副本。此外，m1 处的未决请求将在某个时间超时。

如果你仔细观察，你会发现目前的服务器看起来并不是均匀分布的。可能的情况是，由于非均匀分布，大部分流量由单台机器呈现。像这里，从 m3 到 m1 有很大的差距。这可以使 m1 保持比 m2 和 m3 更多的负载，因为大多数对象散列将占据 m3 和 m1 之间的空间。那我们该怎么办？

这里的想法是创建`virtual nodes`。这意味着什么？这是算法上的东西，而不是面向硬件的。

我们所做的是用不同的散列函数多次散列一个服务器。这是什么意思？在图 4 中观察到，m1 出现在 15°左右，m4 出现在 25°左右，m3 出现在 220°左右，m2 出现在 315°左右。我们当前的哈希函数`h(x)`负责将这些服务器保持在这个位置，我们现在所做的是使用不同的哈希函数将它们分别哈希 3 次，每次得到不同的值，并将它们分别放置在这个循环排列上。

![](img/77087a752f8d65857e0ea6c183b66e2d.png)

图 5

这里，在`Figure 5`中，创建了 m1、m2、m3 和 m4 的多个虚拟副本。这使得服务器的分布更加均匀。使用单个散列函数来定义这些服务器的初始位置，现在使用多个不同的散列函数来创建这些服务器的更多虚拟位置。这增加了服务器的随机性，从而使对象存储在服务器之间保持一致。考虑这样一种情况，我们给这个环增加了一个高容量的机器。我们可以通过使用更多数量的散列函数来创建更多的虚拟副本，并且高容量服务器将比其他服务器更多地出现在这个环中。这就是我们如何利用不同服务器的能力。明智的方法是使缓存服务器的虚拟副本数量与服务器的容量成比例。

参考资料:CS168 斯坦福大学