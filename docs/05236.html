<html>
<head>
<title>Using alwaysAI to Build Your Own License Plate Detection Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用alwaysAI构建自己的车牌检测模型</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/using-alwaysai-to-build-your-own-license-plate-detection-model-5914c8b2068?source=collection_archive---------16-----------------------#2020-08-13">https://levelup.gitconnected.com/using-alwaysai-to-build-your-own-license-plate-detection-model-5914c8b2068?source=collection_archive---------16-----------------------#2020-08-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f1f1cdce45528f147cf3186840539b3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJ8MsrLmDjlQ7VPFTuHE_g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">车牌检测模型的输出示例。</figcaption></figure><p id="3cb2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在本教程中，我们将介绍创建'<strong class="ke ir">always ai/vehicle _ license _ mobilenet _ SSD</strong>'模型的步骤和决策点，这是一个用于识别车辆和牌照的对象检测模型。</p><p id="b8f2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在alwaysAI，我们希望所有开发人员都能使用计算机视觉。计算机视觉中更具挑战性的部分之一是模型训练。本教程的目的是详细概述如何使用alwaysAI模型训练工具快速轻松地训练自定义模型，从数据收集开始，到测试模型的性能结束，包括模型训练的一些提示和技巧。</p><p id="20e7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">关于模型训练的一般信息，请查看这篇文章:<a class="ae la" href="https://alwaysai.co/blog/introduction-to-computer-vision-model-training?&amp;utm_campaign=Open%20Beta&amp;utm_source=aai_blog&amp;utm_content=making_license_plate_model" rel="noopener ugc nofollow" target="_blank">计算机视觉模型训练简介</a>。</p><p id="b7b0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你想加入我们的模特训练测试计划，训练你自己的模特，你可以填写<a class="ae la" href="https://alwaysai.surveykiwi.com/model-training-signup" rel="noopener ugc nofollow" target="_blank">这个简短的调查</a>来报名！</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="4ae1" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">车牌模型介绍</h1><p id="3fb9" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">开发该模型的目的是使其足够通用，能够检测美国和欧洲的车牌，并应用于一些现场使用案例，包括仪表板摄像机和静态交通摄像机:</p><ul class=""><li id="9cad" class="ml mm iq ke b kf kg kj kk kn mn kr mo kv mp kz mq mr ms mt bi translated">十字路口</li><li id="a9d3" class="ml mm iq ke b kf mu kj mv kn mw kr mx kv my kz mq mr ms mt bi translated">天桥</li><li id="a5ec" class="ml mm iq ke b kf mu kj mv kn mw kr mx kv my kz mq mr ms mt bi translated">停车场</li><li id="b209" class="ml mm iq ke b kf mu kj mv kn mw kr mx kv my kz mq mr ms mt bi translated">商店或房屋正面</li></ul><p id="63b4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该模型检测四轮车辆，包括</p><ul class=""><li id="4dd0" class="ml mm iq ke b kf kg kj kk kn mn kr mo kv mp kz mq mr ms mt bi translated">轿子</li><li id="bf4f" class="ml mm iq ke b kf mu kj mv kn mw kr mx kv my kz mq mr ms mt bi translated">卡车</li><li id="0672" class="ml mm iq ke b kf mu kj mv kn mw kr mx kv my kz mq mr ms mt bi translated">公共汽车</li></ul></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="39f2" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">数据收集</h1><p id="088b" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">我们从支持上述期望用例的不同角度收集数据。这包括来自高速公路立交桥、高角度街景、低角度街景、停车库和停车场的图像。我们的目标是从尽可能多的角度和距离捕捉代表可读板的图像。下面是一些包含图片的例子。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/91d0ab7c64f26353850e0e887861b93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gsh19l-_P88fydhF"/></div></div></figure><p id="0246" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">大多数数据最初是作为视频收集的，然后从视频中对单个帧进行采样。</p><p id="4653" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">拥有大量非常相似的图像不会增强模型的性能，因此我们对所有收集的数据进行了采样，以确保输入数据足够多样。对于照片，这仅仅意味着排除太相似的个别照片。对于视频，需要做更多的工作。首先，这些视频在QuickTime Player等应用程序中进行编辑，以删除视频中大量不可用的部分，如死画面或没有汽车的镜头等。一旦视频被清理了一点，它们就被使用<a class="ae la" href="https://ffmpeg.org/" rel="noopener ugc nofollow" target="_blank"> ffmpeg </a>采样。</p><p id="9bda" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用的命令是</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="7df3" class="nj lj iq nf b gy nk nl l nm nn">ffmpeg -i movie_name.mov -r 2 -q:v 1 image_name_%4d.png</span></pre><p id="d769" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该命令每秒采样2帧(用'-r 2 ')并使用最高质量(用'-q:v 1 ')保存为png，png使用无损压缩(而不是jpg)。</p><p id="67f8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一旦视频被采样，产生的图像被手动扫描，以消除近似重复或不包含感兴趣的对象的帧。</p><p id="81fa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们还创建了一个数据收集入门应用程序，使您能够使用edge设备收集数据并执行简单的采样，该应用程序可供模型培训测试版用户使用。如上所述，您可以使用“ffmpeg”来执行更高级的采样。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="04c5" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">数据注释</h1><p id="9569" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">计算机视觉注释工具(<a class="ae la" href="https://github.com/opencv/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>)用于执行数据注释，使用alwaysAI CLI注释工具，可通过“aai annotate”访问。使用CVAT，在给定时间可以上传的数据量是有限制的，所以注释是成批完成的，注释集后来被合并，我们将在本文后面介绍。对于每个任务(每个任务包含大约40-100张图片)，标签保持不变。</p><p id="7b24" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最初，我们使用“汽车”和“牌照”的标签，但是我们决定“车辆”更适合一般的模型，而“牌照”可以避免路上空白的问题。CVAT的一个有用的特性是，你可以作为超级用户登录，导航到'<a class="ae la" href="https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md#administration-panel" rel="noopener ugc nofollow" target="_blank">管理</a>面板，并随时修改注释任务的标签！</p><p id="8fec" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当一系列图像包含相同的标注对象时，使用<a class="ae la" href="https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md#track-mode-basics" rel="noopener ugc nofollow" target="_blank">插值模式</a>；此模式使注释能够从一帧持续到下一帧，从而显著减少了注释数据集所需的时间。</p><p id="492c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">注意:CVAT不会自动保存你的工作，所以记得经常保存！</p><p id="7c2e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">CVAT支持多种注释格式，但alwaysAI目前只使用PASCAL VOC格式。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bbd216f073a395023fd072ab949285c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/0*S7gYcraL2_Tlo5Ji"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">以PASCAL VOC格式导出数据集的例子。</figcaption></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="4963" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">要注释什么</h1><p id="d9ae" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">总的来说，我们选择注释任何可识别的牌照和车辆，并在它们周围画一个方框。偶尔，这意味着注释没有牌照的车辆或注释部分被遮挡的车辆，尽管我们试图尽可能地限制这些情况。如果图像的一部分清楚地代表了我们想要检测的对象，即使它非常小，我们也会对它进行注释。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/7bbce581c73ff37e2a4960bda86a4bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cyw_G6B_dWRF13ZJ"/></div></div></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="1fc7" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">合并注释</h1><p id="64f9" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">正如我们上面提到的，你可能无法一次上传所有的图片。因此，您最终会得到多个需要合并的导出数据集。如果您为训练传递多个文件，训练工具将自动合并您的数据集，但是，如果您希望仅使用一个数据集并简化训练命令，也可以使用alwaysAI CLI命令“aai dataset merge”轻松完成此操作。</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="2283" class="nj lj iq nf b gy nk nl l nm nn">aai dataset merge dataset1.zip dataset2.zip dataset3.zip</span></pre><p id="a2fb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在上面的命令中，我们显示了三个数据集被合并，但是您可以根据需要指定尽可能多的数据集进行合并。</p><p id="a3c4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="no">注意:我们在合并直接从CVAT导出的“原始”注释集方面取得了最大的成功。如果您需要在不是从CVAT导出的数据集上进行训练，请先尝试压缩父注释目录中的单个文件夹(“Annotation”和“JPEGImages”)。然后尝试合并产生的压缩文件。</em></p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="982e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">训练模型</h1><p id="3799" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">我们使用alwaysAI的CLI工具对模型进行了训练。该工具目前处于封闭测试阶段，我们正在快速迭代其特性和功能。关于培训功能的更多文档将很快发布。</p><p id="6934" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="no">注:如果你有兴趣加入模联培训测试版，请填写此</em> <a class="ae la" href="https://alwaysai.surveykiwi.com/model-training-signup" rel="noopener ugc nofollow" target="_blank"> <em class="no">简短调查</em> </a> <em class="no">！</em></p><p id="f53c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">目前，该工具可以通过使用Tensorflow 1.14在COCO数据集上训练的mobilenet ssd网络上使用迁移学习来训练对象检测模型。支持使用CPU或GPU进行训练，一旦完成，该模型立即与alwaysAI平台兼容。</p><p id="e289" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们最初使用个人笔记本电脑上的CPU训练模型，特别是MacBook Pro。我们从批量大小1开始，增加到16，这时笔记本电脑的内存就用完了。这很可能是在数据集中使用大图像的结果。我们决定对概念模型的验证使用4的批量大小，改变历元和训练图像的数量。一旦我们对模型的进展感到满意，我们就决定大幅增加纪元的数量。本次培训的规格和各种配置如下表所示，培训时间约为20小时。</p><p id="db1e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">五金器具</p><p id="42a6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="no">注意:有更强大的EC2实例可用；我们可以将GPU的数量增加到24个，或者使用更强大的Tesla V100内核，但我们希望在更真实的机器上进行测试。</em></p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/36cbe3e71ddccc482023534037be2590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9O-ee9Ktz83aBiE-5-fiEg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">用于创建牌照检测模型的训练配置。</figcaption></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="3875" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">分析模型性能</h1><figure class="na nb nc nd gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a12eb4fe4bc8ccf1e50d191b71e761d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*3vbaUroc79URC4svBTeo5Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">车牌检测模型的最终性能指标(丢失和地图)</figcaption></figure><p id="ae60" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该模型的最终统计数据表明，我们训练的步数超过了要求。对于损耗图，你可以看到一条相对平坦的长线。它上下波动，但肯定变平了。在精确度和召回率的图表中，我突出显示了趋势停止上升的区域。似乎我们可以在大约35k步时停止训练，并获得类似的结果。</p><p id="21a8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是培训课程的损失图表。x轴表示步数，每200步绘制一次损耗。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/82fe97a1fbb336c2602770cd24947afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bCf5ULw6G6nZksIp"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">损失与步骤</figcaption></figure><p id="b8e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是训练过程中输出的精度和召回统计数据。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/608c09b49f2767d1dea8c426ffb259cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nLm8zoHCHeilDxro"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">映射和回忆与步骤</figcaption></figure><p id="1df3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">虽然图表显示了扁平化，但模型似乎并没有过度适应我们的数据集。这可以通过绘制验证损失来确认，这是我们即将实现的功能。我们最依赖的测试是对新数据的视觉测试，使用alwaysAI平台很容易执行，这是我们接下来要描述的。</p><p id="c028" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用alwaysAI CLI训练的模型可以使用发布</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="19f3" class="nj lj iq nf b gy nk nl l nm nn">aai app publish &lt;username/modelname&gt;</span></pre><p id="f41c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">发布模型后，您可以使用将其添加到应用程序中</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="8ef3" class="nj lj iq nf b gy nk nl l nm nn">aai app model add &lt;username/modelname&gt;</span></pre><p id="2e32" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您还可以在本地测试它，而不用发布它，方法是使用</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="ef39" class="nj lj iq nf b gy nk nl l nm nn">aai app model add --local-version &lt;version&gt;</span></pre><p id="2890" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们希望测试模型的实时性能，因此我们修改了现有的starter应用程序，以使用文件流，并使用预先收集的视频来表示所需的用例。你可以在这个博客中看到这是如何做到的。</p><p id="0a9a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">测试车牌检测器模型的一些示例输出如下所示:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/a6b3c5a4302b8121e87ff6147372830e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Vyl0yiI2e8IlwHyS"/></div></div></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="c1e6" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">后续步骤</h1><p id="4ccc" class="pw-post-body-paragraph kc kd iq ke b kf mg kh ki kj mh kl km kn mi kp kq kr mj kt ku kv mk kx ky kz ij bi translated">要访问车牌检测器和许多其他预先训练的模型，注册一个免费的<a class="ae la" href="https://alwaysai.co/auth?register=true?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=making_license_plate_model" rel="noopener ugc nofollow" target="_blank">帐户</a>，立即开始使用计算机视觉。如果您有兴趣参加我们的模型训练封闭测试版，并训练您自己的对象检测模型，请填写<a class="ae la" href="https://alwaysai.surveykiwi.com/model-training-signup" rel="noopener ugc nofollow" target="_blank">调查</a>进行报名！</p><p id="4c38" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您可以在这里找到创建'<strong class="ke ir">alwaysai/vehicle _ license _ mobilenet _ SSD</strong>'模型<a class="ae la" href="https://www.alwaysai.co/docs/_static/beta/dataset_sample_592.zip?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=making_license_plate_model" rel="noopener ugc nofollow" target="_blank">中使用的数据集的子集，在这里</a>找到更大的版本<a class="ae la" href="https://www.alwaysai.co/docs/_static/beta/dataset_sample_1186.zip?&amp;utm_campaign=Open%20Beta&amp;utm_source=medium&amp;utm_content=making_license_plate_model" rel="noopener ugc nofollow" target="_blank">，以及在</a><a class="ae la" href="https://github.com/alwaysai/license-plate-detector" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上测试您的模型的相应车牌跟踪器应用程序的所有代码。</p><p id="4213" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">托德·格里德和谷嘉诚对本文的贡献</p></div></div>    
</body>
</html>