# 香农理论与集合成形理论

> 原文：<https://levelup.gitconnected.com/shannon-theory-vs-set-shaping-theory-14dfb966666c>

![](img/c89b66985c436c1e8ed23e8820e9ca22.png)

来自[皮克斯拜](https://pixabay.com/de/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1759619)的[马诺洛·弗兰科](https://pixabay.com/de/users/manolofranco-1029720/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1759619)的照片

在本文中，我们将展示 Shannon 发展的理论和一种称为集合成形理论的新理论在方法上的差异，这种理论正在彻底改变信息理论。

为了理解这两种不同方法之间的区别，我们必须从描述最一般形式的信息传递问题开始。

让我们从下面这个问题开始:**信息传递的目的是什么？**

目的是在位于不同地方的两个主体之间传递大量的信息，我们称之为消息。

**为了能够相互交流并传递信息，两个主体必须具备的最低条件是什么？**

*最低条件是共享一种交流语言，例如共享同一种语言。*

现在，我们介绍两个角色鲍勃和爱丽丝，他们将通过一系列实际例子向我们展示信息论的一些基本要素。

鲍勃和爱丽丝是两个朋友，他们使用同一种交流语言，英语。

鲍勃在一张纸上写下下面的信息“你好，爱丽丝”,并把它递给爱丽丝。

艾丽丝收到了这条信息，由于她懂英语，她认出了鲍勃使用的符号。

鲍勃用 8 个符号来发送这个信息，空格也被认为是一个符号。鲍勃使用的媒介，在纸上书写，可以代表英语字母表中的所有符号。

爱丽丝乘飞机去住在一个离鲍勃住处很远的城市。

为了快速与爱丽丝沟通，鲍伯决定使用网际网路连线。在这种情况下，鲍勃遇到了一个问题:用于与爱丽丝交流的新方法只允许他们表示两个符号，零和一。

因此，Bob 被迫用代表 0 和 1 序列的代码字对他的消息的字母进行编码。

**我们将编码定义为将符号属于字母 A 的消息转换为符号属于字母 b 的新消息的过程。**

Bob 使用 ASCII 格式对消息“Hi Alice”进行编码。

H = 100 1000

I = 100 1001

A = 1000001

L = 100 1100

C = 100 0011

E= 100 0101

space = 010 0000

消息“嗨爱丽丝”变成:100 1000100 10010 000001000001100 1100100 1001100 001100 00101

Alice 收到编码消息，但不知道解码方案(ASCII 码)，她无法理解该消息。事实上，我们设定的条件是爱丽丝和鲍勃共享英语，英语使用 26 个字母的字母表。

Alice 联系 Bob，让他知道她没有理解消息，Bob 道歉并给他发送解码表。Alice 使用解码表(ASCII 码)并获得原始消息“Hi Alice”。

由于这个简单的例子，你已经理解了编码操作，其中消息被转换成具有属于不同字母表的符号的新消息，**具有等同于传达解码方案所需的比特数的成本。**

总之，如果我们对消息进行编码，我们将符号转换成代码字，因此，我们开发出解码消息所必需的解码方案。因此，如果我们想有效地传输一个编码信息，我们必须回答下面的问题**“与信息中出现的每个符号相关的码字的最小长度是多少？”**

伴随着这个问题，数据压缩理论诞生了。**因此，压缩消息意味着使用最小长度的码字对消息进行有效编码。**

香农在他的著名文章《交流的数学理论》中试图用科学中最常用的方法之一来回答这个问题，即通过定义一个子问题来简化问题。Shannon 引入了两个约束:

1.它删除了消息并引入了源的概念。消息来源是生成消息的原因。

**结果:编码方案是根据信源的特征定义的(信源编码),因此是在生成消息之前开发的。**

2.消息的发送者(编码器)和接收者(解码器)都知道源。

**后果:解码器也知道解码器方案。因此，压缩消息仅由编码消息定义。**

香农提出的这些假设大大简化了数学处理；事实上**，最难用数学方法形式化的方面是由编码方案表示的。**困难源于描述编码方案所需的最少位数取决于通信语言这一事实。

**香农，假设编码方案对解码器也是已知的，去掉了最难用数学方式形式化的方面，得到了一个从概率角度可以解决的问题。**

然而，这种简化使我们远离了最初的问题。为了理解 Shannon 提出的这个假设的结果，我们必须问自己以下问题:**码字长度最小化的编码方案必须具有什么特征？**

在示例中，Bob 使用 ASCII 编码对消息进行编码，该代码独立于消息，并使用固定长度的码字。因此，它不能用于压缩消息(具有相同符号数的所有消息都用相同数量的 0 和 1 编码)。

*因此，编码方案必须具有的特征是，它依赖于要编码的消息。*

从这个编码方案必须具备的必要特征，一个基本问题出现了**事实上，任何不独立于消息的信息都必须被传输。**因此，要发送的消息由编码序列加上编码方案组成。

因此，香农提出的不考虑编码方案的假设，相当于说解码器已经知道一部分消息信息。因此，显而易见，香农提出的简化大大改变了信息传输的问题。

因此，基于这些考虑，Bob 有两种可能与 Alice 通信:

1.使用固定代码，如 ASCII 代码。

优点:代码必须只传达给爱丽丝一次。

缺点:没有压缩；每个消息的每个符号与等长的码字相关联。

2.使用依赖于消息的编码方案，最大限度地减少码字。

优点:可以利用消息中存在的冗余来减小编码消息的大小(用码字代替符号)。

缺点:编码方案必须与编码消息一起发送。

总之，如果我们想对消息进行编码，而不利用任何冗余，则必须传输的消息仅由其编码决定。**的确，在这种情况下，不必每次都发送编码方案，我们可以将它视为通信语言的一部分。**另一方面，如果我们想通过利用可能的冗余来压缩消息，则传输的消息也必须包含编码方案。

**总之，编码方案是我们通过利用现有的冗余来压缩信息所必须付出的代价。如果我们要压缩的消息没有冗余，因此所有符号都用等长的码字编码，会发生什么情况？在这种情况下，编码方案增加了消息的长度，而没有减少加密消息的长度。**

可以用来解释这一概念的另一个观点是提请注意这样一个事实，即由于编码方案依赖于消息，所以它实际上携带了一部分消息信息。**因此，编码方案中存在的信息量与编码序列中存在的信息相比是冗余的。**为此，编码方案也代表了熵编码的低效。

因此，Bob 必须做出一个重要的选择，如果他有关于他想发送给 Alice 的消息的信息，他可以使用这个信息做出最佳选择。**但是如果鲍勃对这些信息一无所知，他该怎么办呢？如果 Bob 没有关于未来消息的信息，这个问题就没有答案。*因此，不存在最优选择；如果符号是等概率的(最大熵),则第一种方法是最佳的，如果符号不是等概率的(低熵),则第二种选择是最佳的。***

基于这些考虑，我们可以理解香农提出的方法如何对简化数学处理特别有用。然而，这种方法也有缺点，事实上，从理论的角度来看，如果使用 Shannon 提出的假设，我们已经讨论过的许多方面是不可检测的。

现在，让我们来考虑一下集合成形理论，但在继续之前，我想问你以下问题:**一个导致真正科学进步的理论，从理论的角度来看会有什么后果？**

这似乎是一个特别困难的问题，但给出一个几乎符合任何革命性理论的答案是可能的。*事实上，一个带来重大科学进步的理论几乎总是涉及到去除一些先前引入的用来简化原始问题处理的假设。*

**因此，科学研究的目的是以最普遍的形式去理解问题。**

当谈到集合成形理论时，经常使用“革命”这个词，因为它消除了香农提出的假设，并以最普遍的形式解决了信息传递的问题。

为了介绍集合成形理论的观点，让我们回到 Bob 和 Alice。如上所述，鲍勃通过由 26 个符号组成的英语与爱丽丝交流。如果 Bob 使用固定长度的消息，例如 50 个符号，那么 Bob 可以发送给 Alice 的可能消息的数量是 26⁵⁰(所有可能的组合)。

现在，假设 Bob 选择使用最小化码字的编码方案(消息相关编码方案)。如前所述，在这种情况下，Bob 设法利用了消息中存在的冗余，然而，他的缺点是必须将编码方案与编码序列一起发送。

此外，我们还设置了一个条件，即 Bob 不知道他要向 Alice 发送的消息。因此，他每次都必须为他想传送的信息制定一个最佳的编码方案。

为了简化讨论，让我们假设 Bob 具有理想的编码算法，该算法设法达到理论编码极限，该极限由零阶经验熵 H0(M)乘以消息长度来定义。

**然而，这个限制有一个基本的约束，即:在 H0(M)的计算中使用的频率必须在编码中使用。**

给定消息 M，零阶经验熵被计算为源的熵，但是使用消息中符号的频率作为符号的概率。

例如，给定以下消息 M:

aaaaaacbbc

符号的频率为:

a=5/10

b=2/10

c=3/10

零阶经验熵 H0(M)是:

H0(M)=-5/10 ln 5/10–2/10 ln 2/10–3/10 ln 3/10 = 1，49 位

因此，编码序列的长度限制是:

N*H0(M)=10*1，49=14.9 位

在这一点上，我们问自己以下问题:**如果鲍勃已经有了一个接近 NH0(M)的理想编码器，他如何改进数据压缩？**

我们说过，这个限制有一个约束，事实上，计算 H0(M)所用的频率必须在编码中使用。*因此，Bob 改进数据压缩的唯一方法是拥有一个函数，该函数以大于 50%的概率将消息 M 转换成编码极限小于 NH0(M)的新消息 f(M)。此外，此函数不得修改符号所属的字母表。*

**这个条件很重要，因为如果我们增加字母表的长度，编码的长度也会增加。因此，通过增加编码方案的长度，我们获得的增益被抵消。**

为了解决这个问题，set shaping 理论提出了以下问题:**Bob 想要传达给 Alice 的信息来自哪里？**

正如我们所说的，Bob 想要向 Alice 发送属于英语字母表的 50 个符号的消息，其中包括 26 个符号。*因此，我们可以说，包含所有 26⁵⁰消息的集合，代表了所有可能的组合，代表了消息所来自的宇宙。*

我们说过，鲍勃不知道他将发送给爱丽丝的可能的消息，因此，我们可以认为所有的 26⁵⁰消息是同样可能的。因此，一个有趣的数据由所有 26⁵⁰可能消息中编码极限的平均值来表示。因此，这个参数很好地估计了 Bob 将发送给 Alice 的编码消息的平均长度。

因此，如果我们能够找到一组具有较小编码极限平均值的大小 26⁵⁰，我们将证明存在一个函数，该函数以大于 50%的概率将消息 m 变换成编码极限小于 NH0(M)的新消息 f(M)。事实上，这个函数就是唯一连接两个集合的元素的函数。

为了证明具有这些特征的集合存在，我们取两个集合 X 和 X1。集合 x 由所有长度为 m 的消息和属于字母表 a 的符号组成，而集合 X1 由所有长度为 M+1 的消息和属于字母表 a 的符号组成。因此，x 的大小是|A|^N，X1 的维数是|A|^N+1.因此，集合 X1 比集合 x 大得多。集合整形理论告诉我们，如果从集合 X1，我们定义一个由属于 X1 的具有最小编码极限的消息组成的大小为|A|^N 的子集，这个大小等于 x 的新集合由编码极限的平均值小于属于 x 的消息的编码极限的平均值的消息组成

**因此，作为在两个集合的元素之间建立链接的函数，该函数独立于所发送的消息，因此该函数不得计入所发送的消息中。**事实上，由于对每条消息都有效，它不必在每次发送消息时都被传输。正如我们所说的，在压缩的消息中，只有依赖于消息的信息必须被考虑。

在这里你可以找到这个方法的详细描述。

在本文中，这一理论被应用到一个具体的数据压缩案例中。

[](https://deepai.org/publication/practical-applications-of-set-shaping-theory-in-huffman-coding) [## 集合成形理论在霍夫曼编码中的实际应用

### 对集合成形理论的最大批评之一是缺乏实际应用。这是由于…

deepai.org](https://deepai.org/publication/practical-applications-of-set-shaping-theory-in-huffman-coding) 

数据压缩测试将在以下演示中介绍:

[](https://www.academia.edu/88055617/Description_of_the_program_used_to_validate_the_theoretical_results_of_the_Set_Shaping_Theory) [## 用于验证集合成形理论的理论结果的程序描述

### 本演示描述了用于实验验证理论预测的数据压缩实验…

www.academia.edu](https://www.academia.edu/88055617/Description_of_the_program_used_to_validate_the_theoretical_results_of_the_Set_Shaping_Theory) 

在很长一段时间里，人们认为不可能改进香农提出的方法，现在有了一种新的理论，帮助我们以最普遍的形式理解信息传递的问题。