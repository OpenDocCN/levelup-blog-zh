<html>
<head>
<title>Hardware-accelerated video stitching on GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于GPU的硬件加速视频拼接</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/faster-video-stitching-with-opengl-9e9132c72def?source=collection_archive---------2-----------------------#2020-10-29">https://levelup.gitconnected.com/faster-video-stitching-with-opengl-9e9132c72def?source=collection_archive---------2-----------------------#2020-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3b6d0b6a3f5d62c7f72245f991834276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRMSnJa3BlZFsN5YRYGuIg.jpeg"/></div></div></figure><div class=""/><blockquote class="jy jz ka"><p id="2edc" class="kb kc kd ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">用OpenCV拼接当然很好，但是如果你想用普通的OpenGL在GPU上用硬件来完成呢？</p></blockquote><h2 id="f407" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="ed96" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">OpenCV附带了一个高级的样本实现，可以在静态图像上产生很好的效果，然而，在视频流的每一帧上使用这个程序毫无疑问会非常慢<em class="kd"/>。这是使用树莓派制作<a class="ae mb" href="https://medium.com/@vejipe/360-video-stitching-with-raspberry-pi-and-opencv-30549b37acbc" rel="noopener">360°视频的解决方案。</a></p><p id="f7cf" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">这篇文章是上一篇文章的后续，在上一篇文章中，视频帧通过OpenCV在CPU上进行转换，并介绍了一个完整的GPU管道。</p><p id="3658" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">需要注意的是，OpenCV对很多操作都有GPU支持，但是启用它仍然会导致很多低效的数据在CPU和GPU之间来回复制。</p><h1 id="27c4" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">为什么是OpenGL而不是OpenCV？</h1><p id="52ea" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">针对低延迟和实时视频拼接，OpenCV 2D像素变换被一个迷你OpenGL 3D引擎所取代。</p><p id="5f0e" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">它有多种好处:</p><ul class=""><li id="cabd" class="mt mu jb ke b kf kg kj kk lj mv ln mw lr mx kz my mz na nb bi translated">摄像机ISP或硬件视频解码器可以将视频帧直接传送到GPU中的OpenGL纹理(避免通过CPU复制缓冲区)</li><li id="12a8" class="mt mu jb ke b kf nc kj nd lj ne ln nf lr ng kz my mz na nb bi translated">GPU具有针对像素处理和纹理采样的特定硬件加速</li><li id="23de" class="mt mu jb ke b kf nc kj nd lj ne ln nf lr ng kz my mz na nb bi translated">拼接帧已经在GPU中，几乎没有延迟就可以推送显示</li><li id="c745" class="mt mu jb ke b kf nc kj nd lj ne ln nf lr ng kz my mz na nb bi translated">OpenGL是一个开放标准，对大多数嵌入式目标都有很好的支持</li></ul><p id="e13a" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">它也有缺点:</p><ul class=""><li id="7889" class="mt mu jb ke b kf kg kj kk lj mv ln mw lr mx kz my mz na nb bi translated">将OpenGL帧缓冲区读回CPU内存通常很慢且效率低下</li><li id="c562" class="mt mu jb ke b kf nc kj nd lj ne ln nf lr ng kz my mz na nb bi translated">OpenGL渲染功能(特别是。OpenGL ES)通常依赖于连接的屏幕(例如，渲染速度不能超过60fps)</li><li id="6c56" class="mt mu jb ke b kf nc kj nd lj ne ln nf lr ng kz my mz na nb bi translated">OpenGL的API很大，理解起来很复杂</li></ul><h1 id="4bf4" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">一种嵌入式视频拼接架构</h1><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/9eca6b7ae2f00d2d1f35fc64e351cd4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6wPk34XYMCv2J89bRo0yOQ.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">涉及CPU、视频硬件和GPU的拼接流水线</figcaption></figure><p id="65b3" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">🅐 — CPU从MJPEG(即连接的JPEG文件)中读取流<br/> 🅑 — JPEG解析器在流中查找单个帧，并将其与捕获时间戳相关联。<br/>🅒——硬件JPEG解码器向OpenGL纹理缓冲区生成一个位图帧。<br/>🅓——GPU对每个纹理进行采样，以应用2D透视变换(使用像素着色器)<br/>🅔——GPU输出帧缓冲区由JPEG编码硬件读回<br/>🅕——CPU获得回调，并将JPEG缓冲区附加到输出文件</p><h2 id="6a9e" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍Inatech的开源缝合器</h2><p id="914e" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">in astight是一个开源项目，旨在实现这个拼接管道:</p><div class="ip iq gp gr ir nq"><a href="https://github.com/inastitch/inastitch" rel="noopener  ugc nofollow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jc gy z fp nv fr fs nw fu fw ja bi translated">不缝合/不缝合</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">Inatech stitcher。在GitHub上创建一个帐户，为in astight/in astight的发展做出贡献。</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">github.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe ix nq"/></div></div></a></div><p id="6a5d" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">注意:在撰写本文时，硬件JPEG解码还没有实现，解码/编码是在CPU上用<code class="fe of og oh oi b">libturbojpeg</code>完成的(由于CPU矢量化，仍然非常快)。</p><h1 id="f2ea" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">内部<strong class="ak">in针脚</strong></h1><p id="53f2" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated"><strong class="ke jc"> inastitch </strong>将一组视频流、帧时间戳以及每个流的2D变换矩阵作为输入。</p><p id="9fec" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">同步的视频流和时间戳由改进的Raspberry Pi相机工具生成:<strong class="ke jc">raspivid-inatech</strong><br/><a class="ae mb" href="https://github.com/inastitch/raspivid-inatech" rel="noopener ugc nofollow" target="_blank">https://github.com/inastitch/raspivid-inatech</a></p><h2 id="80c5" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">校准工具</h2><p id="0a12" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">转换矩阵由校准工具使用OpenCV库生成:<strong class="ke jc">ina stitch _ cal<br/></strong><a class="ae mb" href="https://github.com/inastitch/inastitch/tree/master/tools/calibration" rel="noopener ugc nofollow" target="_blank">https://github . com/ina stitch/ina stitch/tree/master/tools/calibration</a></p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/f4a9a065387c35690f350db5cb2a9722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pA4sc8VMIKvtZzNcX6iJag.png"/></div></div></figure><p id="6633" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">校准阶段的目的是找到<em class="kd">单应矩阵</em>。</p><p id="c919" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">单应矩阵是第二摄像机的视点的变换，以使其看起来像来自第一摄像机的视点。<br/>参见<em class="kd">什么是单应矩阵？<a class="ae mb" href="https://docs.opencv.org/master/d9/dab/tutorial_homography.html" rel="noopener ugc nofollow" target="_blank"> OpenCV单应教程</a>中的</em>。</p><p id="9cbc" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">注意:在校准工具中，<em class="kd">左图像</em>保持为参考视点(第一个摄像机)，变换矩阵应用于<em class="kd">右图像</em>(第二个摄像机)。</p><h2 id="8a30" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">OpenGL渲染场景的描述</h2><p id="8bad" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">每个视频帧被转换成一个纹理，然后被绑定到一个简单的两个三角形的平面矩形，用于并排呈现每个匹配的帧。</p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/6686e31c594f63e5a815c066ee18c930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-tfu65OlIgY4r3LKf2WqEA.png"/></div></div></figure><p id="df1e" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">透视2D变换通过一个非常简单的像素着色器应用于纹理:</p><pre class="ni nj nk nl gt ol oi om on aw oo bi"><span id="633b" class="la lb jb oi b gy op oq l or os">varying vec2 texCoordVar;<br/>uniform sampler2D texture1;<br/>uniform mat3 warp;</span><span id="9663" class="la lb jb oi b gy ot oq l or os">void main() {<br/>   vec3 dst = warp * vec3((texCoordVar.x+1.0), texCoordVar.y, 1.0f);<br/>   gl_FragColor = texture2D(texture1, vec2((dst.x/dst.z), (dst.y/dst.z)) );<br/>}</span></pre><p id="2f54" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated"><code class="fe of og oh oi b">warp</code>是来自OpenCV的单应矩阵，归一化到OpenGL坐标。</p><h1 id="1c49" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">演示时间到了！</h1><p id="65e6" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">这里是一个以100fps录制的三个同步流的演示。</p><figure class="ni nj nk nl gt is"><div class="bz fp l di"><div class="ou ov l"/></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">第一次试驾时<strong class="ak">处于缝合状态</strong></figcaption></figure><p id="9da2" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">内部视图的相同视频:</p><figure class="ni nj nk nl gt is"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="da33" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">以25fps而不是100fps播放的同一视频的一部分(即4倍慢速):</p><figure class="ni nj nk nl gt is"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="01c2" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">注:Youtube将原始视频缩小到60fps。</p><h1 id="f7e9" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">结论</h1><p id="be6c" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">对于拼接静态图像，OpenCV非常棒，并且非常可定制，但不适合视频处理，因为视频处理中整个管道都需要硬件加速。OpenGL ES中的迷你3D引擎是一个更好的选择，它支持从嵌入式SoC到数据中心GPU的硬件加速。当然Vulkan会比OpenGL更好，但代价是与更少的GPU硬件兼容。</p><h1 id="2094" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">下一步</h1><p id="ed4c" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">下一步是<strong class="ke jc">实时</strong>拼接使用相同的GPU流水线。</p><p id="dddb" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">这里的主要挑战将是通过以太网使用实时视频流。同步的视频帧需要以一致的延迟一起传送，以避免在网络的拼接器端进行缓冲。普通以太网不支持这种用例。</p><p id="2691" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated"><em class="kd">时间敏感网络</em> (TSN)是对以太网的补充，旨在解决对时间敏感的数据包传输问题。</p><h1 id="a288" class="mc lb jb bd lc md me mf lf mg mh mi li mj mk ml lm mm mn mo lq mp mq mr lu ms bi translated">更进一步</h1><h2 id="a139" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用3D变换代替2D</h2><p id="596c" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">你可能已经注意到<strong class="ke jc">in astigh</strong>使用像素着色器而不是使用顶点着色器的3D渲染在纹理中进行2D透视变换，以产生相同的透视效果，这将更好/更简单地使用GPU硬件。</p><p id="a142" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">一种想法是将单应矩阵分解成更简单的3D旋转和平移，然后可以应用于视频矩形的顶点。</p><p id="24c9" class="pw-post-body-paragraph kb kc jb ke b kf kg kh ki kj kk kl km lj ko kp kq ln ks kt ku lr kw kx ky kz ij bi translated">参见<a class="ae mb" href="https://docs.opencv.org/master/d9/dab/tutorial_homography.html" rel="noopener ugc nofollow" target="_blank"> OpenCV单应性教程</a>中的<em class="kd">演示4:分解单应性矩阵</em>，以及函数<code class="fe of og oh oi b">cv::decomposeHomographyMat</code>。</p><h2 id="db2f" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">更好的缝合</h2><p id="d926" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">正如在<a class="ae mb" href="https://vejipe.medium.com/360-video-stitching-with-raspberry-pi-and-opencv-30549b37acbc" rel="noopener">上一篇文章</a>中详细解释的那样，由于相机变换是<strong class="ke jc">而不是</strong>纯旋转，拼接不可能完美。使用alpha通道和视频纹理网格，可以在OpenGL中有效地执行接缝混合和遮罩。</p><h2 id="b401" class="la lb jb bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">制作汽车友好型原型</h2><p id="69ae" class="pw-post-body-paragraph kb kc jb ke b kf lw kh ki kj lx kl km lj ly kp kq ln lz kt ku lr ma kx ky kz ij bi translated">inastitch 可以做一个很好的后视镜，不是吗？以下是一些建议:</p><div class="ip iq gp gr ir nq"><a href="https://medium.com/@vejipe/about-your-next-automotive-friendly-prototype-53ce5f2923e7" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jc gy z fp nv fr fs nw fu fw ja bi translated">关于你的下一个汽车友好型原型</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">你有很酷的项目想法，你想做一个更符合汽车世界的原型？这里有一些…</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">medium.com</p></div></div><div class="nz l"><div class="ow l ob oc od nz oe ix nq"/></div></div></a></div><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/53a57908bf46d1919c2d73082318c742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sRs3CMZtZ0cqDiV0ms2Ecg.jpeg"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk translated">小心那条狗！</figcaption></figure></div></div>    
</body>
</html>