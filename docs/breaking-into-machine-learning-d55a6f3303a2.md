# 闯入机器学习

> 原文：<https://levelup.gitconnected.com/breaking-into-machine-learning-d55a6f3303a2>

![](img/2ed73e23e0a70894ae9e7c3383bfb952.png)

[美国地质勘探局](https://unsplash.com/@usgs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/image?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

我从事 web (JavaScript)编程已经超过 5 年了，我觉得我相当擅长编写 web 和移动应用程序。我离开担任 CTO 的创业公司已经快两年了。就在离开我的创业公司后，我订购了一本关于动手机器学习的书，并开始阅读和写作第一行。我不知道自己在做什么，进入其中令人沮丧。

实际上，那次我并没有进入状态。我换了一份工作，呆在我熟悉的网络应用领域更舒服。我做了几次尝试进入机器学习的尝试，但直到上周，我才最终训练出一个正常工作的机器学习模型。

关于这个主题的大多数课程(可能还有大多数其他主题)都是在你真正开始做有意义的事情之前教给你基本的基础知识。就编程本身而言，在你知道它有什么用途之前，你要用 python(事实上的机器学习语言)编写类似于`console.log("Hello World")` — `print("Hello World")`的东西。当然，你必须从某个地方开始，但是在你看到全局之前，花几个月甚至几年的时间去实现一个小拼图是非常困难的。在写一行代码之前，第十次看到数学方程式让我昏昏欲睡。

进入: [fast.ai](https://www.fast.ai/) —大约一年前我偶然发现了这个平台，但当时没有时间。现在，结束了 8 个月的旅行，我终于有了一些空闲时间，花了两周左右的时间做准备并再次进入素材。他们的方法是直接编码和实现第一个模型。而且成功了！我训练我的第一个图像分类器来区分 6 种不同型号的摩托车。我还没学完这门课，所以我想还会有更多的理论。然而，能够这么快看到结果是令人欣慰的。

## 回到学校

阻碍我进入机器学习的另一件事是当你沉浸在一个你一无所知(或知之甚少)的新话题中时的感觉。我在网络应用上工作了很长时间，所以我感觉很舒服，知道所有的细节。即使选择一个像 GraphQL 这样的新库也没什么大不了的，它仍然是 JavaScript，并且是一个相同概念的工具。当学习一些完全不同的东西时，感觉势不可挡，提前退出是一个迷人的前景。直到现在我才回过头来，想起它是如何从 web 开发开始的，花了这么多时间学习和摆弄我并不真正理解的东西(我花了一年多的时间才理解 AJAX 调用！).

![](img/5d8342c7d958f232a783dda96c88d969.png)

我新买的雅马哈 XSR 900 在左边/杜卡迪扰频器在右边

## 雅马哈 XSR 900 与杜卡迪扰频器

最初，我认为深度学习模型可以很好地区分不同的对象，例如摩托车和汽车。然而，事实证明该领域在过去几年甚至几个月里进步如此之大，以至于这项任务对于当前的模型来说很容易。即使对于相当相似的物体(在我的例子中是摩托车模型)，精确度也相当不错。我最终的错误率在 13%左右。通过过滤不正确的图像，我降低了 2.8%的错误率(意味着 97.2%的图像被正确分类)，但我无法重现这种准确性。

在任何情况下，经过训练的模型能够区分 6 种不同的摩托车变体。甚至雅马哈 XSR 和杜卡迪扰频器都被正确标记。我猜大多数非摩托车的人很难正确地指出它们。除此之外，我有以下类别:雅马哈 XSR 900，杜卡迪扰频器，川崎 Z900，宝马 S1000RR，本田 Fireblade 和杜卡迪帕尼加尔 V2。如果你不知道那些是什么，它们长什么样，不要担心——我的 MIC(摩托车图像分类器——这是我刚编的名字)会给你看。查看下面的现场演示。

![](img/2d9c70e72532b548030fdf3ad451d16c.png)

## 训练模型

关于如何设置数据集、准备数据集以及实际训练和调整模型，我不会讲太多细节。fast.ai 上的课程涵盖了所有这些——坦率地说，我没有资格解释这些。然而，这里有一个快速纲要:

1.  建立一个图像数据集，每个图像都标有一个给定的类别(在我的例子中，雅马哈 XSR 900，杜卡迪扰频器等)。)
2.  使用卷积神经网络(CNN)来训练模型，使用 [Resnet34](https://www.kaggle.com/pytorch/resnet34) 作为架构。我想从零开始建立一个有效的神经网络，但我可能离那还远着呢。
3.  通过改变学习率、时期数和过滤掉不想要的图像来调整神经网络

训练模型可以在任何安装了 python 的机器上进行。然而，在标准笔记本电脑上训练模型可能比在更强大的机器上慢得多，尤其是如果您使用 GPU 的话。我第一次尝试在我 3 个月大的 16 英寸 MacBook Pro 上运行它，但最终的成绩是 1 分 20 秒。我尝试在 Google Cloud 上设置一台机器，但是推荐的层只是有时可用，甚至可能会关闭，以防生产机器的需求很高。我最后看了看 AWS，发现了一个很好的设置，有一个 g4dn.xlarge 实例(每小时花费 0，658 美元)，我可以简单地 SSH 到其中并训练我的模型。这台机器每历元耗时 3 秒。一旦经过充分的训练，模型就可以导出，并在任何环境中进行相当(运行时)经济高效的预测。请继续阅读我的模型的部署版本的示例。

## 部署模型并运行实时预测

训练模型并在 Jupyter 笔记本上看到它的工作都很好，但它并不代表真实世界。我想将经过训练的模型部署到准生产环境中，在那里可以**看到**模型做了什么。

为了实现这个目标，web app 是必不可少的。正如吴恩达在最近与 Lex Fridman 的采访中所说的，与一切工作所需的基础设施和面向用户的元素相比，训练和使用机器学习模型的代码相对较少。对于我的样本摩托车分类器，我用 React.js 和 Node.js 后端构建了一个小的 web 应用程序，它允许您上传照片。然后，服务器运行 python 中的“child_process”来对图像进行分类。效果出奇的好。

![](img/9ca7183729e7c1eb6d772385710d6cc5.png)

如果你对我如何设置服务器和围绕它的 web 应用感兴趣，我在 GitHub 上创建了一个 [repo。请随意下载并使用它。](https://github.com/gisderdube/motorcycle-classifier)

## 我遇到的问题

模型文件的大小稍微大一点，在我的例子中总共大约 330MB。我不太确定这个尺寸是否正常，但我怀疑它是正常的。GitHub 不允许上传大于 100MB 的文件，所以我把它们上传到一个 S3 桶中，并在`npm install`之后下载文件

如今，部署网站、web 服务器或 web 应用程序非常简单，甚至不需要为部署支付任何费用。对于非常简单或演示的项目，我通常默认使用 Heroku，对于更复杂的项目，我默认使用 AWS (Beanstalk)。我尝试了几个不同的 Heroku 构建包，但最终受到了限制，Heroku 只允许 500MB 的 slug 大小。随着`conda`和`fastai`的安装，slug 的大小很快变得大于 3GB，这使得它无法在 Heroku 上运行。

我最终回到 AWS EC2，在我训练模型的 EC2 实例上运行 web 服务器。这可能是不必要的，因为您只需要一个用于 web 服务器和分类脚本的基本 CPU，但是服务器已经配置好了。我唯一要做的事情就是在 EC2 实例上克隆 repo，安装并运行服务器。打开这个实例的传入端口后，我就能够访问我部署的模型了。不幸的是，我不能让它出于演示的目的运行，因为这个实例每小时的成本大约是 0，60 美元。即使是更便宜的实例类型也要花费一些，所以我关闭了实例

在训练了图像分类器模型之后，部署它对我来说更简单了，因为我以前做过无数次这样的部署。在 python 中运行分类脚本可以采用不同的方式，并且可以在将来进行优化。为了减少分类时间，让 python 工作者已经在运行可能是有用的。或者，您也可以使用像 Django 或 Flask 这样的框架在 python 中运行整个 web 服务器。对我来说，web 服务器可能会用 Node.js 来实现，因为我对它很满意，并且知道潜在的安全隐患。让我知道你的想法，如果你了解不同的摩托车！