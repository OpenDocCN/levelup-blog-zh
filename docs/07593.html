<html>
<head>
<title>Portfolio Allocation with TensorTrade: (Part 1/2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于TensorTrade的投资组合配置(下)</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/portfolio-allocation-with-tensortrade-part-1-2-1d0c3b126bf6?source=collection_archive---------1-----------------------#2021-02-26">https://levelup.gitconnected.com/portfolio-allocation-with-tensortrade-part-1-2-1d0c3b126bf6?source=collection_archive---------1-----------------------#2021-02-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2782" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我将在TensorTrade中制作一个不同类型的算法。如题所示，我将实现一个在每个时间步在资产组合中重新分配资金的环境。在我之前的<a class="ae ko" rel="noopener ugc nofollow" target="_blank" href="/using-tensortrade-for-making-a-simple-trading-algorithm-6fad4d9bc79c">文章</a>中，我使用正弦曲线来检查环境是否真的达到了预期的目标。我将在这里采用类似的方法。然而，我将通过在等式中注入一些随机性来增加价格曲线的复杂性。这一系列有许多主题，让我们开始吧！</p><blockquote class="kp kq kr"><p id="4cde" class="jq jr ks js b jt ju jv jw jx jy jz ka kt kc kd ke ku kg kh ki kv kk kl km kn im bi translated">"没有一个聪明人每天都去尝试他前一天已经证明是错误的东西."<br/>——詹姆斯·特鲁·亚当斯</p></blockquote><h1 id="249c" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">环境</h1><p id="3eeb" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">我所构建的环境受到了大约一年前我读过的一篇论文<a class="ae ko" href="https://arxiv.org/pdf/1706.10059.pdf" rel="noopener ugc nofollow" target="_blank">的启发，这篇论文给出了一个投资组合配置环境的结构框架。虽然我不会完全按照本文所做的来构建，但是我会解释一下我在实现中所做的一些小的不同。关于行动方案，一切都是一样的。然而，与论文不同的是，我将奖励方案公式化为应用重新分配前后投资组合价值的差异。下图显示了转换的样子:</a></p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/11978daffc28cc3c7ee68df5ba2c0c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3PFa7NFtiEkVVyVM-yKLQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">推移图</figcaption></figure><p id="5f7c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个时间步的资金分配由现金和资产行上不同深浅的橙色表示。该图显示，当资金被分配给价格上涨的资产时，回报是正的，如果资金被分配给价格下跌的资产，回报是负的。记住这个图表，让我们开始构建组件。</p><h2 id="e049" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">行动方案</h2><p id="f0d9" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">到目前为止，还没有任何一个TensorTrade行动计划涉及到对行动空间的具体要求。具体来说，TensorTrade中显示的所有环境到目前为止一直使用离散的动作空间。例如，前一篇文章的动作空间是二进制的。然而，对于投资组合分配，行动空间是连续的。事实上，假设投资组合有<em class="ks"> m </em>项资产，那么行动空间就是一个标准的<a class="ae ko" href="https://en.wikipedia.org/wiki/Simplex" rel="noopener ugc nofollow" target="_blank">m-单纯形</a>。以下代码是使用<code class="fe nb nc nd ne b">gym.Space</code>接口实现<code class="fe nb nc nd ne b">Simplex</code>动作空间:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">行为空间</figcaption></figure><p id="e63c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在行动方案中，投资组合权重和投资组合价值被更新以反映已经应用的行动。此外，计算中还包括佣金率，因此当资金被重新分配时，行动计划将产生成本。我添加了一个<em class="ks">交易剩余因子</em>，正如论文所称，这是一个考虑佣金成本的特定变量。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">行动方案</figcaption></figure><h2 id="d620" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">奖励计划</h2><p id="f5cb" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">代理的目标是最大化最终的投资组合价值，这可以分解为:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nh"><img src="../Images/3ff43bafbf39b1ea9cb8f3dcd86ad732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DhufuGCSV5Nnhmaa.png"/></div></div></figure><p id="c8ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<em class="ks"> p(t) </em>是时间步长<em class="ks"> t. </em>的投资组合价值，由于最大化结果不依赖于添加到目标中的常数，我们可以将此目标表示为t=1:T的投资组合价值之间的差异之和，即算法的累积利润。在论文中，他们使用累积对数回报的平均值作为奖励。然而，我发现这种奖励对于训练策略和价值函数并不奏效。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">奖励计划</figcaption></figure><h2 id="24fc" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">观察者</h2><p id="4d74" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">对于观察者，我使用了一个包含三个组件的数据馈送:<em class="ks"> state </em>、<em class="ks"> obs </em>和<em class="ks"> performance。</em><em class="ks">状态</em>保存关于环境变量的信息，以计算变化，将其带入下一步。<em class="ks"> obs </em>产生与我将输入模型的内容相关的变量。最后，<em class="ks">性能</em>给出了渲染器用来渲染环境图像的变量。</p><p id="3fb0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于有些特性需要一段特定的时间来预热，所以我向观察器添加了一个参数<em class="ks"> min_periods </em>，以确保在代理开始交互时环境已经准备好。还有一个用于回看窗口大小的参数叫做<em class="ks"> window_size </em>。以下代码是环境的观察者组件的实现:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">观察者</figcaption></figure><h2 id="8c36" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">特征</h2><p id="ea97" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">为了检查这个设置在行动和奖励方案方面的功能，我将使用具有不同位移和频率的正弦曲线来表示每个资产的价格。此外，我还从-10到10的截尾正态分布中添加了随机噪声。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ni"><img src="../Images/f360e7004f68bae22475bb032041e41d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V7MPeiW9MxzF1ZTuFn3QiQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">价格曲线</figcaption></figure><p id="870b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">过去，环境中只包含简单的功能；然而，我将添加更复杂的设置。对于每种资产，我将添加以下三个特征:分数微分、相对强弱指数(RSI)和移动平均收敛发散(MACD)。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h2 id="007e" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">渲染器</h2><p id="299e" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">要实现的最后一个组件是渲染器，它创建了整个剧集中代理决策的可视化。我将从这一集中收集的信息是，随着时间的推移，当与资产价格直接比较时，权重分布是什么样子。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h2 id="3c50" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">把所有的放在一起</h2><p id="61df" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">创建完所有部分后，我构建了一个函数，将所有部分组合起来，创建一个交易环境的实例。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">环境创造</figcaption></figure><p id="2e61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了测试一切都正常运行，我在环境中使用从动作空间随机采样的动作进行了冒烟测试。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">测试运行环境</figcaption></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nj"><img src="../Images/cd7a2eee46847244991b761b7013b952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DxmofWgOHvXTw-UAxJna2g.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">投资组合再分配图表</figcaption></figure><h1 id="d2cf" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h1><p id="97d5" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">随着环境的建立和准备就绪，所有需要的是一个代理可以学习如何在这些价格曲线上分配资金。我将在本系列的第2部分讨论这一部分。下一篇文章将涵盖以下主题:</p><ul class=""><li id="cd3c" class="nk nl it js b jt ju jx jy kb nm kf nn kj no kn np nq nr ns bi translated">使用Ray库中的PPO算法，在portfolio环境中调整、训练和评估代理。</li><li id="1938" class="nk nl it js b jt nt jx nu kb nv kf nw kj nx kn np nq nr ns bi translated">使用PyTorch创建一个自定义模型和动作分布，以插入到Ray中的PPO算法中</li><li id="8e9f" class="nk nl it js b jt nt jx nu kb nv kf nw kj nx kn np nq nr ns bi translated">向TensorBoard添加自定义指标，以便在训练时跟踪代理的表现。</li></ul><p id="5d88" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我希望你喜欢这篇文章，我期待在下一篇文章中见到大家，敬请期待！</p><h2 id="beb4" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">密码</h2><ul class=""><li id="70aa" class="nk nl it js b jt lu jx lv kb ny kf nz kj oa kn np nq nr ns bi translated"><a class="ae ko" href="https://colab.research.google.com/drive/13Jr5KHWdtqYgCt-9I4LNIZLD4qaty_eI?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab </a></li></ul><h2 id="b1ef" class="mp kx it bd ky mq mr dn lc ms mt dp lg kb mu mv lk kf mw mx lo kj my mz ls na bi translated">参考</h2><ul class=""><li id="64f1" class="nk nl it js b jt lu jx lv kb ny kf nz kj oa kn np nq nr ns bi translated">蒋、、徐迪星、梁金军。"金融投资组合管理问题的深度强化学习框架."ArXiv.org(2017年)。网络。【https://arxiv.org/abs/1706.10059】&lt;<a class="ae ko" href="https://arxiv.org/pdf/1706.10059.pdf" rel="noopener ugc nofollow" target="_blank">&gt;。</a></li></ul></div></div>    
</body>
</html>