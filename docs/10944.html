<html>
<head>
<title>How I scrape lots of sites with one python script</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何用一个python脚本抓取大量网站</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-i-scrape-lots-of-sites-with-one-python-script-9fba09d5c9be?source=collection_archive---------0-----------------------#2022-01-28">https://levelup.gitconnected.com/how-i-scrape-lots-of-sites-with-one-python-script-9fba09d5c9be?source=collection_archive---------0-----------------------#2022-01-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b2c7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">代码可配置执行的能力。</h2></div><p id="1f9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你有没有想刮一个网站却又不想花钱买Octoparse这样的刮除工具？或者你只需要从网站上抓取几页，不想设置抓取脚本。在这篇博文中，我将向你展示我如何创建了一个工具，只用python和一点docker就能免费抓取90%的网站。</p><p id="4f38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb"> UPD: </em> </strong> <a class="ae lc" href="https://destiq.medium.com/how-i-scrape-lots-of-sites-with-one-python-script-part-2-with-docker-9722d9348303" rel="noopener"> <em class="lb">我是如何用一个Python脚本刮出很多站点的。Part 2带Docker </em> </a> <em class="lb">可用！不过，我鼓励您阅读这篇文章，让您对脚本解决方案有一个大致的了解。</em></p><blockquote class="ld le lf"><p id="d9dd" class="kf kg lb kh b ki kj jr kk kl km ju kn lg kp kq kr lh kt ku kv li kx ky kz la ij bi translated">你可以在这里找到我关于<a class="ae lc" href="https://bit.ly/3omBlaG" rel="noopener ugc nofollow" target="_blank">网页抓取的代码</a>，格式简单。</p></blockquote><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/084cb573e911445eca95b67ef0c83116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*wyiQJUiyWTS239K6pHKWTA.png"/></div></figure><h1 id="2f21" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">可以抓取的数据类型</h1><p id="9460" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">大多数抓取机器人都是为了抓取<strong class="kh ir">表格数据或列表</strong>而创建的。就标记而言，表格和列表本质上是相同的。在一个容器中，它们保存的行的单元格中填充了值。因此脚本的算法是:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/0329265d0a68e88aa5fcf6773c64a08b.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*CkwKVJvManQ5ZOxpGk1-Pg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk translated">申请流程图</figcaption></figure><h1 id="0504" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">抓取网站的过程</h1><p id="4b09" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">为了扩展潜在的抓取目标列表，我决定使用python和Selenium的老式组合。虽然我很喜欢使用Scrapy，并且在创建自己的解析脚本时深受其可配置设计的影响，但它在使用分页解析站点方面有一定的限制，所以我不得不选择已经提到的解决方案。</p><p id="e6c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了稳定起见，我还决定使用chromedriver 的<strong class="kh ir">dockered版本。它在本地Chrome的更新过程中为我节省了一些痛苦，并且总是在那里，为我准备好，不像你在操作系统上安装的版本，它可能会被系统更新或新软件的安装搞砸。</strong></p><p id="cce0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设您的机器上已经运行了docker服务，那么用chromedriver启动一个新容器就像运行两个命令一样简单:</p><pre class="lk ll lm ln gt mt mu mv mw aw mx bi"><span id="121f" class="my ls iq mu b gy mz na l nb nc">$ docker pull selenium/standalone-chrome</span><span id="df20" class="my ls iq mu b gy nd na l nb nc">$ docker run -d -p 4444:4444 -p 7900:7900 — shm-size=”2g” selenium/standalone-chrome<br/>My python script for scraping websites </span></pre><p id="9182" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个帖子的核心——代码共享段落。首先，我将向您介绍助手方法:</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="9dc0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两个版本允许我在开发过程中需要调试时在Selenium的dockerized版本和本地版本之间切换。</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="e76c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有一种直接的方法可以从我正在使用的HTML元素中提取文本。在不久的将来，我计划添加助手来自动提取链接和图像。如果对这个主题感兴趣，我可以分享一个脚本的更新版本。</p><p id="6746" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种基于硒的蜘蛛的本质在下面的要点中。请通读评论，如果有任何关于它如何工作的问题，请在评论中告诉我。</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h1 id="aaf3" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">如何使用脚本抓取网站</h1><p id="1e2d" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在这一部分，我将演示如何使用这个脚本。首先，您需要创建一个YAML配置文件，然后运行您的蜘蛛。例如，让我们刮刮老好人quotes.toscrape.com。它的配置示例如下所示:</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="9412" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，注意$p$是未来页码的占位符。这是因为大多数网站提供的页面内容在URL上有明显的变化。你的任务将是确定它是如何从一页到另一页的变化，并为你的蜘蛛配置这个掩码。</p><p id="8316" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，在数据选择器和数据列标题中，顺序很重要。例如，引号中的文本将从选择器中解析。正文”(咄)。</p><p id="f789" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准备好配置后，可以使用以下命令执行它:</p><pre class="lk ll lm ln gt mt mu mv mw aw mx bi"><span id="761b" class="my ls iq mu b gy mz na l nb nc">python -m spider -c “./configs/quotes.yaml” -o “./outputs/quotes/$(date +%Y-%m-%d).csv”</span></pre><p id="70c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的Bash行从"。/configs/quotes.yaml "文件并将结果存储在CSV文件中。/outputs/quotes/<em class="lb">current _ date</em>。csv "</p><h1 id="7b65" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">关于如何改善刮削过程的提示</h1><ul class=""><li id="b186" class="ng nh iq kh b ki mj kl mk ko ni ks nj kw nk la nl nm nn no bi translated">使用代理</li></ul><p id="56f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Selenium允许传递代理IP地址，就像在构造函数中添加一个参数一样简单。在StackOverflow 有一个完美的<a class="ae lc" href="https://stackoverflow.com/a/17093125/5601064" rel="noopener ugc nofollow" target="_blank">答案，所以我不会尝试发明轮子。</a></p><ul class=""><li id="5d4c" class="ng nh iq kh b ki kj kl km ko np ks nq kw nr la nl nm nn no bi translated">对你正在解析的网站要温和</li></ul><p id="dc6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看robots.txt并遵守。使用特定的超时运行您的请求，以平稳加载。使用调度在晚上或当你认为该网站的传入流量低时运行脚本。</p><h1 id="3504" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">群众的声音</h1><p id="9385" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">敏捷抓取机器人最大的好处之一是，你不必为每个你想解析的站点编写一个新的机器人。你只需要一个好的脚本，可以针对每个网站或领域进行调整。回想一下今年到目前为止你所有的搜集项目——你希望我在我的剧本中加入什么？</p></div></div>    
</body>
</html>