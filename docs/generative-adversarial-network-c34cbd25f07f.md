# ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/generative-adversarial-network-c34cbd25f07f>

2014 å¹´ï¼ŒIan Goodfellow å’Œå…¶ä»–äººåœ¨ Yoshua Bengio çš„å®éªŒå®¤é‡Œé¦–æ¬¡æŠ¥é“äº†â€œç”Ÿæˆæ•Œå¯¹ç½‘ç»œâ€ã€‚ä»é‚£ä»¥åï¼ŒGANs å¼€å§‹æµè¡Œèµ·æ¥ã€‚è¿™é‡Œæœ‰å‡ ä¸ªä¾‹å­å¯ä¾›å‚è€ƒ:

*   [Pix2Pix](https://affinelayer.com/pixsrv/)
*   [æœ±ä¿Šå½¦ PyTorch çš„ cycle gan&pix 2 pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
*   [ç”Ÿæˆæ¨¡å‹åˆ—è¡¨](https://github.com/wiseodd/generative-models)

GANs èƒŒåçš„æƒ³æ³•æ˜¯ä¸€ä¸ªäººæœ‰ä¸¤ä¸ªç½‘ç»œï¼Œä¸€ä¸ªç”Ÿæˆå™¨*ğº*å’Œä¸€ä¸ªé‰´åˆ«å™¨ *ğ·* ï¼Œç›¸äº’ç«äº‰ã€‚ç”Ÿæˆå™¨ç”Ÿæˆâ€œå‡â€æ•°æ®ä¼ é€’ç»™é‰´åˆ«å™¨ã€‚é‰´åˆ«å™¨è¿˜å¯ä»¥çœ‹åˆ°çœŸå®çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶é¢„æµ‹å®ƒæ”¶åˆ°çš„æ•°æ®æ˜¯çœŸæ˜¯å‡ã€‚

*   ç”Ÿæˆå™¨è¢«è®­ç»ƒæ¥æ¬ºéª—é‰´åˆ«å™¨ï¼Œå®ƒæƒ³è¦è¾“å‡ºçœ‹èµ·æ¥å°½å¯èƒ½æ¥è¿‘çœŸå®è®­ç»ƒæ•°æ®çš„æ•°æ®ã€‚
*   é‰´åˆ«å™¨æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå®ƒè¢«è®­ç»ƒæ¥æ‰¾å‡ºå“ªäº›æ•°æ®æ˜¯çœŸå®çš„ï¼Œå“ªäº›æ˜¯è™šå‡çš„ã€‚

æœ€ç»ˆå‘ç”Ÿçš„æƒ…å†µæ˜¯ï¼Œç”Ÿæˆå™¨å­¦ä¹ ç”Ÿæˆä¸é‰´åˆ«å™¨çš„çœŸå®æ•°æ®æ— æ³•åŒºåˆ†çš„æ•°æ®ã€‚

![](img/3fada5587a1846dff949b8c6808b145c.png)

å›¾ç‰‡æ¥æº:Udacity

## æ„å»º GAN:

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å°è¯•å»ºç«‹ä¸€ä¸ªç®€å•çš„ç”˜äº§ç”Ÿæ–°çš„æ‰‹å†™å›¾åƒçš„åŸºç¡€ä¸Š MNIST æ•°æ®é›†ã€‚

æ­¥éª¤ 1:åŠ è½½å¿…è¦çš„åº“ï¼Œæˆ‘ä»¬å°†ä¸ºè¿™ä¸ªæ¨¡å‹ä½¿ç”¨ PyTorchã€‚

```
%matplotlib inline
import numpy as np
import torch
import matplotlib.pyplot as plt
from torchvision import datasets
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import pickle as pkl
```

æ­¥éª¤ 2:ç°åœ¨æˆ‘ä»¬å°†åŠ è½½å†…ç½®çš„ MNIST æ•°æ®é›†ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ‰¹é‡å¤§å°ä¸º 64 çš„ train_loaderã€‚

æ­¥éª¤ 3:å¯è§†åŒ–æ•°æ®

å¯è§†åŒ–æ•°æ®çš„ä»£ç 

![](img/80d099107a6be9673c68c30d6d2c81b7.png)

ä¸Šè¿°ä»£ç çš„è¾“å‡º

## å®šä¹‰æ¨¡å‹

ä¸€ä¸ª GAN ç”±ä¸¤ä¸ªå¯¹ç«‹çš„ç½‘ç»œç»„æˆï¼Œä¸€ä¸ªé‰´åˆ«å™¨å’Œä¸€ä¸ªç”Ÿæˆå™¨ã€‚

![](img/b50c48fe5938d7e404e8b37b39324bf0.png)

## é‰´åˆ«å™¨

é‰´åˆ«å™¨ç½‘ç»œå°†ä¼šæ˜¯ä¸€ä¸ªéå¸¸å…¸å‹çš„çº¿æ€§åˆ†ç±»å™¨ã€‚ä¸ºäº†ä½¿è¿™ä¸ªç½‘ç»œæˆä¸ºä¸€ä¸ªé€šç”¨çš„å‡½æ•°æŒªç”¨å™¨ï¼Œæˆ‘ä»¬è‡³å°‘éœ€è¦ä¸€ä¸ªéšè—å±‚ï¼Œå¹¶ä¸”è¿™äº›éšè—å±‚åº”è¯¥æœ‰ä¸€ä¸ªå…³é”®å±æ€§ã€‚è¿™é‡Œæˆ‘ä»¬å°†å®šä¹‰ 3 ä¸ªéšè—å±‚å’Œ 1 ä¸ªå…¨è¿æ¥å±‚ã€‚æ¯ä¸€å±‚éƒ½æœ‰ä¸€ä¸ªæ¼é‡æ¿€æ´»åŠŸèƒ½ã€‚æ³„æ¼çš„ ReLU ç±»ä¼¼äºæ™®é€šçš„ ReLUï¼Œåªæ˜¯å¯¹äºè´Ÿè¾“å…¥å€¼æœ‰ä¸€ä¸ªå°çš„éé›¶è¾“å‡ºï¼Œå®ƒæ˜¯é€šè¿‡ä¹˜ä»¥ä¸€ä¸ªå°å¸¸æ•°å¾—åˆ°çš„ã€‚

æˆ‘ä»¬è¿˜å°†é‡‡ç”¨åœ¨è¾“å‡ºç«¯ä½¿ç”¨æ•°å€¼ä¸Šæ›´ç¨³å®šçš„æŸå¤±å‡½æ•°çš„æ–¹æ³•ã€‚å›æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›é‰´åˆ«å™¨è¾“å‡ºä¸€ä¸ª 0â€“1 çš„å€¼ï¼Œè¡¨ç¤ºä¸€å¹…å›¾åƒæ˜¯*çœŸçš„è¿˜æ˜¯å‡çš„*ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æœ€ç»ˆè¾“å‡ºå±‚ä¸åº”è¯¥æœ‰ä»»ä½•æ¿€æ´»åŠŸèƒ½åº”ç”¨äºå®ƒã€‚

```
class Discriminator(nn.Module):
 def __init__(self, input_size, hidden_dim, output_size):
  super(Discriminator, self).__init__()

    # define all layers

    #There are three hidden layers
    self.layer1=nn.Linear(input_size,hidden_dim*4)
    self.layer2=nn.Linear(hidden_dim*4,hidden_dim*2)
    self.layer3=nn.Linear(hidden_dim*2,hidden_dim)

    #This is the fully connected layer
    self.layer4=nn.Linear(hidden_dim,output_size)

    #A dropout with value 0.2 is added
    self.dropout=nn.Dropout(0.2)

 def forward(self, x):
    # flatten image
    x=x.view(-1,28*28)
    # pass x through all layers
    # apply leaky relu activation to all hidden layers
    x=F.leaky_relu(self.layer1(x),0.2)
    x=self.dropout(x)
    x=F.leaky_relu(self.layer2(x),0.2)
    x=self.dropout(x)
    x=F.leaky_relu(self.layer3(x),0.2)
    x=self.dropout(x)

    output=self.layer4(x)
    return output
```

## å‘ç”µæœº

å‘ç”Ÿå™¨ç½‘ç»œå°†ä¸é‰´åˆ«å™¨ç½‘ç»œå‡ ä¹å®Œå…¨ç›¸åŒï¼Œé™¤äº†æˆ‘ä»¬å°†ä¸€ä¸ª[åŒæ›²æ­£åˆ‡æ¿€æ´»å‡½æ•°](https://pytorch.org/docs/stable/nn.html#tanh)åº”ç”¨åˆ°æˆ‘ä»¬çš„è¾“å‡ºå±‚ã€‚å·²ç»å‘ç°ï¼Œå¯¹äºå‘ç”µæœºè¾“å‡ºæ¥è¯´ï¼Œå…·æœ‰ *ğ‘¡ğ‘ğ‘›â„* çš„å‘ç”µæœºè¡¨ç°æœ€ä½³ï¼Œå…¶å°†è¾“å‡ºç¼©æ”¾åˆ°-1 å’Œ 1 ä¹‹é—´ï¼Œè€Œä¸æ˜¯ 0 å’Œ 1ã€‚

```
class Generator(nn.Module): def __init__(self, input_size, hidden_dim, output_size):
   super(Generator, self).__init__()

     # define all layers

     #There are three hidden layers
     self.layer1=nn.Linear(input_size,hidden_dim)
     self.layer2=nn.Linear(hidden_dim,hidden_dim*2)
     self.layer3=nn.Linear(hidden_dim*2,hidden_dim*4)

     #This is the fully connected layer
     self.layer4=nn.Linear(hidden_dim*4,output_size)

     #A dropout with value 0.2 is added
     self.dropout=nn.Dropout(0.2) def forward(self, x):
     # pass x through all layers

     # final layer should have tanh applied
     x=F.leaky_relu(self.layer1(x),0.2)
     x=self.dropout(x)
     x=F.leaky_relu(self.layer2(x),0.2)
     x=self.dropout(x)
     x=F.leaky_relu(self.layer3(x),0.2)
     x=self.dropout(x)
     output=F.tanh(self.layer4(x))
     return output
```

ä¸‹ä¸€æ­¥æ˜¯ä¸ºæˆ‘ä»¬çš„æ¨¡å‹è®¾ç½®è¶…å‚æ•°

ç°åœ¨æˆ‘ä»¬å°†å»ºç«‹å®Œæ•´çš„æ¨¡å‹ã€‚

è¾“å‡ºå°†æ˜¾ç¤ºæˆ‘ä»¬å®Œæ•´çš„æ¨¡å‹æ¶æ„ï¼Œ

```
Discriminator(
  (layer1): Linear(in_features=784, out_features=128, bias=True)
  (layer2): Linear(in_features=128, out_features=64, bias=True)
  (layer3): Linear(in_features=64, out_features=32, bias=True)
  (layer4): Linear(in_features=32, out_features=1, bias=True)
  (dropout): Dropout(p=0.2)
)

Generator(
  (layer1): Linear(in_features=100, out_features=32, bias=True)
  (layer2): Linear(in_features=32, out_features=64, bias=True)
  (layer3): Linear(in_features=64, out_features=128, bias=True)
  (layer4): Linear(in_features=128, out_features=784, bias=True)
  (dropout): Dropout(p=0.2)
)
```

## é‰´é¢‘å™¨æŸè€—

å¯¹äºé‰´åˆ«å™¨ï¼Œæ€»æŸå¤±æ˜¯çœŸå®å’Œä¼ªé€ å›¾åƒçš„æŸå¤±ä¹‹å’Œï¼Œ`d_loss = d_real_loss + d_fake_loss`ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬å¸Œæœ›é‰´é¢‘å™¨ä¸ºçœŸå®å›¾åƒè¾“å‡º 1ï¼Œä¸ºè™šå‡å›¾åƒè¾“å‡º 0ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è®¾ç½®æŸè€—æ¥åæ˜ è¿™ä¸€ç‚¹ã€‚

æŸå¤±å°†ç”±äºŒå…ƒäº¤å‰ç†µæŸå¤±ä¸ logitsï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸ [BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) ã€‚è¿™å°†`sigmoid`æ¿€æ´»å‡½æ•°**å’Œ**äºŒå…ƒäº¤å‰ç†µæŸå¤±ç»“åˆåœ¨ä¸€ä¸ªå‡½æ•°ä¸­ã€‚

## å‘ç”µæœºæŸè€—

åªæœ‰åœ¨æ ‡ç­¾ç¿»è½¬çš„æƒ…å†µä¸‹ï¼Œå‘ç”µæœºæŸè€—æ‰ä¼šçœ‹èµ·æ¥ç›¸ä¼¼ã€‚ç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯å¾—åˆ°`D(fake_images) = 1`ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ ‡ç­¾è¢«**ç¿»è½¬**ä»¥è¡¨ç¤ºç”Ÿæˆå™¨è¯•å›¾æ¬ºéª—é‰´åˆ«å™¨ï¼Œä½¿å…¶è®¤ä¸ºç”Ÿæˆçš„å›¾åƒ(èµå“)æ˜¯çœŸå®çš„ï¼

æˆ‘ä»¬å¸Œæœ›åˆ†åˆ«æ›´æ–°ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨å˜é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸¤ä¸ªç‹¬ç«‹çš„ Adam ä¼˜åŒ–å™¨ã€‚

# åŸ¹å…»

è®­ç»ƒå°†åŒ…æ‹¬äº¤æ›¿è®­ç»ƒé‰´åˆ«å™¨å’Œå‘ç”Ÿå™¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å‡½æ•°`real_loss`å’Œ`fake_loss`æ¥å¸®åŠ©æˆ‘ä»¬è®¡ç®—ä»¥ä¸‹æ‰€æœ‰æƒ…å†µä¸‹çš„é‰´é¢‘å™¨æŸè€—ã€‚

## ç”„åˆ«è®­ç»ƒ

åœ¨çœŸå®çš„è®­ç»ƒå›¾åƒä¸Šè®¡ç®—é‰´åˆ«å™¨æŸå¤±ï¼Œç„¶åç”Ÿæˆå‡å›¾åƒã€‚æœ€åï¼Œæ‰§è¡Œåå‘ä¼ æ’­+ä¼˜åŒ–æ¥æ›´æ–°é‰´åˆ«å™¨çš„æƒé‡ã€‚

## å‘ç”µæœºåŸ¹è®­

ä½¿ç”¨**ç¿»è½¬çš„**æ ‡ç­¾ç”Ÿæˆå‡å›¾åƒå¹¶è®¡ç®—å‡å›¾åƒçš„é‰´åˆ«å™¨æŸè€—ã€‚æ‰§è¡Œåå‘ä¼ æ’­+ä¼˜åŒ–æ¥æ›´æ–°ç”Ÿæˆå™¨çš„æƒé‡ã€‚

```
num_epochs = 100
samples = []
losses = []
print_every = 400sample_size=16
fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))
fixed_z = torch.from_numpy(fixed_z).float()D.train()
G.train()
for epoch in range(num_epochs):
   for batch_i, (real_images, _) in enumerate(train_loader):
        batch_size = real_images.size(0)
        real_images = real_images*2â€“1 
        d_optimizer.zero_grad()
        D_real = D(real_images)
        d_real_loss = real_loss(D_real, smooth=True)

        z = np.random.uniform(-1, 1, size=(batch_size, z_size))
        z = torch.from_numpy(z).float()
        fake_images = G(z)

        D_fake = D(fake_images)
        d_fake_loss = fake_loss(D_fake)

        d_loss = d_real_loss + d_fake_loss
        d_loss.backward()
        d_optimizer.step()

        g_optimizer.zero_grad()

        z = np.random.uniform(-1, 1, size=(batch_size, z_size))
        z = torch.from_numpy(z).float()
        fake_images = G(z)
        D_fake = D(fake_images)
        g_loss = real_loss(D_fake) 
        g_loss.backward()
        g_optimizer.step()
        if batch_i % print_every == 0:
             print(â€˜Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss:  
                   {:6.4f}â€™.format(epoch+1, num_epochs,  
                    d_loss.item(), g_loss.item()))## AFTER EACH EPOCH##
   losses.append((d_loss.item(), g_loss.item()))
   G.eval() 
   samples_z = G(fixed_z)
   samples.append(samples_z)
   G.train()with open(â€˜train_samples.pklâ€™, â€˜wbâ€™) as f:
   pkl.dump(samples, f)
```

## åŸ¹è®­æŸå¤±

è¿™é‡Œæˆ‘ä»¬å°†ç»˜åˆ¶å‘ç”Ÿå™¨å’Œé‰´åˆ«å™¨çš„è®­ç»ƒæŸè€—ï¼Œåœ¨æ¯ä¸ªæ—¶æœŸåè®°å½•ã€‚

![](img/fedc52ee45d50603c3309a0087754d06.png)

åŸ¹è®­æŸå¤±

æœ€åï¼Œè®©æˆ‘ä»¬æµ‹è¯•ç”Ÿæˆçš„æ–°å›¾åƒã€‚

![](img/f5705cc05e769b1e580f9d448d2d5b50.png)

æ–° MNIST å½¢è±¡ï¼ï¼

Tadaï¼è¿™é‡Œä½¿ç”¨ GANï¼Œç”Ÿæˆäº†æ–°çš„æ‰‹å†™å›¾åƒã€‚ç±»ä¼¼åœ°ï¼ŒGANs å¯ç”¨äºä»ç°æœ‰å›¾åƒç”Ÿæˆæ–°å›¾åƒã€‚äº«å—æ¢ç´¢ç”˜æ–¯çš„ä¹è¶£ã€‚

ç¼–ç å¿«ä¹ï¼

[](https://skilled.dev) [## ç¼–å†™é¢è¯•é—®é¢˜

### ä¸€ä¸ªå®Œæ•´çš„å¹³å°ï¼Œåœ¨è¿™é‡Œæˆ‘ä¼šæ•™ä½ æ‰¾åˆ°ä¸‹ä¸€ä»½å·¥ä½œæ‰€éœ€çš„ä¸€åˆ‡ï¼Œä»¥åŠâ€¦

æŠ€æœ¯å¼€å‘](https://skilled.dev)