<html>
<head>
<title>K’s Nearest Neighbour Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k的最近邻Python</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/ks-nearest-neighbour-python-60b7bb9415d7?source=collection_archive---------2-----------------------#2021-04-10">https://levelup.gitconnected.com/ks-nearest-neighbour-python-60b7bb9415d7?source=collection_archive---------2-----------------------#2021-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="5aeb" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">简介:</h1><p id="2dc7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我要感谢Onel Harrison对KNN的解释，以下解释摘自他的文章，如果你想深入了解KNN，我推荐你阅读:</p><div class="lj lk gp gr ll lm"><a href="https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761" rel="noopener follow" target="_blank"><div class="ln ab fo"><div class="lo ab lp cl cj lq"><h2 class="bd ir gy z fp lr fr fs ls fu fw ip bi translated">基于K-最近邻算法的机器学习基础</h2><div class="lt l"><h3 class="bd b gy z fp lr fr fs ls fu fw dk translated">k-最近邻(KNN)算法是一个简单，易于实现的监督机器学习算法，可以…</h3></div><div class="lu l"><p class="bd b dl z fp lr fr fs ls fu fw dk translated">towardsdatascience.com</p></div></div><div class="lv l"><div class="lw l lx ly lz lv ma mb lm"/></div></div></a></div><p id="14fb" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">k-最近邻(KNN)算法是一种简单、易于实现的监督机器学习算法，可用于解决分类和回归问题</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/0aa7706186c7b77420bb5533ac0ee2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G5l4VXKZ7ZboeKTSI1oWEg.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">游戏的一个例子</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/70184b4e3489b91cf85d2a45ff4cafbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W4cpga6i8bHH7tE7XJnLMQ.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk translated">标准偏差不同的另一个例子</figcaption></figure><pre class="mi mj mk ml gt mw mx my mz aw na bi"><span id="0b64" class="nb jo iq mx b gy nc nd l ne nf">import numpy as np<br/>import pygame<br/>import sys<br/>import time<br/><br/>WIDTH = 750<br/>running = True<br/>POINTS = 3000<br/>NUMBER_OF_POINTS = 100<br/>RED_RANGE = [[0,750],[0,450]]<br/>GREEN_RANGE = [[0,450],[0,750]]<br/>BLUE_RANGE = [[450,750],[0,750]]<br/>STANDARD_DEVIATION_DIVISOR = 1<br/>SPAM_NEW_GRIDS = True<br/><br/>WHITE = (255, 255, 255)<br/>BLUE =     (0,0,128)<br/>RED = (255,0,0)<br/>GREEN = (0, 255, 0)<br/>chars = {'R': RED,<br/>         'G': GREEN,<br/>         'B': BLUE}<br/><br/>pygame.init()<br/>screen = pygame.display.set_mode((WIDTH, WIDTH))<br/>screen.fill(WHITE)<br/>pygame.display.set_caption("K's Nearest Neighbour")<br/><br/><br/>def generate_starting_points(minimum, maximum, number_of_points):<br/>    mean = (maximum + minimum) / 2<br/>    standard_deviation = (maximum + minimum) / STANDARD_DEVIATION_DIVISOR<br/>    points = np.array(np.random.normal(mean, standard_deviation, number_of_points))<br/>    return points<br/><br/><br/>def display_starting_grid(red, green, blue, points):<br/>    redX = generate_starting_points(red[0][0], red[0][1], points)<br/>    redY = generate_starting_points(red[1][0], red[1][1], points)<br/>    red = np.stack((redX, redY), axis=-1)<br/><br/>    blueX = generate_starting_points(blue[0][0], blue[0][1], points)<br/>    blueY = generate_starting_points(blue[1][0], blue[1][1], points)<br/>    blue = np.stack((blueX, blueY), axis=-1)<br/><br/>    greenX = generate_starting_points(green[0][0], green[0][1], points)<br/>    greenY = generate_starting_points(green[1][0], green[1][1], points)<br/>    green = np.stack((greenX, greenY), axis=-1)<br/>    return np.stack((red, green, blue))<br/><br/><br/>def display(window, redArr, blueArr, greenArr):<br/>    for point in redArr:<br/>        pygame.draw.circle(window, RED, (point[0], point[1]), 1)<br/>    for point in greenArr:<br/>        pygame.draw.circle(window, GREEN, (point[0], point[1]), 1)<br/>    for point in blueArr:<br/>        pygame.draw.circle(window, BLUE, (point[0], point[1]), 1)<br/><br/><br/>def connectLines(points, window, mouse):<br/>    colors=np.array([ord(point[2]) for point in points])<br/>    most_frequent_colour = chr(np.bincount(colors).argmax())<br/>    for point in points:<br/>        pygame.draw.line(window, chars.get(point[2]), mouse, point[1], 1)<br/>    pygame.draw.circle(window, chars.get(most_frequent_colour), mouse_position, 8)<br/><br/><br/>def KNN(mouse, points, window):<br/>    #closest_points = [[sqrt(2*WIDTH**2),'NULL'] for _ in range(10)]<br/>    closest_points = []<br/>    for point in points[0]:<br/>        distance = np.linalg.norm(mouse - point)<br/>        value = np.array([distance, point, 'R'], dtype=object)<br/>        closest_points.append(value)<br/>    for point in points[1]:<br/>        distance = np.linalg.norm(mouse - point)<br/>        value = np.array([distance, point, 'G'], dtype=object)<br/>        closest_points.append(value)<br/>    for point in points[2]:<br/>        distance = np.linalg.norm(mouse - point)<br/>        value = np.array([distance, point, 'B'], dtype=object)<br/>        closest_points.append(value)<br/>    closest_points = sorted(closest_points, reverse=False, key= lambda x:x[0])[:NUMBER_OF_POINTS]<br/>    connectLines(closest_points, window, mouse)<br/><br/><br/>points = display_starting_grid(RED_RANGE, GREEN_RANGE, BLUE_RANGE, POINTS)<br/>while running:<br/>    start= time.time()<br/>    screen.fill(WHITE)<br/>    red, green, blue = points[0], points[1], points[2]<br/>    display(screen, red, blue, green)<br/>    mouse_position = np.array(pygame.mouse.get_pos())<br/>    KNN(mouse_position, points, screen)<br/>    for event in pygame.event.get():<br/>        if event.type == pygame.QUIT:<br/>            running = False<br/>            pygame.quit()<br/>            sys.exit()<br/>    if SPAM_NEW_GRIDS:<br/>        points = display_starting_grid(RED_RANGE, GREEN_RANGE, BLUE_RANGE, POINTS)<br/>        print(time.time()- start)<br/>    pygame.display.flip()</span></pre><p id="4202" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated"><strong class="kn ir">有监督的机器学习</strong>算法(与无监督的机器学习算法相反)是一种依靠有标签的输入数据来学习一个函数的算法，当给定新的无标签数据时，该函数产生适当的输出。</p><p id="d303" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">监督机器学习算法用于解决分类或回归问题。</p><p id="dfb9" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">一个<strong class="kn ir">分类问题</strong>有一个离散值作为它的输出。例如，“喜欢比萨饼上的菠萝”和“不喜欢比萨饼上的菠萝”是不连续的。没有中间地带。上面教孩子识别猪的类比是分类问题的另一个例子。</p><p id="2106" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">一个<strong class="kn ir">回归问题</strong>的输出是一个实数(一个带小数点的数)。例如，我们可以使用下表中的数据，在给定身高的情况下估计某人的体重。</p><p id="672c" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">回归分析中使用的数据看起来与上图中显示的数据相似。我们有一个独立变量(或一组独立变量)和一个因变量(在给定独立变量的情况下，我们试图猜测的东西)。例如，我们可以说身高是自变量，体重是因变量。</p><p id="2c9d" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">此外，每行通常称为<strong class="kn ir">示例、观察值或数据点</strong>，而每列(不包括标签/因变量)通常称为<strong class="kn ir">预测值、维度、自变量或特征。</strong></p><p id="7d55" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">一个<strong class="kn ir">无监督的机器学习</strong>算法使用没有任何标签的输入数据——换句话说，没有老师(标签)告诉孩子(计算机)什么时候是正确的，什么时候它犯了错误，以便它可以自我纠正。</p><p id="2678" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">监督学习试图学习一个函数，该函数将允许我们在给定一些新的未标记数据的情况下进行预测，而非监督学习则不同，它试图学习数据的基本结构，以便让我们对数据有更多的了解。</p><h1 id="6790" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">KNN:</h1><p id="15f8" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">KNN算法假设相似的事物存在于附近。换句话说，相似的事物彼此靠近。因此，在示例代码中，我利用np的内置函数来尽可能快地获取代码。</p><p id="42a5" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">看看代码，如果你有任何疑问，请评论！</p></div></div>    
</body>
</html>