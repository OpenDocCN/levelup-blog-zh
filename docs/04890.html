<html>
<head>
<title>A Neural Network In Under 4KB</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">4KB以下的神经网络</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/a-neural-network-in-under-4kb-41fc2d7d9174?source=collection_archive---------20-----------------------#2020-07-21">https://levelup.gitconnected.com/a-neural-network-in-under-4kb-41fc2d7d9174?source=collection_archive---------20-----------------------#2020-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b5ec" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">介绍</h2></div><p id="c540" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几年前，我开始编写C++模板库，目标是在嵌入式系统中实例化和运行神经网络和机器学习算法。我没有FPU(浮点单元)、GPU(图形处理单元)或任何矢量化指令(例如SIMD)，因此我需要确保我可以只用一个非常简单的CPU来运行这些算法。在我的环境中，存储代码和数据的内存也非常有限。我没有空间来存储我不打算使用的代码和数据。</p><p id="9b24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我对这些库的灵感来自安德烈·亚历山德雷斯库的现代C++设计。这本书是我第一次接触到C++模板和<a class="ae lb" href="https://en.wikipedia.org/wiki/Template_metaprogramming" rel="noopener ugc nofollow" target="_blank">模板元编程</a>的力量。在书中，他描述了如何使用策略类作为模板参数来设计代码，以定制行为。这完全符合我的需求，因为我希望代码可以从一个问题扩展到下一个问题(例如，解决方案、激活函数等)。)我还使用这种技术使这些库中的代码尽可能地小而高效。</p><p id="144b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了演示<a class="ae lb" href="https://github.com/danmcleran/tinymind" rel="noopener ugc nofollow" target="_blank">我的神经网络库</a>能做什么，我选择为神经网络实现一个经典的“hello world”类程序(<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/examples/xor/xor.cpp" rel="noopener ugc nofollow" target="_blank"> xor.cpp </a>)。在这里，我将演示如何实例化和训练一个神经网络来预测数学异或函数的结果。我们将生成已知数据并将其输入神经网络，并训练它成为XOR预测器。通过在编译期间检查生成的输出文件，我们可以向自己证明，假设我们打开了编译器优化，整个神经网络以及相关的代码和数据在最终图像中占用的空间不到4KB。</p><h2 id="3f7a" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">q格式</h2><p id="22f8" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">要让神经网络超小超快，浮点这个奢侈品我们可买不起。另外，我的硬件没有浮点单元，这使得使用浮点更加困难。我们需要用定点数来解决这个问题。<a class="ae lb" href="https://github.com/danmcleran/tinymind" rel="noopener ugc nofollow" target="_blank"> Tinymind </a>包含一个C++模板库在这里帮助我们，<a class="ae lb" rel="noopener ugc nofollow" target="_blank" href="/qformat-92b4e570235f"> Q格式</a>。参见<a class="ae lb" rel="noopener ugc nofollow" target="_blank" href="/qformat-92b4e570235f">这篇文章</a>了解它如何工作的完整解释。我们像这样声明我们的Q格式类型的大小和分辨率:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="9c76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在已经声明了一个带符号的定点类型，它可以表示值-128到127.99609375。我们的分辨率是2^(-8)或0.00390625，因为我们使用8位作为q格式数的小数部分。从这个例子中你会看到，我们有足够的动态范围和分辨率来解决这个问题，没有浮点。该值的固定部分和小数部分连接成一个16位字段。举个例子。浮点数1.5将以上面选择的q格式在0x180处表示。这是因为整数部分(1)上移了小数位数(8)，从而得到0x100。我们将数字中的OR表示为8位动态范围的一半(十六进制为128或0x80)。</p><h2 id="f563" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">神经网络</h2><p id="c339" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们需要指定我们的神经网络架构。我们的做法如下:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="a511" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们想要一个具有2个输入神经元、1个包含3个神经元的隐藏层和1个输出神经元的神经网络。2个输入神经元将从训练数据中接收1和0的流。输出神经元输出操作的预测结果。给定输入值和已知结果，隐藏层是学习预测结果的传递函数。</p><p id="d0ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里提供了神经网络的图形视图:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/0fb71276705dc27c738d11852669a351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*0rsrg7zTdgjvVgE1n2NrJw.png"/></div></figure><p id="c192" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们定义了神经网络传递函数策略以及神经网络本身:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="826b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TransferFunctionsType指定了ValueType(我们的Q格式类型)，神经网络的随机数生成器，输入-&gt;隐藏层的激活策略，以及隐藏-&gt;输出层的激活策略。<a class="ae lb" href="https://github.com/danmcleran/tinymind" rel="noopener ugc nofollow" target="_blank"> tinymind </a>内的神经网络代码对其环境不做任何假设。需要为它提供封装策略的模板参数。</p><h2 id="c07a" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">查找表</h2><p id="128d" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">因为我没有浮点运算，所以我也没有内置的数学函数来处理tanh、sigmoid等。为了绕过这个限制，<a class="ae lb" href="https://github.com/danmcleran/tinymind" rel="noopener ugc nofollow" target="_blank"> tinymind </a>为这些激活函数(<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/apps/activation/activationTableGenerator.cpp" rel="noopener ugc nofollow" target="_blank">activationtablegenerator . CPP</a>)生成并利用查找表(lut)。这个生成器为每个支持的激活函数和Q格式分辨率生成头文件。因为我们不想生成我们不打算使用的代码，我们需要定义预处理器符号来编译我们需要的LUT。如果查看compile命令，您会看到以下内容:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="5aa3" class="lc ld iq ml b gy mp mq l mr ms">-DTINYMIND_USE_TANH_8_8=1</span></pre><p id="bce1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这指示编译器为Q格式类型Q8.8构建tanh激活LUT，这就是我们在这个例子中使用的。我们需要为我们计划使用的每个LUT都这样做。</p><h2 id="7b06" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">生成训练数据</h2><p id="852a" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们将以编程方式生成训练数据。调用函数generateXorTrainingValue来生成单个训练样本。我们使用内置的随机数生成器来生成2个输入。我们生成一个随机数，然后将其与0x1进行and运算。如果随机数是偶数，结果将是0，如果随机数是奇数，结果将是1。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="45a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将数据输入神经网络，预测输出，然后在误差超出零容忍范围时进行训练。：</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="728a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将在预测误差不在零容忍范围内的每次迭代中训练神经网络。神经网络预测值的误差实际上永远不会为零。我们需要一种方法来决定何时足够接近。如果我们足够接近零误差，那么最好不要去管权重。当声明神经网络的传递函数策略时，指定零容忍策略。在本例中，我们只是使用这些策略的默认值:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><h2 id="58c7" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">编译示例</h2><p id="1633" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">这里我将展示如何在我的Linux机器上编译这个例子。我还使用Visual Studio在Windows上编译了代码。为了编译示例而不将不需要的文件添加到repo中，我简单地创建了一个目录来保存输出的可执行文件，并在编译和链接之后移动它。</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="df20" class="lc ld iq ml b gy mp mq l mr ms">mkdir -p ~/xor</span><span id="3a03" class="lc ld iq ml b gy mt mq l mr ms">g++ -O3 -o ~/xor/xor xor.cpp xornet.cpp ../../cpp/lookupTables.cpp -DTINYMIND_ENABLE_OSTREAMS=1 -DTINYMIND_USE_TANH_8_8=1 -I../../cpp -I../../apps/include</span></pre><p id="4370" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要运行该示例，只需cd到~/xor并运行生成的可执行文件。</p><h2 id="6095" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">绘图结果</h2><p id="c990" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">运行示例后，您会看到有一个文本文件输出nn_fixed_xor.txt，我提供了一个python脚本来绘制神经网络单元测试中神经网络训练的结果(<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/unit_test/nn/nn_plot.py" rel="noopener ugc nofollow" target="_blank"> nn_plot.py </a>)。绘制神经网络权重、预期输出、预测输出以及计算误差。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/c2b3b1733a7f087be2341874945da4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_cvfBsTENIr_wMpEPuUdA.png"/></div></div></figure><p id="f058" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着预测值接近预期值，您可以看到重量训练时间以及误差减少时间。注意数字的大小。期望值在0到256之间变化。对于我们的Q格式类型，这映射到0和1的表示。1在带符号的Q8.8格式(8位小数分辨率，8位整数表示)中的表示为0x100。简单来说，就是将数字1左移分数分辨率的位数。还要注意重量的变化。它几乎看起来像浮点，但它不是。我们有2^(-8)或0.00390625值之间的分辨率。</p><p id="6067" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要使用绘图脚本，只需将运行示例程序的结果文件的路径传递给它。</p><h2 id="92cc" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">确定神经网络大小</h2><p id="3093" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">为了更容易地确定这个例子中神经网络代码和数据占用了多少空间，我确保将所有的神经网络代码放入它自己的文件中，<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/examples/xor/xornet.cpp" rel="noopener ugc nofollow" target="_blank"> xornet.cpp </a>。为了确定代码和数据在这个程序中占用了多少空间，我们在编译期间生成并解析一个输出文件。我用来编译<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/examples/xor/xornet.cpp" rel="noopener ugc nofollow" target="_blank"> xornet.cpp </a>并移动结果输出文件的命令行如下:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="fbdd" class="lc ld iq ml b gy mp mq l mr ms">g++ -c xornet.cpp ../../cpp/lookupTables.cpp -O3 -DTINYMIND_USE_TANH_8_8=1 -I../../cpp &amp;&amp; mv xornet.o ~/xor/. &amp;&amp; mv lookupTables.o ~/xor/.</span></pre><p id="335f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用Linux下的size实用程序来解析编译<a class="ae lb" href="https://github.com/danmcleran/tinymind/blob/master/examples/xor/xornet.cpp" rel="noopener ugc nofollow" target="_blank"> xornet.cpp </a>的输出文件:</p><pre class="ma mb mc md gt mk ml mm mn aw mo bi"><span id="4332" class="lc ld iq ml b gy mp mq l mr ms">size lookupTables.o<br/>text    data     bss     dec     hex filename<br/> 192       0       0     192      c0 lookupTables.o</span><span id="2443" class="lc ld iq ml b gy mt mq l mr ms">size xornet.o<br/>text    data     bss     dec     hex filename<br/>3369       8     388    3765     e8a xornet.o</span></pre><p id="063f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以看到，这个神经网络、Q格式支持和lut占用的总空间不到4KB。神经网络本身占用396字节，而相关代码占用3369字节。LUT占用192个字节，总计3957个字节。</p><h2 id="8a02" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">结论</h2><p id="03cd" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">使用<a class="ae lb" href="https://github.com/danmcleran/tinymind" rel="noopener ugc nofollow" target="_blank"> tinymind </a>，可以使用定点数来实例化神经网络，这样它们就占用了非常少量的代码和数据空间。可以训练它们在2000个训练样本下预测一个基本函数的结果。我希望这能启发你克隆tinymind，并看看单元测试和例子。甚至可能产生一个你自己的。</p></div></div>    
</body>
</html>