<html>
<head>
<title>Beginner’s Guide to Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark初学者指南</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/beginners-guide-to-apache-spark-15dc5fe4de65?source=collection_archive---------8-----------------------#2020-01-27">https://levelup.gitconnected.com/beginners-guide-to-apache-spark-15dc5fe4de65?source=collection_archive---------8-----------------------#2020-01-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="09c4" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">阿帕奇火花</h2><div class=""/><div class=""><h2 id="3577" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">Apache Spark与Hadoop MapReduce——各有利弊</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/ef567bd8eb042552ec9984abe9c0e283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YwZ1LNRUryd3OHi2tpw9zw.png"/></div></div></figure><h1 id="6529" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">什么是阿帕奇火花？</h1><p id="0166" class="pw-post-body-paragraph lw lx iu ly b lz ma ke mb mc md kh me mf mg mh mi mj mk ml mm mn mo mp mq mr in bi translated">由Spark的创造者创建的公司Databricks在他们的<strong class="ly je"><em class="ms">Apache Spark电子书</em> </strong> ( <em class="ms">强烈推荐阅读——本文末尾提供PDF下载链接</em>)中最好地总结了它的功能:</p><p id="405d" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">“Apache Spark是一个统一的计算引擎和一组用于在计算机集群上进行并行数据处理的库。截至本文撰写之时，Spark是针对该任务开发的最活跃的开源引擎；<strong class="ly je">让它成为任何对大数据感兴趣的开发人员或数据科学家的事实上的工具</strong>。Spark支持多种广泛使用的编程语言(Python、Java、Scala和R)，包括用于各种任务的库，从SQL到流和机器学习，并且可以在任何地方运行，从笔记本电脑到数千个服务器的集群。<strong class="ly je">这使得该系统易于启动，并可扩展至难以置信的大规模大数据处理</strong>。”</p><h1 id="0e68" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">什么是大数据？</h1><p id="4579" class="pw-post-body-paragraph lw lx iu ly b lz ma ke mb mc md kh me mf mg mh mi mj mk ml mm mn mo mp mq mr in bi translated">让我们看看Gartner广泛使用的大数据定义，这样我们就可以理解Spark如何选择解决与大规模实时处理大数据相关的诸多挑战:</p><blockquote class="my"><p id="4f99" class="mz na iu bd nb nc nd ne nf ng nh mr dk translated">“大数据是高容量、高速度和/或高多样性的信息资产，需要经济高效、创新的信息处理形式来增强洞察力、决策制定和流程自动化。”</p></blockquote><figure class="nj nk nl nm nn kx gi gj paragraph-image"><div class="gi gj ni"><img src="../Images/c2032d3a28dd444c012fa209d51869a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*IkNUCp7IbjTqQKRw14VXGg.jpeg"/></div><figcaption class="no np gk gi gj nq nr bd b be z dk translated">复杂的大数据世界</figcaption></figure><blockquote class="ns nt nu"><p id="47c8" class="lw lx ms ly b lz mt ke mb mc mu kh me nv mv mh mi nw mw ml mm nx mx mp mq mr in bi translated"><strong class="ly je">注意:</strong>这里的关键要点是，大数据中的“大”不仅仅是指容量。你不仅会得到大量数据，而且这些数据还会以复杂的格式、从各种来源快速实时地向你袭来。因此，大数据有三个v—<strong class="ly je">量、速度、多样性。</strong></p></blockquote><h1 id="4eb3" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">为什么大多数大数据分析公司在听说spark的所有有用功能时都会“眼前一亮”？</h1><p id="4a5b" class="pw-post-body-paragraph lw lx iu ly b lz ma ke mb mc md kh me mf mg mh mi mj mk ml mm mn mo mp mq mr in bi translated">根据我的初步研究，似乎有三个主要因素使Apache Spark成为大规模高效处理大数据的领导者，这促使许多处理大量非结构化数据的大公司在其堆栈中采用Apache Spark</p><ol class=""><li id="764c" class="ny nz iu ly b lz mt mc mu mf oa mj ob mn oc mr od oe of og bi translated"><strong class="ly je"> Spark是处理大数据的统一一站式商店</strong>—“Spark旨在支持广泛的数据分析任务，从简单的数据加载和SQL查询到机器学习和流计算，通过相同的计算引擎和一致的API集。这一目标背后的主要观点是，现实世界的数据分析任务——无论是Jupyter笔记本等工具中的交互式分析，还是生产应用程序的传统软件开发——往往会结合许多不同的处理类型和库。Spark的统一性质使得这些任务编写起来更加容易和高效”(<em class="ms"> Databricks电子书</em>)。例如，如果您使用SQL查询加载数据，然后使用Spark的ML库对机器学习模型进行评估，引擎可以将这些步骤合并为对数据的一次扫描。此外，<strong class="ly je">数据科学家</strong> <strong class="ly je">在建模时可以从一组统一的库(例如Python或R)中受益</strong>，而<strong class="ly je"> Web开发人员可以从Node.js或Django等统一框架中受益</strong>。</li><li id="c84e" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated"><strong class="ly je"> Spark优化了其核心引擎的计算效率</strong>——“我们的意思是Spark只处理从存储系统加载数据并在其上执行计算，而不是永久存储本身。Spark可以用于各种各样的持久存储系统，包括云存储系统，如Azure Storage和亚马逊S3，分布式文件系统，如Apache Hadoop，键值存储，如Apache Cassandra，以及消息总线，如Apache Kafka。然而，Spark本身既不长期存储数据，也不支持其中任何一种。这里的主要动机是大多数数据已经驻留在混合存储系统中。移动数据的成本很高，因此Spark专注于对数据进行计算，无论数据位于何处”(<em class="ms"> Databricks电子书</em>)。Spark对计算的专注使其不同于早期的大数据软件平台，如Apache Hadoop。Hadoop包括一个存储系统(Hadoop文件系统，设计用于Spark 4商用服务器集群上的低成本存储)和一个计算系统(MapReduce)，它们紧密集成在一起。然而，这种选择使得很难在没有其他系统的情况下运行一个系统，或者更重要的是，很难编写访问存储在其他地方的数据的应用程序。虽然Spark在Hadoop存储上运行良好，但它现在也广泛用于Hadoop架构没有意义的环境，如公共云(存储可以与计算分开购买)或流媒体应用。</li><li id="6188" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated">Spark的库给了它非常广泛的功能 —今天，Spark的标准库是开源项目的主体。自首次发布以来，Spark core引擎本身几乎没有什么变化，但这些库已经发展到提供越来越多类型的功能，将其转变为多功能数据分析工具。Spark包括SQL和结构化数据(Spark SQL)、机器学习(MLlib)、流处理(Spark流和较新的结构化流)和图形分析(GraphX)的库。除了这些库，还有数百个开源外部库，从各种存储系统的连接器到机器学习算法。</li></ol><h1 id="376e" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">Apache Spark vs . Hadoop MapReduce…应该用哪个？</h1><p id="bc25" class="pw-post-body-paragraph lw lx iu ly b lz ma ke mb mc md kh me mf mg mh mi mj mk ml mm mn mo mp mq mr in bi translated">简短的回答是——这取决于您的业务的特定需求，但根据我的研究，似乎10次中有7次答案是——火花。<strong class="ly je"> <em class="ms">对庞大数据集的线性处理</em> </strong>是Hadoop MapReduce的优势，而Spark则提供了<strong class="ly je"> <em class="ms">快速性能</em> </strong>、<strong class="ly je"> <em class="ms">迭代处理、</em> </strong> <strong class="ly je"> <em class="ms">实时分析、图形处理、机器学习等更多</em> </strong>。</p><p id="ccee" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">好消息是，Spark与Hadoop生态系统完全兼容，并且可以与<strong class="ly je"> <em class="ms"> Hadoop分布式文件系统(HDFS) </em> </strong>、Apache Hive等顺利协作。因此，当数据太大，Spark无法在内存中处理时，Hadoop可以通过其HDFS功能帮助克服这一障碍。下面是Spark和Hadoop如何协同工作的可视化示例:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj om"><img src="../Images/693a45cae8e6b87c9ab5f63ea228feb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4fiU1Qo_1tnpGx_fesKGWw.png"/></div></div><figcaption class="no np gk gi gj nq nr bd b be z dk translated"><a class="ae on" href="https://www.quora.com/What-is-the-difference-between-Hadoop-and-Spark" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/Hadoop和Spark的区别是什么</a></figcaption></figure><p id="ec73" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">上图演示了Spark如何通过<strong class="ly je"><em class="ms"/></strong>读取和存储数据、<strong class="ly je"> MapReduce </strong>进行可选处理、<strong class="ly je"> YARN </strong>进行资源分配，从而利用Hadoop的最佳部分。</p><p id="db1b" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">接下来，我将通过一个简单的<strong class="ly je">对比来强调Spark相对于Hadoop MapReduce的诸多优势。</strong></p><h1 id="285e" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">速度</h1><ul class=""><li id="2f4f" class="ny nz iu ly b lz ma mc md mf oo mj op mn oq mr or oe of og bi translated"><strong class="ly je"> <em class="ms"> Apache Spark — </em> </strong>它是一个快如闪电的集群计算工具。与Hadoop  相比，Spark通过减少<strong class="ly je"> </strong>对磁盘的读写周期数并在内存中存储中间数据，在内存和磁盘上运行应用的速度分别提高了100倍和10倍。</li><li id="86b0" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je"><em class="ms">Hadoop MapReduce</em></strong>—MapReduce<strong class="ly je"><em class="ms">从磁盘读写，减缓了</em> </strong>的处理速度和整体效率。</li></ul><h1 id="dd4c" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">易用性</h1><ul class=""><li id="bc08" class="ny nz iu ly b lz ma mc md mf oo mj op mn oq mr or oe of og bi translated"><strong class="ly je"><em class="ms">Apache Spark</em></strong>—Spark的许多库通过<strong class="ly je"> <em class="ms">(弹性分布式数据集)</em> </strong>方便了许多主要高级操作符的执行。</li><li id="0808" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je"> <em class="ms"> Hadoop </em> </strong> —在MapReduce中，开发人员需要手工编码每一个操作，这使得它更难以用于大规模的复杂项目。</li></ul><h1 id="d69a" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">处理大量数据</h1><ul class=""><li id="da16" class="ny nz iu ly b lz ma mc md mf oo mj op mn oq mr or oe of og bi translated"><strong class="ly je"><em class="ms">Apache Spark</em></strong>—由于Spark通过将大部分数据存储在内存中而不是磁盘上来优化速度和计算效率，<strong class="ly je">当数据变得如此之大以至于RAM不足成为一个问题时，它的性能可能不如Hadoop MapReduce </strong> <strong class="ly je">。</strong></li><li id="d3fb" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je"><em class="ms">Hadoop</em></strong>—Hadoop MapReduce允许并行处理海量数据。它将一个大数据块分成几个小数据块，在不同的数据节点上分别处理。如果结果数据集大于可用RAM，Hadoop MapReduce可能会优于Spark。<strong class="ly je">如果处理速度不重要</strong> <strong class="ly je">并且任务可以通宵运行</strong>以便在第二天早上生成结果，这是一个很好的解决方案。</li></ul><h1 id="a76e" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">功能</h1><blockquote class="ns nt nu"><p id="a2ef" class="lw lx ms ly b lz mt ke mb mc mu kh me nv mv mh mi nw mw ml mm nx mx mp mq mr in bi translated">阿帕奇火花在这个类别中是无可争议的赢家。以下是Spark优于Hadoop的许多大数据分析任务列表:</p></blockquote><ul class=""><li id="249e" class="ny nz iu ly b lz mt mc mu mf oa mj ob mn oc mr or oe of og bi translated"><strong class="ly je">迭代处理。</strong>如果任务是反复处理数据——Spark打败Hadoop MapReduce。Spark的弹性分布式数据集(rdd)支持内存中的多个地图操作，而Hadoop MapReduce必须将临时结果写入磁盘。</li><li id="109c" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je">近实时处理。</strong>如果企业需要即时洞察，那么他们应该选择Spark及其内存处理。</li><li id="5bb0" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je">图形处理。</strong> Spark的计算模型适用于图形处理中常见的迭代计算。Apache Spark有GraphX——一个用于图形计算的API。</li><li id="c953" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je">机器学习</strong>。Spark有ml lib——内置的机器学习库，而Hadoop需要第三方提供。MLlib有现成的算法，也可以在内存中运行。</li><li id="45b4" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr or oe of og bi translated"><strong class="ly je">连接数据集。由于其速度，Spark可以更快地创建所有组合，尽管如果需要加入需要大量洗牌和排序的非常大的数据集，Hadoop可能会更好。</strong></li></ul><h2 id="9f52" class="os lf iu bd lg ot ou dn lk ov ow dp lo mf ox oy lq mj oz pa ls mn pb pc lu ja bi translated">Spark的众多功能及其与其他大数据引擎和编程语言的兼容性的直观总结如下:</h2><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pd"><img src="../Images/baf98fc25e6a8e9cd05d577ce661d541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*8OaZK7o_QTHiSayGgRIfBQ.png"/></div><figcaption class="no np gk gi gj nq nr bd b be z dk translated">来源:<a class="ae on" href="https://www.quora.com/Is-Spark-a-component-of-the-Hadoop-ecosystem" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/Is-Spark-a-component-of-the-Hadoop-ecosystem</a></figcaption></figure><ol class=""><li id="35db" class="ny nz iu ly b lz mt mc mu mf oa mj ob mn oc mr od oe of og bi translated"><strong class="ly je"> Spark Core </strong> — Spark Core是大规模并行和分布式数据处理的基础引擎。此外，构建在核心之上的附加库允许流、SQL和机器学习的不同工作负载。它负责内存管理和故障恢复，调度、分发和监控与存储系统交互的集群&amp;上的作业。</li><li id="8fe6" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated"><strong class="ly je">集群管理</strong> —集群管理器用于获取执行作业的集群资源。Spark core运行在不同的集群管理器上，包括Hadoop YARN、Apache Mesos、Amazon EC2和Spark的内置集群管理器。集群管理器处理Spark应用程序之间的资源共享。另一方面，Spark可以访问HDFS、Cassandra、HBase、Hive、Alluxio和任何Hadoop数据源中的数据</li><li id="f38c" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated"><strong class="ly je">Spark Streaming</strong>—Spark Streaming是Spark的组件，用于处理实时流数据。</li><li id="7b3d" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated"><strong class="ly je"> Spark SQL </strong> : Spark SQL是Spark中的一个新模块，它将关系处理与Spark的函数式编程API集成在一起。它支持通过SQL或Hive查询语言查询数据。Spark SQL的数据帧和数据集API为结构化数据提供了更高层次的抽象。</li><li id="ef13" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated">GraphX  : GraphX是用于图形和图形并行计算的Spark API。因此，它用弹性分布式属性图扩展了火花RDD。</li><li id="fc13" class="ny nz iu ly b lz oh mc oi mf oj mj ok mn ol mr od oe of og bi translated"><strong class="ly je"> MLlib </strong>(机器学习):MLlib代表机器学习库。Spark MLlib用于在Apache Spark中执行机器学习。</li></ol><h1 id="e906" class="le lf iu bd lg lh li lj lk ll lm ln lo kj lp kk lq km lr kn ls kp lt kq lu lv bi translated">结论</h1><p id="16ac" class="pw-post-body-paragraph lw lx iu ly b lz ma ke mb mc md kh me mf mg mh mi mj mk ml mm mn mo mp mq mr in bi translated">随着大数据的大规模爆炸和计算能力的指数级增长，Apache Spark和其他大数据分析引擎等工具将很快成为数据科学家不可或缺的工具，并将迅速成为实时执行大数据分析和解决大规模复杂业务问题的行业标准。</p><p id="0a2a" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">如果您喜欢这篇介绍文章，并且想更进一步，开始深入研究如何在Spark中使用分步示例和代码语法构建端到端解决方案，我强烈推荐下面的博客:</p><div class="pe pf gq gs pg ph"><a href="https://neptune.ai/blog/apache-spark-tutorial" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fp"><div class="pj ab pk cl cj pl"><h2 class="bd je gz z fq pm fs ft pn fv fx jd bi translated">Apache Spark教程:开始使用Spark - neptune.ai服务ML模型</h2><div class="po l"><h3 class="bd b gz z fq pm fs ft pn fv fx dk translated">预计到2025年，每天将产生463的数据。数据科学家需要搞清楚…</h3></div><div class="pp l"><p class="bd b dl z fq pm fs ft pn fv fx dk translated">海王星. ai</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv lc ph"/></div></div></a></div><p id="1cf9" class="pw-post-body-paragraph lw lx iu ly b lz mt ke mb mc mu kh me mf mv mh mi mj mw ml mm mn mx mp mq mr in bi translated">对于那些对我博客中描述的所有Spark功能背后的技术感兴趣的人，请点击下面的链接并下载Databricks的电子书—“<strong class="ly je"><em class="ms">Apache Spark的温和介绍”，</em> </strong>或查看下面<strong class="ly je"> <em class="ms">中的“<strong class="ly je"><em class="ms">Apache Spark的大数据分析”。</em>T11】</strong></em></strong></p><div class="pe pf gq gs pg ph"><a href="https://databricks.com/p/ebook/gentle-intro-to-apache-spark?utm_source=databricks&amp;utm_medium=homev2tiletest&amp;_ga=2.185801641.1051240058.1550856188-1502813917.1547430685" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fp"><div class="pj ab pk cl cj pl"><h2 class="bd je gz z fq pm fs ft pn fv fx jd bi translated">Apache Spark简介</h2><div class="po l"><h3 class="bd b gz z fq pm fs ft pn fv fx dk translated">Apache Spark将分析应用程序的速度提高了几个数量级，其多功能性和易用性…</h3></div><div class="pp l"><p class="bd b dl z fq pm fs ft pn fv fx dk translated">databricks.com</p></div></div></div></a></div><div class="pe pf gq gs pg ph"><a href="https://link.springer.com/article/10.1007/s41060-016-0027-9" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fp"><div class="pj ab pk cl cj pl"><h2 class="bd je gz z fq pm fs ft pn fv fx jd bi translated">Apache Spark上的大数据分析</h2><div class="po l"><h3 class="bd b gz z fq pm fs ft pn fv fx dk translated">Salman sall Oum Ruslan Dautov Patrick Joshua zhe Xue Huang评论大数据分析是…</h3></div><div class="pp l"><p class="bd b dl z fq pm fs ft pn fv fx dk translated">link.springer.com</p></div></div><div class="pq l"><div class="pw l ps pt pu pq pv lc ph"/></div></div></a></div></div></div>    
</body>
</html>