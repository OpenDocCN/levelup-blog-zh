# sci kit-å­¦ä¹ å¤‡å¿˜å•(2022)ï¼Œç”¨äºæ•°æ®ç§‘å­¦çš„ Python

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/scikit-learn-cheat-sheet-2022-python-for-data-science-61c0a2e8517b>

## åˆå­¦è€…å­¦ä¹  Scikit çš„ç»å¯¹åŸºç¡€â€”â€”2022 å¹´å­¦ä¹ 

![](img/5195f3ad25fdd2879e91539e0b231c18.png)

æ¥è‡ª Unsplash çš„ç…§ç‰‡ç”± [Tim Stief](https://unsplash.com/photos/YFFGkE3y4F8) æ‹æ‘„

Scikit-learn æ˜¯ Python ç¼–ç¨‹è¯­è¨€çš„å…è´¹è½¯ä»¶æœºå™¨å­¦ä¹ åº“ã€‚å®ƒå…·æœ‰å„ç§åˆ†ç±»ã€å›å½’ã€èšç±»ç®—æ³•ï¼Œä»¥åŠç”¨äºæ•°æ®æŒ–æ˜å’Œæ•°æ®åˆ†æçš„é«˜æ•ˆå·¥å…·ã€‚å®ƒæ„å»ºåœ¨ NumPyã€SciPy å’Œ Matplotlib ä¹‹ä¸Šã€‚

> ***ç« èŠ‚:***1ã€‚[åŸºæœ¬ç¤ºä¾‹](#4e6d)
> 2ã€‚[åŠ è½½æ•°æ®](#cc46)
> 3ã€‚[åŸ¹è®­å’Œæµ‹è¯•æ•°æ®](#aa8f)
> 4ã€‚[é¢„å¤„ç†æ•°æ®](#3446)
> 5ã€‚[åˆ›å»ºä½ çš„æ¨¡å‹](#df83)
> 6ã€‚[æ¨¡å‹æ‹Ÿåˆ](#8c18)
> 7ã€‚[é¢„æµ‹](#2ea8)
> 8ã€‚[è¯„ä¼°ä½ æ¨¡ç‰¹çš„è¡¨ç°](#60b6)
> 9ã€‚[è°ƒæ•´æ‚¨çš„æ¨¡å‹](#022d)

# åŸºæœ¬ç¤ºä¾‹:

ä¸‹é¢çš„ä»£ç æ¼”ç¤ºäº†ä½¿ç”¨ scikit-learn åœ¨ä¸€ç»„æ•°æ®ä¸Šåˆ›å»ºå’Œè¿è¡Œæ¨¡å‹çš„åŸºæœ¬æ­¥éª¤ã€‚

ä»£ç ä¸­çš„æ­¥éª¤åŒ…æ‹¬:åŠ è½½æ•°æ®ï¼Œåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç¼©æ”¾é›†ï¼Œåˆ›å»ºæ¨¡å‹ï¼Œæ ¹æ®æ•°æ®æ‹Ÿåˆæ¨¡å‹ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œæœ€åè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

```
>>> from sklearn import neighbors, datasets, preprocessing
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.metrics import accuracy_score
>>> iris = datasets.load_iris()
>>> X,y = iris.data[:,:2], iris.target
>>> X_train, X_test, y_train, y_test = train_test_split(X,y)
>>> scaler = preprocessing_StandardScaler().fit(X_train)
>>> X_train = scaler.transform(X_train)
>>> X_test = scaler.transform(X_test)
>>> knn = neighbors.KNeighborsClassifier(n_neighbors = 5)
>>> knn.fit(X_train, y_train)
>>> y_pred = knn.predict(X_test)
>>> accuracy_score(y_test, y_pred)
```

# åŠ è½½æ•°æ®

æ‚¨çš„æ•°æ®éœ€è¦æ˜¯æ•°å­—ï¼Œå¹¶å­˜å‚¨ä¸º NumPy æ•°ç»„æˆ– SciPy å¤‡ç”¨çŸ©é˜µã€‚è½¬æ¢æˆæ•°å­—æ•°ç»„çš„å…¶ä»–ç±»å‹ä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„ï¼Œæ¯”å¦‚ Pandas DataFrameã€‚

```
>>> import numpy as np
>>> X = np.random.random((10,5))array([[0.21069686, 0.33457064],
       [0.23887117, 0.6093155 ],
       [0.48848537, 0.62649292]])>>> y = np.array(['A','B','A'])array(['A', 'B', 'A'])
```

# åŸ¹è®­å’Œæµ‹è¯•æ•°æ®

å°†æ•°æ®é›†åˆ†ä¸º X å’Œ y å˜é‡çš„å®šå‹é›†å’Œæµ‹è¯•é›†ã€‚

```
>>> from sklearn.model_selection import train_test_split
>>> X_train,X_test,y_train,y_test = train_test_split(X,y, random_state = 0)
```

# é¢„å¤„ç†æ•°æ®

åœ¨æ¨¡å‹æ‹Ÿåˆä¹‹å‰å‡†å¤‡å¥½æ•°æ®ã€‚

## æ ‡å‡†åŒ–

é€šè¿‡ç§»é™¤å¹³å‡å€¼å¹¶ç¼©æ”¾è‡³å•ä½æ–¹å·®æ¥æ ‡å‡†åŒ–è¦ç´ ã€‚

```
>>> from sklearn.preprocessing import StandardScaler
>>> scaler = StandardScaler().fit(X_train)
>>> standarized_X = scaler.transform(X_train)
>>> standarized_X_test = scaler.transform(X_test)
```

## æ­£å¸¸åŒ–

å…·æœ‰è‡³å°‘ä¸€ä¸ªéé›¶åˆ†é‡çš„æ¯ä¸ªæ ·æœ¬(å³æ•°æ®çŸ©é˜µçš„æ¯ä¸€è¡Œ)ç‹¬ç«‹äºå…¶ä»–æ ·æœ¬è¢«é‡æ–°ç¼©æ”¾ï¼Œä½¿å¾—å…¶èŒƒæ•°ç­‰äº 1ã€‚

```
>>> from sklearn.preprocessing import Normalizer
>>> scaler = Normalizer().fit(X_train)
>>> normalized_X = scaler.transform(X_train)
>>> normalized_X_test = scaler.transform(X_test)
```

## äºŒå€¼åŒ–

æ ¹æ®é˜ˆå€¼å°†æ•°æ®äºŒå€¼åŒ–(å°†ç‰¹å¾å€¼è®¾ç½®ä¸º 0 æˆ– 1)ã€‚

```
>>> from sklearn.preprocessing import Binarizer
>>> binarizer = Binarizer(threshold = 0.0).fit(X)
>>> binary_X = binarizer.transform(X_test)
```

## ç¼–ç åˆ†ç±»ç‰¹å¾

ä½¿ç”¨ä»‹äº 0 å’Œ n_classes-1 ä¹‹é—´çš„å€¼å¯¹ç›®æ ‡æ ‡ç­¾è¿›è¡Œç¼–ç ã€‚

```
>>> from sklearn import preprocessing
>>> le = preprocessing.LabelEncoder()
>>> le.fit_transform(X_train)
```

## è¾“å…¥ç¼ºå¤±å€¼

å¡«è¡¥ç¼ºå¤±å€¼çš„æ’è¡¥è½¬æ¢å™¨ã€‚

```
>>> from sklearn.impute import SimpleImputer
>>> imp = SimpleImputer(missing_values = 0, strategy = 'mean')
>>> imp.fit_transform(X_train)
```

## ç”Ÿæˆå¤šé¡¹å¼è¦ç´ 

ç”Ÿæˆç”±é˜¶æ•°å°äºæˆ–ç­‰äºæŒ‡å®šé˜¶æ•°çš„è¦ç´ çš„æ‰€æœ‰å¤šé¡¹å¼ç»„åˆç»„æˆçš„æ–°è¦ç´ çŸ©é˜µã€‚

```
>>> from sklearn.preprocessing import PolynomialFeatures
>>> poly = PolynomialFeatures(5)
>>> poly.fit_transform(X)
```

# åˆ›å»ºæ‚¨çš„æ¨¡å‹

åˆ›å»ºå„ç§ç›‘ç£å’Œéç›‘ç£å­¦ä¹ æ¨¡å‹ã€‚

# ç›‘ç£å­¦ä¹ æ¨¡å‹

*   çº¿æ€§å›å½’

```
>>> from sklearn.linear_model import LinearRegression
>>> lr  = LinearRegression(normalize = True)
```

*   æ”¯æŒå‘é‡æœº(SVM)

```
>>> from sklearn.svm import SVC
>>> svc = SVC(kernel = 'linear')
```

*   æœ´ç´ è´å¶æ–¯

```
>>> from sklearn.naive_bayes import GaussianNB
>>> gnb = GaussianNB()
```

*   KNN

```
>>> from sklearn import neighbors
>>> knn = neighbors.KNeighborsClassifier(n_neighbors = 5)
```

# æ— ç›‘ç£å­¦ä¹ æ¨¡å‹

*   ä¸»æˆåˆ†åˆ†æ

```
>>> from sklearn.decomposition import PCA
>>> pca = PCA(n_components = 0.95)
```

*   k è¡¨ç¤º

```
>>> from sklearn.cluster import KMeans
>>> k_means = KMeans(n_clusters = 3, random_state = 0)
```

# æ¨¡å‹æ‹Ÿåˆ

å°†ç›‘ç£å’Œéç›‘ç£å­¦ä¹ æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ä¸Šã€‚

# ç›‘ç£å­¦ä¹ 

*   ä½¿æ¨¡å‹ç¬¦åˆæ•°æ®

```
>>> lr.fit(X, y)
>>> knn.fit(X_train,y_train)
>>> svc.fit(X_train,y_train)
```

# æ— ç›‘ç£å­¦ä¹ 

*   ä½¿æ¨¡å‹ç¬¦åˆæ•°æ®

```
>>> k_means.fit(X_train)
```

*   é€‚åº”æ•°æ®ï¼Œç„¶åè½¬æ¢æ•°æ®

```
>>> pca_model = pca.fit_transform(X_train)
```

# é¢„è¨€ï¼›é¢„æµ‹ï¼›é¢„å‘Š

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æµ‹è¯•é›†ã€‚

*   é¢„æµ‹æ ‡ç­¾

```
#Supervised Estimators
>>> y_pred = lr.predict(X_test)#Unsupervised Estimators
>>> y_pred = k_means.predict(X_test)
```

*   ä¼°è®¡æ ‡ç­¾çš„æ¦‚ç‡

```
>>> y_pred = knn.predict_proba(X_test)
```

# è¯„ä¼°æ‚¨çš„æ¨¡å‹çš„æ€§èƒ½

ç¡®å®šæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°å¦‚ä½•çš„å„ç§å›å½’å’Œåˆ†ç±»æŒ‡æ ‡ã€‚

# åˆ†ç±»æŒ‡æ ‡

*   å‡†ç¡®åº¦åˆ†æ•°

```
>>> knn.score(X_test,y_test)
>>> from sklearn.metrics import accuracy_score
>>> accuracy_score(y_test,y_pred)
```

*   åˆ†ç±»æŠ¥å‘Š

```
>>> from sklearn.metrics import classification_report
>>> print(classification_report(y_test,y_pred))
```

*   æ··æ·†çŸ©é˜µ

```
>>> from sklearn .metrics import confusion_matrix
>>> print(confusion_matrix(y_test,y_pred))
```

# å›å½’åº¦é‡

*   ç»å¯¹å¹³å‡è¯¯å·®

```
>>> from sklearn.metrics import mean_absolute_error
>>> mean_absolute_error(y_test,y_pred)
```

*   å‡æ–¹è¯¯å·®

```
>>> from sklearn.metrics import mean_squared_error
>>> mean_squared_error(y_test,y_pred)
```

*   r åˆ†æ•°

```
>>> from sklearn.metrics import r2_score
>>> r2_score(y_test, y_pred)
```

# èšç±»åº¦é‡

*   è°ƒæ•´åçš„å…°å¾·æŒ‡æ•°

```
>>> from sklearn.metrics import adjusted_rand_score
>>> adjusted_rand_score(y_test,y_pred)
```

*   åŒç§

```
>>> from sklearn.metrics import homogeneity_score
>>> homogeneity_score(y_test,y_pred)
```

*   å‚ç›´æµ‹é‡

```
>>> from sklearn.metrics import v_measure_score
>>> v_measure_score(y_test,y_pred)
```

# äº¤å‰éªŒè¯

*   é€šè¿‡äº¤å‰éªŒè¯è¯„ä¼°åˆ†æ•°

```
>>> from sklearn.model_selection import cross_val_score
>>> print(cross_val_score(knn, X_train, y_train, cv=4))
```

# è°ƒæ•´æ‚¨çš„æ¨¡å‹

æ‰¾åˆ°å°†æœ€å¤§åŒ–æ¨¡å‹é¢„æµ‹å‡†ç¡®æ€§çš„æ­£ç¡®å‚æ•°å€¼ã€‚

# ç½‘æ ¼æœç´¢

å¯¹ä¼°è®¡é‡çš„ç‰¹å®šå‚æ•°å€¼çš„ç©·ä¸¾æœç´¢ã€‚ä¸‹é¢çš„ç¤ºä¾‹è¯•å›¾æ‰¾åˆ°ä¸º knn æŒ‡å®šçš„æ­£ç¡®èšç±»æ•°é‡ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

```
>>> from sklearn.model_selection import GridSearchCV
>>> params = {'n_neighbors': np.arange(1,3), 'metric':['euclidean','cityblock']}
>>> grid = GridSearchCV(estimator = knn, param_grid = params)
>>> grid.fit(X_train, y_train)
>>> print(grid.best_score_)
>>> print(grid.best_estimator_.n_neighbors)
```

# éšæœºå‚æ•°ä¼˜åŒ–

è¶…å‚æ•°çš„éšæœºæœç´¢ã€‚ä¸ç½‘æ ¼æœç´¢ç›¸åï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„å‚æ•°å€¼éƒ½è¢«å°è¯•ï¼Œè€Œæ˜¯ä»æŒ‡å®šçš„åˆ†å¸ƒä¸­é‡‡æ ·å›ºå®šæ•°é‡çš„å‚æ•°è®¾ç½®ã€‚å°è¯•çš„å‚æ•°è®¾ç½®çš„æ•°é‡ç”± n_iter ç»™å‡ºã€‚

```
>>> from sklearn.model_selection import RandomizedSearchCV
>>> params = {'n_neighbors':range(1,5), 'weights':['uniform','distance']}
>>> rsearch = RandomizedSearchCV(estimator = knn, param_distributions = params, cv = 4, n_iter = 8, random_state = 5)
>>> rseach.fit(X_train, y_train)
>>> print(rsearch.best_score_)
```

Scikit-learn å¯¹äºå„ç§æœºå™¨å­¦ä¹ æ¨¡å‹æ¥è¯´æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åº“ã€‚ä»¥ä¸Šéƒ¨åˆ†æä¾›äº†åœ¨ä¸åŒæ¨¡å‹ä¸Šæ‰§è¡Œåˆ†æçš„åŸºæœ¬åˆ†æ­¥è¿‡ç¨‹ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œè¯·æŸ¥é˜… [Scikit-Learn](https://scikit-learn.org/stable/) çš„æ–‡æ¡£ï¼Œå› ä¸ºè¿˜æœ‰å¾ˆå¤šæœ‰ç”¨çš„å‡½æ•°å¯ä»¥å­¦ä¹ ã€‚

[**ä¸ 5k ä»¥ä¸Šçš„äººä¸€èµ·åŠ å…¥æˆ‘çš„ç”µå­é‚®ä»¶åˆ—è¡¨ï¼Œå…è´¹è·å¾—â€œå®Œæ•´çš„ Python æ•°æ®ç§‘å­¦å°æŠ„æ‰‹å†Œâ€**](https://pages.christopherzita.com/python-cheat-sheet)

# åˆ†çº§ç¼–ç 

æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:

*   ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰
*   ğŸ“°æŸ¥çœ‹[å‡çº§ç¼–ç å‡ºç‰ˆç‰©](https://levelup.gitconnected.com/?utm_source=pub&utm_medium=post)ä¸­çš„æ›´å¤šå†…å®¹
*   ğŸ””å…³æ³¨æˆ‘ä»¬:[Twitter](https://twitter.com/gitconnected)|[LinkedIn](https://www.linkedin.com/company/gitconnected)|[æ—¶äº‹é€šè®¯](https://newsletter.levelup.dev)

ğŸš€ğŸ‘‰ [**å°†åƒä½ è¿™æ ·çš„å¼€å‘äººå‘˜å®‰ç½®åœ¨é¡¶çº§åˆ›ä¸šå…¬å¸å’Œç§‘æŠ€å…¬å¸**](https://jobs.levelup.dev/talent/welcome?referral=true)