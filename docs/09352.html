<html>
<head>
<title>How to Change Voices Using a PyTorch Implementation of MaskCycleGAN-VC on WSL2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在WSL2上使用MaskCycleGAN-VC的PyTorch实现来改变声音</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-change-voices-using-a-pytorch-implementation-of-maskcyclegan-vc-on-wsl2-8bdfeb1faecb?source=collection_archive---------6-----------------------#2021-07-30">https://levelup.gitconnected.com/how-to-change-voices-using-a-pytorch-implementation-of-maskcyclegan-vc-on-wsl2-8bdfeb1faecb?source=collection_archive---------6-----------------------#2021-07-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1e54" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="77b9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">漂亮简单的教程，一步一步的指导</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c2cc6a083d4d55153b45ae86f96e0c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rctxhHfGcuPPjHl9-pYTFQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="https://unsplash.com/@zvandrei" rel="noopener ugc nofollow" target="_blank">安德烈·萨金塞夫</a></figcaption></figure><h2 id="5010" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">预览:</h2><p id="6a3d" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">| <a class="ae lh" href="https://github.com/GANtastic3/MaskCycleGAN-VC" rel="noopener ugc nofollow" target="_blank"> GitHub </a> | <a class="ae lh" href="https://arxiv.org/pdf/2102.12841.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> | <a class="ae lh" href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/maskcyclegan-vc/index.html" rel="noopener ugc nofollow" target="_blank">音频样本</a> |</p><h2 id="54dd" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">总结:</h2><p id="826d" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">这个库将一个说话者的声音转换成另一个说话者的声音。可以在不同男声之间，不同女声之间，男女声之间变换声音，反之亦然。它还可以使用说出他们自己的句子的每个说话者的非并行数据来训练模型，而不是需要说出相同句子的说话者的并行数据。</p><h2 id="45e9" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">目录:</h2><ol class=""><li id="4779" class="mw mx it mf b mg mh mj mk lr my lv mz lz na mv nb nc nd ne bi translated"><a class="ae lh" href="#8a97" rel="noopener ugc nofollow">知识库背景</a></li><li id="a757" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#0313" rel="noopener ugc nofollow">安装要求</a></li><li id="b056" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#e328" rel="noopener ugc nofollow">安装仓库</a></li><li id="e57f" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#0d0f" rel="noopener ugc nofollow">预处理数据集</a></li><li id="f359" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#012e" rel="noopener ugc nofollow">训练模型</a></li><li id="f022" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#735b" rel="noopener ugc nofollow">恢复训练</a></li><li id="910e" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#3106" rel="noopener ugc nofollow">测试模型</a></li><li id="26fb" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#159e" rel="noopener ugc nofollow">使用自定义数据集测试模型</a></li></ol><h2 id="3b79" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">附录:</h2><ol class=""><li id="bbba" class="mw mx it mf b mg mh mj mk lr my lv mz lz na mv nb nc nd ne bi translated"><a class="ae lh" href="#50ec" rel="noopener ugc nofollow">教程:人工智能设置</a></li><li id="53f8" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#c3c2" rel="noopener ugc nofollow">教程:人工智能课程</a></li><li id="2474" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv nb nc nd ne bi translated"><a class="ae lh" href="#e533" rel="noopener ugc nofollow">教程:人工智能知识库</a></li></ol><h2 id="8a97" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">存储库背景:</h2><p id="57ad" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated"><strong class="mf jd">MaskCycleGAN-VC:</strong>cycle gan-VC2的扩展，它使用非并行语音转换来训练语音转换器，而不需要说出相同句子的说话者的数据。它使用一种称为填充帧的新型辅助任务，将时间掩模应用于输入mel-spectrogram，并鼓励转换器根据周围的帧填充缺失的帧。</p><ul class=""><li id="5a88" class="mw mx it mf b mg nk mj nl lr nm lv nn lz no mv np nc nd ne bi translated">它受到了其他领域方法的启发，如计算机视觉中的图像修复和自然语言处理中的文本填充。</li><li id="35f4" class="mw mx it mf b mg nf mj ng lr nh lv ni lz nj mv np nc nd ne bi translated">它在自然度和说话人相似度方面的得分高于当时公认的基准CycleGAN-VC2和CycleGAN-VC3。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/61f4b256828471b9a038917ef92b693c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNJ1-iZqriFnsrsQ3AKExw.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="https://arxiv.org/pdf/2102.12841.pdf" rel="noopener ugc nofollow" target="_blank"> MaskCycleGAN-VC </a>提供</figcaption></figure><h2 id="0313" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">安装要求:</h2><p id="c600" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">这一节是关于安装操作系统运行特定存储库所需的各种软件。它可以包括更新包管理器、下载包管理器、安装包管理器以及向包管理器授予权限。它还可能涉及对所需的任何程序执行相同的过程。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="7c85" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># open the bash shell on windows</strong><br/>1. press “⊞ windows”<br/>2. enter “wsl” into the search bar<br/>3. click “wsl”</span><span id="1dac" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># update the information about linux programs</strong><br/>sudo apt update</span><span id="0d53" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># upgrade the linux programs</strong><br/>sudo apt --yes upgrade</span><span id="341f" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># set the windows account username</strong><br/>username=$(wslvar username)</span><span id="b44e" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install the linux programs<br/></strong>sudo apt install --yes axel unzip git <!-- -->ffmpeg</span><span id="4f5f" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install the youtube downloader</strong><br/>sudo axel --num-connections 10 --output /usr/local/bin/yt-dlp <a class="ae lh" href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp" rel="noopener ugc nofollow" target="_blank">https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp</a></span><span id="629d" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># grant permissions to the youtube downloader </strong><br/>sudo chmod a+rx /usr/local/bin/yt-dlp</span><span id="ef03" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># download the miniconda package manager<br/></strong>sudo axel --num-connections 10 --output /mnt/c/users/${username}/downloads/miniconda.sh <a class="ae lh" href="https://repo.anaconda.com/miniconda/Miniconda3-4.7.12.1-Linux-x86_64.sh" rel="noopener ugc nofollow" target="_blank">https://repo.anaconda.com/miniconda/Miniconda3-4.7.12.1-Linux-x86_64.sh</a></span><span id="3759" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install the miniconda package manager using the default settings</strong><br/>sudo /mnt/c/users/${username}/downloads/miniconda.sh</span><span id="ea12" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># grant permissions to the miniconda package manager</strong><br/>sudo chown -R $USER:$USER ~/miniconda3</span><span id="6890" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># update the python program information</strong><br/>conda update --all --yes</span><span id="d239" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install virtualenv to create virtual environments</strong><br/>python -m pip install virtualenv</span><span id="43e8" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># reload the bash configuration file</strong><br/>source ~/.bashrc</span></pre><h2 id="e328" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">安装存储库:</h2><p id="e5d7" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">这一节是关于准备在python中运行的存储库。它包括下载存储库、创建虚拟环境、激活虚拟环境以及安装必要的python程序。它还可能涉及从源代码安装存储库，以及使用特定的python包管理器、python版本和python程序版本。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="6810" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># set the windows account username<br/></strong>username=$(wslvar username)</span><span id="f0d0" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># navigate to the desktop directory</strong><br/>cd /mnt/c/users/$username/desktop/</span><span id="93e0" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install the maskcyclegan</strong><strong class="ns jd">-vc</strong><strong class="ns jd"> repository</strong><br/>git clone <a class="ae lh" href="https://github.com/GANtastic3/MaskCycleGAN-VC.git" rel="noopener ugc nofollow" target="_blank">https://github.com/GANtastic3/MaskCycleGAN-VC.git</a></span><span id="8b9a" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># navigate to the maskcyclegan</strong><strong class="ns jd">-vc</strong><strong class="ns jd"> repository<br/></strong>cd MaskCycleGAN-VC</span><span id="638f" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># create the python virtual environment </strong><br/>conda env create -f environment.yml</span><span id="2283" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># activate the python virtual environment</strong><br/>conda activate MaskCycleGAN-VC</span><span id="ad66" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># install an additional python program</strong><br/>conda install --channel conda-forge --yes librosa</span></pre><h2 id="0d0f" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">预处理数据集:</h2><p id="4139" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节是关于准备要加载到模型中的数据集。它包括下载、解包和将数据分成训练集、验证集和测试集。它可能涉及扩充数据、规范化数据、转换数据以及将数据转换成其他格式。它还包括删除不必要的、重复的和不一致的数据。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="f3f8" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># download the training set</strong><br/>axel --insecure --output vcc2018_database_training.zip https://datashare.ed.ac.uk/bitstream/handle/10283/3061/vcc2018_database_training.zip</span><span id="ba48" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># download the evaluation set</strong><br/>axel --insecure --output vcc2018_database_evaluation.zip https://datashare.ed.ac.uk/bitstream/handle/10283/3061/vcc2018_database_evaluation.zip</span><span id="ed8f" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># download the reference data</strong><br/>axel --insecure --output vcc2018_database_reference.zip https://datashare.ed.ac.uk/bitstream/handle/10283/3061/vcc2018_database_reference.zip</span><span id="bd5d" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># make the dataset subdirectory</strong><br/>mkdir -p datasets/vcc2018/</span><span id="0396" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># unzip the training set</strong><br/>unzip vcc2018_database_training.zip -d <!-- -->datasets/<!-- -->vcc2018/</span><span id="dc81" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># unzip the evaluation set</strong><br/>unzip vcc2018_database_evaluation.zip -d <!-- -->datasets/<!-- -->vcc2018/</span><span id="9d46" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># unzip the reference data</strong><br/>unzip vcc2018_database_reference.zip -d <!-- -->datasets/<!-- -->vcc2018/</span><span id="2633" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># move the reference data to the evaluation subdirectory</strong><br/>mv -v datasets/vcc2018/vcc2018_reference/* datasets/vcc2018/vcc2018_evaluation/</span><span id="b3b9" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># remove the reference data subdirectory<br/></strong>rm -rf datasets/vcc2018/vcc2018_reference/</span><span id="9892" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># preprocess the training set<br/></strong>python data_preprocessing/preprocess_vcc2018.py --data_directory datasets/vcc2018/vcc2018_training --preprocessed_data_directory datasets/vcc2018_preprocessed/vcc2018_training --speaker_ids VCC2SF1 VCC2SF2 VCC2SF3 VCC2SF4 VCC2SM1 VCC2SM2 VCC2SM3 VCC2SM4 VCC2TF1 VCC2TF2 VCC2TM1 VCC2TM2</span><span id="f486" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># preprocess the evaluation set<br/></strong>python data_preprocessing/preprocess_vcc2018.py --data_directory datasets/vcc2018/vcc2018_evaluation --preprocessed_data_directory datasets/vcc2018_preprocessed/vcc2018_evaluation --speaker_ids VCC2SF1 VCC2SF2 VCC2SF3 VCC2SF4 VCC2SM1 VCC2SM2 VCC2SM3 VCC2SM4 VCC2TF1 VCC2TF2 VCC2TM1 VCC2TM2</span><span id="90a2" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># make the voices subdirectory</strong><br/>mkdir -p /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/</span><span id="9eb1" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># create a sample file for each of the 12 different voices</strong><br/>cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sf1/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SF1.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sf2/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SF2.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sf3/20001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SF3.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sf4/20001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SF4.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sm1/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SM1.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sm2/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SM2.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sm3/20001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SM3.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2sm4/20001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2SM4.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2tf1/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2TF1.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2tf2/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2TF2.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2tm1/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2TM1.wav; cp /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_training/vcc2tm2/10001.wav /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/VCC2TM2.wav;</span><span id="a269" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># store the wav files in the voices subdirectory</strong><br/>voices_file_list=$(ls /mnt/c/users/${username}/desktop/maskcyclegan-vc/datasets/vcc2018/vcc2018_voices/ | awk -v username="$username" '{print "c:\\users\\"username"\\desktop\\maskcyclegan-vc\\datasets\\vcc2018\\vcc2018_voices\\"$0}')</span><span id="acb3" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># open the wav files in windows media player</strong><br/>"/mnt/c/program files (x86)/windows media player/wmplayer.exe" /Task NowPlaying $voices_file_list</span></pre><h2 id="012e" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">训练模型:</h2><p id="6a58" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节是关于训练模型使用指定的设置进行预测。它可以包括指定预处理数据集位置、预训练模型位置和保存位置。它可以包括指定时期数、学习率和批量大小。它还可能涉及指定存储库特有的各种其他设置。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="5ef8" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># change "VCC2SM1" to one of the 12 speaker ids</strong><br/>speaker_a_id="VCC2SM1"</span><span id="bd09" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># change "VCC2SF1" to one of the 12 speaker ids</strong><br/>speaker_b_id="VCC2SF1"</span><span id="6aee" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># train the model</strong><br/>python -W ignore::UserWarning -m mask_cyclegan_vc.train --name mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id} --seed 0 --save_dir results/ --preprocessed_data_dir datasets/vcc2018_preprocessed/vcc2018_training/ --speaker_A_id ${speaker_a_id} --speaker_B_id ${speaker_b_id} --epochs_per_save 50 --epochs_per_plot 10000 --num_epochs 6172 --batch_size 1 --decay_after 1e4 --sample_rate 22050 --num_frames 64 --max_mask_len 25 --gpu_ids 0</span></pre><h2 id="735b" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">继续培训:</h2><p id="7900" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节是关于从指定的检查点继续训练过程。它可以包括指定检查点位置、类型和纪元编号。它可能涉及指定相同的设置，以便从指定的检查点训练相同的模型。它还可以包括指定不同的设置来微调模型和实现各种训练技术。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="9458" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># continue training the model</strong><br/>python -W ignore::UserWarning -m mask_cyclegan_vc.train --name mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id} --seed 0 --save_dir results/ --preprocessed_data_dir datasets/vcc2018_preprocessed/vcc2018_training/ --speaker_A_id ${speaker_a_id} --speaker_B_id ${speaker_b_id} --epochs_per_save 50 --epochs_per_plot 10000 --num_epochs 6172 --batch_size 1 --decay_after 1e4 --sample_rate 22050 --num_frames 64 --max_mask_len 25 --gpu_ids 0 --continue_train</span></pre><h2 id="3106" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">测试模型:</h2><p id="4c11" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节是关于使用具有指定设置的训练模型来处理验证集中的数据。它可以包括检查日志文件以找到具有最低验证损失值的纪元编号。它可以包括指定检查点位置、类型和纪元编号。它还可能涉及指定存储库特有的各种其他设置。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="5ee6" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># find the epoch number with the lowest "d_loss" value</strong><br/>awk “/epoch:/” results/<!-- -->mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}/mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}<!-- -->.log | awk “NR % 50 == 0”</span><span id="d869" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># replace "500" with the epoch number from the last step</strong><br/>epoch=500</span><span id="1b6c" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># test the model</strong><br/>python -W ignore::UserWarning -m mask_cyclegan_vc.test --name mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id} --save_dir results/ --preprocessed_data_dir datasets/vcc2018_preprocessed/vcc2018_evaluation --gpu_ids 0 --speaker_A_id ${speaker_a_id} --speaker_B_id ${speaker_b_id} --ckpt_dir results/mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}/ckpts --load_epoch ${epoch} --model_name generator_A2B</span><span id="744d" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># review the results<br/></strong>explorer.exe "c:\users\\${username}\desktop\<!-- -->MaskCycleGAN-VC\results\mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}\converted_audio"</span></pre><h2 id="159e" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">使用自定义数据集测试模型:</h2><p id="e8ad" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节是关于使用具有指定设置的训练模型来处理自定义数据集中的数据。它可能涉及查找、下载、转换和转化自定义数据集中的数据。它可以包括指定检查点位置、类型和纪元编号。它还可能涉及指定存储库特有的各种其他设置。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="1d6e" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># select a youtube video that's less than 30 seconds</strong><br/>1. visit the y<a class="ae lh" href="https://www.youtube.com/" rel="noopener ugc nofollow" target="_blank">outube</a> website<br/>2. find a video with good sound quality</span><span id="b6f6" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># change the url to the url of the selected youtube video</strong><br/>url=<a class="ae lh" href="https://www.youtube.com/watch?v=V1QidirATFc" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=V1QidirATFc</a></span><span id="00c9" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># make the custom dataset subdirectory</strong><br/>mkdir datasets/vcc2018/vcc2018_evaluation/CUSTOM</span><span id="b868" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># download the youtube video as a wav file<br/></strong>yt-dlp --extract-audio --audio-format wav -o "datasets/custom/session/%(title)s.%(ext)s" ${url}</span><span id="6951" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># preprocess the custom dataset subdirectory</strong><br/>python data_preprocessing/preprocess_vcc2018.py --data_directory datasets/vcc2018/vcc2018_evaluation --preprocessed_data_directory <!-- -->datasets/<!-- -->vcc2018_preprocessed/vcc2018_evaluation --speaker_ids CUSTOM</span><span id="7ca4" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># test the model using the custom dataset</strong><br/>python -W ignore::UserWarning -m mask_cyclegan_vc.test --name mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id} --save_dir results/ --preprocessed_data_dir datasets/vcc2018_preprocessed/vcc2018_evaluation --gpu_ids 0 --speaker_A_id CUSTOM --speaker_B_id ${speaker_b_id} --ckpt_dir results/mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}/ckpts --load_epoch ${epoch} --model_name generator_A2B</span><span id="ea58" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># review the results</strong><br/>explorer.exe "c:\users\\${username}\desktop\<!-- -->MaskCycleGAN-VC\results\mask_cyclegan_vc_${speaker_a_id}_${speaker_b_id}\converted_audio"</span></pre><blockquote class="ob"><p id="96c2" class="oc od it bd oe of og oh oi oj ok mv dk translated">"最后，记得订阅并按住鼓掌按钮，以获得定期更新和帮助."</p></blockquote><h2 id="876e" class="li lj it bd lk ll ol dn ln lo om dp lq lr on lt lu lv oo lx ly lz op mb mc iz bi translated">附录:</h2><p id="fde1" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">这个博客的存在是为了提供完整的解决方案，回答你的问题，加速你与人工智能相关的进步。它提供了设置计算机和完成fastai课程前半部分所需的一切。它将让你接触到人工智能子领域中最先进的知识库。它也将涵盖fastai课程的后半部分。</p><h2 id="50ec" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">教程:人工智能设置</h2><p id="a074" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本节提供了设置电脑所需的一切。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="5309" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># linux</strong><br/>01. <a class="ae lh" href="https://medium.com/p/916990dabe4b" rel="noopener">install and manage multiple python versions</a><br/>02. <a class="ae lh" href="https://medium.com/p/cd5b3a4f824" rel="noopener">install the nvidia cuda driver, toolkit, cudnn, and tensorrt</a><br/>03. <a class="ae lh" href="https://medium.com/p/b2c14c47b446" rel="noopener">install the jupyter notebook server</a><br/>04. <a class="ae lh" href="https://medium.com/p/1556c8655506" rel="noopener">install virtual environments in jupyter notebook</a><br/>05. <a class="ae lh" href="https://medium.com/p/765678fcb4fb" rel="noopener">install the python environment for ai and machine learning</a><br/>06. <a class="ae lh" href="https://medium.com/p/116415a9df22/" rel="noopener">install the fastai course requirements</a></span><span id="6079" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># wsl 2</strong><br/>01. <a class="ae lh" href="https://medium.com/p/cbdd835612fb" rel="noopener">install windows subsystem for linux 2</a><br/>02. <a class="ae lh" href="https://medium.com/p/1131c4e50a58" rel="noopener">install and manage multiple python versions</a><br/>03. <a class="ae lh" href="https://medium.com/p/9800abd74409" rel="noopener">install the nvidia cuda driver, toolkit, cudnn, and tensorrt</a> <br/>04. <a class="ae lh" href="https://medium.com/p/7c96b3705df1" rel="noopener">install the jupyter notebook server</a><br/>05. <a class="ae lh" href="https://medium.com/p/3e6bf456041b" rel="noopener">install virtual environments in jupyter notebook</a><br/>06. <a class="ae lh" href="https://medium.com/p/612240cb8c0c" rel="noopener">install the python environment for ai and machine learning</a><br/>07. <a class="ae lh" href="https://medium.com/p/95911ee2997f" rel="noopener">install ubuntu desktop with a graphical user interface</a><br/>08. <a class="ae lh" href="https://medium.com/p/15a77fc7e301/" rel="noopener">install the fastai course requirements</a></span><span id="baa6" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># windows 10</strong><br/>01. <a class="ae lh" href="https://medium.com/p/4876738e7aa0" rel="noopener">install and manage multiple python versions</a><br/>02. <a class="ae lh" href="https://medium.com/p/af58647b6d9a/" rel="noopener">install the nvidia cuda driver, toolkit, cudnn, and tensorrt</a><br/>03. <a class="ae lh" href="https://medium.com/p/e8f3e9436044" rel="noopener">install the jupyter notebook server</a><br/>04. <a class="ae lh" href="https://medium.com/p/5c189856479" rel="noopener">install virtual environments in jupyter notebook</a><br/>05. <a class="ae lh" href="https://medium.com/p/23c34b2baf12" rel="noopener">install the python environment for ai and machine learning</a><br/>06. <a class="ae lh" href="https://medium.com/p/90236724f881/" rel="noopener">install the fastai course requirements</a></span><span id="1b10" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># mac<br/></strong>01. <a class="ae lh" href="https://medium.com/p/ca01a5e398d4" rel="noopener">install and manage multiple python versions</a><br/>02. <a class="ae lh" href="https://medium.com/p/2a276f679e0" rel="noopener">install the jupyter notebook server</a><br/>03. <a class="ae lh" href="https://medium.com/p/e3de97491b3a" rel="noopener">install virtual environments in jupyter notebook</a><br/>04. <a class="ae lh" href="https://medium.com/p/2b2353d7bcc3" rel="noopener">install the python environment for ai and machine learning</a><br/>05. <a class="ae lh" href="https://medium.com/p/90fdd524bc82" rel="noopener">install the fastai course requirements</a></span></pre><h2 id="c3c2" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">教程:人工智能课程</h2><p id="2c40" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本部分包含每课结束时对问卷的回答。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="05fc" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># fastai course<br/></strong>01. <a class="ae lh" href="https://medium.com/p/6f266bdb1340/" rel="noopener">chapter 1: your deep learning journey q&amp;</a>a<br/>02. <a class="ae lh" href="https://medium.com/p/5a0902207f5b" rel="noopener">chapter 2: from model to production q&amp;a</a><br/>03. <a class="ae lh" href="https://medium.com/p/501bb37ca30d" rel="noopener">chapter 3: data ethics q&amp;a</a><br/>04. <a class="ae lh" href="https://medium.com/p/89077906197e/" rel="noopener">chapter 4: under the hood: training a digit classifier q&amp;a</a><br/>05. <a class="ae lh" href="https://medium.com/p/aa7cacdeab1/" rel="noopener">chapter 5: image classification q&amp;a</a><br/>06. <a class="ae lh" href="https://medium.com/p/aa7cacdeab1/" rel="noopener">chapter 6: other computer vision problems q&amp;a</a><br/>07. <a class="ae lh" href="https://medium.com/p/6f6dcc83dd9f/" rel="noopener">chapter 7: training a state-of-the-art model q&amp;a</a><br/>08. <a class="ae lh" href="https://medium.com/p/52d3583d626b/" rel="noopener">chapter 8: collaborative filtering deep dive q&amp;a</a></span></pre><h2 id="e533" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">教程:人工智能库</h2><p id="9b18" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">这个部分包含不同子领域中的最先进的知识库。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="548e" class="li lj it ns b gy nw nx l ny nz"><strong class="ns jd"># repositories related to audio<br/></strong>01. <a class="ae lh" href="https://medium.com/p/e3dd979056e0/" rel="noopener">raise audio quality using nu-wave</a><br/>02. <a class="ae lh" href="https://medium.com/p/8bdfeb1faecb/" rel="noopener">change voices using maskcyclegan-vc</a><br/>03. <a class="ae lh" href="https://medium.com/p/7b8609438001/" rel="noopener">clone voices using real-time-voice-cloning toolbox</a></span><span id="8b94" class="li lj it ns b gy oa nx l ny nz"><strong class="ns jd"># repositories related to images</strong><br/>01. <a class="ae lh" href="https://medium.com/p/9c9fefb3f863/" rel="noopener">achieve 90% accuracy using facedetection-dsfd</a></span></pre></div></div>    
</body>
</html>