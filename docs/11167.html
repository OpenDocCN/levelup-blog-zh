<html>
<head>
<title>Databricks CI/CD using Azure DevOps: Part I, CI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Azure DevOps的数据块CI/CD:第一部分，CI</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/databricks-ci-cd-using-azure-devops-part-i-ci-e9cacd89b6c2?source=collection_archive---------1-----------------------#2022-02-22">https://levelup.gitconnected.com/databricks-ci-cd-using-azure-devops-part-i-ci-e9cacd89b6c2?source=collection_archive---------1-----------------------#2022-02-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="95f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于多数据块环境的CI/CD系统的系列文章的第一部分，包括使用Azure DevOps的测试、包、笔记本和init脚本</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/b24e5d5783a280be655595c90fe203a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17rWphWg3R1C6FeLRyRyew.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk translated">使用<strong class="bd lb"> Azure DevOps </strong>的<strong class="bd lb">数据块CI/CD </strong>的概要</figcaption></figure><p id="3cc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Databricks </strong> —一个最初围绕Spark构建的平台，通过引入Lakehouse概念、Delta表和许多其他最新的行业发展，已经成功成为满足数据科学和数据工程需求的领导者之一。尽管开始使用<strong class="jp ir"> Databricks </strong>非常容易，但由于<strong class="jp ir"> Spark </strong>的语言灵活性(它支持<strong class="jp ir"> Scala </strong>、<strong class="jp ir"> Python </strong>、<strong class="jp ir"> Java </strong>、<strong class="jp ir"> SQL </strong>和<strong class="jp ir"> R </strong>)以及笔记本的用户友好性，使其成为生产级工具并不是一项简单的任务，当然需要一些努力。在这个由两部分组成的系列文章中，我将概述如何使用<strong class="jp ir"> Azure DevOps </strong>为<strong class="jp ir">数据块</strong>构建一个完整的<strong class="jp ir"> CI/CD </strong>系统。</p><h1 id="8424" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">TLDR——给我看看代码</h1><p id="a0e9" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">用于此<strong class="jp ir"> CI/CD </strong>流程的所有代码可在以下网址找到:</p><p id="e42b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd" rel="noopener ugc nofollow" target="_blank">https://github.com/szymonzaczek/databricks-ci-cd</a></p><p id="7604" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">免责声明:</strong> <strong class="jp ir">我没有包含任何将在data brick集群上运行的实际data brick相关代码，我只是分享CI/CD流程。</strong></p><p id="250f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在深入解释如何处理作品之前，让我简单地告诉你为什么我们在<a class="ae me" href="https://ecovadis.com/" rel="noopener ugc nofollow" target="_blank"> Ecovadis </a>中需要这样一个工具。</p><h1 id="cd4f" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">为什么Ecovadis中的数据块需要CI/CD系统？</h1><p id="7fcd" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">Ecovadis是一家为供应链企业提供环境、可持续性和道德评估的公司。随着市场的快速增长和公司规模的扩大，我们显然需要改变数据工程解决方案的方法，以防止成为业务需求的瓶颈。这就是为什么我们一直致力于实现<strong class="jp ir">数据网格</strong>架构，其中每个域都处理自己的数据。我们决定在新方法中使用的核心技术组件之一是<strong class="jp ir">数据块</strong>。</p><p id="39bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，对<strong class="jp ir"> git </strong>库的原生支持被引入其中，但代码版本化只是我们需求的冰山一角——从分散在不同业务领域的许多repos中的许多内部制作的Python包驱动的过多笔记本的角度来看……嗯，我希望你明白这一点——如果没有一个针对与<strong class="jp ir">数据块</strong>相关的代码的简化的<strong class="jp ir"> CI/CD </strong>系统，我们很快就不能提供任何新的功能，相反，我们将被处理与日常操作相关的错误和问题所淹没我们的未来不会很光明，不是吗？尽管如此，我还是强烈推荐看看Ecovadis，这是一家提供旨在解决环境和社会挑战的服务的伟大公司，我们也碰巧在这方面使用了非常酷的技术，我希望你通过阅读这篇文章很快就会发现！</p><div class="mf mg gp gr mh mi"><a href="https://ecovadis.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd ir gy z fp mn fr fs mo fu fw ip bi translated">业务可持续性评级| EcoVadis</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">评估企业社会责任和可持续采购的评级平台。解决方案包括风险…</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">ecovadis.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw kv mi"/></div></div></a></div><p id="8c7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事不宜迟，让我们使用<strong class="jp ir"> Azure DevOps </strong>进入<strong class="jp ir"> CI/CD </strong>系统获取<strong class="jp ir">数据块</strong>。首先，我将概述<strong class="jp ir"> CI </strong>和<strong class="jp ir"> CD </strong>的具体目标。</p><h1 id="9d7b" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">CI的具体目标</h1><ul class=""><li id="a88c" class="mx my iq jp b jq lz ju ma jy mz kc na kg nb kk nc nd ne nf bi translated">在运行CI管道的代理上安装所有Python依赖项</li><li id="453f" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">从所有<code class="fe nl nm nn no b">setup.py</code>文件中构建<code class="fe nl nm nn no b">wheel</code>文件</li><li id="3525" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">运行所有可用的测试文件</li><li id="8ee1" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">发布测试结果</li><li id="b4d8" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">为<strong class="jp ir">数据块集群</strong>创建初始化脚本</li><li id="a50a" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">将所有东西打包成一个工件</li><li id="88d5" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">发布工件</li></ul><h1 id="bf87" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">裁谈会的具体目标</h1><ul class=""><li id="5b62" class="mx my iq jp b jq lz ju ma jy mz kc na kg nb kk nc nd ne nf bi translated">与多个<strong class="jp ir">环境</strong> / <strong class="jp ir">数据块工作区</strong>无缝集成</li><li id="2d1a" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">在指定的<strong class="jp ir">数据块集群</strong>上安装所有Python依赖项</li><li id="a6cd" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">上传在<strong class="jp ir"> CI </strong>步骤中构建的包(<code class="fe nl nm nn no b">wheel</code>文件)</li><li id="d236" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">将初始化脚本上传到Databricks工作区</li><li id="3bd9" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated">将笔记本上传到Databricks工作区</li></ul><h1 id="7395" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">CI/CD中包含的数据块功能</h1><p id="7ac5" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated"><strong class="jp ir">本文介绍的CI/CD </strong>系统将侧重于:</p><ul class=""><li id="5052" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir"> Python库</strong></li></ul><p id="aa60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">构建</strong>(创建<code class="fe nl nm nn no b">.whl</code>文件)和<strong class="jp ir">单元测试</strong>Python包，这些包将包含满足您的数据工程和数据科学需求的任何类和函数。</p><ul class=""><li id="df95" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir">笔记本</strong></li></ul><p id="b5f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">他们最好广泛使用定制的库(应该与这个CI/CD进程挂钩)或可从<strong class="jp ir"> pypi安装的库。</strong>我建议尽可能保持简洁，而将主要代码存储在Python包中；在这个过程中，<strong class="jp ir"> Python </strong>和<strong class="jp ir"> SQL </strong>笔记本都被支持。</p><ul class=""><li id="50fe" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir">初始化脚本</strong></li></ul><p id="1baa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Init脚本通常包含您将使用的任何非标准设置，包括安装定制的库、pip可安装的包、repo中指定的需求或任何附加的spark变量。它们非常有用，因为它们可以与作业集群和实例池一起使用，这可以显著降低使用<strong class="jp ir">数据块</strong>的成本。</p><h1 id="1ecb" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">CI/CD中使用的基于Azure的工具</h1><p id="0ecb" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">在这个CI/CD系统中，我们利用了以下<strong class="jp ir"> Azure </strong>服务:</p><ul class=""><li id="0fcb" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir"> Azure DevOps </strong> <br/> -存储库<br/> - yaml管道(<strong class="jp ir"> CI </strong> ) <br/> -工件<br/> -测试<br/> -发布(<strong class="jp ir"> CD </strong>)</li><li id="0d9a" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated"><strong class="jp ir"> Azure的KeyVault </strong></li><li id="c955" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated"><strong class="jp ir"> Azure的应用注册(服务主体)</strong></li><li id="618f" class="mx my iq jp b jq ng ju nh jy ni kc nj kg nk kk nc nd ne nf bi translated"><strong class="jp ir"> Azure的数据块工作区</strong></li></ul><h1 id="610e" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">CI/CD中使用的基于代码的工具</h1><p id="9ecd" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">为了调整CI/CD流程以满足我们的需求，我采用了以下基于代码的工具:</p><ul class=""><li id="cbd4" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir"> JSON配置</strong>—Azure devo PS变量的替代</li></ul><p id="b9e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">整个进程的配置存在于单个<strong class="jp ir"> JSON </strong>文件中。显然，不应该将任何敏感信息放在那里，例如连接字符串或秘密——它们应该存储在<strong class="jp ir"> Keyvault </strong>中，并在需要时由管道检索。在<strong class="jp ir"> Azure DevOps </strong>中使用配置的标准方法可能是使用<strong class="jp ir">变量组</strong>，然而，由于这些变量的历史无论如何都不会保留，它们可以从代码中单独更改，这意味着单个拉请求不足以让您的代码得到部署——您需要记住并(正确地)在Azure DevOps中添加/更改这些变量，否则<strong class="jp ir"> CI/CD </strong>管道可能会失败。我和我的同事们已经与它们进行了激烈的斗争，为了我们的目的，JSON configs工作得更好。</p><p id="5fcc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> JSON </strong>配置示例:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="14cb" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir">数据块API </strong></li></ul><p id="07e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了让您宝贵的代码进入Databricks工作区，在那里它可以真正地生活和工作，我们将利用一个强大的<strong class="jp ir"> Databricks API </strong>。它将用于与在<code class="fe nl nm nn no b">config.json</code>中定义的工作区通信，它将允许把你的库、它的需求、笔记本和init脚本放到所有正确的地方。为了让这种交流顺利进行，我写了一些函数和类，我很快会和大家分享。<strong class="jp ir"> Databricks API </strong>将在<strong class="jp ir"> CD </strong>的相关文章中大量使用，即将问世。</p><ul class=""><li id="75f0" class="mx my iq jp b jq jr ju jv jy np kc nq kg nr kk nc nd ne nf bi translated"><strong class="jp ir">数据块连接(数据库连接)</strong></li></ul><p id="601e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Databricks Connect </strong>是一个允许将本地运行的代码连接到Databricks <strong class="jp ir"> </strong>集群的库。在这里，它用于测试目的——作为包的一部分编写的单元测试将使用dbconnect进行测试。与直接在数据块<strong class="jp ir"> </strong>上运行代码相比，它有一些限制，在这里列出:<a class="ae me" href="https://docs.databricks.com/dev-tools/databricks-connect.html#limitations" rel="noopener ugc nofollow" target="_blank">数据块-连接-限制</a>。尽管如此，当使用dbconnect作为<strong class="jp ir"> CI </strong>管道的一部分时，没有代码被部署到data bricks——data bricks只是用作本地代码的运行时，这就是我选择在这里使用它的原因。使用时，请确保使用匹配版本的数据库连接<strong class="jp ir"> </strong>和数据块运行时(<a class="ae me" href="https://docs.databricks.com/dev-tools/databricks-connect.html#requirements" rel="noopener ugc nofollow" target="_blank">数据块连接需求</a>)。</p><h1 id="8534" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">代码结构</h1><p id="44c5" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这个CI/CD过程将对代码的结构做出一些假设，尽管您显然可以根据您的具体需求对其进行裁剪。它的设计目标是成为一个可扩展的工具，将各种新的Python包和附带的笔记本引入到不同的Databricks工作区，而这些不同的包存在于单个git存储库中。这样，只要您的数据块相关代码遵循标准的线性环境方法，您就可以完全控制何时将给定的<strong class="jp ir"> PR </strong>的结果部署到下一个环境。显然，如果你在一个大型的工程师团队中工作，同时处理不同的功能，将你的代码分成不同的库可能是一个更好的主意，但是这是你自己的决定。在这种情况下，你仍然可以使用我在这里分享的发布过程，但是你可以跳过在单个repo中将你的代码分割成多个包。正如我前面提到的，你可以(也应该！)定制所展示的流程，以满足您的确切需求。</p><p id="3480" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在主项目目录(<a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd" rel="noopener ugc nofollow" target="_blank"> databricks-ci-cd </a>)中，除了一个配置文件，<code class="fe nl nm nn no b">README.md</code>文件，一个有用的<code class="fe nl nm nn no b">.gitignore</code>文件，还有一个<code class="fe nl nm nn no b">azure-pipelines.yml</code>文件。该文件是一个实际的<strong class="jp ir"> CI </strong>流程——它包含将在<strong class="jp ir"> Azure DevOps </strong>代理上执行的步骤，这些步骤将生成一个已构建并经过测试的工件，该工件已准备好部署到<strong class="jp ir"> Databricks </strong>工作区。</p><p id="202f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除此之外，项目中的每个包都应该有一个指定的需求目录，其中包含<code class="fe nl nm nn no b">common.txt</code>和<code class="fe nl nm nn no b">dev.txt</code>文件(<a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd/tree/master/package1/requirements" rel="noopener ugc nofollow" target="_blank">需求</a>)。<code class="fe nl nm nn no b">common.txt</code>文件应包含对运行开发包至关重要的需求，而<code class="fe nl nm nn no b">dev.txt</code>文件将包含任何对您的工作有帮助但对包的功能不重要的附加包，如linter/格式化工具、测试包等。</p><p id="be63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后但同样重要的是，该项目包含<code class="fe nl nm nn no b">ci_cd_scripts</code>目录(<a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd/tree/master/ci_cd_scripts" rel="noopener ugc nofollow" target="_blank"> ci-cd-scripts </a>)。它是一个Python脚本的集合，将帮助整个CI/CD过程，例如将JSON文件输出到bash变量中，建立路径需求和笔记本目录，以及与Databricks API本身的通信。基本上，它将包含流程本身的所有支持代码，而不是在数据块上实际执行任何操作的代码。<code class="fe nl nm nn no b">ci_cd_scripts</code>目录的内容是平面的——所有的脚本都直接存在于这个目录中，没有进一步的代码划分为子模块——这是因为Python代码并不意味着既作为模块/子模块运行，也作为脚本运行(<a class="ae me" href="https://stackoverflow.com/questions/14132789/relative-imports-for-the-billionth-time" rel="noopener ugc nofollow" target="_blank">相对导入</a>)。</p><p id="94d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些脚本被编写为<strong class="jp ir">命令行应用程序(CLI)</strong>——它们将作为脚本从shell中运行，它们接受各种参数，这些参数可以是在Azure DevOps代理上分配的字符串或bash变量(例如，<code class="fe nl nm nn no b">json.config</code>的内容将被映射到bash变量上)。虽然它们很可能是更好的方法，但是我使用标准的<code class="fe nl nm nn no b">sys</code>模块来编写那些<strong class="jp ir"> </strong> CLI <strong class="jp ir"> </strong>脚本——对于这个过程来说，这是完全可行的。</p><p id="5ca5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">整个目录和文件结构可能如下所示:</p><pre class="km kn ko kp gt nu no nv nw aw nx bi"><span id="66bb" class="ny ld iq no b gy nz oa l ob oc">project<br/>│   README.md<br/>│   azure-pipelines.yml   <br/>│   config.json<br/>│   .gitignore<br/>└─── package1<br/>│       │   __init__.py<br/>│       │   setup.py<br/>│       │   README.md<br/>│       │   file.py<br/>│       └── submodule<br/>│       │      │   file.py<br/>│       │      │   file_test.py     <br/>│       └── requirements<br/>│       │      │   common.txt<br/>│       │      │   dev.txt<br/>│       └─  notebooks<br/>│              │   notebook1.txt<br/>│              │   notebook2.txt<br/>└─── package2<br/>|       │   ...<br/>└─── ci_cd_scripts<br/>        │   requirements.py<br/>        │   script1.py<br/>        │   script2.py<br/>        │   ...</span></pre><p id="6319" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">显然，在这里我试图创建一个尽可能健壮的versataile结构，但是你可以根据你的需要很容易地定制它——例如，为了在主项目目录中有一个<code class="fe nl nm nn no b">setup.py</code>,并在存储库中的所有包中构建一个库，你所需要做的就是在<code class="fe nl nm nn no b">azure-pipelines.yml</code>中改变一个引用，你就可以处理你的情况了。</p><h1 id="fbbe" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">持续集成CI</h1><p id="1c56" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated"><strong class="jp ir"> CI </strong>流程的一部分被默认设置为在<code class="fe nl nm nn no b">dev</code>环境下运行(如<code class="fe nl nm nn no b">config.json</code>中所定义)——这意味着它将连接到分配给该环境的Keyvault，它将使用<code class="fe nl nm nn no b">dev</code> Databricks workspace等。当然，如果你的用例是不同的，你可能会改变它，因为你觉得合适。</p><h2 id="f07c" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">Azure的神器</h2><p id="2a28" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">在设置Azure的管道之前，您应该为您的工件创建一个feed，并将Universal package连接到它——我发现这个选项最适合我的特定需求，因为它允许自动处理包版本。有关这方面的更多信息，请参考<a class="ae me" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/artifacts/universal-packages?toc=%2Fazure%2Fdevops%2Fartifacts%2Ftoc.json&amp;bc=%2Fazure%2Fdevops%2Fartifacts%2Fbreadcrumb%2Ftoc.json&amp;view=azure-devops&amp;tabs=yaml" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="d724" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">服务主体</h2><p id="39ae" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">作为所呈现的<strong class="jp ir"> CI </strong>管道的一部分，在<strong class="jp ir"> Azure DevOps </strong>代理和其他Azure的服务——<strong class="jp ir">key vault</strong>和<strong class="jp ir"> Azure CLI </strong>之间有一个连接。为了使流程正常工作，Azure DevOps和Azure Resource Manager之间必须有一个适当订阅的连接。要进行设置，请参考<a class="ae me" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/connect-to-azure?view=azure-devops" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="281f" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated"><strong class="ak">基于代码部分的布局</strong></h2><p id="c8ab" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">整个<strong class="jp ir"> CI </strong>流程在<code class="fe nl nm nn no b">azure-pipelines.yml</code>中定义。我将在相关的<strong class="jp ir"> Python </strong>脚本中分享每个讨论步骤的代码片段，但是您可以随时在<a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd" rel="noopener ugc nofollow" target="_blank"> databricks-ci-cd </a>上参考整个存储库。</p><p id="21bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，<code class="fe nl nm nn no b">azure-pipelines.yml</code>中的大部分步骤看起来与此相似:</p><pre class="km kn ko kp gt nu no nv nw aw nx bi"><span id="9f75" class="ny ld iq no b gy nz oa l ob oc">- script: | <br/>   python ci_cd_scripts/file1_cli.py arguments<br/>displayName: 'Set env variables from JSON cfg file'</span></pre><p id="623f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着运行<strong class="jp ir"> CI </strong>管道的Azure DevOps代理正在运行带有<code class="fe nl nm nn no b">arguments</code>的<code class="fe nl nm nn no b">ci_cd_scripts/file1_cli.py</code> Python文件。当给定的Python文件第一次出现在代码中时，我包含了它们的代码，并且我尽了最大努力提供了管道中每一步的简要说明。</p><h2 id="b93e" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">CI设置</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="ea25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何运行<strong class="jp ir"> CI </strong>流程首先要考虑的是确定<code class="fe nl nm nn no b">trigger</code>的类型。我决定使用<code class="fe nl nm nn no b">trigger</code>，这里使用的是pushed分支中的管道版本。这里，流水线被触发用于<code class="fe nl nm nn no b">release*</code>和<code class="fe nl nm nn no b">main</code>分支。更多信息请参考<a class="ae me" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/build/triggers?view=azure-devops" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="5f8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来要做的是决定由哪个代理来管理你的管道。说实话，我对PowerShell不是很熟悉，因此我求助于标准的Ubuntu机器。</p><p id="b618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还对Python版本使用了矩阵策略——基本上，这意味着如果我在这里指定了多个Python版本，管道将会运行多次。在这里，如果需要使用一个以上的Python版本，它只是作为一个简单的工具来扩展代码测试。</p><h2 id="cbf5" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">正在读取配置</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c6a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">azure_pipeline.yml</code>的这段代码运行<code class="fe nl nm nn no b">ci_cd_scripts/read_config_cli.py</code>文件，传递<code class="fe nl nm nn no b">config.json</code>作为参数。</p><p id="edf4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">read_config_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="dc97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">read_config.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="8f29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这部分管道将<code class="fe nl nm nn no b">config.json</code>的内容设置为正在运行的<strong class="jp ir"> Azure DevOps </strong>代理会话上的bash变量。所以基本上这允许稍后从bash控制台本身引用变量，这在处理各种环境时非常方便。</p><h2 id="51fe" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">从Keyvault的</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="1e42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keyvault中的秘密可以使用我们之前设置的服务连接来检索(<strong class="jp ir">不要</strong>将秘密放在代码版本化的存储库中！).我倾向于使用的密钥库通常位于防火墙之后，因此，为了实现这一点，我们需要将运行我们管道的代理的IP列入白名单。通过这样使用它，来自Keyvault的秘密被映射到bash变量——就像之前从一个<strong class="jp ir"> JSON </strong>文件中读取的配置一样。如果你试图访问的Keyvault不在防火墙后面，可以跳过白名单。</p><p id="b955" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以在<strong class="jp ir"> Keyvault </strong>中放入任意多的参数——该脚本将下载所有参数(如果您只想下载特定的秘密，只需更改<code class="fe nl nm nn no b">SecretsFilter</code>)。不过，在这个CI流程中，我们将使用<code class="fe nl nm nn no b">databricks_token</code>secret——这是一个<strong class="jp ir">个人访问令牌</strong>,您可以在<strong class="jp ir"> Databricks UI </strong>中直接生成。有关如何操作的更多说明，请参考<a class="ae me" href="https://docs.databricks.com/dev-tools/api/latest/authentication.html" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="eb24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">取回机密后，我们应该从<strong class="jp ir">密钥库</strong>白名单中删除代理的IP——我们不希望未经授权的人访问我们宝贵的机密，不是吗？</p><h2 id="19aa" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">查找Python包的要求</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="b06e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在安装依赖项之前，让我们确保<code class="fe nl nm nn no b">pip</code>已经升级并且轮子已经安装在其中。</p><p id="06d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">find_files_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="5e88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">find_files.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c114" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用<code class="fe nl nm nn no b">find_files_cli.py</code>来建立repo中需求目录的路径。我以这样的方式写了这个脚本，作为第一个参数，你必须提供你想调用的函数，然后你提供必要的参数。在函数<code class="fe nl nm nn no b">find_files_in_nested_dir_job()</code>的情况下，您提供工作目录、嵌套目录的深度(项目结构中有多少个目录)、您将在其中查找单个文件的嵌套目录(在本例中为<code class="fe nl nm nn no b">requirements</code>)、您正在查找的文件的扩展名(在这里为<code class="fe nl nm nn no b">txt</code>)，以及可选的文件名(没有扩展名)和用于命名bash变量的后缀。像我在这里做的那样运行这个脚本将导致在Azure DevOps代理上创建一个bash变量，该变量将存储包内模块的<code class="fe nl nm nn no b">requirements</code>子目录中带有<code class="fe nl nm nn no b">txt</code>扩展名的文件的绝对路径。这是通过调用以下代码行来实现的:</p><p id="9e72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">print(f”##vso[task.setvariable variable={variable_name}]{string_output}”)</code></p><p id="4311" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如<code class="fe nl nm nn no b">find_files.py</code>中<code class="fe nl nm nn no b">output_list_as_bash_variable_ado()</code>功能所定义。Azure DevOps代理上Python代码中的这种打印内容为一个名为<code class="fe nl nm nn no b">variable_name</code>的bash变量赋值<code class="fe nl nm nn no b">string_output</code>。尽管这种方式看起来有点不太好，但这是我发现的从Python脚本内部分配bash变量的最佳方式。当然，这个bash变量将只包含string(当导出变量到bash时，Python类型将不被保留),但是它的内容将非常容易恢复，通过调用<code class="fe nl nm nn no b">string.split(',')</code>函数，这将产生一个整洁的列表，其中包含从需求目录到文件的路径。猜猜会发生什么——通过这样的设置，同一个项目中的多个包被一起处理！是不是很酷？</p><p id="d065" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">需求bash变量内容的一个例子:</p><p id="a5db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">/home/vsts/work/1/s/module/requirements/common.txt,/home/vsts/work/1/s/module/requirements/dev.txt</code></p><p id="0549" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以请注意，实际上有两个文件输出到这个变量。</p><h2 id="35b5" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">在本地安装Python需求</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="165a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">process_requirements_locally_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="15c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">process_requirements_locally.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="cec0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦建立了所有需求文件的路径，我们就可以继续安装它们了。为了正确地处理它，我再次求助于一个简短的CLI Python脚本，它与参数一起被调用，参数是一个bash变量，包含需求文件的路径和我们希望安装哪种依赖项。因为现在这样做是为了测试的目的，所以我在这里选择了<code class="fe nl nm nn no b">dev</code>需求——这意味着模块的<code class="fe nl nm nn no b">requirements</code>目录中的任何<code class="fe nl nm nn no b">dev.txt</code>文件中指定的所有依赖项都将被本地安装。</p><h2 id="82a6" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">查找setup.py文件</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="cc3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将再次利用<code class="fe nl nm nn no b">find_files_cli.py</code>，但这一次是为了找到<code class="fe nl nm nn no b">setup.py</code>文件，然后用它们构建<code class="fe nl nm nn no b">wheel</code>文件。我们指定工作目录、嵌套目录的深度(这里是1，因为我们要在项目的下一个目录中查找文件)、<code class="fe nl nm nn no b">None</code>作为字符串(在函数内部解析为通配符<code class="fe nl nm nn no b">**</code>)、<code class="fe nl nm nn no b">py</code>用作扩展名，最后<code class="fe nl nm nn no b">setup</code>用作扩展名之前的文件名，这导致将<code class="fe nl nm nn no b">setup.py</code>文件的路径输出到Azure DevOps代理上的bash变量<code class="fe nl nm nn no b">setup_files</code>。</p><p id="a75a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">setup_files</code>变量的一个例子:</p><p id="0c12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">/home/vsts/work/1/s/package1/setup.py</code></p><h2 id="8b91" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">在本地构建包</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="41fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">build_packages_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f281" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">build_packages.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="b6b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">构建<code class="fe nl nm nn no b">wheel</code>文件的标准方式是在终端中运行<code class="fe nl nm nn no b">python setup.py bdist_wheel</code>。为此，我求助于使用<code class="fe nl nm nn no b">subprocess</code> Python模块——这样我可以非常容易地利用我在上一步中创建的<code class="fe nl nm nn no b">setup_files</code> bash变量。通过将<code class="fe nl nm nn no b">sys.executable</code>传递给<code class="fe nl nm nn no b">subprocess.check_call()</code>，我们确保了我们在这项工作中使用了正确的Python解释器。运行这个脚本会为我们项目中的任何包生成<code class="fe nl nm nn no b">wheel</code>文件，因此您编写的代码已经正式变成了可安装的Python库。有了这个，你可以非常容易地在任何你想要的地方使用你的Python代码——例如，你可以使用Databricks UI将它直接上传到Databricks集群。另一方面，你可以继续阅读，找出自动完成这项工作的方法。然而，在此之前，我们应该<strong class="jp ir">测试</strong>转化为库的代码。</p><h2 id="9782" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">设置数据块连接</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="cd50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了对刚刚构建的库运行单元测试，除非您想100%在本地运行它们，否则您应该使用<code class="fe nl nm nn no b">dbconnect</code>库连接到<strong class="jp ir"> Databricks集群</strong>。事实上，这非常简单，我们已经做好了这样做的所有准备——除了<code class="fe nl nm nn no b">databricks_token</code>之外，这一步中使用的所有变量都取自<code class="fe nl nm nn no b">config.json</code>—这个<strong class="jp ir">必须从密钥库中检索</strong>。</p><h2 id="70db" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">运行测试并发布结果</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="3bb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于到Databricks集群的连接已经建立，我们现在可以运行测试。为此，应用使用<code class="fe nl nm nn no b">pytest</code>库的标准方法。这些测试的结果被本地输出到<code class="fe nl nm nn no b">TEST-LOCAL.xml</code>文件中，该文件随后被用于将测试结果发布到Azure DevOps测试实用程序中，这有助于您跟踪测试结果的演变以及代码的增长。请记住，因为我没有在repo中包含任何实际的Python包，所以我也跳过了包含测试文件。</p><h2 id="adf9" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">准备工件目录</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="ff76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了创建一个部署工件，让我们准备在一个地方收集所有的东西。这包括<code class="fe nl nm nn no b">config.json</code>和<code class="fe nl nm nn no b">ci_cd_scripts</code>，它们也将在CD工艺中大量使用。</p><h2 id="1a27" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">找到。whl文件，并将它们复制到工件的目录中</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="6067" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">copy_files_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e256" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">copy_files.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="789d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以着手完成我们的艺术品了。这里的第一步非常简单——找到<code class="fe nl nm nn no b">wheel</code>文件(默认情况下，它们被输出到各自父目录中的<code class="fe nl nm nn no b">dist</code>目录),并将它们复制到指定的路径，这里是将被打包成可部署工件的目录。</p><h2 id="52a8" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">找到笔记本并将其复制到工件的目录中</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="3710" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">discover_and_copy_notebooks_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="1569" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于笔记本是只能在数据块上直接使用的实体，并且不需要在Azure DevOps代理上对它们做任何事情，所以我采用了在一个脚本中处理它们，而没有将任何变量输出到bash shell中。但是值得注意的是，笔记本的结构保存在工件中——源自<code class="fe nl nm nn no b">package1</code>的笔记本将被放在目录<code class="fe nl nm nn no b">package1</code>中，一旦它们被部署到Databricks workspace中，这将导致保存文件和目录的结构。为了给下一篇关于<strong class="jp ir"> CD </strong>过程的文章提供一个小小的剧透，Databricks workspace上的文件结构将如下所示:</p><pre class="km kn ko kp gt nu no nv nw aw nx bi"><span id="5cee" class="ny ld iq no b gy nz oa l ob oc">cd_deployed_dir_name<br/>└─── notebooks<br/>       └── package1<br/>       │      │   notebook1.py<br/>       │      │   notebook2.py    <br/>       └── package2<br/>              │   notebook1.py<br/>              │   notebook2.py<br/>                  ...</span></pre><p id="11a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，每台笔记本电脑的来源和包装会有非常明显的区别。</p><h2 id="89f0" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">创建初始化脚本</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="fc6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">create_init_script_cli.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c5d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe nl nm nn no b">create_init_script.py</code>的内容:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="b14b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">init脚本是一个bash脚本，每次<strong class="jp ir"> Databricks </strong>集群启动时都会执行。通过利用这一功能，您可以大幅削减成本——它允许对任何工作负载使用作业集群而不是交互式集群，因为您可以完全使用这些init脚本来设置集群。在此<strong class="jp ir"> CI </strong>流程中，脚本将升级pip，使用针对<code class="fe nl nm nn no b">common</code>需求指定的pip安装<strong class="jp ir"> Python </strong>库，并安装在此流程中构建的<code class="fe nl nm nn no b">wheel</code>包。初始化脚本的示例:</p><pre class="km kn ko kp gt nu no nv nw aw nx bi"><span id="db74" class="ny ld iq no b gy nz oa l ob oc">#!/bin/bash<br/>pip install --upgrade pip<br/>pip install azure-mgmt-datafactory&gt;=2.2.0<br/>pip install azure-identity&gt;=1.7.1<br/>pip install dbfs/FileStore/jars/databricks_ci_cd-0.1-py3-none-any.whl</span></pre><h2 id="06db" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">将需求文件复制到工件的目录中</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="ea67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是将所有的需求文件复制到工件目录中。由于早期的需求是以两个文件的形式指定的:<code class="fe nl nm nn no b">dev</code>和<code class="fe nl nm nn no b">common</code>，脚本需要正确地处理它。由于工件是软件开发过程的最终产品，它将永远不需要<code class="fe nl nm nn no b">dev</code>依赖——只有对其功能至关重要的库才会被发布。</p><h2 id="40e7" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">人工制品的包装和出版</h2><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f276" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">剩下的最后一步是将我们的工作打包成一个工件，放到一个<code class="fe nl nm nn no b">zip</code>文件中，并发布它。我个人的偏好是使用<code class="fe nl nm nn no b">UniversalPackages</code>任务而不是<code class="fe nl nm nn no b">PublishBuildArtifact</code>任务，但是为了方便起见，我还是把它们都包括在内。前者提供了一个非常简洁的版本处理(它可以自动创建工件的增量版本),所以如果您不想在每次推送一些更改时手动更改版本，我推荐您尝试一下。</p><h2 id="f818" class="ny ld iq bd lb od oe dn lh of og dp ll jy oh oi lp kc oj ok lt kg ol om lx on bi translated">概述</h2><p id="ce24" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">一旦完成了<strong class="jp ir"> CI </strong>的设置过程，并且管道成功地完成了它的运行，您应该会在Azure DevOps UI中看到下面这个辉煌的屏幕:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi oo"><img src="../Images/e029f9ecf796c99691c907665504df43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kF6W3O4AY-WxpJjwcMgszg.png"/></div></div></figure><p id="01b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着<strong class="jp ir"> CI </strong>管道已经成功运行！现在让我们简要地看一下我们精心准备的艺术品。其文件结构如下所示:</p><pre class="km kn ko kp gt nu no nv nw aw nx bi"><span id="56cd" class="ny ld iq no b gy nz oa l ob oc">artifact<br/>│    config.json<br/>│    databricks_init_script.sh<br/>│    package1.whl<br/>│    package2.whl<br/>│    requirements.txt<br/>└─── ci_cd_scripts<br/>      │    requirements.txt<br/>      │    script1.py<br/>      │    ...<br/>      └─── notebooks<br/>             └── package1<br/>             │      │   notebook1.py<br/>             │      │   notebook2.py    <br/>             └── package2<br/>                    │   notebook1.py<br/>                    │   notebook2.py<br/>                        ...</span></pre><p id="c428" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于工件最重要的一点是，它包含了<strong class="jp ir">用于<strong class="jp ir">数据块</strong>上数据处理的所有内容</strong>，唯一的例外是秘密——它们保存在keyvault中，将在<strong class="jp ir"> CD </strong>步骤中从那里检索。还请注意，有两套<code class="fe nl nm nn no b">requirements.txt</code>文件。在<code class="fe nl nm nn no b">artifact</code>目录中的一个用于已构建的<code class="fe nl nm nn no b">wheel</code>包的依赖关系，而在<code class="fe nl nm nn no b">ci_cd_scripts</code>目录中的一个包含运行脚本的依赖关系，这些脚本将在<strong class="jp ir"> CD </strong>进程中使用。在工件级别维护这样的文件结构允许在将笔记本部署到Databricks工作区时保持相同的结构，从而确保一个非常整洁的工作环境。</p><p id="90ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只是提醒一下——你可以在我的Github repo访问这里分享的所有代码:</p><p id="6be7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae me" href="https://github.com/szymonzaczek/databricks-ci-cd" rel="noopener ugc nofollow" target="_blank">https://github.com/szymonzaczek/databricks-ci-cd</a></p><h1 id="3507" class="lc ld iq bd lb le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">摘要</h1><p id="7281" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">在<strong class="jp ir">多环境</strong>设置中使用<strong class="jp ir">数据块</strong>可能看起来令人生畏。尤其是如果你不喜欢只使用笔记本，并且还需要一种健壮的方式来处理Python包。当然，尽可能降低成本总是一个好主意，所以通过使用init脚本来设置作业集群而不是交互式集群来利用作业集群看起来确实非常合理。当然，任何代码都不应该在没有正确测试的情况下使用，对吗？</p><p id="bc97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你同意以上的陈述，我希望这篇文章对你有用。最后，我们现在只剩下一个工件，它包含了在数据块上进行基于Python的处理所需的一切。</p><p id="62ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下一部分，我将分享<strong class="jp ir">持续部署</strong>流程——我将展示如何将您珍贵的包和笔记本电脑运送到您选择的任何环境的步骤。所以，如果你对如何做感兴趣，请继续关注，不要犹豫，在评论中分享你的反馈。</p></div></div>    
</body>
</html>