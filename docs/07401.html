<html>
<head>
<title>Scrape Data from a Website and PDF Document with a Django App</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Django应用程序从网站和PDF文档中抓取数据</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/scrap-data-from-website-and-pdf-document-for-django-app-fa8f37010085?source=collection_archive---------12-----------------------#2021-02-15">https://levelup.gitconnected.com/scrap-data-from-website-and-pdf-document-for-django-app-fa8f37010085?source=collection_archive---------12-----------------------#2021-02-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3895" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的Django web应用程序现在需要数据——我们将使用python从网站和PDF文档中获取数据。在本教程中，我们将介绍BeautifulSoup的基本web抓取和PyPDF2的PDF抓取。我们将使用这两种技术来获取数据，并将其添加到我们的数据库中，以便Django应用程序能够在前端提供数据。</p><p id="3f09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个新的应用程序，当我们上线并部署我们的应用程序时，我们首先需要实时数据。在用户可以开始注册个人资料之前，他们必须看到一个具有读取数据的工作应用程序。真实可靠的数据，提升你的诚信，并吸引人们访问你的网站。</p><p id="0c39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">真实的工作数据也会提高你的搜索能力——搜索引擎会有更多的数据，因此你的网站可能会有更多的关键词排名。</p><p id="a5ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还将使用这些数据在我们的社交媒体页面上发布，进一步扩大我们的覆盖范围和社区。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/e47951497536d646291a9226b4dd6127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*P6GzwGKdxmCAzoJaOH3kVw.jpeg"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">从网站和PDF中删除数据</figcaption></figure><h1 id="1800" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">从PDF文档中删除数据</h1><p id="2898" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将使用Python库PyPDF2来废弃PDF文档，但是首先我们必须从互联网上下载文件。为此，我们需要一个下载url。以下是从PDF文档中删除数据的步骤:</p><ul class=""><li id="d579" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated">查找下载网址——浏览网站</li><li id="fa2e" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">下载文档</li><li id="c809" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">阅读文件</li><li id="1992" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">在您需要匹配Django模型的数据结构中解析文档</li><li id="388e" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">将数据保存到数据库</li></ul><h2 id="f912" class="mo ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">关闭网站</h2><p id="27da" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将使用BeautifulSoup并请求python中的库来废弃这个网站:<a class="ae na" href="http://www.dpsa.gov.za/dpsa2g/vacancies.asp" rel="noopener ugc nofollow" target="_blank">http://www.dpsa.gov.za/dpsa2g/vacancies.asp</a></p><p id="bdc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">获取我们下载PDF数据所需的所有文档链接。</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="cde9" class="mo ky iq nc b gy ng nh l ni nj">import requests<br/>from bs4 import BeautifulSoup</span><span id="19ec" class="mo ky iq nc b gy nk nh l ni nj">headers =  {'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'}<br/>url = "<a class="ae na" href="http://www.dpsa.gov.za/dpsa2g/vacancies.asp" rel="noopener ugc nofollow" target="_blank">http://www.dpsa.gov.za/dpsa2g/vacancies.asp</a>"</span><span id="bec5" class="mo ky iq nc b gy nk nh l ni nj">r = requests.get(url, headers=headers)<br/>c = r.content<br/>soup = BeautifulSoup(c, "html.parser")<br/>tables = soup.find_all(&lt;tag&gt;, {&lt;attribute&gt;: &lt;value&gt;})</span></pre><p id="0589" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你得到了汤，你可以调用一个特定的HTML标签行，比如“h1”，“table”，“span”。这个公式将返回您要求的所有标签，如果它们存在于页面上的话。为了缩小搜索范围，我们可以传入一个属性参数。这可以是“风格”、“类别”等。例如，您可以说—返回所有“h1”<tag>和“文本-主要”<value>的“类”<attribute>。代码应该是这样的:</attribute></value></tag></p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="7ab3" class="mo ky iq nc b gy ng nh l ni nj">tables = soup.find_all(&lt;h1&gt;, {"class": "text-primary"})</span></pre><p id="0cbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果HTML中存在表格，该函数将返回符合查询的所有h1的列表。如果没有匹配，这将返回一个空列表。</p><p id="387f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们运行这段代码来查找我们将在下面的代码中使用的所有链接。</p><h2 id="1a23" class="mo ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">下载文档</h2><p id="67b2" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将使用命令行和<strong class="jp ir"> wget </strong>来下载我们的文档，这是最快的方法，但是程序可以从Python内部编写，所以我们可以自动化它。</p><p id="8416" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先为此导入子流程。然后，我们需要设置下载url和保存文档的位置文件路径。对所有要下载的文档运行此代码。</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="11df" class="mo ky iq nc b gy ng nh l ni nj">import subprocess</span><span id="455a" class="mo ky iq nc b gy nk nh l ni nj">url = '<a class="ae na" href="http://www.dpsa.gov.za/dpsa2g/documents/vacancies/2021/05/a.pdf'" rel="noopener ugc nofollow" target="_blank">http://www.dpsa.gov.za/dpsa2g/documents/vacancies/2021/05/a.pdf'</a><br/>location  = 'filepath-location-on-your-computer-documentName.pdf'</span><span id="e3be" class="mo ky iq nc b gy nk nh l ni nj">def run_command(command):<br/>    p = subprocess.Popen(command, stdout=subprocess.PIPE)<br/>    out, err = p.communicate()<br/>    return out</span><span id="dfd0" class="mo ky iq nc b gy nk nh l ni nj">run_command(["wget", "-O", "{}".format(location), "{}".format(url)])</span></pre><h2 id="f72b" class="mo ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">阅读文件</h2><p id="af14" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将使用PyPDF2，PdfFileReader来读取上面刚刚保存的文档。我们首先计算页面数量，然后收集每个页面的数据——之后，我们将这些信息提取到Python字符串列表中。这个字符串列表是基于文档部分划分的，这将允许我们稍后提取特定的职务信息。</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="c51d" class="mo ky iq nc b gy ng nh l ni nj">from PyPDF2 import PdfFileReader<br/>location  = 'filepath-location-on-your-computer-documentName.pdf'</span><span id="dd69" class="mo ky iq nc b gy nk nh l ni nj">content_list = []<br/>with open(location, 'rb') as f:<br/>    doc = PdfFileReader(f)<br/>    pages = doc.numPages</span><span id="e770" class="mo ky iq nc b gy nk nh l ni nj">count = 0<br/>    while count &lt; pages:<br/>        the_page = doc.getPage(count)<br/>        the_text = the_page.extractText()<br/>        a_list = the_text.replace('\n', '').split(' : ')<br/>        for x in a_list:<br/>            content_list.append(x)<br/>        count += 1</span></pre><h2 id="df5e" class="mo ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">提取数据并进行组织</h2><p id="edd0" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">如果你很好地分割了文档，下一步应该会更容易。我必须提到，这一步是针对文档设计的。本规范不适用于所有PDF文档。你必须通读你的文件，在文档中找到特定的元素，你可以用它来锚定你的内容搜索。我选择在分号“:”上分割文档，如上面的代码所示。因此，如果我找到了正确的索引，我就可以从该索引向前计数，以识别作业数据的所有后续部分。</p><p id="8b53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我也很幸运，所有的文档都遵循相同的结构，所以这是可能的。</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="3121" class="mo ky iq nc b gy ng nh l ni nj">post_string = 'POST 05/'</span><span id="3587" class="mo ky iq nc b gy nk nh l ni nj">post_list = []<br/>index_list = []</span><span id="ebf5" class="mo ky iq nc b gy nk nh l ni nj">final_jobs = []</span><span id="c536" class="mo ky iq nc b gy nk nh l ni nj">for x in content_list:<br/>    if post_string in x:<br/>        post_list.append(x)</span><span id="16e1" class="mo ky iq nc b gy nk nh l ni nj">for x in post_list:<br/>    the_index = content_list.index(x)<br/>    index_list.append(the_index)</span><span id="ad19" class="mo ky iq nc b gy nk nh l ni nj">for x in index_list:<br/>    obj = {}</span><span id="35c3" class="mo ky iq nc b gy nk nh l ni nj">#Titles<br/>    a = content_list[x+1]<br/>    obj['title'] = a</span><span id="e10d" class="mo ky iq nc b gy nk nh l ni nj">b = content_list[x+2]<br/>    obj['salary'] = b</span><span id="2087" class="mo ky iq nc b gy nk nh l ni nj">c = content_list[x+3]<br/>    obj['location'] = c</span><span id="2a42" class="mo ky iq nc b gy nk nh l ni nj">d = content_list[x+4]<br/>    obj['requirements'] = d</span><span id="b06d" class="mo ky iq nc b gy nk nh l ni nj">e = content_list[x+5]<br/>    obj['duties'] = e</span><span id="0730" class="mo ky iq nc b gy nk nh l ni nj">f = content_list[x+6]<br/>    obj['enquiries'] = f</span><span id="17d6" class="mo ky iq nc b gy nk nh l ni nj">final_jobs.append(obj)</span></pre><p id="8fdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作业数据现在将被组织到作业的final_jobs列表中。</p><h2 id="70bb" class="mo ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">将数据保存到数据库中</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/63e1ad00ea8c5f77e70d03ad1fa8c534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*84yjx6t33mM7mC3mdJjmFg.jpeg"/></div></figure><p id="76e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是最后一步——我们稍后将讨论模型文件。</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="86de" class="mo ky iq nc b gy ng nh l ni nj">#import models<br/>from jobs.models import *<br/>from django.contrib.auth.models import User</span><span id="acfd" class="mo ky iq nc b gy nk nh l ni nj">the_user = User.objects.get(email='admin@skolo.online')<br/>the_company = Company.objects.get(uniqueId='**********')<br/>the_category = Category.objects.get(uniqueId='***********')</span><span id="17d0" class="mo ky iq nc b gy nk nh l ni nj">for test_job in final_jobs:</span><span id="c5d3" class="mo ky iq nc b gy nk nh l ni nj">    Jobs.objects.create(<br/>    title = test_job['title'],<br/>    location = test_job['location'],<br/>    salary = test_job['salary'],<br/>    requirements = test_job['requirements'],<br/>    duties = test_job['duties'],<br/>    date_posted = date.today(),<br/>    enquiries = test_job['enquiries'],<br/>    company = the_company,<br/>    category = the_category,<br/>    owner = the_user,<br/>    )</span></pre><p id="f0f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这段代码必须在Django环境中运行才能访问模型和数据库。</p><h1 id="5cd4" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">Django工作、公司和类别的模型文件</h1><p id="e364" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">如上面的代码所示，我们需要(1)工作，(2)公司和(3)类别的模型文件。我们下载的所有作业数据都将根据数据库中的模型进行组织。</p><p id="01e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">jobs类中的models.py文件应该如下所示:</p><pre class="km kn ko kp gt nb nc nd ne aw nf bi"><span id="c9de" class="mo ky iq nc b gy ng nh l ni nj">from django.db import models<br/>from django.utils import timezone<br/>from django.contrib.auth.models import User<br/>from django.template.defaultfilters import slugify<br/>from uuid import uuid4</span><span id="343a" class="mo ky iq nc b gy nk nh l ni nj">class Company(models.Model):<br/>    title = models.CharField(max_length=200, null=True, blank=True)<br/>    description = models.TextField(null=True, blank=True)<br/>    uniqueId = models.CharField(null=True, blank=True, max_length=100)<br/>    companyLogo = models.ImageField(default='default.png', upload_to='upload_images')<br/>    slug = models.SlugField(max_length=500, unique=True, blank=True, null=True)<br/>    seoDescription = models.CharField(max_length=500, null=True, blank=True)<br/>    seoKeywords = models.CharField(max_length=500, null=True, blank=True)</span><span id="60fb" class="mo ky iq nc b gy nk nh l ni nj">def __str__(self):<br/>        return '{} - {}'.format(self.title, self.uniqueId)</span><span id="7e99" class="mo ky iq nc b gy nk nh l ni nj">def get_absolute_url(self):<br/>        return reverse('company-detail', kwargs={'slug': self.slug})</span><span id="dba1" class="mo ky iq nc b gy nk nh l ni nj">def save(self, *args, **kwargs):<br/>        if self.uniqueId is None:<br/>            self.uniqueId = str(uuid4()).split('-')[0]<br/>            self.slug = slugify('Company {} {}'.format(self.title, self.uniqueId)) #company-absa-h37dhe3wf</span><span id="7a73" class="mo ky iq nc b gy nk nh l ni nj">self.slug = slugify('Company {} {}'.format(self.title, self.uniqueId))<br/>        self.seoDescription = 'Apply for {} Jobs on careers portal, start your career journey today'.format(self.title)<br/>        self.seoKeywords = '{}, Jobs, Careers Portal, Apply Jobs'.format(self.title)<br/>        super(Company, self).save(*args, **kwargs)</span><span id="1a6c" class="mo ky iq nc b gy nk nh l ni nj">class Category(models.Model):<br/>    title = models.CharField(max_length=200, null=True, blank=True)<br/>    description = models.TextField(null=True, blank=True)<br/>    uniqueId = models.CharField(null=True, blank=True, max_length=100)<br/>    categoryImage = models.ImageField(default='category.png', upload_to='upload_images')<br/>    slug = models.SlugField(max_length=500, unique=True, blank=True, null=True)<br/>    seoDescription = models.CharField(max_length=500, null=True, blank=True)<br/>    seoKeywords = models.CharField(max_length=500, null=True, blank=True)</span><span id="942d" class="mo ky iq nc b gy nk nh l ni nj">def __str__(self):<br/>        return '{} - {}'.format(self.title, self.uniqueId)</span><span id="cf98" class="mo ky iq nc b gy nk nh l ni nj">def get_absolute_url(self):<br/>        return reverse('category-detail', kwargs={'slug': self.slug})</span><span id="9c8a" class="mo ky iq nc b gy nk nh l ni nj">def save(self, *args, **kwargs):<br/>        if self.uniqueId is None:<br/>            self.uniqueId = str(uuid4()).split('-')[0]<br/>            self.slug = slugify('Category {} {}'.format(self.title, self.uniqueId))</span><span id="6067" class="mo ky iq nc b gy nk nh l ni nj">self.slug = slugify('Category {} {}'.format(self.title, self.uniqueId))<br/>        self.seoDescription = 'Apply for {} Jobs online, start your career journey today'.format(self.title)<br/>        self.seoKeywords = '{}, Jobs, Careers Portal, Apply Jobs'.format(self.title)<br/>        super(Category, self).save(*args, **kwargs)</span><span id="f8db" class="mo ky iq nc b gy nk nh l ni nj">class Jobs(models.Model):<br/>    FULL_TIME = 'Full Time'<br/>    PART_TIME = 'Part Time'<br/>    REMOTE = 'Remote'<br/>    NOT_PROVIDED = 'N/A'<br/>    TIER1 = 'Less than 2yrs'<br/>    TIER2 = '2yrs - 5yrs'<br/>    TIER3 = '5yrs - 10yrs'<br/>    TIER4 = '10yrs - 15yrs'<br/>    TIER5 = 'More than 15yrs'</span><span id="7c25" class="mo ky iq nc b gy nk nh l ni nj">TYPE_CHOICES = [<br/>        (FULL_TIME, 'Full Time'),<br/>        (PART_TIME, 'Part Time'),<br/>        (NOT_PROVIDED, 'N/A'),<br/>        (REMOTE, 'Remote'),<br/>    ]<br/>    EXP_CHOICES = [<br/>        (TIER1, 'Less than 2yrs'),<br/>        (TIER2, '2yrs - 5yrs'),<br/>        (TIER3, '5yrs - 10yrs'),<br/>        (TIER4, '10yrs - 15yrs'),<br/>        (TIER5, 'More than 15yrs'),<br/>        (NOT_PROVIDED, 'N/A'),<br/>    ]</span><span id="d5f6" class="mo ky iq nc b gy nk nh l ni nj">title = models.CharField(max_length=500, null=True, blank=True)<br/>    company = models.ForeignKey(Company, on_delete=models.CASCADE, null=True, blank=True)<br/>    category = models.ForeignKey(Category, on_delete=models.CASCADE, null=True, blank=True)<br/>    location = models.CharField(max_length=500, null=True, blank=True)<br/>    salary = models.CharField(max_length=500, null=True, blank=True)<br/>    uniqueId = models.CharField(null=True, blank=True, max_length=100)<br/>    type = models.CharField(max_length=100 ,choices=TYPE_CHOICES, default=NOT_PROVIDED)<br/>    experience = models.CharField(max_length=100, choices=EXP_CHOICES, default=NOT_PROVIDED)<br/>    summary = models.TextField(null=True, blank=True)<br/>    description = models.TextField(null=True, blank=True)<br/>    requirements = models.TextField(null=True, blank=True)<br/>    duties = models.TextField(null=True, blank=True)<br/>    enquiries = models.TextField(null=True, blank=True)<br/>    applications = models.TextField(null=True, blank=True)<br/>    note = models.TextField(null=True, blank=True)<br/>    closing_date = models.DateField(blank=True, null=True)<br/>    date_posted = models.DateField(blank=True, null=True)<br/>    contract_type = models.CharField(max_length=500, null=True, blank=True)<br/>    date_created = models.DateTimeField(default=timezone.now)<br/>    owner = models.ForeignKey(User, on_delete=models.CASCADE)<br/>    slug = models.SlugField(max_length=500, unique=True, blank=True, null=True)<br/>    seoDescription = models.CharField(max_length=500, null=True, blank=True)<br/>    seoKeywords = models.CharField(max_length=500, null=True, blank=True)<br/>    urlLink = models.CharField(max_length=500, null=True, blank=True)</span><span id="35ed" class="mo ky iq nc b gy nk nh l ni nj">def __str__(self):<br/>        return '{} - {} - {}'.format(self.company, self.title, self.location)</span><span id="536d" class="mo ky iq nc b gy nk nh l ni nj">def get_absolute_url(self):<br/>        return reverse('job-detail', kwargs={'slug': self.slug})</span><span id="e9f7" class="mo ky iq nc b gy nk nh l ni nj">def save(self, *args, **kwargs):<br/>        #Creating a unique Identifier for the resume(useful for other things in future)<br/>        if self.uniqueId is None:<br/>            self.uniqueId = str(uuid4()).split('-')[0]<br/>            self.slug = slugify('{} {} {}'.format(self.title, self.location, self.uniqueId))</span><span id="5f19" class="mo ky iq nc b gy nk nh l ni nj">self.slug = slugify('{} {} {}'.format(self.title, self.location, self.uniqueId))<br/>        self.seoKeywords = 'Careers Portal, Online job application, full time jobs, part time jobs, get a job, apply for a job, {}'.format(self.title)<br/>        self.seoDescription = '{}'.format('Careers Portal, Job application. Apply for job: {} in {}, online today'.format(self.title, self.location))<br/>        super(Jobs, self).save(*args, **kwargs)</span></pre><p id="f815" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型文件类似于我们之前在<a class="ae na" href="https://skolo-online.medium.com/django-models-with-slugfield-override-model-save-method-and-custom-html-forms-73db161e2fb" rel="noopener">添加带有slug字段的Django模型并覆盖保存方法</a>时看到的。</p><p id="1651" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，因为我们想最大限度地利用SEO元素，我们正在创建两个新的领域:(1) SEO描述和(2) SEO关键字。这些字段将在模型保存时自动填充——我们将从模型变量中自动创建SEO变量。</p><p id="45c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们可以从Django HTML模板中访问这些变量。</p><h1 id="c668" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">从Django Web App在线视频教程的网站和PDF文档中删除数据。</h1><p id="833a" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">要更详细地理解这些概念，请查看我们的视频教程:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">为Django web应用程序教程从网站和PDF中删除数据</figcaption></figure></div></div>    
</body>
</html>