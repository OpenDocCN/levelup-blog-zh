# 如何用多线程编写并发 Python 代码

> 原文：<https://levelup.gitconnected.com/how-to-write-concurrent-python-code-with-multithreading-b24dec228c43>

## 提高应用程序的并发性

在本文中，将介绍 Python 中多线程的基础知识。我们将介绍进程、线程、全局解释器锁(GIL)、CPU 绑定任务和 IO 绑定任务的概念。然后，我们将学习如何使用本机`threading.Thread`和更高级别的`concurrent.futures.ThreadPoolExecutor`创建多线程应用程序。我们还将介绍如何正确处理线程中出现的异常，这样程序就不会无声无息地失败。最后，我们将构建一个简单的带有队列和多线程的发布者/订阅者(Pub/Sub)异步消息传递系统，它结合了本文中介绍的多线程的所有高级特性。

![](img/f704445e217296b41961028098d1de6b.png)

图片来自 [Pixabay](https://pixabay.com/photos/geese-flying-goose-glide-sail-4028227/) 。

**进程 vs 线程**。

这更像是一个普通的计算机科学问题，而不是 Python 问题。关于这个问题有[个关于栈溢出的活跃讨论](https://stackoverflow.com/questions/200469/what-is-the-difference-between-a-process-and-a-thread?page=1&tab=votes#tab-top)。本质上，**进程**是程序的执行实例，提供执行程序所需的资源。一个程序可以同时运行多个进程。在这种情况下，程序被认为是并行运行的，可以利用机器上可用的多个 CPU 内核。同一程序的不同进程相互隔离。他们有隔离的资源，尤其是全局内存空间。

一个**线程**也是一个独立的程序执行单元。线程是在进程的上下文中创建的，并且只能访问进程中可用的资源。每个进程都是由一个单独的线程创建的，这个线程被称为主线程。我们可以从同一个进程中创建多个线程，就像本教程中将要做的那样。这些源自同一进程的线程共享“父”进程的相同全局内存空间。然而，每个线程也可以有自己的线程本地存储，我们将在后面看到。应该注意的是，进程(主线程下)和显式创建的线程都不绑定到单个处理器或 CPU 内核。一个进程或线程可以跳过不同的内核，这种行为由操作系统通过一种叫做[处理器/线程关联](https://en.wikipedia.org/wiki/Processor_affinity)的机制来决定。在开始使用 Python 中的线程之前，您不需要理解所有的技术细节。如果你感兴趣或感到困惑，这里只是解释一下。

线程比进程更轻量级，因为线程是在进程内部创建的。此外，由于线程共享相同的全局内存空间，因此它们之间的通信更容易。另一方面，由于不同的进程具有隔离的内存空间，因此它们之间的通信要求更高。要在进程间共享的数据需要是可序列化的或可处理的，这是一个主要的限制，会给问题带来额外的开销和复杂性。然而，尽管有这些限制，多线程和多重处理都有它们自己的用例，这将在下面介绍。

**Python 全局解释器锁(GIL)** 。

顾名思义，Python 全局解释器锁(GIL)是 Python 解释器上的一个锁。由于一个进程只有一个解释器实例，所以在同一个进程中创建的所有线程共享同一个解释器。GIL 限制只有一个线程可以控制公共 Python 解释器，这意味着在任何时间点只有一个线程可以处于执行状态。因此，有了 GIL，用多线程完全并行执行程序是不可能的。然而，对于 CPU 受限的应用程序来说，GIL 只是一个瓶颈，这些应用程序需要繁重的 CPU 计算，而不是(输入/输出)IO 等待。对于 IO 绑定的应用程序，大部分时间都花在等待远程服务器的响应上，GIL 不是一个限制。当一个线程被阻塞并等待来自文件、数据库或网页的响应时，另一个线程可以接管解释器的控制权并执行其代码。由于执行其他代码所花费的时间比 IO 等待时间少几个数量级，所以 GIL 的影响很小。

**CPU 受限的任务实例**。

让我们用简单的例子来看看 GIL 对 CPU 和 IO 相关任务的影响。让我们先来看看多线程是否能让 CPU 受限的计算更快:

函数`cpu_bound_job`是一个受 CPU 限制的任务，因为它所做的只是纯粹的算术计算。没有 IO 正在等待此任务。当我们用单线程计算一个大数字时，需要 15.14 秒。如果你想得到一个相似的计算时间，你可能需要根据你的计算机的计算能力来改变这个数字。当我们把大的数拆分成较小的数，尝试用三个线程来做计算时，计算并不比单线程快。这意味着多线程不适用于 CPU 受限的任务，您不应该浪费时间尝试使用多线程来加速 CPU 受限的应用程序。相反，你应该尝试使用[多重处理](https://docs.python.org/3/library/multiprocessing.html)软件包。

**IO 绑定任务示例**。

受输入/输出(IO)限制的任务大部分时间都在等待。它们可能正在等待来自文件、数据库或 web 服务器的响应。现在我们将使用`time.sleep()`来模拟一个 IO 绑定的任务。稍后将使用*请求*模块来模拟更实际的用法。

在这个简单的例子中，每个请求需要 3 秒钟才能完成。这是一个 IO 绑定的任务，因为它大部分时间都在等待(这里是休眠)。当我们用单线程发出三个请求时，用了 9 秒。当我们用三个线程发出三个请求，每个线程得到一个请求时，只需要三秒钟，这意味着 IO 绑定的任务确实与多线程并发运行。原因是当一个线程被阻塞时，解释器的控制权可以被另一个线程接管。这样，缓慢的 IO 步骤可以看似同时运行。当缓慢的 IO 步骤完成时，代码的其他部分将有机会再次运行。其他代码运行如此之快，以至于缓慢的 IO 步骤几乎同时开始和结束。

到目前为止，您应该很好地理解了为什么多线程适合 IO 绑定的任务，而不是 CPU 绑定的任务。现在我们将介绍更高级的多线程知识，这将有助于您的工作。

**线程安全**和**线程本地存储**。

如果你有 Java 的背景，你会非常熟悉“线程安全”的概念。虽然在 Python 中不太流行，但是如果您编写多线程代码，这个概念也适用。基本上，[线程安全](https://en.wikipedia.org/wiki/Thread_safety)意味着一个对象可以被多个线程安全地访问，没有[竞争条件](https://en.wikipedia.org/wiki/Race_condition)。线程安全代码意味着同一段代码可以由多个线程同时正确执行，不会出现意外行为。

Python 中有一些对象不是线程安全的。一个例子是*请求*库的`[Session](https://github.com/psf/requests/issues/2766)`对象。另一个常见的例子是 [*SQLAlchemy*](https://docs.sqlalchemy.org/en/13/orm/session_basics.html#is-the-session-thread-safe) 库的数据库连接和会话对象。在这种情况下，我们需要在由`threading.local()`表示的线程本地存储中存储它们的一个实例。

*   在前面的例子中，我们已经使用本地的`threading`模块显式地创建了一个线程。我们还可以使用来自`concurrent.futures`库的`ThreadPoolExecutor`类，这是在 Python 中创建线程化作业的更好方法。有了`ThreadPoolExecutor`，我们可以将线程的总数限制在一个固定的数字，这样我们就不会创建大量的线程并耗尽计算机的内存。此外，我们可以使用`ThreadPoolExecutor`作为上下文管理器，从而可以在线程任务完成时释放线程池。
*   对于非线程安全的对象，我们需要为每个线程创建一个不同的实例。在这种情况下， *requests* 库的`Session`对象不是线程安全的，因此我们需要为每个线程创建一个新的实例。注意，神奇的`threading.local()`方法将返回单个线程可以访问的变量。这是保存一些临时数据的常用方法，这些数据应该只能由单个线程访问。

在本例中，我们证实了多线程可以显著提高 IO 绑定任务的速度。

**如何处理线程中出现的异常**？

当我编写上面的脚本并在代码中犯了一些错别字时，错误不会显示出来，我们只会看到以下信息:

```
IO-bound job finished in 0.00 seconds with one thread.
IO-bound job finished in 0.00 seconds with ten threads.
```

你可以尝试在函数`io_bound_job`中引入一些错误，你会看到同样的结果。

这是因为，默认情况下，线程中的错误会被隐藏，不会显示在主线程中。为了捕捉线程中的错误，您需要循环执行从 executor 返回的 *futures* 。 [*future*](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future) 是一个对象，表示在一个线程中运行的目标函数的执行。

*   这一次，我们使用执行器的`submit`方法显式提交每个任务。使用`submit`方法的好处是返回一个 *future* 对象，您可以稍后使用它来检查线程中执行的函数的结果。
*   `as_completed`函数返回已完成或取消的*期货*。
*   `result()`方法返回*未来*所代表的函数的结果。GCP 的 Pub/Sub 也使用了`result()`方法来构建[消息/队列系统](https://medium.com/codex/how-to-use-google-pub-sub-to-build-an-asynchronous-messaging-system-in-python-3b43094627dc)。
*   当循环通过*期货*时，如果线程中出现异常，它将被捕获，并可以更优雅地处理。

现在，如果您试图在函数`io_bound_job`中引入任何错误，它总是会在`try/except`块中被捕获。

**用多线程构建发布者/订阅者系统**。

在最后一节中，我们将使用 Python 中的多线程构建自己的发布/订阅系统。如果你不熟悉 GCP 发布/订阅系统，你可能会对这篇介绍性文章感兴趣。在下面的例子中，我们将用上面学到的知识构建一个超级简单的发布/订阅系统。现在先让代码说话，然后我们来解释重点:

乍一看，这个脚本可能有点复杂。然而，一旦你理解了基本的逻辑，事情就简单了。

1.  我们使用一个`queue.Queue`来存储和获取结果。有了队列，我们不需要手动管理线程的[锁](https://docs.python.org/3/library/threading.html#threading.Lock)。如果您需要从线程发送/接收数据，这是推荐的方法。可以指定队列的最大大小。如果队列中的消息数量达到最大值，则无法发送新消息，发布者将被阻止。创建的队列作为位置参数发送给发布者和订阅者。
2.  我们使用`threading.Event()`向用户发送终止信号。如果不希望订阅服务器永远运行，这是必要的。订阅者将运行以接收所有发布的消息，然后退出。请注意，在调用`event.set()`之前，我们必须*让*休眠足够的时间。否则，该程序将被阻止。原因是队列有一个最大大小设置，如果我们设置事件过早，让订阅者过早退出，我们将达到最大队列大小，发布者将被阻塞。
3.  在订阅者中，如果没有设置事件信号并且队列不为空，我们将继续从队列中获取数据。有了这两个条件，我们就可以确保发布者发布的所有消息都能被接收到。订阅者的超时是针对没有消息发布的情况。如果没有设置超时，并且没有发布任何消息，订阅者将被阻止。

如果您想构建一个本地分布式计算系统，这个用原生 Python 代码编写的发布/订阅系统会很有帮助。当一个数据库可以有多个读操作，但只允许一个写操作时，这种方法特别有用。在这种情况下，您可以启动多个发布者和一个订阅者，并充分利用您的系统。

本文介绍了多线程的基础知识。我们已经介绍了进程、线程、全局解释器锁(GIL)、CPU 绑定任务和 IO 绑定任务的概念。我们现在可以用原生的`threading.Thread`和更高级的`concurrent.futures.ThreadPoolExecutor`创建线程化的应用。我们还介绍了如何正确处理线程中出现的异常，这样程序就不会无声无息地失败。最后，我们构建了一个简单的带有队列和多线程的发布者/订阅者(Pub/Sub)异步消息传递系统，它结合了我们在本教程中介绍的多线程的所有高级特性。

相关文章:

*   [如何在控制台和 VS 代码中调试 Python 脚本和 API 代码](https://medium.com/codex/how-to-debug-python-scripts-and-api-code-in-the-console-and-in-vs-code-a0b825ad7d41?source=your_stories_page----------------------------------------)