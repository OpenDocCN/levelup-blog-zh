<html>
<head>
<title>Building a Deployable Jira Bug Classification Engine using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tensorflow构建可部署的吉拉Bug分类引擎</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-a-deployable-jira-bug-classification-engine-using-tensorflow-745667c72607?source=collection_archive---------20-----------------------#2020-06-08">https://levelup.gitconnected.com/building-a-deployable-jira-bug-classification-engine-using-tensorflow-745667c72607?source=collection_archive---------20-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6675c5d9de73a1d44570217967f59f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOXy1fyrMurqNOnTJb7PCA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">埃菲尔铁塔下的深层网络(鸣谢:作者自有)</figcaption></figure><h1 id="d90c" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">介绍</h1><p id="3422" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我有一段时间的职业抱负之一实际上是开始写一些ML代码，并最终掌握DNNs(深度神经网络)和<em class="mb"> Tensorflow。</em>我在<a class="ae mc" href="http://www.coursera.org" rel="noopener ugc nofollow" target="_blank"> Coursera </a>和<a class="ae mc" href="http://www.udemy.com" rel="noopener ugc nofollow" target="_blank"> Udemy </a>上上过一些课程，但是没有什么比得上在一个真实的项目中实际工作。另外，我一直在做一个名为<strong class="lf iu">章鱼</strong>的项目(肯定是我一直在吃的所有Tako-pachi或日本章鱼球)。Octopus是一个使用传统ML将吉拉bug票证分类给工程团队的项目，我想看看DNN是否可以应用于类似的项目:根据描述为吉拉bug票证分配优先级。</p><p id="7c8f" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">当我报名参加AICamp的在线课程时，我有机会这样做。这是一个为期4周的强化课程，向你介绍DNNs的基础知识，但以一种非常实际的方式进行。作为课程的一部分，我开始着手一个顶点项目，瞧，这就是我真正钻研的机会！</p><p id="574d" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">只有两个问题:</p><ol class=""><li id="f6f1" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">由于这个项目将是监督学习，我需要带标签的训练数据。我不能使用八达通数据，因为这是内部数据。此外，数据集太小(DNN训练需要数百对数万)。</li><li id="9bee" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">AICamp课程中的所有示例主要集中在图像分类上，例如MNIST、CIFAR。没有关于文本分类的。</li></ol><p id="9b3a" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">我还想获得以下方面的实践经验:</p><ol class=""><li id="2241" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">使用GPU训练模型，感受训练中的加速效果。</li><li id="d7f5" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">将模型打包成某种可部署的形式(可能使用<em class="mb"> pickle </em>)。</li><li id="be2c" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">使用Apache Flask将预测器打包成HTTP POST API。</li><li id="f7e8" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">创建预测器包的Docker映像。</li><li id="53a8" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">创建一个CI管道来构建包并部署到Docker注册中心。</li></ol><p id="1eb5" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">这些是我能够完成的，你可以在这里找到Jupyter笔记本、数据、Dockerfile、Gitlab YAML:</p><blockquote class="mw"><p id="abbd" class="mx my it bd mz na nb nc nd ne nf ma dk translated"><a class="ae mc" href="https://gitlab.com/foohm71/octopus2/-/tree/master" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/foohm71/octopus2</a></p></blockquote><p id="526f" class="pw-post-body-paragraph ld le it lf b lg ng li lj lk nh lm ln lo ni lq lr ls nj lu lv lw nk ly lz ma im bi translated">由于我设定要完成的目标之一是使用GPU训练模型，因此使用<a class="ae mc" href="http://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>很自然(Colab是Google的笔记本工具，相当于Jupyter)。此外，Google Colab内置了Tensorflow 2，并对Jupyter Notebook进行了一些漂亮的增强，使Python和数据科学方面的工作变得更容易。回购中的大多数笔记本都是要在Google Colab上运行的。</p><h1 id="19f9" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">数据</h1><p id="2277" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">原来有人已经从几个开源项目中开源了吉拉机票数据，并将其导入到PostgresSQL数据库中。你可以在这里找到<a class="ae mc" href="https://github.com/marcoortu/jira-social-repository" rel="noopener ugc nofollow" target="_blank"/>:【1】。致力于提取这个数据集的团队也就此写了一篇论文[2]。</p><p id="b0bd" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">下一步是安装PostgresSQL并执行数据导入。</p><p id="5a08" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">一旦完成，我想要一个适当大小的数据集，只是为了看看传统的ML算法将如何坚持，因为不像Octopus，我们将把票分类到bug优先级，而不是团队，因为没有开源项目的团队数据。</p><p id="9b23" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">我为此选择了动物园管理员项目的bug票:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="705c" class="nu kg it nq b gy nv nw l nx ny">select * from jira_issue_report <br/>   where status = ‘Closed’ <br/>      and type = ‘Bug’ <br/>      and project = ‘ZOOKEEPER’ <br/>      not (description is null or description = ‘’) <br/>      and priority is not null</span></pre><p id="ef4e" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">您可以在名为<code class="fe nz oa ob nq b">JIRA_OPEN_DATA_ZOOKEEPER.csv</code>的存储库中找到这个文件的CSV。这大约有400行。</p><p id="dbb3" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">我还将所有的票提取到一个CSV: <code class="fe nz oa ob nq b">JIRA_OPEN_DATA_ALL.csv</code>。这大约有20万行。</p><p id="5fd0" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">然而，我很快意识到这个数据集太大了，无法在Google Colab上处理(这很遗憾)，所以我创建了一个大约40k行的子集:<code class="fe nz oa ob nq b">JIRA_OPEN_DATA_LARGESET.csv</code>使用SQL查询:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="c709" class="nu kg it nq b gy nv nw l nx ny">select * from jira_issue_report <br/>  where status = ‘Closed’ <br/>    and type = ‘Bug’ <br/>    and (project = ‘FLEX’ <br/>    or project = ‘JBIDE’ <br/>    or project = ‘RF’ <br/>    or project = ‘SPR’ <br/>    or project = ‘HBASE’) <br/>    and not (description is null or description = ‘’) <br/>    and priority is not null</span></pre><h1 id="0961" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">使用传统ML的文本分类</h1><p id="5f74" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><em class="mb">注意:我只简要介绍这一部分，因为它不是本文的核心。关于这个主题的很好的介绍，参见[4]。</em></p><p id="8ae8" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">在<strong class="lf iu">exploratorydataanalysis . ipynb</strong>中，进行了非常基本的探索性数据分析。同样，一个非常简单的<em class="mb">文本斑点朴素贝叶斯</em>分类器被用于基线分类。这是根据[3]中的例子。</p><p id="e00e" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">需要注意一些事情:</p><ol class=""><li id="0f4d" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">文本blob朴素贝叶斯分类器的准确率约为49%</li><li id="a681" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">分类目标很偏。我们不想平衡，而是想看看这会有多糟糕/好</li><li id="0522" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">为了获得一个TF-IDF作为传统ML分类的特征，我进行了一些单词分析，从本质上提取出冗余数据，如id、电子邮件、URL。还进行了单词和二元模型的标记化。</li></ol><p id="f138" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">所有这些都是使用<em class="mb"> Numpy </em>、<em class="mb"> Pandas </em>、<em class="mb"> Sci-kit Learn </em>和<em class="mb"> Matplotlib </em>库完成的。</p><p id="6488" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">关于如何做到这一点的指南可以在[4]和[5]中找到。</p><p id="f64a" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">接下来，我使用处理过的数据集，并在以下分类器上运行:<em class="mb">朴素贝叶斯、逻辑回归、SVM和随机森林</em>分类器，还按照【6】的指导对随机森林分类器执行了一些<em class="mb">超参数调整</em>。</p><p id="5816" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">你可以在回购的<strong class="lf iu"> ModelAnalysis.ipynb </strong>中找到所有这些。最终的准确度只有33%。(当时我并没有尝试使用<em class="mb"> XGBoost </em>。也许以后吧！)</p><h1 id="9963" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">基于DNN和张量流的文本分类</h1><p id="fd1d" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">如果你看一下文献，将DNNs应用于文本分类通常分为以下几种方法:</p><ol class=""><li id="7bef" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">使用<em class="mb">循环神经网络</em> (RNN)，特别是<em class="mb"> LSTM </em>(长短期记忆)。</li><li id="28f2" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">使用一个<em class="mb">卷积神经网络</em> (CNN)。</li><li id="4777" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">使用单词嵌入，如<em class="mb"> word2vec，GloVe。</em></li><li id="9ff4" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">使用预训练模型作为基础模型，冻结/解冻层，例如<em class="mb"> BERT。</em></li></ol><p id="5f62" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">我决定去CNN，因为我在参加AICamp课程后对它有所熟悉。用于图像分类和文本分类的标准CNN之间的主要区别如下:</p><ol class=""><li id="60f2" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">使用<em class="mb">嵌入层</em>将每个单词映射到向量空间</li><li id="63db" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">使用<em class="mb"> 1D卷积层</em>代替2D卷积层</li></ol><p id="bc04" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">网络的其余部分是一个非常标准的CNN图像分类。</p><p id="764b" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">为了更好地理解CNN如何应用于文本分类，我建议要么观看Lukas Biewald的YouTube视频“使用卷积神经网络进行文本分类(2019)”——见[7]，要么参加Udemy上的懒惰程序员课程“Tensorflow 2.0:深度学习和人工智能”[8]。有一节是关于将LSTM和CNN应用于二进制文本分类的。</p><p id="76ef" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">嵌入层背后的关键思想是这样的:如果我们将每个单词映射到一个N维向量空间，那么单词之间的“距离”(即。每个单词如何相互关联)可以通过调整每个单词在向量空间中的位置来“学习”。</p><p id="35f3" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">至于1D卷积层——其想法与2D卷积层相同，但我们不是在<code class="fe nz oa ob nq b">n x n</code>内核上操作，而是在<code class="fe nz oa ob nq b">1 x n</code>内核上操作，后者是单词的数字表示。这背后的关键直觉是单词与其旁边的单词有关系(与在传统NLP中使用n元语法的想法相同)。</p><h2 id="e764" class="nu kg it bd kh oc od dn kl oe of dp kp lo og oh kt ls oi oj kx lw ok ol lb om bi translated">数据准备</h2><p id="62c0" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">类似于传统的ML，我们将原始文本转换为TF-IDF矩阵，我们必须在这里做一些类似的事情。基本上创建一系列单词序列，并在末尾填充零。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="ac19" class="nu kg it nq b gy nv nw l nx ny"># Convert sentences to sequences<br/>MAX_VOCAB_SIZE = 20000<br/>tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)<br/>tokenizer.fit_on_texts(df_train)<br/>sequences_train = tokenizer.texts_to_sequences(df_train)<br/>sequences_test = tokenizer.texts_to_sequences(df_test)</span><span id="0251" class="nu kg it nq b gy on nw l nx ny"># get word -&gt; integer mapping<br/>word2idx = tokenizer.word_index<br/>V = len(word2idx)</span><span id="2cfa" class="nu kg it nq b gy on nw l nx ny"># pad sequences so that we get a N x T matrix<br/>data_train = pad_sequences(sequences_train)</span><span id="0536" class="nu kg it nq b gy on nw l nx ny"># get sequence length<br/>T = data_train.shape[1]</span><span id="25b2" class="nu kg it nq b gy on nw l nx ny">data_test = pad_sequences(sequences_test, maxlen=T)</span></pre><h2 id="570a" class="nu kg it bd kh oc od dn kl oe of dp kp lo og oh kt ls oi oj kx lw ok ol lb om bi translated">模型探索/调整</h2><p id="3eb4" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在<strong class="lf iu">dnnmodelansalysis . ipynb</strong>中你会发现模型探索:</p><ol class=""><li id="f76a" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">我从针对二元分类提出的基本CNN模型开始，并将其修改为处理多类别分类。</li><li id="7fb9" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">逐渐添加更多的卷积和密集层，以帮助模型更好地学习。</li><li id="2a72" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">添加批量标准化和剔除以减少过度拟合。</li><li id="14d4" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">最后加上早停。</li></ol><p id="7fb3" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">最终模型包含以下内容:</p><ul class=""><li id="a7c2" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma oo mo mp mq bi translated">嵌入层</li><li id="f162" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">内核大小为3的6个1D conv层</li><li id="c2f4" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">最大池层</li><li id="72cd" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">内核大小为3的4个1D conv层</li><li id="7b8a" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">最大池层</li><li id="b970" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">内核大小为3的2个1d conv层</li><li id="7803" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">全局最大池</li><li id="2870" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">4个密集层，有漏失</li><li id="b2fa" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">批量标准化的所有图层</li><li id="7268" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated">提前停止</li></ul><p id="3673" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">代码:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="ee2b" class="nu kg it nq b gy nv nw l nx ny">D = 20</span><span id="3003" class="nu kg it nq b gy on nw l nx ny">early_stopper = EarlyStopping(monitor=’val_loss’, patience=5, restore_best_weights=True)</span><span id="f392" class="nu kg it nq b gy on nw l nx ny">model = Sequential()<br/>model.add(Input(shape=(T,)))</span><span id="e5af" class="nu kg it nq b gy on nw l nx ny">model.add(Embedding(V + 1, D))</span><span id="470f" class="nu kg it nq b gy on nw l nx ny">model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(32, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling1D(3))</span><span id="e2bf" class="nu kg it nq b gy on nw l nx ny">model.add(Conv1D(64, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(64, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(64, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(64, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(MaxPooling1D(3))</span><span id="a22b" class="nu kg it nq b gy on nw l nx ny">model.add(Conv1D(128, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Conv1D(128, 3, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(GlobalMaxPooling1D())</span><span id="8472" class="nu kg it nq b gy on nw l nx ny">model.add(Dense(units=800, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.2))<br/>model.add(Dense(units=400, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.2))<br/>model.add(Dense(units=200, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.2))<br/>model.add(Dense(units=100, activation=’relu’))<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.2))<br/>model.add(Dense(units=num_classes, activation=’softmax’))</span><span id="fd5c" class="nu kg it nq b gy on nw l nx ny">model.compile(optimizer=’adam’, loss=’categorical_crossentropy’, metrics=[‘accuracy’])<br/>history = model.fit(data_train1, training_labels1, epochs=40, batch_size=8, verbose=True, validation_split=.2, callbacks=[early_stopper])<br/>plot_training_history(history, model, data_test1, test_labels1)</span></pre><p id="81ff" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">即使我们将其与传统的ML模型进行比较，其精度也达到了约54%,但是大型数据集对于ML模型来说太大了，而ZOOKEEPER数据集对于DNN来说太小了。</p><h1 id="5339" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">构建可部署模型</h1><p id="e226" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这有3个组成部分:</p><ol class=""><li id="cff8" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">培训和保存模型</li><li id="e7cd" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">构建简单的HTTP POST API包装器</li><li id="e4fb" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">构建简单的CI渠道</li></ol><p id="b5b0" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated"><em class="mb">注意:有几种方法可以构建云部署的可部署模型:谷歌云(GCP)有几种方法可以做到这一点，这些方法都有很好的记录，亚马逊(AWS)也是如此，例如Sagemaker和微软Azure。</em></p><h2 id="5ce4" class="nu kg it bd kh oc od dn kl oe of dp kp lo og oh kt ls oi oj kx lw ok ol lb om bi translated">培训和保存模型</h2><p id="86cc" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lf iu">dnnproductiontraining . ipynb</strong>包含我用来训练模型并将模型保存到<code class="fe nz oa ob nq b">.h5</code>文件中的步骤。它被设计为使用GPU和高RAM运行时在Google Colab上运行。在传统的CPU上，这将需要更长的时间来训练。</p><p id="9490" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">该模型与上一节中描述的最终模型相同。唯一不同的是，这次它是用整个大数据集训练的(没有训练/测试分裂)。</p><p id="1694" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">一旦被训练，它被保存:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="0a15" class="nu kg it nq b gy nv nw l nx ny">model.save(“/content/gdrive/My Drive/Colab Notebooks/Octopus2/jira_open_data_classifier.h5”, save_format=’tf’)</span></pre><p id="c848" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">然后我们测试这个模型，看它是否能预测。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="7dfa" class="nu kg it nq b gy nv nw l nx ny">test_sentance = [‘The hard coded host of the client can only let it run on the same host as the thrift server.’]</span><span id="913a" class="nu kg it nq b gy on nw l nx ny">test_seq = tokenizer.texts_to_sequences(test_sentance)</span><span id="e75f" class="nu kg it nq b gy on nw l nx ny">test_padded = pad_sequences(test_seq, maxlen=T)</span><span id="af37" class="nu kg it nq b gy on nw l nx ny">p = model.predict_classes(test_padded)</span></pre><h2 id="5a8d" class="nu kg it bd kh oc od dn kl oe of dp kp lo og oh kt ls oi oj kx lw ok ol lb om bi translated">构建简单的HTTP POST API包装器</h2><p id="6c7e" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这本质上是回购中的<code class="fe nz oa ob nq b"><strong class="lf iu">app.py</strong></code>。</p><p id="0205" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">这只是一个Apache Flask应用程序，它:</p><ol class=""><li id="e635" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma mn mo mp mq bi translated">从<code class="fe nz oa ob nq b">jira_open_data_classifier.h5</code>加载模型</li><li id="9ab2" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">从JSON POST有效负载中提取“标题”和“描述”</li><li id="62bf" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma mn mo mp mq bi translated">运行预测并输出预测。这段代码类似于上一节中的测试代码。</li></ol><p id="326a" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">要跑<code class="fe nz oa ob nq b">app.py,</code>只需<code class="fe nz oa ob nq b">python3 app.py</code></p><p id="59a7" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated"><code class="fe nz oa ob nq b">test.sh</code>包含执行POST的curl命令:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="771f" class="nu kg it nq b gy nv nw l nx ny">curl -X POST -H “Content-Type: application/json” \<br/>  -d ‘{“title”: “TestSizeBasedThrottler fails occasionally”, “description”: “Every now and then TestSizeBasedThrottler fails reaching the test internal timeouts.I think the timeouts (200ms) are too short for the Jenkins machines.On my (reasonably fast) machine I get timeout reliably when I set the timeout to 50ms, and occasionally at 100ms.”}’ \<br/>  <a class="ae mc" href="http://localhost:5000/api_predict" rel="noopener ugc nofollow" target="_blank">“http://localhost:5000/api_predict</a>"</span></pre><h2 id="b038" class="nu kg it bd kh oc od dn kl oe of dp kp lo og oh kt ls oi oj kx lw ok ol lb om bi translated">构建简单的CI渠道</h2><p id="0f67" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我发现Gitlab的一个好处是，它们为<code class="fe nz oa ob nq b">.gitlab-ci.yml</code>(CI)和<code class="fe nz oa ob nq b">Dockerfile</code>提供了模板。要创建CI管道，你只需要在主项目页面上，点击“设置CI/CD”按钮，它将创建一个基本的空白<code class="fe nz oa ob nq b">.gitlab-ci.yml</code>，将有一个下拉菜单，上面写着“应用模板”，让你从各种类型的构建管道中进行选择，如Android、C++等。为此，我选择了“Docker ”,因为我想创建一个Docker容器。</p><figure class="nl nm nn no gt ju gh gi paragraph-image"><div class="gh gi op"><img src="../Images/cf37c86120f36d1794c4c1946841183f.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*OiUBlPRJBkwW4_F0xDBuGQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">“设置配置项/光盘”按钮</figcaption></figure><figure class="nl nm nn no gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oq"><img src="../Images/bebc4d0d5da2e70c87cfc7ec3291446f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QLmvFE4WY0AJgrM3ZxXUzA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">如何应用“Docker”模板”</figcaption></figure><p id="0f83" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated"><em class="mb">注意:如果你从未创建过Docker容器并在Docker注册表上发布过Hello World容器，我建议你前往</em><a class="ae mc" href="http://docker.com" rel="noopener ugc nofollow" target="_blank"><em class="mb">docker.com</em></a><em class="mb">并按照快速入门教程创建一个简单的Hello World容器并将其发布在Docker注册表上。</em></p><p id="c0e9" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">回到<code class="fe nz oa ob nq b">.gitlab-ci.yml</code>，您会注意到以下环境变量:</p><ul class=""><li id="206c" class="mi mj it lf b lg md lk me lo mk ls ml lw mm ma oo mo mp mq bi translated">【docker.com】—这是您用来登录注册中心的用户标识(在本例中为T4)</li><li id="c1ee" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated"><code class="fe nz oa ob nq b">$CI_REGISTRY_PASSWORD</code> —这是您用于登录注册表的密码(在本例中为<a class="ae mc" href="http://docker.com" rel="noopener ugc nofollow" target="_blank">docker.com</a>)</li><li id="66c8" class="mi mj it lf b lg mr lk ms lo mt ls mu lw mv ma oo mo mp mq bi translated"><code class="fe nz oa ob nq b">$CI_REGISTRY</code> —这可以删除，因为我们使用的是默认的Docker注册表。这将是必要的，如果你有一个单独的Docker注册表，如AWS</li></ul><p id="9564" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">这些环境变量需要在“设置-&gt; CI / CD -&gt;变量”下进行配置。在那里，您可以将这些变量添加为键值对。</p><figure class="nl nm nn no gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi or"><img src="../Images/178e4ea841e4815d21c893546f864500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1JT7hgM48ugxt_BrHFXXA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">在哪里配置CI/CD变量</figcaption></figure><p id="902d" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">如果你已经正确地设置好了一切(事实上一旦repo中有一个<code class="fe nz oa ob nq b">.gitlab-ci.yml</code>), git lab将开始构建。转到“CI / CD - &gt;管道”，您应该会看到一些运行。</p><figure class="nl nm nn no gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi os"><img src="../Images/a75ff5b63e04465d650d455d267e4bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0MfuL828mJnipsglu27URA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">CI/CD管道视图</figcaption></figure><p id="08da" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">如果您单击管道散列，导航到正在运行的作业并单击它，您将能够看到该作业的控制台日志。</p><figure class="nl nm nn no gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ot"><img src="../Images/f3bb27b88065e283ae5a0a0fecc1d7e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kTWlFyGzjC-CzCD6Ctw8GA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">成功完成的作业的控制台日志</figcaption></figure><p id="a779" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">不幸的是，管道最有可能失败，因为Dockerfile文件尚未创建。为此，请转到“项目概述”并单击“新建文件”按钮(如果您没有看到“新建文件”按钮，您也可以单击“更改日志”按钮)。</p><figure class="nl nm nn no gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ou"><img src="../Images/809ac8e6e0bbba80c55d6f1aa0d684cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uP8b1Gt6hAQVno38Wv1qbQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">如何添加Dockerfile文件</figcaption></figure><p id="4790" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">然后将允许您选择一个模板。我选择了<em class="mb"> Python </em>的一个作为底子。</p><p id="f8af" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">我创建的Dockerfile文件是:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="c5a9" class="nu kg it nq b gy nv nw l nx ny">FROM python:3.6<br/><br/>WORKDIR /usr/src/app<br/><br/>COPY requirements.txt /usr/src/app/<br/>RUN pip install --no-cache-dir -r requirements.txt<br/><br/>COPY . /usr/src/app<br/><br/># Inform Docker that the container is listening on the specified port at runtime.<br/>EXPOSE 5000<br/><br/># Run command<br/>CMD ["python", "app.py"]</span></pre><p id="78b0" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">一旦就位，构建就应该成功了。docker映像被构建并在注册表上发布。</p><h1 id="74c0" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">参考</h1><p id="becf" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">[1]吉拉社会知识库，马可·奥图等著<a class="ae mc" href="https://github.com/marcoortu/jira-social-repository" rel="noopener ugc nofollow" target="_blank">https://github.com/marcoortu/jira-social-repository</a></p><p id="323a" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[2]JIRA储存库数据集，Marco Ortu等人，2015年9月<a class="ae mc" href="https://www.researchgate.net/publication/301370380_The_JIRA_Repository_Dataset" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/publication/301370380 _ The _ JIRA _储存库_数据集</a></p><p id="9928" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[3]教程:构建文本分类系统，Text blob【https://textblob.readthedocs.io/en/dev/classifiers.html T4】</p><p id="3e30" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[4]使用NLTK的初学者的文本分析，Avinash Navlani，2019年12月<a class="ae mc" href="https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/Text-Analytics-初学者-nltk </a></p><p id="76a6" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[5]理解Python中的随机森林分类器，Avinash Navlani，2019年5月<a class="ae mc" href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/Random-Forests-classifier-Python</a></p><p id="5803" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[6]Hyperparameter Tuning the Random Forest in Python，Will Koehrsen，2018年1月<a class="ae mc" href="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74" rel="noopener" target="_blank">https://towardsdatascience . com/Hyperparameter-Tuning-the-Random-Forest-in-Python-using-scikit-learn-28 D2 aa 77 DD 74</a></p><p id="4b51" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[7]使用卷积神经网络的文本分类(2019)，卢卡斯·比沃尔德<a class="ae mc" href="https://youtu.be/8YsZXTpFRO0" rel="noopener ugc nofollow" target="_blank">https://youtu.be/8YsZXTpFRO0</a></p><p id="6f25" class="pw-post-body-paragraph ld le it lf b lg md li lj lk me lm ln lo mf lq lr ls mg lu lv lw mh ly lz ma im bi translated">[8] Tensorflow 2.0:深度学习与人工智能，懒程序员<a class="ae mc" href="https://www.udemy.com/course/deep-learning-tensorflow-2/learn/lecture/15862048?start=390#questions" rel="noopener ugc nofollow" target="_blank">https://www.udemy.com/course/deep-learning-tensorflow-2/</a></p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><div class="nl nm nn no gt pc"><a href="https://skilled.dev" rel="noopener  ugc nofollow" target="_blank"><div class="pd ab fo"><div class="pe ab pf cl cj pg"><h2 class="bd iu gy z fp ph fr fs pi fu fw is bi translated">编写面试问题</h2><div class="pj l"><h3 class="bd b gy z fp ph fr fs pi fu fw dk translated">一个完整的平台，在这里我会教你找到下一份工作所需的一切，以及…</h3></div><div class="pk l"><p class="bd b dl z fp ph fr fs pi fu fw dk translated">技术开发</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq jz pc"/></div></div></a></div></div></div>    
</body>
</html>