<html>
<head>
<title>Building a Real-Time digit classifier using MNIST (99.17% accuracy)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用MNIST构建实时数字分类器(99.17%准确度)</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-a-real-time-digit-classifier-using-mnist-99-17-accuracy-1b894b07cae7?source=collection_archive---------11-----------------------#2020-07-01">https://levelup.gitconnected.com/building-a-real-time-digit-classifier-using-mnist-99-17-accuracy-1b894b07cae7?source=collection_archive---------11-----------------------#2020-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/e7620493a3de60425cfd89c7d99be1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Ft2rLuO82eItlvJn5HOi9A.png"/></div></figure><p id="ab9b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><em class="kv">你可以看看已部署的</em> <a class="ae kw" href="https://mnist.dube.io" rel="noopener ugc nofollow" target="_blank"> <em class="kv">互动演示</em> </a> <em class="kv">或者看看</em> <a class="ae kw" href="https://github.com/gisderdube/mnist" rel="noopener ugc nofollow" target="_blank"> <em class="kv"> github回购</em> </a> <em class="kv">。</em></p><p id="1abe" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><a class="ae kw" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>是使用深度学习训练图像分类器的经典数据集。该数据集由70，000个手写数字组成，存储为图像。现在，我在玩深度学习，我想看看作为该领域的新手，可能会有什么样的表现会很有趣。</p><figure class="ky kz la lb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/e2b5757d6adc6a56b0676d475e1d79b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*B79qfsdotgbay2yo7x7caw.gif"/></div></div></figure><p id="e53f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我的想法是把一个分类器和一个小前端结合起来，让用户用鼠标画一个数字，并实时看到结果。毕竟，让一段代码表现良好是一回事，但让它对用户来说容易理解是另一回事。</p><p id="ead1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">从事Web开发已经有几年了，构建前端并不是太大的问题。我知道我可以用画布让用户画画。围绕这一点，我需要一个基本的网页，显示结果，加载状态等。稍后会详细介绍。</p><h2 id="b487" class="lg lh it bd li lj lk dn ll lm ln dp lo ki lp lq lr km ls lt lu kq lv lw lx ly bi translated">训练模型</h2><p id="0c9e" class="pw-post-body-paragraph jx jy it jz b ka lz kc kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku im bi translated">正如之前的深度学习项目一样，我使用了fast.ai库来创建和训练一个神经网络。该库为您提供了快速入门所需的所有工具(尤其是对初学者而言)。您只需加载数据，选择一个基础架构，提供一些基础变量，然后让模型自行训练。</p><p id="2f55" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">提供数据很容易，至少我一开始是这样认为的。数据集已经存在，我只需要下载数据并提供给模型。下载并解压存档数据后，我注意到它几乎是无格式数据，即“无符号字节”。虽然很可能有一种方法可以将它输入到神经网络中，但我希望数据是单个的PNG文件。我尝试运行一些脚本来转换它，但最终发现这个<a class="ae kw" href="https://github.com/myleott/mnist_png" rel="noopener ugc nofollow" target="_blank"> github repo </a>将数据集转换成了PNG。</p><figure class="ky kz la lb gt ju gh gi paragraph-image"><div class="gh gi me"><img src="../Images/c5cfa5a8318ecf4849690fcff0f95ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*ucExC1ri1YAkuicoEbsPmw.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">第一轮培训</figcaption></figure><p id="fc80" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">有了可用格式的数据(对我来说)，我就可以继续训练模型了。我使用resnet34作为CNN的基础架构，并训练模型。开箱即用，模型达到了~98.9%的准确率，非常惊人。能够在一天之内训练一个手写识别模型(只有数字)达到如此高的精度令人兴奋不已。知道来龙去脉的人可能能够在&lt;20 minutes, but still a good timeframe!</p><figure class="ky kz la lb gt ju gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/4f09b64fd5f49e76c2ef0bb7c6267fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*OoM847uQ8mhutXYgbmF3fQ.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">second training round after unfreezing</figcaption></figure><p id="99a0" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">I thought I might unfreeze the model (allowing to change weights of all layers of the neural net) and train again, but the error_rate didn’t seem to come down.</p><p id="355f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">Clearly there must be something that is missing, as I would expect the unfreezed training to reduce the error rate. I went back and had a look at the learn rates for both freezed and unfreezed stages and voilà, things got below the 1% error rate threshold:</p><figure class="ky kz la lb gt ju gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/58e343a828da4e25409d1ccf60c78a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*2mfEMx38Iq94wo7Hi2lrpg.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">learn rate for freezed model</figcaption></figure><figure class="ky kz la lb gt ju gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/17977a03d5f08c1f8c2c5b166a0d843a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*FYoEKe9PmZaVMhYp8qc1EQ.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">fresh training with freezed model &amp; good LR</figcaption></figure><figure class="ky kz la lb gt ju gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/e0b705577f3f9e01ba84042df882ae7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*XmOy2-3BFxL-ZdtQhDYgrw.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk translated">training with unfreezed model &amp; good LR</figcaption></figure><h2 id="9160" class="lg lh it bd li lj lk dn ll lm ln dp lo ki lp lq lr km ls lt lu kq lv lw lx ly bi translated">Overfitting after unfreezing</h2><p id="f75d" class="pw-post-body-paragraph jx jy it jz b ka lz kc kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku im bi translated">With a good learn rate, the error rate dropped to 0.833% for the freezed model and even 0.767% for the unfreezed one after training. At first sight, the 0.767% seems better, but after deploying the model to the <a class="ae kw" href="https://mnist.dube.io" rel="noopener ugc nofollow" target="_blank">互动演示</a>中做到这一点，我发现实际性能更差。例如，如果我在矩形(=0)的上部画一个小圆，模型会将其归类为9。我不太确定这到底是什么原因，以及它是否真的过度拟合，但我会在冻结模型和0.833%的错误率下获得更好的真实性能。</p><h2 id="62d9" class="lg lh it bd li lj lk dn ll lm ln dp lo ki lp lq lr km ls lt lu kq lv lw lx ly bi translated">部署应用程序</h2><p id="28f9" class="pw-post-body-paragraph jx jy it jz b ka lz kc kd ke ma kg kh ki mb kk kl km mc ko kp kq md ks kt ku im bi translated">在我的上一个项目中，我使用node.js服务器为web应用程序提供服务，对于任何分类任务，node.js进程都会生成一个子python进程来运行实际的分类。这是可行的，但并不真正有效，因为模型本身的大小约为200MB。启动python进程、加载模型和运行分类脚本将花费相当多的时间，尤其是当有多个请求进入时。这一次，我选择了一个python进程，它可以一直运行，并将模型保存在内存中。node.js (express)和python (flask)服务器将通过HTTP进行通信，只有node.js服务器可以被外界访问。当然，有可能只有一个python服务器，让它也为web应用服务。然而，由于对Node.js更加熟悉，我选择了这个解决方案。此外，这使得主服务器负载相对较低(在这种情况下，这不是一个大问题)。你可以在<a class="ae kw" href="https://github.com/gisderdube/mnist" rel="noopener ugc nofollow" target="_blank"> github repo </a>中查看完整设置。用于训练模型的Jupyter笔记本也在那里，但是你需要预先下载数据来运行它。</p></div></div>    
</body>
</html>