<html>
<head>
<title>Neural Network from scratch: Multiply entities Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的神经网络:多重实体分类</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/neural-network-from-scratch-multiply-entities-classification-72f7d5f4c2e?source=collection_archive---------10-----------------------#2021-01-13">https://levelup.gitconnected.com/neural-network-from-scratch-multiply-entities-classification-72f7d5f4c2e?source=collection_archive---------10-----------------------#2021-01-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="f65a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/better-programming/neural-network-from-scratch-hidden-layers-bb7a9e252e44" rel="noopener">上一次</a>我们讨论了向我们的神经网络添加隐藏层，它在解决二进制分类任务方面做得很好。但是如果我们的本体中有更多的实体呢？让我们来想想如何教会我们的神经网络如何解决多个实体分类问题！</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/0874270b998003031c5db659a1fac8b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODTYQqjGZ15yHEf7bXRDqA.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae ko" href="https://pixabay.com/photos/artificial-intelligence-brain-think-3382521/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h2 id="7a61" class="lf lg it bd lh li lj dn lk ll lm dp ln kb lo lp lq kf lr ls lt kj lu lv lw lx bi translated"><strong class="ak">生成数据</strong></h2><p id="3974" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">说到神经网络，训练数据集是第一位的！我们将生成数据集的3个部分，以演示如何处理两个以上的分类。每个片段将包含两个痴呆坐标阵列，我们将指定这些点的范围，以将它们分组在一起。因此，每一段将以0:-3，3，3和-3，3点为中心。并且每个段将对应于一个输出。这是原始数据生成的样子:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi md"><img src="../Images/6c2e1ff30fee4dd861adca16f168a466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lHPsj1ediPFDQV8NA4bTDg.png"/></div></div></figure><p id="ee50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们将在一个数据集中组合所有3个片段，并对其进行标记，这使我们的神经网络能够从中学习。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi me"><img src="../Images/8c1a92bd862cd0deea1e8ae993089b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZi-3Erkf5V5Tuv_Bj0emw.png"/></div></div></figure><p id="ee06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我们的数据:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mf"><img src="../Images/bd42aa3f7d3373dc9ce7e61deab99cfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qX6ldDGRd1oHDiJ6oqPbDw.png"/></div></div></figure><h2 id="3143" class="lf lg it bd lh li lj dn lk ll lm dp ln kb lo lp lq kf lr ls lt kj lu lv lw lx bi translated"><strong class="ak">网络参数</strong></h2><p id="1937" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">下一步是生成神经网络的所有参数。比如隐藏层和输出层的权重和偏差。如果你读了前一篇文章，你可能会注意到我们的神经网络结构非常相似，只有输出层不同。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mg"><img src="../Images/79d3c0c82cd47d599b9657f74eb87900.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZyRpb4rurYveewAhNGX8oQ.png"/></div></div></figure><p id="8965" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里是参数生成的代码:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mh"><img src="../Images/48e5666feddd10a8a5d0beffa2838110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gon03_FQxE_eEktaso4aww.png"/></div></div></figure><p id="17cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">激活功能</strong></p><p id="67f7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以前我们只使用sigmoid激活函数，它很好地服务了我们。但是因为现在我们在输出层有3个类，所以最好使用其他的。</p><p id="b653" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有一个<strong class="js iu"> softmax </strong>函数来帮助我们。softmax函数是两个以上类情况下输出层的常用激活函数。因为输出有3个元素，我们可以把每个元素的输出看作输入层的一个元素。数学上，softmax函数是这样的:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/9e7b67f722c8b74f8b4b92d1cc7a09bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*kB1s-Vh4Drv6BRQokwH9Pw.png"/></div></figure><p id="490e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在简单的语言中，softmax函数将每个输入元素的指数除以每个输入元素的指数之和。这是softmax函数在python中的样子:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mj"><img src="../Images/1e6f70684db5a8a3ea032a24ad71159b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWXDLSR7KVqXboAkDicR1w.png"/></div></div></figure><p id="0cfd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以继续训练我们的模型。</p><p id="9f9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">培训</strong></p><p id="f424" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练过程非常类似于二进制分类。我们有前馈和反向传播阶段。但是因为在输出层上我们使用不同的激活函数，所以存在一些差异。</p><p id="893d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在前馈过程中，我们仍然要为隐藏层使用sigmoid激活函数。softmax函数将用于输出图层。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mk"><img src="../Images/6bb07b4a809a4bec90d706dde6dda465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mQXm9iCg1heSTqDHwUkGlQ.png"/></div></div></figure><p id="9e7d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于反向传播，我们计算输出层的新权重和偏差，作为softmax函数的结果。所有其余的操作基本保持不变。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ml"><img src="../Images/f8b1907ae8a07c1b9a3da5b2843e081b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMql4nIUK84SuVnBgvPpgA.png"/></div></div></figure><p id="2a56" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于softmax情况下的误差成本的计算，我们将使用交叉熵函数而不是均方差。交叉熵函数只是所有标记概率的总和，并且预测概率为负对数。交叉熵函数的数学表示如下:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/a4a77c15abfd524e90f3d20180702dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*9xAVIrFZ3yWfjQi7936NJg.png"/></div></figure><p id="8a89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们准备好生成数据并训练我们的模型。让我们来测试一下。</p><h2 id="ab24" class="lf lg it bd lh li lj dn lk ll lm dp ln kb lo lp lq kf lr ls lt kj lu lv lw lx bi translated"><strong class="ak">测试</strong></h2><p id="0086" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">训练完成后，我们可以使用产生的权重和偏差来尝试随机数据点。对于测试，我们将再现前馈过程，而不是反向传播，因为权重和偏差已经被训练，不需要更新。</p><p id="02cd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们以一个痴呆数组的形式获得softmax函数的输出后，我们可以找到最大值的索引，这将是该数据点的标签。</p><p id="f41e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了添加新的数据点并测试它是否接近我们肉眼所见的事实，我们将向训练数据集和标签集中添加新的数据点及其标签。</p><p id="1b3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们用50000次交互来尝试一下，以确保成本函数得到了很好的优化。第一个坐标将是[0.0，0.5]，这是我们的模型如何在地图上标记它:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mn"><img src="../Images/7f9eef374adc919c5810614d562677da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PYjHqelOTEscS4maoHSF4Q.png"/></div></div></figure><p id="70cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于位置的解码，只需记住在softmax函数的输出中，数组中有3个元素。元素索引0代表蓝色标签，元素索引1代表粉色，元素索引2代表黄色。我们可以看到，模型非常确定这个点应该是蓝色的，我们可以在图上看到它的预测是正确的。</p><p id="abcb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一种情况是[-2.0，1.0]，我们可以看到模型非常自信地认为它是黄色的。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mo"><img src="../Images/27091cd6c0df160f94683aee1b2a8128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rgDt99DNE_N-SuRfFBKCg.png"/></div></div></figure><p id="9739" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">而最后的测试是[2.0，-0.5]。在这种情况下，mode确信它绝对不是黄色的。它更倾向于蓝色，但仍然有很多疑问。对于这样一个边缘案例来说，这是一个很好的结果。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mp"><img src="../Images/f8f18cd17d96991344ede40a5838d5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ef-Ir6Kmw4fhqO1ls8YI9Q.png"/></div></div></figure><h2 id="0309" class="lf lg it bd lh li lj dn lk ll lm dp ln kb lo lp lq kf lr ls lt kj lu lv lw lx bi translated"><strong class="ak">完整代码</strong>:</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h2 id="fde7" class="lf lg it bd lh li lj dn lk ll lm dp ln kb lo lp lq kf lr ls lt kj lu lv lw lx bi translated"><strong class="ak">结论</strong></h2><p id="d234" class="pw-post-body-paragraph jq jr it js b jt ly jv jw jx lz jz ka kb ma kd ke kf mb kh ki kj mc kl km kn im bi translated">今天我们学习了如何修改神经网络，使其能够解决多种分类问题。现在我们已经准备好处理真实的数据集，解决真实的问题。这就是我们接下来要做的！</p><p id="8261" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不断学习，不断成长！</p></div></div>    
</body>
</html>