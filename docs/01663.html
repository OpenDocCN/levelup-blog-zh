<html>
<head>
<title>My First Machine Learning Competition — Predicting Titanic Passenger Survivors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我的第一次机器学习竞赛——预测泰坦尼克号乘客幸存者</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/my-first-ml-competition-titanic-74686e0a37a7?source=collection_archive---------12-----------------------#2020-01-20">https://levelup.gitconnected.com/my-first-ml-competition-titanic-74686e0a37a7?source=collection_archive---------12-----------------------#2020-01-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ad290b2ba08bdc2781826c471bbe2ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vU2JHmycmbuO9O1J.jpg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">泰坦尼克</figcaption></figure><p id="3e22" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">什么是Kaggle？Kaggle是一个由数据科学家和机器学习者组成的在线社区。Kaggle允许用户查找和发布数据集，探索和构建模型，与其他数据科学家合作，并参加竞赛以解决数据科学挑战。</p><blockquote class="la lb lc"><p id="4a90" class="kc kd ld ke b kf kg kh ki kj kk kl km le ko kp kq lf ks kt ku lg kw kx ky kz ij bi translated">Kaggle是数据科学家的AirBnB，这是他们度过夜晚和周末的地方。</p></blockquote><p id="5d31" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi">😆</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><p id="5045" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我于2016年加入Kaggle，当时我刚刚进入数据科学领域——<a class="ae lh" href="https://www.kaggle.com/josephanyona" rel="noopener ugc nofollow" target="_blank">请在Kaggle </a>、<a class="ae lh" href="https://www.linkedin.com/in/joseph-magiya/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上查看我的信息。首先出现的是泰坦尼克号比赛，我报名参加了。不幸的是，直到最近我才开始尝试解决这个难题。现在比当时更令人兴奋。如果你是一名数据科学家，正在阅读这篇文章，或者想学习机器学习——注册吧，这是免费的。抓住这个机会，我保证你会从这个过程中学到超乎你想象的东西。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><p id="95ea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">泰坦尼克号在与冰山相撞后沉没了。不幸的是，没有足够的救生艇容纳船上的每个人，导致2224名乘客和船员中的1502人死亡。虽然幸存有一些运气成分，但似乎某些群体比其他群体更有可能幸存。作为一名数据科学家，这立即激起了我的兴趣。</p><p id="2fe7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">比赛的目标很简单:使用机器学习来创建一个模型，预测哪些乘客在泰坦尼克号沉船事件中幸存。</p><p id="8f0b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我认为这是分析后的下一步。在我的研究和分析过程中，我遇到了大量的<a class="ae lh" href="https://www.kaggle.com/c/titanic/notebooks" rel="noopener ugc nofollow" target="_blank">笔记本</a>，它们帮助我找到了正确的方向。我在PowerBI中做了我的分析——它在可视化和分析数据方面更容易、更快捷。</p><p id="8c0b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我也看了竞赛的<a class="ae lh" href="https://www.kaggle.com/c/titanic/overview/tutorials" rel="noopener ugc nofollow" target="_blank">教程</a>部分，我看到Excel里面有机器学习！💥我必须在未来的某个时候尝试这个(从今天起不到3年的时间内)。</p><p id="ffb7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你是一名数据科学家/机器学习大师，或者甚至只是想成为一名数据科学家/机器学习大师，Kaggle是一个很好的开始平台——尤其是在泰坦尼克号挑战中。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><p id="b4ba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我花了大约两周的时间制作这个模型，并提交了我的作品。我喜欢学习不同的方法和模型。我提交了几份申请，试图得到最好的分数</p><p id="1986" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我最好的模型如下所示。</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/59879614c0f86dbe3210da27b7de70c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4KpGkbz_QOlycZ4zGDKbw.png"/></div></div></figure><p id="2940" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在为这项挑战构建不同的模型时，准确度得分如下:</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="b9d5" class="lz ma iq lv b gy mb mc l md me">accuracy = accuracy_score(y_test, y_pred)</span></pre><ul class=""><li id="5344" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz mk ml mm mn bi translated">随机森林— 78.48%</li><li id="63a4" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">XGBoost — 82.96%</li><li id="c9dd" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">XGBoost(超参数调优后)— 82.06% —这里我明显漏掉了一些东西。</li><li id="efef" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">决策树分类器— 82.06%</li><li id="39c0" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">超调决策树分类器— 81.17%</li><li id="c03c" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">特征比例决策树分类器— 79.82%</li><li id="8985" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">套袋— 75.34%</li><li id="5b2d" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">超调套袋——80.27%</li><li id="1173" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">特征比例装袋— 80.27%</li><li id="3d1b" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">梯度提升— 91.03%</li><li id="ce3f" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">额外树分类器— 98.21%</li><li id="6bfc" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">逻辑回归— 77.13%</li><li id="41ed" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">特征比例逻辑回归— 76.68%</li></ul><p id="da7c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如你已经知道的，建立模型时的准确性分数与Kaggle分数非常不同。大多数时候，我们使用<em class="ld"> accuracy_scores </em>来衡量我们模型的性能，从上面可以非常明显地看出，这不足以真正判断我们的模型。在现实世界中，我们可能需要测试不同的东西，看看哪个适合我们的场景——不要害怕尝试。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><p id="0fbd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你需要看一下我的笔记本——里面有比我上面列出的更多的信息，这里有<a class="ae lh" href="https://github.com/JosephMagiya/Kaggle---Titanic-Competition" rel="noopener ugc nofollow" target="_blank">链接</a></p></div></div>    
</body>
</html>