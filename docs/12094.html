<html>
<head>
<title>Spiking Neural Networks and Computational Thinking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脉冲神经网络与计算思维</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/spiking-neural-networks-and-computational-thinking-8e9d03a7481c?source=collection_archive---------7-----------------------#2022-05-14">https://levelup.gitconnected.com/spiking-neural-networks-and-computational-thinking-8e9d03a7481c?source=collection_archive---------7-----------------------#2022-05-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/535cb407cb91ee15a51b98509dca8c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O5Be4wynHMI0STYi"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">米拉德·法库里安在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><figure class="ke kf kg kh gt jr gh gi paragraph-image"><a href="https://www.youtube.com/watch?v=b0cZKXz75xc"><div class="gh gi kd"><img src="../Images/90864874a47093fd292655e483d719b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0e0HiS3bBXxYM3K1_clxKw.jpeg"/></div></a></figure><p id="9dac" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">从我们记事起，人类就对大脑着迷。最初，就像在科学的主要领域一样，人类的大脑只是基于推测；甚至应用了一些理论，但结果都不好。20世纪对几个科学领域来说相当重要(例如，最后，随着爱因斯坦关于布朗运动的论文，原子被证明是真实的和可测量的)；这意味着神经科学的进步。他们最终证明了神经元的存在。与原子、电子等等的故事非常相似，大脑现在是一组离散的细胞和元素，称为<a class="ae kc" href="https://en.wikipedia.org/wiki/Neuron" rel="noopener ugc nofollow" target="_blank">神经元</a>。</p><figure class="ke kf kg kh gt jr gh gi paragraph-image"><a href="https://upload.wikimedia.org/wikipedia/commons/3/32/Smi32neuron.jpg"><div class="gh gi lg"><img src="../Images/3339c3d4e174ea753302f7f695476b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/0*WJ4BZ619tmjIj-55.jpg"/></div></a><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">神经网络染色后的样子。想想一个隐形人，随便拿点颜料颜料扔hm！😂😁😎这是动画片里的经典！</figcaption></figure><h1 id="182c" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">神经网络和被称为深度学习的后起之秀</h1><p id="89dd" class="pw-post-body-paragraph ki kj iq kk b kl mf kn ko kp mg kr ks kt mh kv kw kx mi kz la lb mj ld le lf ij bi translated"><em class="mk">经许可转载</em>:皮雷，豪尔赫·格拉。我从Medium中选择的关于计算机编程的分析:Angular、JavaScript、机器学习、TensorFlow.js等等！第一卷。(我在媒介上的写作)(第74页)。ediao do Kindle。</p><p id="8dcc" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">神经网络(NNs)一开始是一个很大的承诺，与我们今天的模型相比，它们的模型非常简单:它是一个简单的神经元，具有基于阈值的二进制输出；一方面，我们让神经科学的一些人在模型上看到对他们的生物现象的可能解释(即，计算机模拟)；另一方面，应用数学和计算机科学家正在寻找新的开箱即用的解决方案(例如，异或问题)。</p><figure class="ke kf kg kh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/ad6dbe8fbe58202ce3f6a0aa3d7700b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ntklifm8TYeOQ2m6"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/@cadop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马修·施瓦茨</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><blockquote class="mm mn mo"><p id="c92f" class="ki kj mk kk b kl km kn ko kp kq kr ks mp ku kv kw mq ky kz la mr lc ld le lf ij bi translated">一方面，我们让神经科学的一些人在模型上看到对他们的生物现象的可能解释(即，计算机模拟)；另一方面，应用数学和计算机科学家正在寻找新的开箱即用的解决方案(例如，异或问题)。</p></blockquote><figure class="ke kf kg kh gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/d49a3affcdef3348c09dbc4d981321fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/0*wEokv_rDHCWCtha8.jpg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">一个通用神经模型。经<a class="ae kc" href="https://www.researchgate.net/publication/281836484_On_the_Applicability_of_Computational_Intelligence_in_Transcription_Network_Modelling/figures" rel="noopener ugc nofollow" target="_blank"> Pires (2012) </a>许可复制。</figcaption></figure><p id="0dd7" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">据说，一位数学家证明了模型的局限性。然而，真正限制NNs应用的是我们无法分层训练神经元的事实，直到<a class="ae kc" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">反向传播算法</a>，将NNs带到了聚光灯下；数据分割问题需要非常复杂的边界定义[34]。然而，另一个问题出现了:我们仍然不能训练几个隐藏层，更不用说当提供新的训练部分时，神经网络会忘记已经获得的知识:想象一下，每当你在大学学习一个新的学科时，你会完全忘记以前的学科，你永远不会完成大学！使用深度学习中使用的算法解决了训练几个层的问题，并且忘记先前训练的网络的问题也通过诸如迁移学习的技术来解决，最初的提议是自适应共振理论(ART)。</p><figure class="ke kf kg kh gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e1d578e97fc22b5282e9fe6756866b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*q2Der32h4CulZ-WCieAOHw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">反向传播和误差波。经<a class="ae kc" href="https://www.researchgate.net/publication/281836484_On_the_Applicability_of_Computational_Intelligence_in_Transcription_Network_Modelling/figures" rel="noopener ugc nofollow" target="_blank">许可复制Pires (2012) </a>。</figcaption></figure><figure class="ke kf kg kh gt jr"><div class="bz fp l di"><div class="mu mv l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">解释简单层神经网络和复杂层神经网络的区别。</figcaption></figure><h1 id="eb70" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">结束语</h1><figure class="ke kf kg kh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/7c8fb0cb0c62276e3e703d9eefcd9365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*95D4DBYcFDZ8ymVY"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/es/@s_midili?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> serjan midili </a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="d2bb" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">我不会剧透，但我们确实对我们即将出版的书进行了一些丰富的讨论。你可以和卡萨伯夫教授一起参加我们的现场直播！</p><blockquote class="mm mn mo"><p id="fcb3" class="ki kj mk kk b kl km kn ko kp kq kr ks mp ku kv kw mq ky kz la mr lc ld le lf ij bi translated">我捍卫人工神经网络模型的多样性，即使深度学习做得很好。</p></blockquote><div class="mx my gp gr mz na"><a href="https://www.linkedin.com/posts/jorgeguerrapires_spiking-neural-networks-and-computational-activity-6935629174497787906-bKU5?utm_source=linkedin_share&amp;utm_medium=member_desktop_web" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">LinkedIn上的Jorge Guerra Pires:尖峰神经网络和计算思维</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">我捍卫人工神经网络模型的多样性，尽管深度学习做得很好…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.linkedin.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no jw na"/></div></div></a></div></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><div class="ke kf kg kh gt na"><a href="https://www.linkedin.com/posts/jorgeguerrapires_spiking-neural-networks-and-computational-activity-6931551291219267584-behC?utm_source=linkedin_share&amp;utm_medium=member_desktop_web" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">LinkedIn上的Jorge Guerra Pires:尖峰神经网络和计算思维</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">神经网络(NNs)开始是一个很大的承诺，与我们现有的模型相比，它们的模型非常简单…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.linkedin.com</p></div></div><div class="nj l"><div class="nw l nl nm nn nj no jw na"/></div></div></a></div><figure class="ke kf kg kh gt jr gh gi paragraph-image"><a href="https://www.facebook.com/groups/DataScienceMachineLearningBR/?multi_permalinks=3190831774505587&amp;notif_id=1652611338735338&amp;notif_t=feedback_reaction_generic&amp;ref=notif"><div class="gh gi nx"><img src="../Images/04651a3b164895a0d828b89bc88dec48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ev8KvMqi2TfCSMSQsUj5eQ.png"/></div></a></figure><figure class="ke kf kg kh gt jr gh gi paragraph-image"><a href="https://www.facebook.com/groups/DeepNetGroup/posts/1706580569734818/?notif_id=1652563022444008&amp;notif_t=group_post_approved&amp;ref=notif"><div class="gh gi ny"><img src="../Images/a7a1749223cca4b37fb93829445f4afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vWT15x4XXRfa_Ansu1WuFQ.png"/></div></a></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><div class="ke kf kg kh gt na"><a href="https://www.linkedin.com/posts/theoretical-and-mathematical-biology_spiking-neural-networks-and-computational-activity-6931234910544216064-4kQ-?utm_source=linkedin_share&amp;utm_medium=member_desktop_web" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">LinkedIn上的理论和数学生物学:脉冲神经网络和计算…</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">脉冲神经网络和计算思维为什么我们应该保持机器学习的多样性#机器学习…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.linkedin.com</p></div></div><div class="nj l"><div class="nz l nl nm nn nj no jw na"/></div></div></a></div></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="7e0f" class="lh li iq bd lj lk oa lm ln lo ob lq lr ls oc lu lv lw od ly lz ma oe mc md me bi translated">阅读建议</h1><div class="mx my gp gr mz na"><a href="https://www.academia.edu/18365339/Redes_Neurais_em_termos_simples_como_aprendemos_pensamos_e_modelamos" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">从简单的角度来看，这是一个抽象的概念</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">描述神经系统，但具体形式，神经系统的人工神经系统</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.academia.edu</p></div></div><div class="nj l"><div class="of l nl nm nn nj no jw na"/></div></div></a></div><p id="6f44" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated"><strong class="kk ir">论计算智能在转录网络建模中的适用性</strong></p><p id="4f6e" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated"><a class="ae kc" href="https://www.researchgate.net/publication/281836484_On_the_Applicability_of_Computational_Intelligence_in_Transcription_Network_Modelling" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/281836484 _ On _ availability _ of _ computing _ Intelligence _ in _ sport _ Network _ modeling</a></p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><figure class="ke kf kg kh gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="ke kf kg kh gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><p id="3332" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated"><em class="mk">尖峰神经网络</em> (SNNs)出来的时候[1]，我想:这就是“事情”；2013年，尼古拉·卡萨博夫(Nikola Kasabov)教授为我开设了第一门正式课程。深度学习在2012年开始增长，在2018年之前，在一个事件和我的博士后上从未听到过，当它变得对我来说很明显，深度学习接管了舞台，从尖峰神经网络再也没有听到过。<em class="mk">为什么？</em>他们没有死，因为卡萨博夫教授在2019年发布了一本新书。<em class="mk">计算思维，</em>亚马逊推出新书</p><p id="6f50" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">在我的第一个博士后期间，我对环境如何变得对深度学习有害印象深刻。我担心的是，即使事情进展顺利，深度学习做得很好，特别是在“谷歌大脑”决定进入游戏之后，我们仍然必须保持多样性，我会说。</p><p id="18a2" class="pw-post-body-paragraph ki kj iq kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ij bi translated">[1]尖峰神经元模型:单个神经元，群体，可塑性。这本书是我读的第一本书，但我受到了尼古拉·k·卡萨伯夫的影响，因为他在巴西做了一系列特别的讲座。他现在也有一本书:<a class="ae kc" href="https://e2.udemymail.com/ls/click?upn=ZF3sOyS2SxEPIoSZT6Aoc2Ciser1e8lA9qDQ158NDkktMORH5Bqm8AgvCGWrtL0b525KUzKlR7HBUb-2BgG9lfm4su-2BIuEoG3GuZb0Vi50dBrbAQ0IgsW25g4yOPMlfGyuhMToQG73yc7HCUlJ5xpcPH0hzY3h9EerjNRawJ6Y8ca-2FaZJEMgtGfCC8tvF9NvsrrqO0PDK65DS0vXmrQr-2B5igBuRBboBcC1DhLbaOooumlXUctRuuDmipJ-2B7U1c7eOMfRThDnNKyUnx6SAoN0XK5Q6GHJJ8SGkvTzy4O02-2BXJ48JQwgpupH8Feb0xOWfrJPMBqH_YFGmhoEOW8-2FYdMy-2BQD-2BKBCWOgPlQjTekFf69-2F-2Fe6C6SkMY41kXi-2BMzaMjcf7J97LDVTs-2BP1cjKS8AnY62M2AuxRwn08h4g6gK57vYdo87rnW-2FG2SyDWUZ3eQJHRsiPCxrTrxrXgCQ7juuoYOFEiVeEdgvSGng6mZ2SjLXB3IaT8m0jPEP6NH-2F-2FdrReXXJvkF65rv2aXew33GKSLbcDfTOI9lP1Fq7T9-2FcKkLE5tJY921oz6QUpZEZRVLQcnL7juHizzm-2F-2FgYAh8RRfvjApV6SzEq42eSjCx4WnmeSEytSibQZJr-2BjHTfakTyFJjgFfsvrMIaRTLEi1dpb3GkOjOxS7MVAla-2BZEjosQ3LMmDxkvDHktUFX4zHnrK-2FM-2Bl0aG7LrvDRmxvWQf8Ux-2BbUnMFFoHsF9BbPu2bRDFWQSQ7RP-2BvEgwn9dLLy60MfQKi1LV-2ByzAwPPXGxPlmvW2oKRkjagg-3D-3D" rel="noopener ugc nofollow" target="_blank">时空、尖峰神经网络和大脑启发的人工智能</a></p></div></div>    
</body>
</html>