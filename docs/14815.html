<html>
<head>
<title>Change Data Capture with QuestDB &amp; Debezium</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用QuestDB &amp; Debezium改变数据捕获</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/change-data-capture-with-questdb-debezium-534bef199d74?source=collection_archive---------16-----------------------#2022-12-26">https://levelup.gitconnected.com/change-data-capture-with-questdb-debezium-534bef199d74?source=collection_archive---------16-----------------------#2022-12-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="ac11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过Debezium和Kafka Connect使用变更数据捕获将数据流式传输到QuestDB。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/d112459c7c1d07550021f63ca689ca11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e4104u033-ljJt9m"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">尼古拉斯·卡佩罗在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="d56a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现代数据架构已经在很大程度上从<strong class="js iu"> ETL </strong>(提取-转换-加载)范式转移到<strong class="js iu"> ELT </strong>(提取-加载-转换)，其中原始数据首先加载到数据湖中，然后再应用转换(例如聚合、连接)进行进一步分析。传统的ETL管道很难维护，并且随着业务需求的变化相对不灵活。随着新的云技术承诺更便宜的存储和更好的可扩展性，数据管道可以从预先构建的提取和批量上传转移到更流媒体的架构。</p><p id="a360" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://en.wikipedia.org/wiki/Change_data_capture" rel="noopener ugc nofollow" target="_blank">变更数据捕获</a> (CDC)非常适合这种范式转变，来自一个源的数据变更可以传输到其他目的地。顾名思义，CDC跟踪数据(通常是数据库)的变化，并提供插件来处理这些变化。对于事件驱动的架构，CDC作为服务边界之间一致的数据交付机制特别有用(例如<a class="ae le" href="https://microservices.io/patterns/data/transactional-outbox.html" rel="noopener ugc nofollow" target="_blank">发件箱模式</a>)。在复杂的微服务环境中，CDC通过减轻CDC系统的负担，帮助简化数据交付逻辑。</p><p id="7527" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了说明这一点，让我们用一个参考架构将股票更新从PostgreSQL流式传输到QuestDB。一个简单的Java Spring应用程序通过股票代码查询股票价格，并将当前价格更新到PostgreSQL数据库。然后，这些更新被Debezium(一个流行的CDC系统)检测到，并被发送到Kafka主题。最后，Kafka Connect QuestDB连接器监听该主题，并将更改传输到QuestDB进行分析。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lf"><img src="../Images/96b6a2f886cc4df27d031bf65fd4a5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FFe-qDAWouWUP0yk"/></div></div></figure><p id="6707" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以这种方式构建数据管道可以使应用程序变得简单。Java Spring应用程序只需要获取最新的股票数据并提交给PostgreSQL。由于PostgreSQL是一个优秀的OLTP(事务性)数据库，该应用程序可以依靠ACID合规性来确保下游服务只能看到提交的数据。应用程序开发人员无需担心复杂的重试逻辑或不同步的数据集。从数据库的角度来看，PostgreSQL可以被优化来做它最擅长的事情——事务查询。Kafka可用于可靠地向其他端点提供数据，QuestDB可用于存储历史数据以运行分析查询和可视化。</p><p id="202a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以，事不宜迟，让我们来看看这个例子:</p><h1 id="840b" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">先决条件</h1><ul class=""><li id="c247" class="me mf it js b jt mg jx mh kb mi kf mj kj mk kn ml mm mn mo bi translated">饭桶</li><li id="e016" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">Docker引擎:20.10以上</li></ul><h1 id="c922" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">设置</h1><p id="f2e4" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">要在本地运行该示例，首先克隆repo: <code class="fe mx my mz na b">git clone <a class="ae le" href="https://github.com/questdb/kafka-questdb-connector.git" rel="noopener ugc nofollow" target="_blank">https://github.com/questdb/kafka-questdb-connector.git</a></code></p><p id="3527" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，导航到<code class="fe mx my mz na b">stocks</code>示例来构建并运行Docker合成文件:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="d04a" class="nf lh it na b be ng nh l ni nj">$ cd kafka-questdb-connector/kafka-questdb-connector-samples/stocks/<br/>$ docker compose build<br/>$ docker compose up</span></pre><p id="5f19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这将为QuestDB构建Java Spring App/Kafka连接器的Dockerfile，并下拉PostgreSQL(预先配置了Debezium)、Kafka/Zookeeper、QuestDB和Grafana容器。Kafka和Kafka Connect需要一点时间来初始化。检查<code class="fe mx my mz na b">connect</code>集装箱，等待原木停止。</p><h2 id="2927" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">启动Debezium连接器</h2><p id="7088" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">此时，Java应用程序正在持续更新PostgreSQL中的股票表，但是连接尚未建立。通过执行以下命令创建Debezium连接器(即PostgreSQL → Debezium → Kafka ):</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="9028" class="nf lh it na b be ng nh l ni nj">curl -X POST -H "Content-Type: application/json" -d  '{"name":"debezium_source","config":{"tasks.max":1,"database.hostname":"postgres","database.port":5432,"database.user":"postgres","database.password":"postgres","connector.class":"io.debezium.connector.postgresql.PostgresConnector","database.dbname":"postgres","database.server.name":"dbserver1"}} ' localhost:8083/connectors</span></pre><h2 id="c8ac" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">启动QuestDB Kafka连接接收器</h2><p id="9b63" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">通过创建Kafka连接端(即Kafka → QuestDB sink)来完成管道工程:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="81a5" class="nf lh it na b be ng nh l ni nj">curl -X POST -H "Content-Type: application/json" -d '{"name":"questdb-connect","config":{"topics":"dbserver1.public.stock","table":"stock", "connector.class":"io.questdb.kafka.QuestDBSinkConnector","tasks.max":"1","key.converter":"org.apache.kafka.connect.storage.StringConverter","value.converter":"org.apache.kafka.connect.json.JsonConverter","host":"questdb", "transforms":"unwrap", "transforms.unwrap.type":"io.debezium.transforms.ExtractNewRecordState", "include.key": "false", "symbols": "symbol", "timestamp.field.name": "last_update"}}' localhost:8083/connectors</span></pre><h1 id="a09a" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">决赛成绩</h1><p id="a22a" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">现在，写入PostgreSQL表的所有更新也将反映在QuestDB中。要进行验证，导航至<code class="fe mx my mz na b">localhost:19000</code>并从<code class="fe mx my mz na b">stock</code>表中选择:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="7d11" class="nf lh it na b be ng nh l ni nj">select * from stock;</span></pre><p id="f250" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您还可以运行聚合来进行更复杂的分析:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="7ec7" class="nf lh it na b be ng nh l ni nj">SELECT<br/>  timestamp,<br/>  symbol,<br/>  avg(price),<br/>  min(price),<br/>  max(price)<br/>FROM stock<br/>  where symbol = 'IBM'<br/>SAMPLE by 1m align to calendar;</span></pre><p id="5f92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，您可以在<code class="fe mx my mz na b"><a class="ae le" href="http://localhost:3000/d/stocks/stocks?orgId=1&amp;refresh=5s&amp;viewPanel=2" rel="noopener ugc nofollow" target="_blank">http://localhost:3000/d/stocks/stocks?orgId=1&amp;refresh=5s&amp;viewPanel=2</a></code>与Grafana仪表盘进行交互，实现可视化</p><p id="5df8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可视化是由Debezium捕获的变化组成的蜡烛图；每根蜡烛线显示在给定的时间间隔内的开盘价、收盘价、最高价和最低价。可以通过选择左上角的“间隔”选项来更改时间间隔:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nw"><img src="../Images/b56e4a06f19ef62606c250d7a33e9851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wBviIi-lxcKbqNBO.png"/></div></div></figure><h1 id="6659" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">深潜</h1><p id="eb8b" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">现在我们已经启动并运行了示例应用程序，让我们更深入地研究一下<a class="ae le" href="https://github.com/questdb/kafka-questdb-connector/tree/main/kafka-questdb-connector-samples/stocks" rel="noopener ugc nofollow" target="_blank">股票</a>示例中的每个组件。</p><p id="34f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将查看以下文件:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="26f8" class="nf lh it na b be ng nh l ni nj">├── kafka-questdb-connector/kafka-questdb-connector-samples/stocks/<br/>│   ├── Dockerfile-App<br/>|   |    -- The Dockerfile to package our Java App<br/>|   ├── Dockerfile-Connect<br/>|   |    -- The Dockerfile to combine the Debezium container<br/>|   |    -- image the with QuestDB Kafka connector<br/>│   ├── src/main/resources/schema.sql<br/>|   |    -- The SQL which creates the stock table in PostgreSQL<br/>|   |    -- and populates it with initial data<br/>│   ├── src/main/java/com/questdb/kafka/connector/samples/StocksApplication.java<br/>|   |    -- The Java Spring App which updates the stock table in PostgreSQL<br/>|   |    -- in regular intervals<br/>...</span></pre><h2 id="7ade" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">生产者(Java应用程序)</h2><p id="cff3" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">生成器是一个简单的Java Spring Boot应用程序。它有两个组成部分:</p><ol class=""><li id="babb" class="me mf it js b jt ju jx jy kb nx kf ny kj nz kn oa mm mn mo bi translated"><code class="fe mx my mz na b"><a class="ae le" href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/src/main/resources/schema.sql" rel="noopener ugc nofollow" target="_blank">schema.sql</a></code>文件。该文件用于在PostgreSQL中创建股票表，并用初始数据填充它。它由Spring Boot应用程序获取，并在启动时执行。</li></ol><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="4ba1" class="nf lh it na b be ng nh l ni nj">create table if not exists stock (<br/>    id serial primary key,<br/>    symbol varchar(10) unique,<br/>    price float8,<br/>    last_update timestamp<br/>);<br/>insert into stock (symbol, price, last_update) values ('AAPL', 500.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('IBM', 50.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('MSFT', 100.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('GOOG', 1000.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('FB', 200.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('AMZN', 1000.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('TSLA', 500.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('NFLX', 500.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('TWTR', 50.0, now()) ON CONFLICT DO NOTHING;<br/>insert into stock (symbol, price, last_update) values ('SNAP', 10.0, now()) ON CONFLICT DO NOTHING;</span></pre><p id="e760" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe mx my mz na b">ON CONFLICT DO NOTHING</code>子句用于在应用程序重启时避免表中出现重复条目。</p><p id="08f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.<a class="ae le" href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/src/main/java/io/questdb/kafka/samples/StockService.java" rel="noopener ugc nofollow" target="_blank"> Java代码</a>用随机值更新价格和时间戳。更新并不是完全随机的，该应用程序使用一个非常简单的算法来生成非常类似于股票价格运动的更新。在现实生活中，应用程序将从一些外部来源获取价格。</p><p id="032a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">生产者被打包成一个最小的docker文件，<code class="fe mx my mz na b"><a class="ae le" href="https://github.com/questdb/kafka-questdb-connector/blob/main/kafka-questdb-connector-samples/stocks/Dockerfile-App" rel="noopener ugc nofollow" target="_blank">Dockerfile-App</a></code>，并链接到PostgreSQL:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="a9b6" class="nf lh it na b be ng nh l ni nj">FROM maven:3.8-jdk-11-slim AS builder<br/>COPY ./pom.xml /opt/stocks/pom.xml<br/>COPY ./src ./opt/stocks/src<br/>WORKDIR /opt/stocks<br/>RUN mvn clean install -DskipTests<br/><br/>FROM azul/zulu-openjdk:11-latest<br/>COPY --from=builder /opt/stocks/target/kafka-samples-stocks-*.jar /stocks.jar<br/>CMD ["java", "-jar", "/stocks.jar"]</span></pre><h2 id="01be" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">Kafka Connect、Debezium和QuestDB Kafka连接器</h2><p id="f952" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">在我们深入研究Kafka Connect、Debezium和QuestDB Kafka连接器配置之前，让我们看一下它们之间的关系。</p><p id="fc74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Kafka Connect是一个框架，用于构建在Kafka和其他系统之间移动数据的连接器。它支持两类连接器:</p><ol class=""><li id="3c5a" class="me mf it js b jt ju jx jy kb nx kf ny kj nz kn oa mm mn mo bi translated">源连接器—从源系统读取数据并将其写入Kafka</li><li id="53a6" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn oa mm mn mo bi translated">接收器连接器—从Kafka读取数据并将其写入接收器系统</li></ol><p id="83ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Debezium是Kafka Connect的一个源连接器，可以监视和捕获数据库中行级别的变化。这是什么意思？每当在数据库中插入、更新或删除一行时，Debezium都会捕捉到这一变化，并将其作为一个事件写入Kafka。</p><p id="8401" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在技术层面上，Debezium是一个运行在Kafka Connect框架内部的Kafka Connect连接器。这反映在<a class="ae le" href="https://hub.docker.com/r/debezium/connect" rel="noopener ugc nofollow" target="_blank"> Debezium容器映像</a>中，它打包了Kafka Connect和预安装的Debezium连接器。</p><p id="d05c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">QuestDB Kafka连接器也是Kafka Connect连接器。它是一个Sink连接器，从Kafka读取数据并将其写入QuestDB。我们将QuestDB Kafka连接器添加到Debezium容器映像中，然后我们得到一个安装了Debezium和QuestDB Kafka连接器的Kafka Connect映像！</p><p id="d650" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我们用来构建图像的Dockerfile文件:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="18a6" class="nf lh it na b be ng nh l ob nj">FROM ubuntu:latest AS builder<br/>WORKDIR /opt<br/>RUN apt-get update &amp;&amp; apt-get install -y curl wget unzip jq<br/>RUN curl -s https://api.github.com/repos/questdb/kafka-questdb-connector/releases/latest | jq -r '.assets[]|select(.content_type == "application/zip")|.browser_download_url'| wget -qi -<br/>RUN unzip kafka-questdb-connector-*-bin.zip<br/><br/>FROM debezium/connect:1.9.6.Final<br/>COPY --from=builder /opt/kafka-questdb-connector/*.jar /kafka/connect/questdb-connector/</span></pre><p id="8540" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Dockerfile下载QuestDB Kafka连接器的最新版本，将其解压缩并复制到Debezium容器映像中。生成的映像安装了Debezium和QuestDB Kafka连接器:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/6a0a2ef93a9410be4d1aaa9d01faf71f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IKyuCPyX9ob9E5Fp.png"/></div></div></figure><p id="2f2a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">整个Kafka连接器包括一个源连接器和一个接收器连接器:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/4289c963dad78ad1d8e8953778e43143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3LTDo4SENtSq0gop.png"/></div></div></figure><h2 id="da85" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">Debezium连接器</h2><p id="a01a" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">我们已经知道Debezium是一个Kafka Connect连接器，它可以监视和捕获数据库中行级别的变化。我们还有一个Docker映像，它安装了Debezium和QuestDB Kafka连接器。但是，此时两个连接器都没有运行。我们需要配置并启动它们。这是通过CURL命令完成的，该命令向Kafka Connect REST API发送POST请求。</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="d1c8" class="nf lh it na b be ng nh l ni nj">curl -X POST -H "Content-Type: application/json" -d  '{"name":"debezium_source","config":{"tasks.max":1,"database.hostname":"postgres","database.port":5432,"database.user":"postgres","database.password":"postgres","connector.class":"io.debezium.connector.postgresql.PostgresConnector","database.dbname":"postgres","database.server.name":"dbserver1"}} ' localhost:8083/connectors</span></pre><p id="c044" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请求体包含Debezium连接器的配置，让我们来分解一下:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="fc9e" class="nf lh it na b be ng nh l ni nj">{<br/>  "name": "debezium_source",<br/>  "config": {<br/>    "tasks.max": 1,<br/>    "database.hostname": "postgres",<br/>    "database.port": 5432,<br/>    "database.user": "postgres",<br/>    "database.password": "postgres",<br/>    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",<br/>    "database.dbname": "postgres",<br/>    "database.server.name": "dbserver1"<br/>  }<br/>}</span></pre><p id="246a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它监听PostgreSQL数据库中的更改，并使用上述配置发布到Kafka。在我们的例子中，主题名称默认为<code class="fe mx my mz na b">&lt;server-name&gt;.&lt;schema&gt;.&lt;table&gt;.</code>，它是<code class="fe mx my mz na b">dbserver1.public.stock</code>。为什么？因为数据库服务器名是<code class="fe mx my mz na b">dbserver1</code>，模式是<code class="fe mx my mz na b">public</code>，我们仅有的表是<code class="fe mx my mz na b">stock</code>。</p><p id="3212" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以在我们发送请求后，Debezium将开始监听<code class="fe mx my mz na b">stock</code>表中的变化，并将它们发布到<code class="fe mx my mz na b">dbserver1.public.stock</code>主题。</p><h2 id="30e4" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">QuestDB Kafka连接器<a class="ae le" href="https://questdb.io/blog/2023/01/03/change-data-capture-with-questdb-and-debezium#questdb-kafka-connector" rel="noopener ugc nofollow" target="_blank"> # </a></h2><p id="b1d2" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">此时，我们有一个用随机股票价格填充的PostgreSQL表<code class="fe mx my mz na b">stock</code>和一个包含变化的Kafka主题<code class="fe mx my mz na b">dbserver1.public.stock</code>。下一步是配置QuestDB Kafka连接器从<code class="fe mx my mz na b">dbserver1.public.stock</code>主题中读取数据，并将数据写入QuestDB。</p><p id="08ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们更深入地看看<a class="ae le" href="https://questdb.io/blog/2023/01/03/change-data-capture-with-questdb-and-debezium#start-the-questdb-kafka-connect-sink" rel="noopener ugc nofollow" target="_blank">start the QuestDB Kafka Connect sink</a>中的配置:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="e29e" class="nf lh it na b be ng nh l ni nj">{<br/>  "name": "questdb-connect",<br/>  "config": {<br/>    "topics": "dbserver1.public.stock",<br/>    "table": "stock",<br/>    "connector.class": "io.questdb.kafka.QuestDBSinkConnector",<br/>    "tasks.max": "1",<br/>    "key.converter": "org.apache.kafka.connect.storage.StringConverter",<br/>    "value.converter": "org.apache.kafka.connect.json.JsonConverter",<br/>    "host": "questdb",<br/>    "transforms": "unwrap",<br/>    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",<br/>    "include.key": "false",<br/>    "symbols": "symbol",<br/>    "timestamp.field.name": "last_update"<br/>  }<br/>}</span></pre><p id="8a58" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里需要注意的重要事项是:</p><ul class=""><li id="47b8" class="me mf it js b jt ju jx jy kb nx kf ny kj nz kn ml mm mn mo bi translated"><code class="fe mx my mz na b">table</code>和<code class="fe mx my mz na b">topics</code>:QuestDB Kafka连接器将创建一个名为<code class="fe mx my mz na b">stock</code>的quest db表，并将来自<code class="fe mx my mz na b">dbserver1.public.stock</code>主题的数据写入其中。</li><li id="4fe8" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">host</code>:QuestDB Kafka连接器将连接到运行在<code class="fe mx my mz na b">questdb</code>主机上的quest db。这是QuestDB容器的名称。</li><li id="5836" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">connector.class</code>:QuestDB Kafka连接器类名。这告诉Kafka Connect使用QuestDB Kafka连接器。</li><li id="5955" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">value.converter</code>:Debezium连接器产生JSON格式的数据。这就是为什么我们需要配置QuestDB连接器来使用JSON转换器读取数据:<code class="fe mx my mz na b">org.apache.kafka.connect.json.JsonConverter</code>。</li><li id="e169" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">symbols</code>:股票符号被翻译成<a class="ae le" href="https://questdb.io/docs/concept/symbol/" rel="noopener ugc nofollow" target="_blank"> QuestDB符号类型</a>，用于基数较低的字符串值(如枚举)。</li><li id="75ab" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">timestamp.field.name</code>:由于QuestDB对时间戳和基于时间戳的分区有很好的支持，我们可以指定指定的时间戳列。</li><li id="8078" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated"><code class="fe mx my mz na b">transforms</code> : unwrap字段使用<code class="fe mx my mz na b">io.debezium.transforms.ExtractNewRecordState</code>类型来提取新数据，而不是Debezium发出的元数据。换句话说，这是一个过滤器，主要用来过滤关于Kafka主题的Debezium数据的<code class="fe mx my mz na b">payload.after</code>部分。更多详情见其<a class="ae le" href="https://debezium.io/documentation/reference/1.9/transformations/event-flattening.html" rel="noopener ugc nofollow" target="_blank">文档</a>。</li></ul><p id="8a6f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe mx my mz na b">ExtractNewRecordState</code>转换可能是配置中最不直观的部分。让我们仔细看看:简而言之，对于PostgreSQL表中的每次更改，Debezium都会向Kafka主题发出一条JSON消息，如下所示:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="e761" class="nf lh it na b be ng nh l ni nj">{<br/>  "schema": {<br/>    "comment": "this contains Debezium message schema, it's not very relevant for this sample"<br/>  },<br/>  "payload": {<br/>    "before": null,<br/>    "after": {<br/>      "id": 8,<br/>      "symbol": "NFLX",<br/>      "price": 1544.3357414199545,<br/>      "last_update": 1666172978269856<br/>    },<br/>    "source": {<br/>      "version": "1.9.6.Final",<br/>      "connector": "postgresql",<br/>      "name": "dbserver1",<br/>      "ts_ms": 1666172978272,<br/>      "snapshot": "false",<br/>      "db": "postgres",<br/>      "sequence": "[\"87397208\",\"87397208\"]",<br/>      "schema": "public",<br/>      "table": "stock",<br/>      "txId": 402087,<br/>      "lsn": 87397208,<br/>      "xmin": null<br/>    },<br/>    "op": "u",<br/>    "ts_ms": 1666172978637,<br/>    "transaction": null<br/>  }<br/>}</span></pre><p id="1dcf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你被这条信息的庞大规模所淹没，不要害怕。大多数字段都是元数据，它们与本示例无关。参见<a class="ae le" href="https://debezium.io/documentation/reference/1.9/connectors/postgresql.html#postgresql-events" rel="noopener ugc nofollow" target="_blank"> Debezium文档</a>，了解更多详情。重要的一点是，我们不能将整个JSON消息推送到QuestDB，我们也不想要QuestDB中的所有元数据。我们需要提取消息的<code class="fe mx my mz na b">payload.after</code>部分，然后将其推送到QuestDB。这正是<code class="fe mx my mz na b">ExtractNewRecordState</code>转换所做的:它将大消息转换成一个更小的消息，其中只包含消息的<code class="fe mx my mz na b">payload.after</code>部分。因此，消息看起来好像是这样的:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="6dfa" class="nf lh it na b be ng nh l ni nj">{<br/>  "id": 8,<br/>  "symbol": "NFLX",<br/>  "price": 1544.3357414199545,<br/>  "last_update": 1666172978269856<br/>}</span></pre><p id="5410" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我们可以推送给QuestDB的消息。QuestDB Kafka连接器将读取该消息，并将其写入QuestDB表。如果QuestDB Kafka连接器不存在，它也会创建QuestDB表。QuestDB表将具有与JSON消息相同的模式——其中每个JSON字段都是QuestDB表中的一列。</p><h2 id="21fa" class="nk lh it bd li nl nm dn lm nn no dp lq kb np nq lu kf nr ns ly kj nt nu mc nv bi translated">QuestDB和Grafana</h2><p id="8abe" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">一旦数据被写入QuestDB表，我们就可以更容易地处理时序数据。由于QuestDB与PostgreSQL wire协议兼容，我们可以使用Grafana上的PostgreSQL数据源来可视化数据。预配置仪表板正在使用以下查询:</p><pre class="kp kq kr ks gt nb na nc bn nd ne bi"><span id="df51" class="nf lh it na b be ng nh l ni nj">SELECT<br/>  $__time(timestamp),<br/>  min(price) as low,<br/>  max(price) as high,<br/>  first(price) as open,<br/>  last(price) as close<br/>FROM<br/>  stock<br/>WHERE<br/>  $__timeFilter(timestamp)<br/>  and symbol = '$Symbol'<br/>SAMPLE BY $Interval ALIGN TO CALENDAR;</span></pre><p id="ffef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们已经创建了一个系统，可以在PostgreSQL表中持续跟踪和存储多只股票的最新价格。然后这些价格通过Debezium作为事件反馈给Kafka，Debezium捕捉每一个价格变化。QuestDB Kafka连接器从Kafka读取这些事件，并将每个变化作为一个新行存储在QuestDB中，使我们能够保留股票价格的全面历史记录。然后可以使用Grafana等工具分析和可视化这一历史，如蜡烛图所示。</p><h1 id="6b15" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">后续步骤</h1><p id="55b2" class="pw-post-body-paragraph jq jr it js b jt mg jv jw jx mh jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">这个示例项目是一个基本的参考架构，用于将数据从关系数据库传输到优化的时序数据库。对于使用PostgreSQL的现有项目，可以将Debezium配置为开始将数据流式传输到QuestDB，并利用时序查询和分区。对于存储原始历史数据的数据库，采用Debezium可能需要一些架构上的改变。然而，这是有益的，因为这是提高性能和在事务性数据库和分析性时序数据库之间建立服务边界的机会。</p><p id="e8b8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该参考架构还可以扩展到配置Kafka Connect，使其也可以传输到其他数据仓库进行长期存储。在检查完数据后，QuestDB还可以配置为对数据进行下采样，以便长期存储，甚至<a class="ae le" href="https://questdb.io/blog/2022/11/02/data-lifecycle-questdb/" rel="noopener ugc nofollow" target="_blank">分离分区以节省空间</a>。</p><p id="5c55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">试试这个<a class="ae le" href="https://github.com/questdb/kafka-questdb-connector/issues/new" rel="noopener ugc nofollow" target="_blank">示例应用程序</a>，如果有任何问题，请加入<a class="ae le" href="https://slack.questdb.io/" rel="noopener ugc nofollow" target="_blank"> QuestDB Slack社区</a>。</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><p id="acff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您成为我们社区的一员！在你离开之前:</p><ul class=""><li id="004d" class="me mf it js b jt ju jx jy kb nx kf ny kj nz kn ml mm mn mo bi translated">👏为故事鼓掌，跟着作者走👉</li><li id="6ac4" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">📰查看<a class="ae le" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">升级编码出版物</a>中的更多内容</li><li id="499d" class="me mf it js b jt mp jx mq kb mr kf ms kj mt kn ml mm mn mo bi translated">🔔关注我们:<a class="ae le" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae le" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae le" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">时事通讯</a></li></ul><p id="af8c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🚀👉<a class="ae le" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">加入升级人才集体，找到一份神奇的工作</strong> </a></p></div></div>    
</body>
</html>