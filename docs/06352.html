<html>
<head>
<title>LVM with Hadoop</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Hadoop的LVM</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/lvm-with-hadoop-63111412fda2?source=collection_archive---------10-----------------------#2020-11-17">https://levelup.gitconnected.com/lvm-with-hadoop-63111412fda2?source=collection_archive---------10-----------------------#2020-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="19b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将了解如何在Hadoop集群中使用LVM(逻辑卷管理)的概念，为datanode共享的存储提供灵活性。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/4fe13504a6a7fad1ebf571b8fe88782e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7GDT1E61CG7xtJWUZt4kFg.png"/></div></div></figure><blockquote class="kx ky kz"><p id="950a" class="jn jo la jp b jq jr js jt ju jv jw jx lb jz ka kb lc kd ke kf ld kh ki kj kk ij bi translated">需要创建基本Hadoop集群的知识。</p></blockquote><p id="ec2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们想要达到的目标，</p><p id="c9e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">◾将LVM与Hadoop相集成，并为DataNode存储提供弹性。</p><p id="8b79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在RHEL8操作系统的虚拟机上执行此任务。</p><p id="9f7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我附加了一个大小为8 GiB的磁盘(这里是/dev/sdb)</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi le"><img src="../Images/a20fda2fce9d5e746ff8f3c0a304484b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eZfmw0lGmQM-suZJ_mt3Aw.png"/></div></div></figure><p id="6cbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在连接的磁盘中创建两个主分区，每个大小为3 GiB，使用fdisk命令进入磁盘</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="075b" class="lk ll iq lg b gy lm ln l lo lp">fdisk /dev/sdb</span></pre><p id="a6d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当创建新分区时，它默认选择主类型，并在最后一个扇区中键入+3G以创建3 GiB的分区，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lq"><img src="../Images/b0033e5b97f0fdc27f9a0db2cb5d1f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_FpyzoirftKmLPvQ3c2UDw.png"/></div></div></figure><p id="dd08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们现在有两个存储设备sdb1和sdb2。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lr"><img src="../Images/ec399cb83d2ab7ff1b19e78d7ae7136f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tSX96CFYC9p3PpitfnP4cg.png"/></div></div></figure><p id="3b86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，使用两个设备创建物理卷(pv)。(我们也可以使用完整的/dev/sdb设备并添加更多存储设备来创建物理卷)</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="188c" class="lk ll iq lg b gy lm ln l lo lp">pvcreate /dev/sdb1<br/>pvcreate /dev/sdb2</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ls"><img src="../Images/24a1091a310a343854f752290cccfc3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UF25Ybj_YjWC6aaGD5eZKg.png"/></div></div></figure><p id="7393" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">pvdisplay命令用于查看可用的物理卷，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lt"><img src="../Images/dce5c88bb6ab2c6c5cd9cb56fccd8fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TF2RXEnJo2ew8fEJAByCA.png"/></div></div></figure><p id="e0e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷组是使用可用的物理卷创建的，因此我们使用前面创建的两个分区创建一个卷组(名为“mygroup”)。由于每个pv的大小为3GiB，卷组的总大小变为6 GiB。</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="1903" class="lk ll iq lg b gy lm ln l lo lp">vgcreate mygroup /dev/sdb1 /dev/sdb2</span></pre><p id="0d7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用vgdisplay命令查看卷组。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lu"><img src="../Images/0ef5ab5586418c864ead243721b427da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AMxV6kPFgz1HcoBHJE7M6Q.png"/></div></div></figure><p id="d792" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们已经创建了一个卷组，因此我们可以创建一个逻辑卷(就像一个分区)。在这里，我创建了一个大小为2 GiB的逻辑卷(来自“my group”VG，其中有6 GiB可用，因此在此之后还有4 GiB ),并将这个lv命名为“mylv”。</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="19b7" class="lk ll iq lg b gy lm ln l lo lp">lvcreate --size 2G --name mylv mygroup</span></pre><p id="6862" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用lvdisplay命令查看所有逻辑卷，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lv"><img src="../Images/5217b44a4a750e5fa505e08c87a43076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fmlq69WtQWEHYXPv-rTJhg.png"/></div></div></figure><p id="4dbd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，当我们创建了一个逻辑卷之后，我们必须在挂载之前对其进行格式化，</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="d45e" class="lk ll iq lg b gy lm ln l lo lp">mkfs.ext4 /dev/mygroup/mylv</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lw"><img src="../Images/722f6c74548a506c586e7554257014e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1Cll9TuaNl0CBnrPG9mJg.png"/></div></div></figure><p id="c201" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们将这个逻辑卷挂载到hadoop集群中datanode的共享目录(这里是/dn)，这样这个目录的大小就变成了逻辑卷的大小。</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="fe2e" class="lk ll iq lg b gy lm ln l lo lp">mount /dev/mygroup/mylv  /dn</span></pre><p id="83f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">之后启动datanode服务，</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="06cc" class="lk ll iq lg b gy lm ln l lo lp">hadoop-daemon.sh start datanode</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lx"><img src="../Images/b54ae172f0dc313ce8412aa6d924f286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O7ERk21OYC02eFnE15OP6g.png"/></div></div></figure><p id="81f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，如果我们检查datanode贡献的存储，它将大约为2gb。</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="ea49" class="lk ll iq lg b gy lm ln l lo lp">hadoop dfsadmin -report</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ly"><img src="../Images/4d7600eb3c123e4a95ce01438227cec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IRK86gbct5hyRrQqJ0azKg.png"/></div></div></figure><p id="20ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们的datanode正在运行，同时共享2gb的存储。我们将动态地将该存储增加到4gb。意味着我们将从vg向这个lv添加更多的2gb(显然vg应该有那么多空间，而lv只能从一个vg中占用空间)，</p><p id="344c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用lvextend命令，</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="0c14" class="lk ll iq lg b gy lm ln l lo lp">lvextend --size +2G /dev/mygroup/mylv</span></pre><p id="a3e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">增加大小后，我们必须在不丢失之前的数据的情况下格式化增加的存储部分，为此使用resize2fs命令。</p><pre class="km kn ko kp gt lf lg lh li aw lj bi"><span id="d97f" class="lk ll iq lg b gy lm ln l lo lp">resize2fs /dev/mygroup/mylv</span></pre><p id="de9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们再次检查datanode的存储贡献时，它现在将变为4 GiB</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lz"><img src="../Images/ee596cd82afe518a99edd18396884398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rgcDtKdRuN7wt3ss7jegFw.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/8b55f03cf78c829a40c34d59425f9e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QcRp2rnDjJkk7W6Wg70Crg.png"/></div></div></figure><p id="e526" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们通过将datanode与LVM的概念相集成，改变了它对hadoop集群的存储贡献。</p><h2 id="4939" class="lk ll iq bd mb mc md dn me mf mg dp mh jy mi mj mk kc ml mm mn kg mo mp mq mr bi translated">谢谢大家！😀</h2></div></div>    
</body>
</html>