<html>
<head>
<title>How I created my first Web Crawler!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何创建我的第一个网络爬虫！</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-i-created-my-first-web-crawler-ff9bea9235bf?source=collection_archive---------12-----------------------#2022-03-14">https://levelup.gitconnected.com/how-i-created-my-first-web-crawler-ff9bea9235bf?source=collection_archive---------12-----------------------#2022-03-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f48e20556ec578df72389a9dccfe9849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lt6src5w3xQ3YhVipjHy4g.png"/></div></div></figure><h1 id="1f47" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">什么是网络爬虫？</h1><p id="3e21" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">网络爬虫是一种将互联网抓取到<strong class="ky ir">索引</strong>并下载网站内容进行抓取的机器人。网络爬虫又称<strong class="ky ir">网络蜘蛛</strong>或<strong class="ky ir">爬行机器人</strong>。网络爬虫需要被提供有初始网站的列表，从该列表开始，它将索引和爬行被索引的网站中存在的链接，以发现新的页面。</p><h1 id="e987" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">图书馆类比</h1><p id="7018" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">打个比方，让我们把互联网上所有的<strong class="ky ir">网站想象成图书馆里的书</strong>。网络爬虫是图书管理员，他的工作是在目录中输入图书的信息，以便在需要时很容易找到这些书。为了组织图书，图书管理员将在目录中存储图书的标题、描述和类别。网络爬虫也会做同样的事情。当网络爬虫索引互联网上的所有页面时，它的目标就完成了。一些不可能实现的事情！</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/d8300fb01c44887430c49c059b0d1005.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*sOcqyNsV_V-XfdfvbDwPOQ.gif"/></div></figure><h1 id="3f18" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">创建网络爬虫</h1><p id="15b9" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这篇博客中，我将用<strong class="ky ir"> python </strong>编写代码。python中有几个web爬行和web抓取框架。我将使用<code class="fe lz ma mb mc b">scrapy</code>。</p><p id="bb16" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">安装scrapy:</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="2cde" class="mm jz iq mc b gy mn mo l mp mq">$ pip install scrapy</span></pre><h2 id="00b0" class="mm jz iq bd ka mr ms dn ke mt mu dp ki lh mv mw km ll mx my kq lp mz na ku nb bi translated">1.使用scrapy创建一个python应用程序</h2><p id="20b8" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">要创建一个scrapy项目，运行以下命令。这里我的应用程序的名称是<code class="fe lz ma mb mc b">my_first_web_crawler</code></p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="607b" class="mm jz iq mc b gy mn mo l mp mq">$ scrapy startproject my_first_web_crawler</span></pre><p id="88f4" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">这将生成一个<code class="fe lz ma mb mc b">scrapy</code>样板代码和文件夹结构，如下所示:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/1fe3a22e443516e8ac1446d505794760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*UCjcm2ihQ25ebSosWdd5bQ.png"/></div></figure><h2 id="25b5" class="mm jz iq bd ka mr ms dn ke mt mu dp ki lh mv mw km ll mx my kq lp mz na ku nb bi translated">2.创建网络爬虫</h2><p id="2144" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">名为<code class="fe lz ma mb mc b">spiders</code>的文件夹包含scrapy用来抓取网站的文件。我将在这个目录下创建一个名为<code class="fe lz ma mb mc b">spider1.py</code>的文件，并编写下面几行代码:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/977188e7b4157ebd0705a8d7a0fe226f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hb4XtDTRhCml2OZD9xbJFw.png"/></div></div></figure><blockquote class="ne nf ng"><p id="e3ee" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated">你可以在这里找到上面的代码:<a class="ae nl" href="https://github.com/gouravdhar/my-first-web-crawler/blob/main/test_spider.py" rel="noopener ugc nofollow" target="_blank">https://github . com/gouravdhar/my-first-we b-crawler/blob/main/test _ spider . py</a></p></blockquote><p id="f699" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">我已经提供了我将要抓取的网页的URL。这些页面包含我的博客链接。您可以提供任意数量的URL，因为这是一个列表。我将抓取的URL:</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="dad4" class="mm jz iq mc b gy mn mo l mp mq"><a class="ae nl" href="https://gourav-dhar.com" rel="noopener ugc nofollow" target="_blank">https://gourav-dhar.com</a> <br/><a class="ae nl" href="https://gourav-dhar.com/profile" rel="noopener ugc nofollow" target="_blank">https://gourav-dhar.com/profile</a></span></pre><p id="b1bf" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">上面的代码遍历链接中提供的网页并下载页面。</p><p id="0a42" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">要执行代码，请运行以下命令:</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="f1c5" class="mm jz iq mc b gy mn mo l mp mq">scrapy crawl &lt;your-spider-name&gt;</span></pre><p id="0ca3" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">我的蜘蛛名是<code class="fe lz ma mb mc b">blogs</code>(在上面代码的第7行中定义)</p><p id="75d8" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir">还有tada！！！链接的数据已下载到项目文件夹中。</strong></p><p id="c579" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">但这还不够，我想实际下载这个页面指向的链接的数据。为此，我不得不抓取主页上的所有链接并浏览。我将使用<strong class="ky ir"> scrapy shell </strong>编写代码来抓取网站信息。</p><blockquote class="ne nf ng"><p id="9068" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated"><strong class="ky ir">注意:Scrapy Shell </strong>是一个交互式Shell，在这里你可以快速地尝试和调试代码</p></blockquote><p id="8c56" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">要启动scrapy shell，只需编写:</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="60e9" class="mm jz iq mc b gy mn mo l mp mq">$ scrapy shell 'https://gourav-dhar.com'</span></pre><p id="d45b" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">即<code class="fe lz ma mb mc b">scrapy shell </code>后跟url</p><p id="455c" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">一旦外壳被打开，输入<code class="fe lz ma mb mc b">response</code>确认你得到一个200的响应。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/6fff953eb2ca9fff70f1d00669048643.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*yV1c6NUvRfUM4OYfuFFO6w.png"/></div></figure><p id="aa3b" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">引用链接通常位于html的<code class="fe lz ma mb mc b">a href</code>类中。我需要抓取这个链接中出现的所有值，所以我将编写这个来查看输出</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="a75e" class="mm jz iq mc b gy mn mo l mp mq">&gt;&gt;&gt; response.css('a::attr(href)')</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/92bb60e98b45585766cfab77919835bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ph-753GNfRx375GNndj3WQ.png"/></div></div></figure><p id="46b4" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">这是页面上的<code class="fe lz ma mb mc b">a href</code>类列表。为了得到一个只有链接的清理结果，我们必须使用<code class="fe lz ma mb mc b">getall()</code>函数</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="b726" class="mm jz iq mc b gy mn mo l mp mq">&gt;&gt;&gt; response.css('a::attr(href)').getall()</span></pre><p id="d1f3" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">结果应该是这样的:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/6567f165f9be22959b261e78ecba920d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jU4JcgqFOxsvEeHEqWowaA.png"/></div></div></figure><p id="dff6" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">这将返回给我一个包含所有<code class="fe lz ma mb mc b">href</code>值的列表。</p><p id="17e8" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">为了下载这个列表中的所有文件，我将在spider代码中修改我的parse函数，使用上面的命令获取所有链接。修改后的解析函数如下所示:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/256900ce9a891728f594e33724e16c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uU4dOmVPaiYwIjb4btX1hw.png"/></div></div></figure><blockquote class="ne nf ng"><p id="4f54" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated"><strong class="ky ir">项目的Github链接可以在这里找到:</strong> <a class="ae nl" href="https://github.com/gouravdhar/my-first-web-crawler" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Github链接</strong> </a></p></blockquote><p id="bd4c" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">现在，再次在终端中运行以下命令:</p><pre class="lv lw lx ly gt mi mc mj mk aw ml bi"><span id="d9d8" class="mm jz iq mc b gy mn mo l mp mq">$ scrapy crawl blogs</span></pre><p id="ed48" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">我可以下载我主页上所有链接的内容。这个功能可以扩展到一个无限循环，你可以在互联网上的所有网站中爬行。</p><h1 id="f5e2" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">概述网络爬虫</h1><p id="15fa" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">网络爬虫是存储和索引网页内容的强大工具。它的应用非常广泛。</p><blockquote class="ne nf ng"><p id="4473" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated">注意:你也可以通过在你的站点的<code class="fe lz ma mb mc b">robots.txt</code>文件中提到黑名单/白名单域来添加过滤器，以确定谁可以抓取你的站点。</p></blockquote><p id="e7d3" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated"><strong class="ky ir">搜索引擎使用网络爬行</strong>来索引和存储数据库中的<code class="fe lz ma mb mc b">meta titles</code>和<code class="fe lz ma mb mc b">descriptions</code>，以快速显示用户输入的查询结果。主要搜索引擎的例子有<code class="fe lz ma mb mc b"><a class="ae nl" href="http://google.com" rel="noopener ugc nofollow" target="_blank">google</a></code>、<code class="fe lz ma mb mc b"><a class="ae nl" href="http://bing.com" rel="noopener ugc nofollow" target="_blank">bing</a></code>、<code class="fe lz ma mb mc b"><a class="ae nl" href="http://yahoo.com" rel="noopener ugc nofollow" target="_blank">yahoo</a></code>、<code class="fe lz ma mb mc b"><a class="ae nl" href="http://duckduckgo.com" rel="noopener ugc nofollow" target="_blank">duck duck go</a></code>。搜索引擎还在这些结果之上添加了他们自己的推荐系统，这使得每个搜索引擎的算法都不同。</p><p id="faf8" class="pw-post-body-paragraph kw kx iq ky b kz md lb lc ld me lf lg lh mf lj lk ll mg ln lo lp mh lr ls lt ij bi translated">网页抓取也用于<strong class="ky ir">版权/剽窃违规检测</strong>。<strong class="ky ir">网络分析</strong>和<strong class="ky ir">数据挖掘</strong>也是主要应用。它还可以用于检测网络恶意软件，如<strong class="ky ir">网络钓鱼攻击</strong>。假设你拥有<code class="fe lz ma mb mc b">facebook.com</code>，你可以抓取互联网来检查是否有其他人正在使用一个看起来类似于<code class="fe lz ma mb mc b">facebook.com</code>的网站，这个网站可能会被用于网络钓鱼攻击。</p><blockquote class="ne nf ng"><p id="4343" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated"><strong class="ky ir">该项目的Github链接可以在这里找到:</strong> <a class="ae nl" href="https://github.com/gouravdhar/my-first-web-crawler" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Github链接</strong> </a></p><p id="b1fd" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated">这是一个探索我们博客平台<a class="ae nl" href="https://www.thegeekyminds.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">的邀请，极客头脑</strong> </a>。一个让您了解软件开发和技术领域最新发展的一站式平台。我们在<a class="ae nl" href="https://www.thegeekyminds.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">的极客头脑</strong> </a> <strong class="ky ir"> </strong>旨在写一些你实际上可以用来提高工作效率和充实你的职业生活的内容。</p><p id="7a2b" class="kw kx nh ky b kz md lb lc ld me lf lg ni mf lj lk nj mg ln lo nk mh lr ls lt ij bi translated">邀请您在<a class="ae nl" href="https://thegeekyminds.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">https://thegeekyminds.com</strong></a>通过我们的平台。并订阅我们的时事通讯，以便在我们每次发布新帖子时收到电子邮件。我们承诺不会向您的收件箱发送垃圾邮件。点击下面的按钮订阅我们的时事通讯</p></blockquote><figure class="lv lw lx ly gt jr gh gi paragraph-image"><a href="https://forms.wix.com/4444cf13-7653-460d-9b32-f2e4e65544d1:c2184260-1ab5-4c6a-a37d-53de0778afa0"><div class="gh gi nq"><img src="../Images/eec8beec45924704f52b518aeb1a3e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/0*1mou_RO9R61sgZPt.jpeg"/></div></a></figure></div></div>    
</body>
</html>