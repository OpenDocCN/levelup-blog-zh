<html>
<head>
<title>Decision Trees and Overfitting: Difficult Concepts Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树和过度拟合:简化的困难概念</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/decision-trees-and-overfitting-difficult-concepts-simplified-e02c6943c7cc?source=collection_archive---------4-----------------------#2022-08-25">https://levelup.gitconnected.com/decision-trees-and-overfitting-difficult-concepts-simplified-e02c6943c7cc?source=collection_archive---------4-----------------------#2022-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b68a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">决策树算法可能变得非常困难:简单的解释</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e3235c601b253526bd8b29e84c5fd99e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PoO-gQsHOXEFSMqvLNMF-Q.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自Unsplash的Fabrice Villard</figcaption></figure><p id="8d99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如今，人工智能不再是一扇紧闭的大门。有多少“免费”或在线培训？—我们都数不清了。</p><p id="dac9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我计划创建一个端到端的人工智能介绍(不特定于机器学习、NLP或深度学习)。在我进一步发展人工智能介绍之前，我发现现在探索学习决策树算法的时机已经非常成熟了。</p><p id="a2a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我在大多数情况下通常做的那样，如果你想深入研究算法，你最好购买一本全面的教科书。或者，你从这些高层次的介绍开始。你想在同一个算法问题空间中进行编码吗？这是一个单独的努力(多部分系列)，至少在我写作的背景下。举个例子，我在SciPy上做过一个多部分的文章:我的第二篇文章是以编码为中心的(这里是[1])。</p><p id="09f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开门见山吧。</p><p id="0d12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">算法目标</strong></p><p id="40d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树方法通常用于有监督的学习问题(我省略了无监督的决策树实现[4])。)其目的是从训练数据中学习模型，该模型可用于根据尚未看到的测试数据生成预测。决策树是机器学习技术的一种形式，用于回归和分类问题。决策树的核心原理是将特征空间划分成区域，然后利用这些区域来预测目标变量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/b0f36e8de069fd56938c80563979a0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PM-cYg0mAMV--OX4o2KapQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">从Pexels中提取产品</figcaption></figure><p id="a822" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">类型(举几个例子)</strong></p><p id="2a27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树算法有许多不同的<strong class="ky ir">类型</strong>；然而，CART(分类和回归树)和ID3(迭代二分法3)经常被使用。在这些算法的每一个中，数据集沿着一个或多个特征递归地切片，直到它们到达每个结果区域包括具有相同目标值的样本的点[2][3]。</p><p id="48ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">工作原理</strong></p><p id="b1c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树的概念可以用非常简单的方式来理解。目标是生成一个模型，该模型最小化与使用训练好的模型对新数据点进行预测相关联的一些成本函数。为了实现这一点，我们需要在我们的数据中找到最大化某个标准的分裂，如信息增益(IG)或基尼系数。当我们已经识别出这些最佳分裂时，我们将能够通过遵循决策树的分支来构建我们的最终模型，该分支导致在树的每个叶节点处每个类别标签的最高可能预测概率。</p><p id="d269" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策树通过从数据中学习一系列if-then-else条件来进行预测。树中的每个条件(如根节点、内部节点或叶节点)都指向一组具有新条件的新节点。这一直持续到尝试了所有可能的结果(“拟合”[5])。在对过去的数据进行训练后，模型可以在给定新数据时判断出它以前从未见过的树中的哪条路径会导致什么结果(这种方法使用训练期间使用的特定示例来分类或预测模型最初创建时没有想到的新值)。最后，决策树算法通过将输入和输出分解成更小的部分，构建成最符合证据的函数，来学习它们之间的复杂关系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/b5a8c74c1e29ddac2b618c040eba6720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GxO0MPtDgq0AmJm35FTg0A.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">来自Unsplash的Jake Melara</figcaption></figure><p id="4d78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">过度装配问题和缓解措施</strong></p><p id="3ec7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">过度拟合是机器学习中出现的一个问题，具体表现为模型在训练数据上表现良好，但不能很好地推广到新的[9]样本。当模型对于所使用的数据来说过于复杂时，这种情况经常发生(但不限于此)。因为对决策树算法学习新模式的能力几乎没有限制，所以它们特别容易过度拟合。</p><p id="bff7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当使用决策树算法时，可以通过多种不同的方式来防止过拟合，其中一些方式如下:</p><p id="d9a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">—预修剪是一种在树达到特定尺寸或深度限制时防止其生长的技术[7]。</p><p id="4ba3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">—后剪枝需要增长整个树[8]，之后，不必要的节点或几乎相同的节点被逐一删除，直到只留下优化性能的节点。在被修整和修剪之后，所讨论的树在其大小和解释方面将更易于管理，并且这将在不过度损失精度的情况下发生。</p><p id="81c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">— K-fold:在尝试了将数据集分为训练集和测试集的各种策略之后，您应该确定每次单独运行的性能水平，然后取这些结果的平均值。</p><p id="a81a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">— Bootstrap aggregating:在原始数据集的随机子样本上拟合多个模型(替换)；之后，通过平均或投票来组合他们的预测[6]。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/eb4c0d6808b757cf313f3da037833a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jBeLn1md-DwpKTcXhZHCCA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">出自<a class="ae kv" href="https://medium.com/@aniltilbe" rel="noopener">作者</a>【10】</figcaption></figure><h1 id="bcbc" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">离别的思绪</h1><p id="ca6e" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">如果你对这篇文章有任何建议或拓宽主题的建议，我将非常感谢你的来信。</p><p id="0936" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，我还写了以下帖子，你可能会感兴趣:</p><div class="ms mt gp gr mu mv"><a rel="noopener  ugc nofollow" target="_blank" href="/top-20-machine-learning-algorithms-explained-in-less-than-10-seconds-each-8fd728f70b19"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd ir gy z fp na fr fs nb fu fw ip bi translated">前20个机器学习算法，每个用不到10秒钟解释</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">对20个最重要的机器学习算法的简单解释，每个都在10秒内完成。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj kp mv"/></div></div></a></div><div class="ms mt gp gr mu mv"><a href="https://uxplanet.org/simplest-artificial-intelligence-guide-top-15-models-with-10-second-explanations-13325967d322" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd ir gy z fp na fr fs nb fu fw ip bi translated">最简单的人工智能指南:10秒钟解释的15大模型</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">对15个最重要的NLP、机器学习和深度学习模型的简单解释，全部在10秒钟内完成…</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">uxplanet.org</p></div></div><div class="ne l"><div class="nk l ng nh ni ne nj kp mv"/></div></div></a></div><div class="ms mt gp gr mu mv"><a rel="noopener  ugc nofollow" target="_blank" href="/top-7-deep-learning-methods-each-explained-in-less-than-10-seconds-3683120de455"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd ir gy z fp na fr fs nb fu fw ip bi translated">7大深度学习方法，每种方法用不到10秒钟的时间解释</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">对7个最重要的深度学习算法的简单解释，每个都在10秒内完成。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="ne l"><div class="nl l ng nh ni ne nj kp mv"/></div></div></a></div><p id="2596" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，可以考虑报名成为一名媒体成员。每月5美元，可以无限制地阅读媒体上的所有报道。如果你注册使用我的链接，我会赚一小笔佣金，不需要你额外付费。</p><div class="ms mt gp gr mu mv"><a href="https://medium.com/@AnilTilbe/membership" rel="noopener follow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd ir gy z fp na fr fs nb fu fw ip bi translated">通过我的推荐链接加入Medium-Anil til be</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">阅读阿尼尔·蒂尔贝(以及媒体上成千上万的其他作家)的每一个故事。你的会员资格直接支持作家…</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">medium.com</p></div></div><div class="ne l"><div class="nm l ng nh ni ne nj kp mv"/></div></div></a></div></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><p id="57a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还有，这是我的时事通讯；我希望你能考虑订阅。</p><div class="ms mt gp gr mu mv"><a href="https://predictiveventures.substack.com" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd ir gy z fp na fr fs nb fu fw ip bi translated">预测风险简讯</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">人工智能和产品的交集。让我先看看预测风险投资时事通讯…</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">predictiveventures.substack.com</p></div></div><div class="ne l"><div class="nu l ng nh ni ne nj kp mv"/></div></div></a></div></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><h2 id="a41c" class="nv lw iq bd lx nw nx dn mb ny nz dp mf lf oa ob mh lj oc od mj ln oe of ml og bi translated">参考资料:</h2><p id="2504" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">1.蒂尔贝，阿尼尔。(2022年8月15日)。线性代数的8个最基本的科学函数。更好的编程。<a class="ae kv" href="https://betterprogramming.pub/8-most-essential-scipy-functions-for-linear-algebra-programming-simplified-e3c7a4db0b58" rel="noopener ugc nofollow" target="_blank">https://better programming . pub/8-most-essential-scipy-functions-for-linear-algorithm-programming-simplified-e 3c 7 a4 db 0 b 58</a></p><p id="582c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.决策树分类器在计算机入侵检测中的应用。信息与通信技术汇刊，25。【https://doi.org/10.2495/DATA000371 T4】</p><p id="9f9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.基于半监督决策树子空间划分的混合分类算法。模式识别，60，157–163。<a class="ae kv" href="https://doi.org/10.1016/j.patcog.2016.04.016" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.patcog.2016.04.016</a></p><p id="81c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.通过构造无监督决策树的可解释层次聚类。IEEE Xplore。<a class="ae kv" href="https://ieeexplore.ieee.org/abstract/document/1363769" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/abstract/document/1363769</a></p><p id="5e84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.通过特征选择、平滑和修剪处理测试代价敏感决策树学习中的过拟合。系统与软件杂志，83(7)，1137–1147。<a class="ae kv" href="https://doi.org/10.1016/j.jss.2010.01.002" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.jss.2010.01.002</a></p><p id="0587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">6.王，琼斯，帕特里奇。(2000年1月1日)。用于构建多分类器系统的神经网络和决策树之间的差异。施普林格柏林海德堡。<a class="ae kv" href="https://link.springer.com/chapter/10.1007/3-540-45014-9_23" rel="noopener ugc nofollow" target="_blank">https://link.springer.com/chapter/10.1007/3-540-45014-9_23</a></p><p id="b71a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">7.芬恩，吉文。在线集成学习:一项实证研究。机器学习，53(1)，71–109页。【https://doi.org/10.1023/A:1025619426553 T2】号</p><p id="9fff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">8.【http://www.ijmlc.org/vol7/641-LC0045.pdf T4】</p><p id="6b70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">9.为什么你的公司需要联合学习技术？<a class="ae kv" href="https://scopenew.com/why-does-your-company-need-federated-learning-techniques/" rel="noopener ugc nofollow" target="_blank">https://scope new . com/why-your-company-need-federated-learning-techniques/</a></p><p id="7d0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">10.OpenAI协助开发了这一可视化工具</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><p id="b389" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到这里<a class="ae kv" href="https://medium.com/@AnilTilbe/about" rel="noopener"> <strong class="ky ir">了解我</strong> </a> <strong class="ky ir">。</strong></p><p id="8811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">阿尼尔·蒂尔贝</p></div></div>    
</body>
</html>