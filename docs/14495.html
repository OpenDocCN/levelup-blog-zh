<html>
<head>
<title>Brain Tumor Classification Using Tensorflow and Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流和迁移学习的脑肿瘤分类</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/brain-tumor-classification-using-tensorflow-and-transfer-learning-b4b7ab5fd7cf?source=collection_archive---------4-----------------------#2022-12-02">https://levelup.gitconnected.com/brain-tumor-classification-using-tensorflow-and-transfer-learning-b4b7ab5fd7cf?source=collection_archive---------4-----------------------#2022-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/d8b0cb7550e19724986d44868c4a51cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/0*NU0lAZTBt0TDygJU"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk translated">来源:Freepik.com</figcaption></figure><p id="7bc6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我使用机器学习技术对四种不同类型的脑瘤进行分类；无肿瘤、神经胶质瘤、脑膜瘤和垂体瘤。所以，我想到了写一篇差不多的文章。</p><p id="51c5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我将这篇文章分为两个不同的部分，在第一部分我们将建立一个机器学习模型来对脑瘤(你正在阅读的那个)进行分类，在<a class="ae jy" href="https://medium.com/gitconnected/machine-learning-in-production-a036567e9c86" rel="noopener">第二部分</a>我将谈论如何将你的机器学习模型投入生产。</p><blockquote class="kx ky kz"><p id="c078" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><a class="ae jy" href="https://medium.com/gitconnected/machine-learning-in-production-a036567e9c86" rel="noopener">第二部分:生产中的机器学习</a></p></blockquote><p id="3937" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们今天要讲的要点是:</p><ul class=""><li id="79f2" class="le lf iq kb b kc kd kg kh kk lg ko lh ks li kw lj lk ll lm bi translated">什么是脑瘤及其类型</li><li id="9555" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">数据准备</li><li id="4843" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">什么是迁移学习？</li><li id="7264" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">不同层的定义</li><li id="99d0" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">训练模型</li><li id="142a" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">通过训练好的模型进行预测</li><li id="5272" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">评估模型</li><li id="f4f1" class="le lf iq kb b kc ln kg lo kk lp ko lq ks lr kw lj lk ll lm bi translated">保存模型以备将来使用。</li></ul><p id="69db" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以，事不宜迟，让我们开始吧。</p><h1 id="f3c4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">脑瘤是什么？</h1><p id="cd70" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">脑瘤只不过是你大脑中异常细胞的聚集或生长。它被认为是儿童和成人中最具侵袭性的疾病之一。检测脑瘤的最佳技术是磁共振成像(MRI)。</p><p id="0023" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">通过扫描产生了大量的图像数据。这些图像由放射科医生检查。由于脑肿瘤及其特性的复杂性，手动检查容易出错。作为一名机器学习爱好者，我能想到的减少人为干预和人为错误的最佳方式是使用机器学习技术自动化这一分类过程。</p><p id="58e6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">说够了，让我们开始实际工作吧！</p><p id="0c95" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将使用<a class="ae jy" href="https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri" rel="noopener ugc nofollow" target="_blank"> <strong class="kb ir"> Kaggle </strong> </a> <strong class="kb ir">提供的数据集。</strong>可以下载或者使用Kaggle笔记本进行分类。我用过Kaggle笔记本，会在<a class="ae jy" href="https://github.com/thejitenpatel/brainTumorDetection" rel="noopener ugc nofollow" target="_blank"> <strong class="kb ir"> GitHub </strong> </a> <strong class="kb ir">上分享给大家。</strong></p><p id="bfdd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如题所示，我们将使用Tensorflow库进行分类任务。除此之外，对于数据分析和可视化，我们将使用其他一些库，如pandas、numpy、seaborn、matplotlilb和Scikit-learn。现在，让我们导入所有的库。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="8f0d" class="ne lt iq na b be nf ng l nh ni">import matplotlib.pyplot as plt<br/>import numpy as np<br/>import seaborn as sns<br/>import cv2<br/>import tensorflow as tf<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>from tqdm import tqdm<br/>import os<br/>from sklearn.utils import shuffle<br/>from sklearn.model_selection import train_test_split<br/>from tensorflow.keras.applications import EfficientNetB0<br/>from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint<br/>from sklearn.metrics import classification_report,confusion_matrix<br/>import ipywidgets as widgets<br/>import io<br/>from PIL import Image<br/>from IPython.display import display,clear_output<br/>from warnings import filterwarnings<br/>for dirname, _, filenames in os.walk('/kaggle/input'):<br/>    for filename in filenames:<br/>        print(os.path.join(dirname, filename))</span></pre><p id="4c65" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">让我们定义一些颜色，这将有助于我们的可视化。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="ebe0" class="ne lt iq na b be nf ng l nh ni">colors_dark = ["#1F1F1F", "#313131", '#636363', '#AEAEAE', '#DADADA']<br/>colors_red = ["#331313", "#582626", '#9E1717', '#D35151', '#E9B4B4']<br/>colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']<br/><br/>sns.palplot(colors_dark)<br/>sns.palplot(colors_green)<br/>sns.palplot(colors_red)</span></pre><h1 id="b9d4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">数据准备</h1><p id="7b35" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">我们将检测四种不同类型的脑瘤。所以，像下面这样声明一个名为label的变量。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="3569" class="ne lt iq na b be nf ng l nh ni">labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']</span></pre><p id="4b43" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将分割训练集以创建分类模型。Kaggle提供的测试集用于将ML模型测试到产品中。如果你现在还不明白，不要担心，继续读这篇文章，你会明白的:)</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="4bbf" class="ne lt iq na b be nf ng l nh ni">X_train = []<br/>y_train = []<br/>image_size = 150<br/>for i in labels:<br/>    folderPath = os.path.join('../input/brain-tumor-classification-mri','Training',i)<br/>    for j in tqdm(os.listdir(folderPath)):<br/>        img = cv2.imread(os.path.join(folderPath,j))<br/>        img = cv2.resize(img,(image_size, image_size))<br/>        X_train.append(img)<br/>        y_train.append(i)<br/>        <br/>for i in labels:<br/>    folderPath = os.path.join('../input/brain-tumor-classification-mri','Testing',i)<br/>    for j in tqdm(os.listdir(folderPath)):<br/>        img = cv2.imread(os.path.join(folderPath,j))<br/>        img = cv2.resize(img,(image_size,image_size))<br/>        X_train.append(img)<br/>        y_train.append(i)<br/>        <br/>X_train = np.array(X_train)<br/>y_train = np.array(y_train)</span></pre><p id="7602" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在上面的代码中，我们遍历了训练和测试目录，并在调整图像大小后追加到python列表中。请注意，我们将图像的大小调整为150x150。</p><p id="1035" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，让我们为每个标签绘制一些图像。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="07c5" class="ne lt iq na b be nf ng l nh ni">k=0<br/>fig, ax = plt.subplots(1,4,figsize=(20,20))<br/>fig.text(s='Sample Image From Each Label',size=18,fontweight='bold',<br/>             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)<br/>for i in labels:<br/>    j=0<br/>    while True :<br/>        if y_train[j]==i:<br/>            ax[k].imshow(X_train[j])<br/>            ax[k].set_title(y_train[j])<br/>            ax[k].axis('off')<br/>            k+=1<br/>            break<br/>        j+=1</span></pre><p id="bedb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将洗牌使用python的<em class="la">洗牌</em>方法创建的<strong class="kb ir"> x_train </strong>和<strong class="kb ir"> y_train </strong>，并查看形状。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="669a" class="ne lt iq na b be nf ng l nh ni">X_train, y_train = shuffle(X_train,y_train, random_state=101)<br/>X_train.shape</span></pre><p id="90d7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">此外，我们将把数据集分成训练集和测试集。测试集是训练集的<strong class="kb ir"> 10% </strong>。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="8e97" class="ne lt iq na b be nf ng l nh ni">X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)</span></pre><p id="0ffe" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将利用sci-kit learn<em class="la">train _ test _ split</em>函数将数据集一分为二。<strong class="kb ir"> test_size </strong>参数帮助我们设置测试集的大小(0.1 = 10%)。</p><p id="dcb4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们都知道计算机只理解数值。我们之前声明过的标签是一串列表。无论如何，我们必须将这些标签转换成数值，以便我们可以将这些标签输入到机器学习模型中。将标签转换成数值的最佳解决方案是使用一种著名的技术<strong class="kb ir"> One Hot Encoding。</strong></p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="a9ef" class="ne lt iq na b be nf ng l nh ni">y_train_new = []<br/>for i in y_train:<br/>    y_train_new.append(labels.index(i))<br/>y_train = y_train_new<br/>y_train = tf.keras.utils.to_categorical(y_train)<br/><br/><br/>y_test_new = []<br/>for i in y_test:<br/>    y_test_new.append(labels.index(i))<br/>y_test = y_test_new<br/>y_test = tf.keras.utils.to_categorical(y_test)</span></pre><p id="c944" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">解释<strong class="kb ir">一个热编码</strong>超出了本文的范围，但是它所做的是为每个标签分配二进制值。上面的代码帮助我们做同样的事情。</p><p id="93f0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">唷！😮‍💨</p><p id="c79f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">很多工作😵</p><p id="f83c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是现在，我们必须做实际的工作:使用迁移学习建立一个分类模型</p><h1 id="9a06" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">什么是迁移学习？</h1><p id="bf95" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">深度卷积神经网络模型可能需要几天甚至几个月的时间在非常大的数据集上进行训练。简化这一过程的一个简单方法是重用为标准计算机视觉基准数据集(如ImageNet图像识别任务)开发的预训练模型的模型权重。简单地说，迁移学习就是在一个新问题上重新使用一个预先训练好的模型。它还建议当我们有一个小数据集时使用迁移学习。</p><p id="f939" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">表现最好的模型可以下载并使用，或者集成到一个新的模型中，以解决您的计算机视觉问题。我们将使用<strong class="kb ir"> EfficientNetB0 </strong>模型，该模型将使用来自<strong class="kb ir"> ImageNet </strong>数据集的权重。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="2fae" class="ne lt iq na b be nf ng l nh ni">effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))</span></pre><p id="a7e1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面一行代码将帮助我们重用权重。将<strong class="kb ir"> include_top </strong>参数设置为<em class="la"> False </em>，这样网络就不包括来自预建模型的<strong class="kb ir">顶层/输出</strong>层，这允许我们根据我们的使用案例添加我们的输出层！</p><p id="3b6e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，我们将把我们的定制层添加到<strong class="kb ir"> EfficientNetB0 </strong>模型中。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="fb7b" class="ne lt iq na b be nf ng l nh ni">model = effnet.output<br/>model = tf.keras.layers.GlobalAveragePooling2D()(model)<br/>model = tf.keras.layers.Dropout(rate=0.5)(model)<br/>model = tf.keras.layers.Dense(4,activation='softmax')(model)<br/>model = tf.keras.models.Model(inputs=effnet.input, outputs = model)</span></pre><p id="9402" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们使用了几层，每层的解释如下:</p><p id="09bd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> GlobalAveragePooling2D: </strong>这一层与CNN中的Max Pooling层类似，唯一的区别是它使用平均值而不是Max值，而<em class="la"> pooling </em>。这将有助于我们在训练时减少机器的计算负荷。</p><p id="cbba" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> Dropout: </strong> Dropout是一种在训练过程中忽略随机选择的神经元的技术。他们是被随机“淘汰”的。这有助于避免过度拟合。</p><p id="32fc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">密集:</strong>一个简单的神经网络层，也是我们的输出层，它将图像分类为4个可能类别中的一个。请注意，在上面的代码中，我们将4作为密集层中的第一个参数，这意味着我们必须输出4种不同的可能性(类)。</p><p id="3bb2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们还在密集层中使用了<em class="la"> Softmax </em>函数，该函数输出预测值的概率。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="3b1c" class="ne lt iq na b be nf ng l nh ni">model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])</span></pre><p id="25de" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们最终编译了我们的模型。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="165c" class="ne lt iq na b be nf ng l nh ni">checkpoint = ModelCheckpoint("effnet.h5",monitor="val_accuracy",save_best_only=True,mode="auto",verbose=1)<br/>reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001, mode='auto',verbose=1)</span></pre><p id="35a9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">回调:</strong>回调可以帮助你更快的修复bug，可以帮助你构建更好的模型。他们可以帮助你可视化你的模型的训练进展，甚至可以通过在每次迭代中实现提前停止或定制学习速率来帮助防止<strong class="kb ir">过度适应</strong>。</p><h1 id="6163" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">培训模式</h1><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="d35c" class="ne lt iq na b be nf ng l nh ni">history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32, callbacks=[tensorboard,checkpoint,reduce_lr])</span></pre><p id="5563" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的代码将帮助您训练模型。如果你使用<strong class="kb ir"> CPU </strong>来训练模型，那么训练模型将花费近一两个小时，但是如果你使用<strong class="kb ir"> GPU </strong>，那么只需要几分钟。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="5083" class="ne lt iq na b be nf ng l nh ni">filterwarnings('ignore')<br/><br/>epochs = [i for i in range(12)]<br/>fig, ax = plt.subplots(1,2,figsize=(14,7))<br/>train_acc = history.history['accuracy']<br/>train_loss = history.history['loss']<br/>val_acc = history.history['val_accuracy']<br/>val_loss = history.history['val_loss']<br/><br/>fig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,fontweight='bold',<br/>             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)<br/><br/>sns.despine()<br/>ax[0].plot(epochs, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],<br/>           label = 'Training Accuracy')<br/>ax[0].plot(epochs, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],<br/>           label = 'Validation Accuracy')<br/>ax[0].legend(frameon=False)<br/>ax[0].set_xlabel('Epochs')<br/>ax[0].set_ylabel('Accuracy')<br/><br/>sns.despine()<br/>ax[1].plot(epochs, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],<br/>           label ='Training Loss')<br/>ax[1].plot(epochs, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],<br/>           label = 'Validation Loss')<br/>ax[1].legend(frameon=False)<br/>ax[1].set_xlabel('Epochs')<br/>ax[1].set_ylabel('Training &amp; Validation Loss')<br/><br/>fig.show()</span></pre><p id="fe90" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在模型被训练之后，在每个<strong class="kb ir">时期可视化你的模型性能是很好的。它帮助我们确定我们的模型在每个时期的表现，以及我们何时可以停止训练等等。衡量模型性能的最佳方式是使用<strong class="kb ir">线图。</strong></strong></p><p id="93c3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的代码绘制了训练和验证准确性/损失的线形图。</p><h1 id="d2bc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">预言；预测；预告</h1><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="a786" class="ne lt iq na b be nf ng l nh ni">pred = model.predict(X_test)<br/>pred = np.argmax(pred,axis=1)<br/>y_test_new = np.argmax(y_test,axis=1)</span></pre><p id="12d5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将使用<em class="la"> argmax </em>函数，因为预测数组中的每一行都包含相应标签的四个值。每行中的<strong class="kb ir">最大值</strong>描述了4种可能结果中的预测输出。</p><p id="7bbf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">因此，使用<em class="la"> argmax </em>，我们将能够找出与预测结果相关的指数。</p><h1 id="eccf" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">估价</h1><p id="53c6" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">在训练模型并进行预测后，我们大多数人(大多数是新手)直接在生产中使用该模型，因为我们大多数人只关心准确性，这是衡量我们模型性能的一种方式，但还有其他不同的方式来衡量<strong class="kb ir">模型性能</strong>。</p><p id="ec8a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">通过评估我们的模型，我们可以深入了解模型的性能。对模型的评估有助于我们理解不同的矩阵(性能测量)。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="6052" class="ne lt iq na b be nf ng l nh ni">print(classification_report(y_test_new,pred))</span></pre><p id="0e54" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">sci-kit learn的<em class="la">分类_报告</em>方法将帮助我们找出不同的性能度量，如<strong class="kb ir">精度、召回率、f1-分数、支持度、准确度、宏观平均值等。</strong></p><p id="d3ae" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们不容易理解数字和文本，但是对数字和文本的可视化有助于我们更好地理解。上面的代码会给你一个不同数字的报告。</p><p id="e055" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">让我们想象一下。</p><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="133b" class="ne lt iq na b be nf ng l nh ni">fig,ax=plt.subplots(1,1,figsize=(14,7))<br/>sns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,<br/>           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])<br/>fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',<br/>             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)<br/><br/>plt.show()</span></pre><p id="f2ce" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将绘制混淆矩阵的<strong class="kb ir">热图</strong>，这反过来有助于我们直观地总结模型性能。</p><h1 id="a13d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">保存我们的模型</h1><pre class="mv mw mx my gt mz na nb bn nc nd bi"><span id="7460" class="ne lt iq na b be nf ng l nh ni">model.save('modelv1.h5')</span></pre><p id="130d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">保存Tensflow模型有不同的方法，但我将模型保存为<strong class="kb ir"> .h5格式。</strong>这是因为这是保存模型最简单的方法，加载模型也更容易。</p><h1 id="15a2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">结论</h1><p id="831f" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">我们学习了迁移学习，并将其应用于现实世界的项目中。上面的代码将帮助你达到98%的准确率。我们也了解脑瘤。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><p id="6c99" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在接下来的文章中，也就是本文的第2部分，我们将使用这个模型来构建web应用程序，并学习如何在生产中使用我们的ML模型。</p><p id="ef31" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在那之前，我希望你喜欢我的文章。你可以在这篇文章中找到必要的链接，下面是我为这个项目编写的<a class="ae jy" href="https://github.com/thejitenpatel/brainTumorDetection" rel="noopener ugc nofollow" target="_blank"> <strong class="kb ir"> Github </strong> </a>代码。我希望我对你有所帮助。</p><p id="33bc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我从我以前的文章中得到了如此多的爱。如果您有任何疑问、建议、问题或任何事情，可以随时在<a class="ae jy" href="https://www.linkedin.com/in/thejitenpatel/" rel="noopener ugc nofollow" target="_blank"><strong class="kb ir">LinkedIn</strong></a><strong class="kb ir"/><a class="ae jy" href="https://twitter.com/thejitenpatel" rel="noopener ugc nofollow" target="_blank"><strong class="kb ir">Twitter</strong></a><strong class="kb ir"/><a class="ae jy" href="https://www.instagram.com/thejitenpatel/" rel="noopener ugc nofollow" target="_blank"><strong class="kb ir">insta gram</strong></a><strong class="kb ir">上联系我。</strong></p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><p id="0852" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一个很小的请求，如果你有任何建议或任何事情，请填写下表，这将有助于我写你希望我写的技术和主题。谢谢:)</p><p id="7ca0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">快乐编码😉</strong></p><p id="7e6c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">https://forms.gle/1zB9GiKAdejyNbkh6<a class="ae jy" href="https://forms.gle/1zB9GiKAdejyNbkh6" rel="noopener ugc nofollow" target="_blank"/></p><div class="nq nr gp gr ns nt"><a href="https://github.com/thejitenpatel/brainTumorDetection" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">GitHub-jaten Patel/脑瘤检测</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh js nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a href="https://thejitenpatel.medium.com/" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">Jiten Patel -培养基</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">阅读吉滕·帕特尔在媒介上的作品。机器学习工程。|扑开发者|写手。每天，吉滕·帕特尔和…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">thejitenpatel.medium.com</p></div></div><div class="oc l"><div class="oi l oe of og oc oh js nt"/></div></div></a></div></div></div>    
</body>
</html>