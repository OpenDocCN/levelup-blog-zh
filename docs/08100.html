<html>
<head>
<title>ARMv9: What is the Big Deal?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ARMv9:有什么大不了的？</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/armv9-what-is-the-big-deal-4528f20f78f3?source=collection_archive---------0-----------------------#2021-04-03">https://levelup.gitconnected.com/armv9-what-is-the-big-deal-4528f20f78f3?source=collection_archive---------0-----------------------#2021-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a9eb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">什么是可伸缩向量扩展？对行业和用户意味着什么？行话背后是什么？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/073ce8b099f8b6b2a3b5e241fd28d776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3OgOa6Sgz1v7TQyBjg8Gg.png"/></div></div></figure><p id="9b7c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你是手机用户，那么你一定知道ARM芯片:它们为你的手机供电，现在它们也为下一代MAC电脑供电。他们也在向服务器领域大举进军。</p><p id="02d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们正处于工业大变革的风口浪尖，这是几十年来从未有过的。是的，这听起来很戏剧化，但是x86已经统治计算行业几十年了，随着ARM的崛起，它可能会面临有史以来最大的挑战。</p><p id="ddb2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这场战斗不会在今年尘埃落定，但现在ARM发布了他们的下一代架构ARMv9，这将设定行业十年的发展方向。因此，这是一个非常重要的事件，值得仔细研究。</p><p id="35f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里有很多东西要谈，但对我来说最大的话题是所谓的<em class="lq">可伸缩向量扩展2 </em> (SVE2)的标准化。你可能听说过SIMD指令集，如英特尔的MMX、SSE2、AVX、AVX-512或ARM的Neon。然而，除了表面上的感觉之外，你可能并不确切知道这些是做什么用的。我将试着解释是什么让SVE/SVE2与这些旧的SIMD指令集如此不同。</p><p id="4c3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您知道富士通在这一切中发挥了重要作用吗？我们正在看到老派超级计算的回归，就像几十年前在Cray-1超级计算机中发现的那样。Cray公司实际上还没有死，但实际上正忙于建造基于Arm的超级计算机:<a class="ae lr" href="https://www.hpcwire.com/off-the-wire/lrz-to-deploy-hpes-cray-cs500-system-to-bring-innovative-architecture-to-the-science-of-its-users/" rel="noopener ugc nofollow" target="_blank"> LRZ部署HPE的Cray CS500系统，采用ARM富士通A64FX处理器。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ls"><img src="../Images/a7265864a1dfc542b98d8cf8be2682ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oix9A1jjyxzRjwvfouubOQ.jpeg"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">克雷-1超级计算机，<em class="lx"> c. </em> 1976年。它大约6英尺高，直径7英尺(1.8米乘2.1米)。</figcaption></figure><h1 id="96a2" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">ARMv9是我可以在商店买到的物理芯片吗？</h1><p id="84c3" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">这不同于AMD或Intel发布新的微处理器，你可以购买并安装在你的电脑上以获得更高的性能。它不是一件物质的东西。相反，这是一种新的微处理器架构，向后兼容以前的ARM架构，如ARMv8。</p><p id="259a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我详细说明这是如何工作的。世界各地的许多公司，如高通、苹果、富士通、安培计算、亚马逊和许多其他公司都设计自己的芯片。这分几个步骤进行。例如，苹果和AMD实际上都不制造自己的微芯片。相反，他们设计芯片，然后将设计运送到我们所谓的代工厂，如全球代工厂或TSMC。他们将设计蚀刻到硅片上，然后切割成微芯片并封装。</p><p id="63f2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ARM公司不像高通或安培计算公司。他们不制作最终的蓝图，而是运送到半导体铸造厂。相反，ARM出售智能建筑或知识产权。像苹果这样的公司可以购买这些不同的设计，并将其组合成最终的蓝图，然后运往TSCM进行生产。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/5787306c9adf3c93d8ed1e3069b569b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*owKoUo4kcY_9XBw7g3m2Rw.jpeg"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">由TSMC制造的基于ARM Neoverse N1的SoC</figcaption></figure><p id="ba59" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是这个有不同的味道。例如，有诸如Neoverse N1这样的实际微处理器核心的蓝图。一家公司可以从ARM购买这种设计，使用他们的设计工具，在屏幕上复制粘贴四个N1内核，绘制一些连接线，拖出一些缓存块，进行一些连接。嘣，他们有了新的微处理器。好吧，比那稍微复杂一点，但是你得到了大概的想法。</p><p id="9b02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ARMv9和之前的ARMv8一样，并不是那种特定的具体设计。这不是一个蓝图说:晶体管以这种或那种方式连接。你如何布局你的晶体管来创造一个高性能的设计，这就是我们所说的<strong class="kw iu">微架构</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/a148ad3a4dfdc275511a3bb84051c198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31vw8E01zM31K37PNJGxZg.jpeg"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">ARMv9是编译器编写者和硬件设计者之间的契约。对于特定ARM处理器的接口应该是什么样子，这是一个普遍的共识。支持哪些指令以及它们是如何工作的。但是它没有提到晶体管是如何做到这一点的。</figcaption></figure><p id="8b73" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">相比之下，ARMv9是<strong class="kw iu"> CPU架构</strong>，更加抽象。它更像是硬件和软件之间的契约。它说什么硬件寄存器应该在你的微处理器上。它们包含多少位(二进制数字)。它说明了支持哪些操作。操作类似于将两个32位数字相加，或将两个64位浮点数相乘，并将结果存储在另一个寄存器中。</p><p id="db44" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">CPU指令的例子，用于分别从存储单元14和24加载数字，并存储在寄存器</em> <code class="fe mx my mz na b"><em class="lq">x1</em></code> <em class="lq">和</em> <code class="fe mx my mz na b"><em class="lq">x2</em></code> <em class="lq">中。添加寄存器并将结果存储在寄存器</em> <code class="fe mx my mz na b"><em class="lq">x3</em></code> <em class="lq">中。</em></p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="a149" class="nf lz it na b gy ng nh l ni nj">load x1, 14       ; x1 ← memory[14]<br/>load x2, 24       ; x2 ← memory[24]<br/>add  x3, x1, x2   ; x3 ← x1 + x2</span></pre><p id="01b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">欲了解更多详情，请阅读我的文章<a class="ae lr" href="https://medium.com/swlh/how-does-a-microprocessor-work-e06d196efd8f" rel="noopener">现代微处理器如何工作？</a></p><p id="a564" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CPU架构对工具制造商来说很重要。像编译器和连接器这样的软件以CPU架构为目标。这意味着当ARM有限公司制造ARMv9时，他们为软件开发人员和硬件制造商制定了一个通用标准。只要高通、苹果、Ampere和其他公司制造的硬件能够理解ARMv9规范所规定的指令，那么为这一规范编写代码的软件也能运行。</p><p id="b0a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">自然，作为这种努力的一部分，ARM将一直在开发实际实现这种新ARMv9标准的微架构。然而，这只是我们可能在未来10年看到的一长串微架构中的一个。在此期间，我们将看到许多不同的硬件，但它们都能够运行为ARMv9规范编写的代码。</p><h1 id="bb98" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">ARMv9有什么新功能？</h1><p id="d715" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">为了了解这种规格意味着什么，有必要提一下ARMv8的含义。ARMv8发布于八年前，是ARM有限公司推出的第一款64位架构。基于ARMv7架构的芯片是32位的。这意味着CPU内部的寄存器只能处理最多32位二进制数字。</p><p id="cd2a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ARMv8对苹果来说是一件大事，因为他们迅速而积极地向64位ARM架构转移，让整个行业大吃一惊。这让iPhone和iPad在竞争中领先一步。毫无疑问，苹果希望尽早进入高性能架构，因为他们的目标是ARM桌面芯片。</p><p id="46cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">简单来说，你可以说ARMv8是桌面计算的ARM架构。ARM迈出了手机的第一步，进入了台式电脑和服务器的世界。</p><p id="4023" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">相比之下，ARMv9完全是超级计算机。这可能会让你觉得，作为一个手机用户或台式电脑用户，这并不意味着什么。然而你错了。这也和消费者有很大关系。</p><p id="8941" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我还没有谈到向量有什么大不了的，或者它们到底是什么。然而，它们在科学上是一件大事。旧的超级计算机，如Cray-1，是围绕处理大量向量而建立的。他们就是我们所说的向量处理机。</p><p id="3bda" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我十几岁时读到克雷电脑，我不明白这意味着什么。我曾经和我的伙伴们幻想在克雷上玩《毁灭战士》会有什么样的帧率。但这可能不会有什么影响。克雷擅长的是科学计算，比如运行天气模拟、药物模拟以及各种数据分析和处理。任何涉及包含大量行和列的大型数据表的东西都可以从矢量处理中受益。</p><p id="f512" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这就是ARMv9通过增加一整套称为SVE2或可伸缩向量扩展2的新微处理器指令而实现的。换句话说，ARM CPUs正变得更像昔日的超级计算机。</p><p id="607c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">更多阅读:<a class="ae lr" href="https://erik-engheim.medium.com/arm-x86-and-risc-v-microprocessors-compared-92bf0d46fd52" rel="noopener"> ARM、x86、RISC-V微处理器对比。</a></p><h2 id="ac9a" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">口袋里的超级电脑</h2><p id="4865" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">但是为什么ARM今天会有超级计算机风格的架构呢？这是怎么回事？</p><p id="8961" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你有没有注意到人脸识别、语音识别、自动驾驶和机器学习已经变得越来越普遍？你有像Siri这样的智能助手，给你开会的提示，回答问题。现在这可能看起来很老套，但是你有没有思考过这些解决方案在过去是如何工作的？</p><p id="06a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每当你对你的数字助理说话时，录音就会通过网络发送到云端，在那里相当于一台超级计算机会分析你的声音，确定你说了什么，然后将结果发送回你的手机。今天，我们正试图将这种智能更广泛地传播到各地更多的设备上。所有这些设备都不具备高速互联网连接，无法吸收大量带宽。</p><p id="e285" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，用户不希望总是连接到他们的数字助理，进行语音识别、人脸识别和其他任务。我们希望这些任务总是可用的，并且在更便宜和无处不在的设备上。事实证明，这类任务反映了经典超级计算机如Cray-1过去所做的事情。因此，曾经旧的现在是新的。</p><p id="cdc8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我将在这里更详细地介绍这一点:<a class="ae lr" href="https://medium.com/swlh/risc-v-vector-instructions-vs-arm-and-x86-simd-8c9b17963a31" rel="noopener"> RISC-V矢量指令vs ARM和x86 SIMD。</a></p><h2 id="5366" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">ARM进军高性能计算领域</h2><p id="02b6" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">继台式机和服务器之后，下一步自然是高性能计算(HPC)。真正的超级计算机。很久以前，这是由ARM等定制硬件解决方案主导的，在大型数据中心包含商用硬件(如配备强大显卡的x86计算机)之前。</p><p id="23d7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着机器学习和数据分析在经济中变得更加主流和重要，英特尔和AMD在这个市场上赚了很多钱。ARM自然想在这个市场上大咬一口。富士的A64FX ARM微处理器是第一把火。</p><p id="4958" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">富士通有使用向量处理构建这种克雷风格超级计算机的经验。他们与ARM合作，使用一种新的指令集来扩展ARM处理器，这种指令集被称为SVE，可扩展向量扩展。虽然ARM已经在这一设计上走得很远，但富士通基于他们的超级计算经验提供了很多帮助。</p><p id="9eab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种组合被用来创建A64FX，它构成了建立世界上最强大的超级计算机的基础:<a class="ae lr" href="https://www.riken.jp/en/news_pubs/news/2020/20200623_1/" rel="noopener ugc nofollow" target="_blank">日本的Fugaku获得世界上最快的超级计算机</a>的称号。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/69b7aefc40c4833a35fa487319a92e0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpZzMB6eZhfuT85u8vKLIg.jpeg"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">A64FX是富士通设计的基于ARMv8的CPU，用于高性能计算。这是第一个具有可扩展向量扩展的芯片。</figcaption></figure><p id="67f7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是有一个非常重要的事实需要注意。这是一个扩展，不是ARMv8基本规范的一部分。例如，你基于ARMv8的iPhone或iPad不可能运行为<a class="ae lr" href="https://www.fujitsu.com/global/products/computing/servers/supercomputer/" rel="noopener ugc nofollow" target="_blank"> Fugaku超级计算机</a>编写的代码，因为它们只是缺乏对SVE微处理器指令的支持。</p><p id="541d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">相反，在ARMv9中，这类指令成为标准的一部分。这就是为什么我说ARM是把一台超级电脑放进你的口袋。</p><p id="f92a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是她还有一个更深层次的故事，需要了解更多的细节。你可以看到ARM正在以某种方式做到这一点，他们可以为最便宜的嵌入式设备提供处理器，一直到最昂贵的超级计算机，同时使所有这些设备都能够运行相同的代码。</p><p id="181e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">他们正在以一种比以前更常规的代码能够获得更高性能的方式来做这件事。对于英特尔和AMD为他们的x86微处理器追求的AVX指令的解决方案来说，这种事情是不可能的。</p><p id="da15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了更好地理解为什么，我们需要更详细地看看向量处理和SIMD指令之间的区别和相似之处。但是首先，什么是向量？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/58e9be038317d3378f542039b92874a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*CAJDq51SGPSuKhkUaebkVw.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">你可以从很多方面来看向量。要么只是一串数字。但实际上它们代表了空间的位移。比如箭头。点的(x，y)表示该点在坐标系中的位置。向量的(x，y)表示向量沿x轴和y轴延伸的距离。向量可以有更多数字的原因是因为它们不局限于2D和3D空间。它们也可以存在于数百甚至数千维的虚拟空间中。在数学中，你能想象的任何事情都是可能的。</figcaption></figure><h1 id="1ee6" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">向量到底是什么？</h1><p id="4777" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">向量只是一系列数字的数学术语。我们通常会这样写:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="491b" class="nf lz it na b gy ng nh l ni nj">[3, 5, 9]</span></pre><p id="782d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过使用名称或标识符引用数字列表来处理它们是可行的。因此，我在这里制作了两个名为<code class="fe mx my mz na b">v1</code>和<code class="fe mx my mz na b">v2</code>的向量:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="8d56" class="nf lz it na b gy ng nh l ni nj">v1 ← [3, 2, 1]      <br/>v2 ← [1, 2, 2]</span></pre><p id="7b89" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一种表达方式，我把向量相加，并把结果存储在<code class="fe mx my mz na b">v3</code>中:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="9c91" class="nf lz it na b gy ng nh l ni nj">v3 ← v1 + v2  ; v3 should now contain [4, 4, 3]</span></pre><p id="033d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为什么用箭头(<code class="fe mx my mz na b">←</code>)符号？当解释计算机内部发生的事情时，这是很有用的，因为我们通常有一些存储数字的内存区域。这种记忆可以被编号或命名。在微处理器内部，我们有一小块叫做<em class="lq">寄存器文件</em>的内存，它被分成叫做寄存器的独立块。在ARM微处理器上，这些寄存器的名称有<code class="fe mx my mz na b">x0</code>、<code class="fe mx my mz na b">x1</code>...<code class="fe mx my mz na b">x31</code>或者可以命名为<code class="fe mx my mz na b">v0</code>、<code class="fe mx my mz na b">v1</code>...<code class="fe mx my mz na b">v31</code>。</p><p id="1bd5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了能够执行诸如加、减或乘之类的运算，需要将它们从内存移到这些寄存器中的一个。您不能直接将存储在主存储器中的两个数字相加。CPU只对存储在其<em class="lq">寄存器文件</em>中的数字进行运算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/9084d9a73c2ad76cd9adde49b5533f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tDrCOzXo5I8VSLXlunC4g.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">在这个微处理器的简图中，<strong class="bd ma">寄存器文件</strong>是标有<strong class="bd ma">寄存器</strong>的灰色方框。内存中的数字通过被称为总线的彩色线路传输给它。寄存器文件将输入馈送到ALU、FPU、LSU和执行实际计算和操作的其它单元。</figcaption></figure><p id="6470" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">顺便说一下，为了避免混淆。<em class="lq">寄存器文件</em>与硬盘上的文件无关。它只是CPU内部的一块内存，可用于算术和逻辑运算。</p><p id="1f9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">矢量的反义词是<em class="lq">标量</em>。那只是一个对单个数字的花哨说法。下面是一个简单的标量操作示例，使用了前面的符号:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="e220" class="nf lz it na b gy ng nh l ni nj">x1 ← 3        ; store 3 in x1<br/>x2 ← 4        ; store 4 in x2<br/>x2 ← x1 + x2  ; adding x1 and x2 gives 7</span></pre><p id="745d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">向量有很多用途。即使你不是程序员，你也可能使用过电子表格应用程序，比如Microsoft Excel。一行中的一列，可以看作是一个向量。我们通常将其视为一个逻辑单元。例如，我们可以将一列中的所有元素相加，或者将一列中的每个单元格与另一列中同一行上的单元格相加。这和你在一个CPU中添加两个向量的情况是一样的。多个列一起形成表格。用数学术语来说，我们会说多个向量构成矩阵。基本上是按行和列组织的数字集合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/cb9ea62275dc6cde58e35a7e3ca86b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*cFlN2xyW1taE2G5LAkvzSg.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">你可以把数量和单位成本看作向量。总成本是对这两个向量进行逐元素数学计算的结果。</figcaption></figure><p id="2f6f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这在机器学习或几乎任何科学工作中都是一件大事。第一台可编程计算机Z1实际上是用来执行矩阵计算的。</p><p id="8e90" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然今天的计算机通常不直接处理矩阵，但我们可以通过使用向量来加速矩阵计算。这就是为什么矢量指令对于加速机器学习、图像识别和语音识别如此重要。向量和矩阵的数学称为线性代数。我给好奇的你们介绍一下:<a class="ae lr" href="https://erik-engheim.medium.com/the-core-idea-of-linear-algebra-7405863d8c1d" rel="noopener">线性代数的核心思想。</a></p><p id="12d7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是让我们不要迷失在数学中。我们真正想知道的是这与微处理器有什么关系。现代微处理器中用来处理向量的指令叫做SIMD指令。</p><h1 id="237d" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">SIMD vs矢量指令</h1><p id="8f11" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">从技术上讲，阿姆斯·霓和SVE指令都是SIMD指令的一种形式。是缩写，是<em class="lq">单指令多数据</em>的简称。我们所说的指令是指像加、减、乘这样的东西。因此，SIMD的思想是，你向CPU发出一条指令，然后它同时对多个值执行同样的操作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nz"><img src="../Images/bd52ceb6256751e55496404ffb56b204.png" data-original-src="https://miro.medium.com/v2/format:webp/1*O4N5IlOJmtl_KLQJul4B_w.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">单指令单数据(SISD)与单指令多数据(SIMD)</figcaption></figure><p id="d8ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种指令集已经存在了一段时间。你可能听说过英特尔和AMD x86微处理器上的MMX、SSE和现在的AVX指令集。他们开始更快地进行多媒体处理，如视频编码和解码。ARMs Neon指令与这些最相似。这些霓虹灯说明看起来像这样:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="c246" class="nf lz it na b gy ng nh l ni nj">LDR v0, [x4]    ; v0 ← memory[x4]<br/>LDR v1, [x6]    ; v1 ← memory[x6]<br/><br/>ADD v4.16B, v0.16B, v1.16B <br/>STR v4, [x8]    ; v4 → memory[x8]</span></pre><p id="24ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这个例子中，标量寄存器<code class="fe mx my mz na b">x4</code>、<code class="fe mx my mz na b">x6</code>和<code class="fe mx my mz na b">x8</code>保存着内存地址，也就是我们要从中加载数字和存储计算结果的内存位置。</p><p id="3f8d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe mx my mz na b">LDR</code>是一条ARM指令，用于将数字从内存加载到寄存器文件的寄存器中。<code class="fe mx my mz na b">STR</code>反其道而行之，将寄存器中的数字存入主存。</p><p id="9d0b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe mx my mz na b">ADD</code>指令可能看起来很奇怪。为什么每个寄存器名称后面都有像<code class="fe mx my mz na b">.16B</code>这样怪异的后缀？</p><h2 id="5e1d" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">向量处理中的车道</h2><p id="7e5f" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">v0和v1等矢量寄存器为128位宽。那是什么意思？它基本上是一个向量寄存器可以容纳的二进制数字的最大数量。</p><p id="a981" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这就为我们可以并行处理多少个数字以及每个数字可以有多少个二进制数字(位)设置了一个上限。例如，如果您想将64位数字相加，那么您只能并行地将两个数字相加，因为在一个128位向量寄存器中只能容纳两个64位数字。然而，如果您使用较小的数字，您可以适合更多。例如，当处理颜色值时，我们通常将红色、绿色和蓝色分量表示为8位值。我们可以在一个128位寄存器中放入16个这样的寄存器。</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="3fac" class="nf lz it na b gy ng nh l ni nj">128/8 = 16</span></pre><p id="1126" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，这应该给你一个提示。<code class="fe mx my mz na b">16B</code>表示16个字节宽的元素。试着猜猜这条加法指令是什么意思:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="2635" class="nf lz it na b gy ng nh l ni nj">ADD v4.2D, v0.2D, v1.2D</span></pre><p id="cbb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在微处理器行话中，我们通常称一个字为32位数字。64位值是一个双字。因此<code class="fe mx my mz na b">.2D</code>表示两个双字。<code class="fe mx my mz na b">.4S</code>表示四个单词:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="693f" class="nf lz it na b gy ng nh l ni nj">128/32 = 4</span></pre><p id="741f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是为什么只有add指令才有这些后缀呢？为什么不加载和存储？因为当我们加载和存储时，我们不需要把每个向量寄存器看作是由多个元素组成的。</p><p id="e83e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在计算过程中，我们将寄存器分割成的元素数量决定了为计算设置了多少个通道。想象一个道路系统，其中的数字沿着多条车道平行流动。下面是一个例子。我们得到了在计算中使用的<code class="fe mx my mz na b">v1</code>和<code class="fe mx my mz na b">v2</code>寄存器，结果存储在<code class="fe mx my mz na b">v3</code>中。我们分成两个元素<code class="fe mx my mz na b">.2D</code>，因此我们有两个通道执行计算。每个通道都有一个ALU(算术逻辑单元)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nz"><img src="../Images/fb04e8b8d11fc7328d4e249982a965c5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*W2u9EzHtbmBOSfz4m1qFBA.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">如何使用多个alu来执行SIMD。我们有两条计算路线。每个通道由一个算术逻辑单元(ALU)处理。</figcaption></figure><p id="22b4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你不喜欢我的例子，那么ARM有另一个例子来说明这个概念，有四个单独的通道用于添加。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nz"><img src="../Images/edbc33fc66260e293bb8708d64356584.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1uhPFDJwD8UwdUMMAj9QUQ.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated"><code class="fe mx my mz na b">v8</code>和<code class="fe mx my mz na b">v9</code>寄存器之间的四通道加法</figcaption></figure><h2 id="ad4f" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">SIMD指令的问题</h2><p id="1995" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">SIMD指令，如下所示，可能看起来像是带有不同参数的相同指令:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="0b5b" class="nf lz it na b gy ng nh l ni nj">ADD v4.2D, v0.2D, v1.2D <br/>ADD v4.4S, v0.4S, v1.4S</span></pre><p id="5690" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，这些被编码为单独的指令。这很快就失去了控制，这在x86方面也有所体现。英特尔从MMX开始，然后是SSE、SSE2、AVX、AVX2，最后是AVX-512。例如，MMX拥有64位向量寄存器，因此您可以并行处理两个32位值或八个8位值。</p><p id="9b70" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着时间的推移，随着晶体管越来越多，他们决定开发新的更大的矢量寄存器。例如，SSE2具有128位向量寄存器。最终这还不够，所以你得到了AVX和AVX2给了我们256位向量寄存器。现在终于AVX-512给了我们疯狂的长512位向量寄存器。所以现在你原则上可以并行计算64个8位颜色值。</p><p id="3bcc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每当英特尔推出更大的寄存器时，他们都必须添加大量新指令。为什么？因为向量寄存器的长度被编码在SIMD指令中。这很快变得臃肿。您将需要一个<code class="fe mx my mz na b">ADD</code>指令用于:</p><ol class=""><li id="5e4f" class="oa ob it kw b kx ky la lb ld oc lh od ll oe lp of og oh oi bi translated">每个向量寄存器宽度为64、128、256或512位。</li><li id="c1fd" class="oa ob it kw b kx oj la ok ld ol lh om ll on lp of og oh oi bi translated">每一个都需要一个单独的变量来表示所使用的通道数。</li></ol><p id="7ed0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，SIMD指令的加入导致了指令数量的爆炸，尤其是对于x86。当然，并不是每个x86处理器都支持所有这些指令。只有较新的版本支持AVX-512。</p><h2 id="85a9" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">为什么ARM不能遵循AMD和Intel的策略</h2><p id="ebb2" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">这种策略对ARM来说是行不通的。英特尔和AMD的使命很简单。他们只是试图在任何时候都尽可能制造最大最便宜的CPU，并将它们推向市场。</p><p id="4902" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">相比之下，ARM试图覆盖非常广泛的需求。ARM运行在微型嵌入式设备上，一直到超级计算机，如Fugaku。ARM可能能够为使用512位向量的服务器提供CPU设计，但在一台小型的ARM上支持这种设计是不可能的，该ARM旨在运行在具有长电池寿命的廉价手机上。当然，ARM可以提供许多不同的指令集。</p><p id="ccff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">事实上，ARM确实为不同的细分市场提供了不同的配置文件。但同样的软件可以在他们的各种芯片上编译和运行，这仍然是arm感兴趣的。</p><p id="85b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">SVE和SVE2允许ARM做的是为卖方设计的每种类型的芯片赋予不同物理长度的向量寄存器。对于SVE/SVE2，向量寄存器必须具有128位的最小长度和2048位的最大长度。对于低功率智能手机，他们可以出售128位向量长度的设计。对于超级计算机，他们可以出售2048位宽向量的设计。</p><p id="069f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">SVE的美妙之处在于，超级计算机和廉价手机都可以使用相同的代码。这对于x86 SIMD指令来说是不可能的。虽然我不是ARM汇编代码专家，但根据使用Neon和SVE时汇编代码的样子，在我看来后者似乎更有效。即使向量寄存器长度相同。</p><p id="097a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">原因是你得到了更短的汇编代码。这意味着缓存可以容纳更少的指令。需要解码和管理的指令更少。让我澄清一下我的意思。当一个微处理器从内存中接收到一个指令，告诉它比如说把两个数字相加或者相乘，那么它就需要计算出这个指令告诉它做什么。这被称为<em class="lq">解码</em>，需要相当大的功率。解码更少的指令可以节省电池。</p><h1 id="bacf" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">可扩展矢量指令的应用</h1><p id="e618" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">如果我们看看Neon指令，它们对前缀中使用的通道数进行编码，如前面的示例所示。</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="ab7d" class="nf lz it na b gy ng nh l ni nj">ADD v4.2D, v0.2D, v1.2D <br/>ADD v4.4S, v0.4S, v1.4S</span></pre><p id="9fe0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，如果我们将此翻译成SVE指令，那么它们看起来几乎是这样的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="28cc" class="nf lz it na b gy ng nh l ni nj">ADD v4.D, v0.D, v1.D <br/>ADD v4.S, v0.S, v1.S</span></pre><p id="f55c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这意味着我们不再暴露我们正在执行的计算的数量。使用SVE指令，你不知道在编译你的代码时会使用多少通道，因为向量长度是未知的。</p><h2 id="e23a" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">述谓</h2><p id="a5fb" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">相反，SVE的主要思想是使用所谓的预测。它有一组特殊的寄存器<code class="fe mx my mz na b">p0</code>、<code class="fe mx my mz na b">p1</code>，...，<code class="fe mx my mz na b">p15</code>它就像是我们计算通道的面具。您可以使用这些来启用和禁用不同的通道。所以前面使用的add指令看起来更像这样:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="9b54" class="nf lz it na b gy ng nh l ni nj">ADD v4.D, p0/M, v0.D, v1.D</span></pre><p id="9c87" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以我们得到了一个额外的参数<code class="fe mx my mz na b">p0/M</code>，CPU只存储<code class="fe mx my mz na b">v4</code>中的<code class="fe mx my mz na b">v0</code>和<code class="fe mx my mz na b">v1</code>相加的结果，其中<code class="fe mx my mz na b">p0</code>为1(真)，我们什么都不做。在伪代码中应该是这样的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="efad" class="nf lz it na b gy ng nh l ni nj">while i &lt; N<br/>   if p0[i] == 1<br/>      v4[i] = v0[i] + v1[i]<br/>   end<br/>   i += 1<br/>end</span></pre><p id="6b9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">谓词寄存器也在例如加载和存储数据时使用。下面是一个从内存加载数据的例子:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="3465" class="nf lz it na b gy ng nh l ni nj">LD1D z1.D, p0/Z, [x1, x3, LSL #3]</span></pre><p id="5383" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这做了一大堆事情，所以它需要一些解释。<code class="fe mx my mz na b">[x1, x3, LSL #3]</code>是指定存储器地址的典型ARM方式。可以这样理解:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="59cc" class="nf lz it na b gy ng nh l ni nj">base_address = x1 + x3*2^3<br/>z1 ← memory[base_address]</span></pre><p id="ddb6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是因为我们有谓词，这并不完全正确。我们需要过滤加载的内容。更准确的描述是这样的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="4611" class="nf lz it na b gy ng nh l ni nj">base = x1 + x3*2^3<br/>while i &lt; N<br/>   if p0[i] == 1<br/>      v1[i] = memory[base + i]<br/>   else<br/>      v1[i] = 0<br/>   end<br/>   i += 1<br/>end</span></pre><p id="20e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个掩码概念也存在于许多高级语言中，例如Python、R和Julia。一个高级语言的例子可能有助于理解这个概念。这是来自Julia命令行的。在R和Python中应该是类似的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="997f" class="nf lz it na b gy ng nh l ni nj">julia&gt; mask = [false, true, true, false];<br/><br/>julia&gt; A = [2, 4, 8, 10];<br/><br/>julia&gt; B = [1, 3, 7, 9];<br/><br/>julia&gt; A[mask]<br/>2-element Vector{Int64}:<br/> 4<br/> 8<br/> <br/>julia&gt; B[[true, false, false, true]]<br/>2-element Vector{Int64}:<br/> 1<br/> 9<br/> <br/>julia&gt; A[mask] + B[mask]<br/>2-element Vector{Int64}:<br/>  7<br/> 15</span></pre><p id="0718" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你在这个例子中看到的是，我们有四个元素的向量。我们使用<code class="fe mx my mz na b">mask</code>，它类似于谓词寄存器，只挑选两个中间元素。或者两条中间的车道。</p><p id="20c4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们可以只对两个中间值进行加法运算。</p><h2 id="87e3" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">如何避免知道向量长度</h2><p id="6d26" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">谓词实际上是对向量处理的if语句的概括。自然，你不能为每个通道独立地跳过代码。为了模拟不同条件的执行，每个通道有不同的结果，我们使用谓词。</p><p id="414a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这也有助于我们极大地简化矢量化代码，避免需要知道矢量的确切长度。假设您有六个32位值要处理。基本上是<code class="fe mx my mz na b">N = 6</code>，而且你只有在编译的时候才知道这个。对于Neon，您会得到如下说明:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="d3e7" class="nf lz it na b gy ng nh l ni nj">ADD v4.4S, v0.4S, v1.4S  ; v4 ← v0 + v1</span></pre><p id="991a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以这样做一次，但是你还有两个元素。如果你做两次，你会得到八个元素，这太多了。因此，常规的向量化代码将不得不做尽可能多的事情，然后在最后有一个我们称之为<em class="lq">的排水循环</em>。这就是使用纯标量运算来计算余数的地方。</p><p id="1ed3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">和SVE在一起，你不需要那样。相反，我们得到了一个叫做<code class="fe mx my mz na b">WHILELT</code>的神奇指令来帮助我们。这里有一个例子:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="ddb0" class="nf lz it na b gy ng nh l ni nj">WHILELT p3.s, x1, x4</span></pre><p id="e4ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是这有什么用呢？我用一个伪代码的例子来说明。让我们称最大车道数为<code class="fe mx my mz na b">M</code>。直到运行时你才知道那个数字，但是让我们说<code class="fe mx my mz na b">M = 4</code>。此外，我们知道我们想要处理的元素数量是<code class="fe mx my mz na b">N = x4 = 6</code>。<code class="fe mx my mz na b">WHILET</code>是<code class="fe mx my mz na b">While Less Than</code>的简称，工作原理是这样的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="3333" class="nf lz it na b gy ng nh l ni nj">i = 0<br/>while i &lt; M<br/>   if x1 &lt; x4<br/>      p3[i] = 1<br/>   else<br/>      p3[i] = 0<br/>  end<br/>  i += 1<br/>  x1 += 1<br/>end</span></pre><p id="42fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，如果我们想象在一个循环中进行这些向量运算，那么在第一次迭代中<code class="fe mx my mz na b">p3</code>将会是这样的:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="b79d" class="nf lz it na b gy ng nh l ni nj">x1 = 0<br/>p3 = [1, 1, 1, 1]</span></pre><p id="ca07" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，在第二次迭代中，<code class="fe mx my mz na b">x1</code>将在某个点不小于<code class="fe mx my mz na b">x4</code>(我们的N)。所以我们得到了</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="4124" class="nf lz it na b gy ng nh l ni nj">p3 = [1, 1, 0, 0]</span></pre><p id="c5c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，在代码中没有任何地方我们需要明确指定我们在多少个车道上操作。<code class="fe mx my mz na b">WHILELT</code>指令将确保所有通道都打开，直到我们到达终点。</p><p id="0e1c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这就是所有SIMD处理的工作方式。你处理一批数字。因此，例如，如果您必须处理20个元素，您的向量寄存器足够大，一次可以处理4个通道，那么您可以进行五次完整的迭代(<code class="fe mx my mz na b">5×4 = 20</code>)。但是如果你有22个元素呢？</p><p id="f392" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您不能在最后进行完整的四元素批处理。因此，您需要一次手动处理一个元素。有了断言寄存器，你就不必这么做了。您只需屏蔽掉最后的too元素。这在将结果写回内存时有效。被<code class="fe mx my mz na b">p3</code>屏蔽的元素不会被写回。</p><h2 id="3427" class="nf lz it bd ma nk nl dn me nm nn dp mi ld no np mk lh nq nr mm ll ns nt mo nu bi translated">聚集-分散加载和存储操作</h2><p id="5d35" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">SVE风格指令的另一个重要特性是支持我们所说的聚集-分散操作。这意味着只需一次操作，就可以用分布在内存中多个位置的数据填充一个向量寄存器。同样，您可以将向量的结果写入多个位置。这个原理类似于我们讨论的谓词。</p><p id="da8c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这有什么用？在高级编程语言中，我们通常以这种方式存储数据:</p><pre class="kj kk kl km gt nb na nc nd aw ne bi"><span id="c3e2" class="nf lz it na b gy ng nh l ni nj"><strong class="na iu">struct</strong> Sale {<br/>    <strong class="na iu">int</strong> unit_price;<br/>    <strong class="na iu">int</strong> sold_units;<br/>    <strong class="na iu">int</strong> tax;<br/>}</span><span id="61be" class="nf lz it na b gy oo nh l ni nj">Sale sales[1000];</span></pre><p id="ac5e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设我们有几千个这样的物体。通常我们要做相关领域之间的计算。例如，您可能想将<code class="fe mx my mz na b">unit_price</code>乘以<code class="fe mx my mz na b">sold_units</code>中售出的单位数。这意味着您希望一个向量寄存器包含许多单位价格，另一个包含所有售出的单位。然而，这些领域并没有整齐地存储在内存中的传染块。它们是交错的。</p><p id="6611" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">像这样的小细节有很多，这使得SVE风格的指令可以应用到你可能产生的更广泛的代码中。更多的for循环可以矢量化，这为性能提升提供了更多的机会。</p><h1 id="c2dc" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">SVE2带来了什么？</h1><p id="a9c4" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">在这一点上，你很自然地想知道SVE2增加了哪些SVE没有的东西？</p><p id="9d6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">SVE只是已经建立的ARMv8架构的可选扩展。对于SVE2和ARMv8，它们都是基础设计的一部分。这意味着霓虹灯和SVE变得更加紧密地结合在一起。SVE得到了额外的指令，这使得SVE2基本上是氖的替代品。你可以用SVE2做所有Neon擅长的事情。</p><p id="2346" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请记住，SVE最初只是为超级计算的东西，而不是Neon的多媒体工作负载。多媒体内容通常不需要长的向量寄存器。考虑像一个彩色像素编码为RGBA。它是四个8位值，全部适合一个32位寄存器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/43a6b77e42cc50465ce6ba9aa9da394c.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*gDfO1cyyyqwqtcGTXFddGA.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk translated">每个像素由四个部分组成:红色、绿色、蓝色和Alpha值。每个都是一个字节，应该单独计算。如果一个32位寄存器是一个有4个分量的向量寄存器，我们可以这样做。</figcaption></figure><p id="f88d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，对于SVE2，更短的向量寄存器非常适合的这些工作负载也可以很好地处理SVE2的可变长度向量。</p><p id="1f95" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这为ARM提供了一个强大的指令集，可以在最小和最节能的芯片上工作，也可以在性能要求最高的芯片上工作，用户只需编译一次。更不用说这对于编译器来说是更容易产生的代码。而ARM也不需要参与英特尔和AMD一直在搞的这场SIMD指令军备竞赛。</p><p id="cf61" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">他们不需要每隔几年就添加一大堆新的SIMD指令。SVE2会给他们一个基础，有很大的稳定性和成长空间。</p><h1 id="deab" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">对用户、开发者和行业的影响</h1><p id="e330" class="pw-post-body-paragraph ku kv it kw b kx mq ju kz la mr jx lc ld ms lf lg lh mt lj lk ll mu ln lo lp im bi translated">对于开发者来说，这意味着编写和优化ARM代码变得更加容易。写机器学习，人脸识别，语音识别变得更容易。不用担心目标平台是否支持这些指令。</p><p id="1e9a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于这个行业来说，这意味着公司将能够提供更多不同的利用机器学习的设备，无论是相机、平板电脑、智能手机、微控制器还是其他东西。</p><p id="4d0f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于用户来说，这意味着你将减少对网络接入的依赖，因为你的设备将能够做很多过去云必须做的事情。</p><p id="5611" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ARM也应该越来越多地将英特尔和AMD挤出利润丰厚的数据中心业务。现在，我不是芯片设计专家，但看到RISC-V也在追求这种类型的指令集，并看到所有的优势，我认为英特尔/AMD在这一点上有点失误。他们的SIMD战略看起来并不明智。我怀疑它会回来困扰他们。</p></div></div>    
</body>
</html>