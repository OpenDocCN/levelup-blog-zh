<html>
<head>
<title>Pyspark: How to Delete and Install Pyspark on Ubuntu</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark:如何在Ubuntu上删除和安装Pyspark</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-delete-and-install-pyspark-on-ubuntu-4e1bbefa11a3?source=collection_archive---------1-----------------------#2022-03-25">https://levelup.gitconnected.com/how-to-delete-and-install-pyspark-on-ubuntu-4e1bbefa11a3?source=collection_archive---------1-----------------------#2022-03-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ju"><img src="../Images/198a0bdb255d8b6912f71ac0f55e61ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zJN3fnIK3Ll7oblg"/></div></div><figcaption class="kg kh gj gh gi ki kj bd b be z dk translated">照片由来自unsplash.com的Jez Timms拍摄</figcaption></figure><p id="50d1" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">所以在过去的几天里，我在电脑上安装PySpark时遇到了一些问题。我试着尽可能多地查找教程，但在试图导入之后，都导致了VS代码中的<code class="fe li lj lk ll b">Pyspark is not defined</code>。我想当我试图解决这个难题时，最好在这里记录下这个过程。</p><p id="1cfd" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">目录:</strong></p><ul class=""><li id="67a5" class="lm ln iq km b kn ko kr ks kv lo kz lp ld lq lh lr ls lt lu bi translated">删除Pyspark和所有相关包。</li><li id="0739" class="lm ln iq km b kn lv kr lw kv lx kz ly ld lz lh lr ls lt lu bi translated">Pyspark依赖项</li><li id="8e84" class="lm ln iq km b kn lv kr lw kv lx kz ly ld lz lh lr ls lt lu bi translated">安装和设置过程</li><li id="b604" class="lm ln iq km b kn lv kr lw kv lx kz ly ld lz lh lr ls lt lu bi translated">结论</li></ul><p id="288c" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">删除Pyspark，spark相关包:</strong> <br/>在开始之前，我确保从我的机器上删除所有Pyspark和Spark的痕迹，这样我就可以重新开始。转到您的终端并运行这些命令。如果您从未在机器上安装Spark或Pyspark，您可以跳过这一步。</p><p id="9f0f" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">→<code class="fe li lj lk ll b">pip uninstall pyspark</code><br/>→<code class="fe li lj lk ll b">pip uninstall findspark</code><br/>→<code class="fe li lj lk ll b">sudo apt-get remove --auto remove spark</code><br/>→可选(可做非此即彼)<br/> → <code class="fe li lj lk ll b">sudo apt-get purge </code> <br/> → <code class="fe li lj lk ll b">sudo apt-get purge --auto-remove spark</code></p><p id="7b52" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">首先我们卸载Pyspark和Findspark。接下来，我们卸载Spark，我们需要使用上面的最后三个命令，确保它及其所有依赖项和配置从系统中完全删除。第四个<code class="fe li lj lk ll b">sudo apt-get purge spark</code>和第五个<code class="fe li lj lk ll b">sudo apt-get purge --auto-remove spark</code>的区别在于，第四个命令只是删除配置和依赖包，而第五个命令删除<strong class="km ir"> <em class="ma">所有关于Spark包的</em> </strong>。</p><p id="15c0" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> Pyspark依赖:</strong> <br/> Python:安装与您正在安装的Pyspark版本相对应的Python版本。</p><p id="784f" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Java-Jdk:要运行Pyspark，您需要Java 8或更高版本。</p><p id="b506" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Apache Spark:由于Pyspark是一个位于Apache Spark之上的Api层，您肯定需要下载它。</p><p id="98a8" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">环境变量:很重要，因为它让Spark知道所需的文件在哪里。</p><p id="73f3" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">安装过程:</strong></p><ol class=""><li id="c320" class="lm ln iq km b kn ko kr ks kv lo kz lp ld lq lh mb ls lt lu bi translated"><strong class="km ir"> Java JDK: <br/> </strong>安装设置Java-jdk: <br/> <br/> a .如果已经安装了Java，检查Java版本:<br/> <code class="fe li lj lk ll b">java --version</code>或<code class="fe li lj lk ll b">java -version</code></li></ol><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="ab gu cl mc"><img src="../Images/561fbd8dba40bf4e51fcbda64a079fbb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*IAaG7VlF4WaUhz8Dz7CgZw.png"/></div></figure><p id="82b2" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">b.安装Java-Jdk(只有在你没有安装正确版本的Java的情况下，我目前版本的Spark需要java 8以上):<br/> <code class="fe li lj lk ll b">sudo apt install openjdk-8-jdk</code></p><p id="4198" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">c.检查java版本:<br/> <code class="fe li lj lk ll b">java --version</code>或<code class="fe li lj lk ll b">java -version</code> <br/> <br/> d .如果您的默认Java版本不同，请更改版本:<br/> —列出Java版本:<code class="fe li lj lk ll b">sudo update-java-alternatives --list</code></p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi md"><img src="../Images/4adebd6833b5a4f82e299b4c4483dc43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d059C0e9E1b0PVlzhpwrNQ.png"/></div></div></figure><p id="97b0" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">—将您的Java版本设置为默认:<code class="fe li lj lk ll b">sudo update-alternatives --config java</code><br/>—<code class="fe li lj lk ll b">*</code>表示您的机器上运行的Java-jdk的当前默认版本。<br/> —您可以通过在选择栏中输入数字来选择您喜欢的版本。在我的例子中，我正在寻找Java 8，所以我将点击2。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi me"><img src="../Images/1700b6d7dd137e2e86a87efb46a810f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bIr35vmOFLdjVAqFZEIx3Q.png"/></div></div></figure><p id="5970" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">e.再次检查java版本，确保Java的默认版本已经更改。<br/> <code class="fe li lj lk ll b">java --version</code>或<code class="fe li lj lk ll b">java -version</code></p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div class="ab gu cl mc"><img src="../Images/561fbd8dba40bf4e51fcbda64a079fbb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*IAaG7VlF4WaUhz8Dz7CgZw.png"/></div></figure><p id="e679" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">f.将java-jdk路径添加到您的环境:<br/> —在您的终端中键入<code class="fe li lj lk ll b">nano /etc/environment</code>并输入以下内容:</p><p id="63bc" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><code class="fe li lj lk ll b">JAVA_HOME="usr/lib/jvm/java-8-openjdk-amd64"</code></p><p id="6ecd" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">—点击<code class="fe li lj lk ll b">ctrl + s</code>保存，点击<code class="fe li lj lk ll b">ctrl + x</code>退出。<br/> —在终端类型<code class="fe li lj lk ll b">source /etc/environment</code>中输入一次，让Bash重新读取您的/etc/environment文件。</p><p id="bb81" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">2.<strong class="km ir">下载安装Spark: <br/> </strong>链接:<a class="ae mf" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/downloads.html</a><br/>a .选择Spark版本和包类型:</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi mg"><img src="../Images/49f5f48e6dad279d4c56c1d81120ddb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1wSACEnos03PTeqqxZRHQ.png"/></div></div></figure><p id="cd30" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 3。</strong> <strong class="km ir">移动一下。tgz文件从下载目录到一个你喜欢的容易访问的目录，对我来说这是我的主目录。</strong></p><p id="b4d0" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 4。提取文件。</strong> <br/> <code class="fe li lj lk ll b">sudo tar -zxvf spark-3.2.1-bin-hadoop3.2.tgz</code></p><p id="b4e4" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 5。设置您的Spark/Pyspark环境变量:<br/> </strong> —在您的终端中键入<code class="fe li lj lk ll b">sudo nano ~/.bashrc</code>。<br/> —在文件末尾输入环境路径。bashrc文件如下:</p><pre class="jv jw jx jy gt mh ll mi mj aw mk bi"><span id="39fd" class="ml mm iq ll b gy mn mo l mp mq">source /etc/environment</span><span id="1556" class="ml mm iq ll b gy mr mo l mp mq">export SPARK_HOME=/home/richarda/spark-3.2.1-bin-hadoop3.2<br/>export PATH=$PATH:$SPARK_HOME/bin<br/>export PYSPARK_PYTHON=/usr/local/bin/python3.7<br/>export PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.7<br/>#when running spark locally, it uses 2 cores, hence local[2]<br/>export PYSPARK_SUBMIT_ARGS="--master local[2] pyspark-shell"</span><span id="6601" class="ml mm iq ll b gy mr mo l mp mq">export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH<br/>export PATH=$PATH:$JAVA_HOME/jre/bin</span></pre><p id="2f45" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">—确保将SPARK_HOME的“richarda”替换为相应的用户名。<br/> —点击<code class="fe li lj lk ll b">ctrl + s </code>保存您的。bashrc文件。<br/> —点击<code class="fe li lj lk ll b">ctrl + x</code>退出。bashrc文件，然后回到你的终端。<br/> —键入<code class="fe li lj lk ll b">source ~/.bashrc</code>以便Bash可以重新读取您的。bashrc文件。</p><p id="54ea" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 6。现在是关键时刻了！</strong> <br/> a .到你的终端键入<code class="fe li lj lk ll b">pyspark</code>如果你的Spark shell初始化了，那么恭喜你！</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi ms"><img src="../Images/79438abb7f10854baabb693c16b1f6ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-cHU11c6g2zQI7RGXC36A.png"/></div></div></figure><p id="df09" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">b.如果火花没有启动，不用担心！因为还有另一种方法来检查Pyspark是否安装正确。<br/> —重启机器。<br/> — <code class="fe li lj lk ll b">cd</code>进入你的星火目录&gt; bin <br/> — Type <code class="fe li lj lk ll b">spark-shell</code>。如果您的终端像这样启动:</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi mt"><img src="../Images/054aa9bf201232646239b706c5a2b9cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*en1h0K7kclwJsDdp0HUDcw.png"/></div></div></figure><p id="1502" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">..那你就可以走了。</p><figure class="jv jw jx jy gt jz gh gi paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="gh gi mu"><img src="../Images/0a3b9d6fd7e1efefcbd2659fc8742341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iikm76dLEncAT1yUzvm4Dw.png"/></div></div></figure><p id="efca" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir">结论:</strong> <br/> —不再有<code class="fe li lj lk ll b">pyspark could not be defined</code>。如果您有一个Pylance错误，不要担心这个错误或警告。用Pyspark应该没问题，好好享受吧！我希望这篇Pyspark安装教程对你有用。</p></div></div>    
</body>
</html>