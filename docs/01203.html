<html>
<head>
<title>Predicting Hospital Scores with Random Forest Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用随机森林回归预测医院得分</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/predicting-hospital-scores-with-random-forest-regression-9108b8ac666f?source=collection_archive---------3-----------------------#2019-11-26">https://levelup.gitconnected.com/predicting-hospital-scores-with-random-forest-regression-9108b8ac666f?source=collection_archive---------3-----------------------#2019-11-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="dd30" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有代码在https://github.com/seho0808/rf_hospital_medium<a class="ae ko" href="https://github.com/seho0808/rf_hospital_medium" rel="noopener ugc nofollow" target="_blank">整齐地归档</a></p><p id="858d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以自由地复制和使用本文中我的任何代码。</p></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="bd24" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">一、这篇文章讲的是什么？</h1><blockquote class="lu"><p id="bc7f" class="lv lw it bd lx ly lz ma mb mc md kn dk translated"><em class="me">假设您正在尝试选择一家离您最近的医院。你在谷歌地图上看到三家医院，但其中只有一家有评级。你会怎么做？</em></p></blockquote><p id="7869" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">这篇文章主要基于我的医院评级预测模型，该模型来自于由Booze Allen Hamilton赞助的弗吉尼亚理工大学的数据竞赛。这个分析获得了第三名。</p><p id="2f23" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从本文中，您可以了解到:</p><ol class=""><li id="3ff6" class="mk ml it js b jt ju jx jy kb mm kf mn kj mo kn mp mq mr ms bi translated">如何通过Scikit-Learn库使用和调整Random Forest。</li><li id="c31d" class="mk ml it js b jt mt jx mu kb mv kf mw kj mx kn mp mq mr ms bi translated">大型数据集的特征提取和数据清洗的基本示例。我们将合并许多包含具有相同医院id的解释变量(X)的文件。</li><li id="8f2c" class="mk ml it js b jt mt jx mu kb mv kf mw kj mx kn mp mq mr ms bi translated">医疗保健行业使用机器学习的一个例子。</li></ol><p id="7e8d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你想要第一条，我推荐你阅读第二和第四部分。</p><p id="446f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你想要第二个，我推荐你阅读第二和第三部分。</p><h1 id="4de1" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">二。资料组</h1><p id="d8db" class="pw-post-body-paragraph jq jr it js b jt nd jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj nh kl km kn im bi translated">所有的数据集都来自https://data.medicare.gov/data/hospital-compare。使用的文件列表包括:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="55f5" class="nr kx it nn b gy ns nt l nu nv">Hvbp_tps_11_07_2017.csv</span><span id="0e08" class="nr kx it nn b gy nw nt l nu nv">Hvbp_hcahps_11_07_2017.csv</span><span id="11d2" class="nr kx it nn b gy nw nt l nu nv">Timely and Effective Care — Hospital.csv</span><span id="e2c8" class="nr kx it nn b gy nw nt l nu nv">Medicare Hospital Spending per Patient — Hospital.csv</span><span id="0fca" class="nr kx it nn b gy nw nt l nu nv">Outpatient Imaging Efficiency — Hospital.csv</span><span id="babb" class="nr kx it nn b gy nw nt l nu nv">Payment and Value of Care — Hospital.csv</span><span id="93a5" class="nr kx it nn b gy nw nt l nu nv">Complications and Deaths — Hospital.csv</span><span id="a2a7" class="nr kx it nn b gy nw nt l nu nv">Ambulatory Surgical Measures-Facility.csv</span><span id="c5e3" class="nr kx it nn b gy nw nt l nu nv">Readmission Reduction.csv</span><span id="39a6" class="nr kx it nn b gy nw nt l nu nv">Healthcare Associated Infections — Hospital.csv</span></pre><p id="8ac2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将尝试预测分数的两个度量。它们是列<code class="fe nx ny nz nn b">total_performance_score</code>和<code class="fe nx ny nz nn b">overall_hospital_performance_rating</code>。这两个小节分别来自<code class="fe nx ny nz nn b">Hvbp_tps_11_07_2017.csv</code>和<code class="fe nx ny nz nn b">Hvbp_hcahps_11_07_2017.csv</code>。我们将使用<strong class="js iu">所有其他数据集</strong>作为我们的预测变量，用于预测Y变量，在本例中是<code class="fe nx ny nz nn b">total_performance_score</code>和<code class="fe nx ny nz nn b">overall_hospital_performance_rating</code> <em class="oa"> </em>。</p><p id="8c4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于我们想要预测两个不同的度量，<strong class="js iu">我们需要运行两个独立的随机森林</strong>模型。为了更容易理解，我们将重点预测<code class="fe nx ny nz nn b">total_performance_score</code> <em class="oa">。</em>姑且把这个措施简称为<code class="fe nx ny nz nn b">tps</code>。这两种方法的结果将在后面的结论部分给出。</p><p id="6fd1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么我们要如何预测<code class="fe nx ny nz nn b">tps</code>？先来先睹为快<code class="fe nx ny nz nn b">Hvbp_tps_11_07_2017.csv</code> <em class="oa"> </em>数据集。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ob"><img src="../Images/7cbf39c8a48fb2cb2bb397191f553968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tW1nHrtSnZARv5C2.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">“Hvbp_tps_11_07_2017.csv”的前五行</figcaption></figure><p id="8f5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以看到数据集给出了提供者编号，即医院ID。我们将使用这个列作为<strong class="js iu">枢纽列，</strong>，这意味着我们将使用医院ID合并不同的数据集。我们还可以在最右边的一栏中找到总绩效分数，如下所示。你可以看到以35.54开始的列…这个列恰恰是我们将要尝试预测的<code class="fe nx ny nz nn b">tps</code> <em class="oa"> </em>列。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi on"><img src="../Images/f78dc1e3366b331f7ff77275b56322ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3sYznHP0aTKe9vkk.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">“Hvbp_tps_11_07_2017.csv”的前五行</figcaption></figure><p id="a79d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是另一个数据集的前五行，我们将使用它来提取<strong class="js iu">预测变量</strong>，也称为<strong class="js iu">解释变量</strong>。<strong class="js iu"> </strong>注意，其他数据集也有类似命名的列，在第一列上表示医院id。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oo"><img src="../Images/e4a9a511d792bacd186735fee6bd6de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GC2W_kWeOw2Kp4Yp.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">前五行“及时有效的护理— Hospital.csv”</figcaption></figure><p id="259c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里需要注意的重要一点是，每个数据集都有不同的评分方法。让我们以及时有效的护理数据集为例。下图和上图显示了相同的行但不同的列。从上面可以看到，有多行具有相同的医院id。有多行是因为有许多衡量医院及时有效护理的指标。看下图。列<code class="fe nx ny nz nn b">measure_id</code>告诉我们<code class="fe nx ny nz nn b">score</code>列指的是哪个得分指标。例如，此处医院ID 10001的ED1测量值为255，ED2测量值为84。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi op"><img src="../Images/99bec89ce2a23504f2f633026e19f544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*idonmJyvimIhAzKI.png"/></div></div></figure><p id="b914" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">事实上，对于这个数据集，似乎有21种独特的方法来评价医院及时有效的护理。如果有十家医院，将有210行。我们将在第三节中尝试合并来自不同数据集的所有这些不同的度量。然后，我们将使用合并后的数据集训练我们的随机森林模型来预测我们的Ys。我们后来在合并的数据集中得到了101列，这些都是来自各种评估医院的方法。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oq"><img src="../Images/d0ca311d5c137d04164d1f231b47cf1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WTOuPS02CPTEGN_n.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">用于及时有效护理的唯一测量id</figcaption></figure><h1 id="adbc" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">三。特征提取/数据清理</h1><p id="e776" class="pw-post-body-paragraph jq jr it js b jt nd jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj nh kl km kn im bi translated">这部分相当繁琐，因为有很多列需要合并。然而，我没有包括执行这个过程的所有代码，所以浏览这一部分应该相对容易。代码都在我的GitHub库中，就在本文标题的下面。</p><p id="5878" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们从提取<em class="oa">m</em>T3】的特征开始这个文件包含了每家医院的及时有效的护理措施，有21种不同的措施。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div class="gh gi or"><img src="../Images/812a535ec41b8f5f4a5f5ac94ea716f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/0*0VOeZq8ajRAGckQ3.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">21种不同的措施与TPS</figcaption></figure><p id="db18" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图显示了每个不同的测量值与<code class="fe nx ny nz nn b">tps</code>测量值的对比。看一眼就知道几乎没有一个是线性特征。我们可以在多维空间中对数据进行聚类，以执行线性/非线性回归，但我们在这里将使用随机森林方法。许多其他机器学习算法也将对该数据集执行。无论如何，如果我们回头看上面的图，我们可以看到一些功能是无用的，以至于它们可能对我们的模型有害。随机森林模型会忽略不提供信息的列，但是无用的特征仍然会增加模型知道它们无用的计算时间。因此，我们不会从一开始就包含无用的特性。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div class="gh gi os"><img src="../Images/d405cd9148338fe4a5e3cac82865d35a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*iYeDbbpECALVuk5o.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">删除无用的列</figcaption></figure><p id="9e85" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从支线剧情中，我们看到第三支线剧情(在支线剧情矩阵中的(1，3)处的剧情)显示了一条直线。这说明了什么？直线意味着所有的x值都是常数。其实所有的值都是零。因此，我们将从数据集中删除这个无用的列。我们还排除了以下位置的其他测量值:(2，1)、(2，3)、(3，5)、(5，1)。子情节是从左到右、从上到下录制的，所以按小节顺序分别是6、8、15、21。我们说这些措施没用，是因为大部分点都是零。它们提供的信息少得多，对我们的模型几乎没有帮助。这些措施几乎不会减少我们的模型后来的残差。删除无用的列后，full_XY合并数据集中现在只剩下有用的列，如下所示。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ot"><img src="../Images/a468e1df4a16b9a12b26bc5a08acd217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pPIQ6nK35s8wrRZt.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">“full_XY”数据集</figcaption></figure><p id="4490" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在转向一个新的数据集。现在我们来看一下<code class="fe nx ny nz nn b">Medicare Hospital Spending per Patient — Hospital.csv</code>数据集。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/851bda202c23035f359fedb4ee6f8aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/0*1y2NZ3_zBiCtPK1x.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">医疗保险数据集已清理</figcaption></figure><p id="e8bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">只有199家医院可用于医疗保险数据，并且只有一种评分方法。我们忽略了整个数据集。</p><p id="cce0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于大多数其他数据集，我们执行与及时有效的护理数据相同的程序。我们提取有用的特征，并将它们合并到主数据集中。</p><p id="4661" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个例外是<code class="fe nx ny nz nn b">Ambulatory Surgical Measures-Facility.csv</code>数据集。我们必须忽略整个数据集，因为它的医院id和名称与其他数据集不匹配。</p><p id="a745" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后一步，我们将清理后的数据集作为新的。csv文件。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ov"><img src="../Images/7f3107184a907c805761593340e589b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*En6CAF9HttjpXu3Y.png"/></div></div></figure><h1 id="e1cb" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">四。随机森林模型的拟合与调整</h1><h1 id="e320" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">拟合随机森林模型</h1><p id="ceb8" class="pw-post-body-paragraph jq jr it js b jt nd jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj nh kl km kn im bi translated">构建模型的代码在GitHub的一个单独的Jupyter笔记本文件中。我强烈建议你先看看GitHub中的原始文件。我们将使用已经调整的参数来拟合随机森林模型。我将在本节的后面告诉您更多关于调优的内容。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ow"><img src="../Images/9278e674d8b168c3862944fe5dabf720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZZK0c8ecz3mmTCQV.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">使用Scikit-Learn的随机森林函数</figcaption></figure><p id="3cd1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将为随机森林的一次运行定义我们的函数。第4行和第5行将所有解释变量划分为X，将我们试图预测的列划分为y。这是第9行的一行代码。我们设置<code class="fe nx ny nz nn b">test_set=0.05</code>，这意味着95%的数据将是训练数据，5%将是测试数据。由于我们随机设置了<code class="fe nx ny nz nn b">random_state</code>，所以每次运行都会形成不同的训练和测试数据子集。然而，你可以通过设置一个额外的<code class="fe nx ny nz nn b">shuffle=false</code>选项来关闭<code class="fe nx ny nz nn b">random_state</code>，这将完全忽略你在<code class="fe nx ny nz nn b">random_state</code>选项中输入的任何内容。保持一定数量的<code class="fe nx ny nz nn b">random_state</code>(即<code class="fe nx ny nz nn b">random_state = 5</code>)可以让你随机洗牌，但是每次运行都保持顺序。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ox"><img src="../Images/90c8c77376e3cebdfe8cf87bc62fccd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IzXkrkIr26cDAMCn.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">从上图中截取的第11~15行</figcaption></figure><p id="7d9d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从第11行到第15行，我们建立一个模型并预测我们的测试集。<code class="fe nx ny nz nn b">max_depth </code>参数限制所有决策树的深度。<code class="fe nx ny nz nn b">n_estimator</code> <em class="oa"> </em>参数设置我们要从多少棵决策树中进行打包。这里我将重点介绍参数的调整。如果你不了解随机森林的基础知识，<a class="ae ko" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener" target="_blank">https://towardsdatascience . com/understanding-Random-Forest-58381 e 0602d 2</a>是了解基础知识的绝佳来源。</p><p id="1d16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测完我们的测试集后，我们用预测值(橙色)、实际值(蓝色)和误差值(绿色)构建一个图，如下图所示。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oy"><img src="../Images/29dd619cf75f745abaeaf52823dc363b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ug9B-vM6LGM6HcLS.png"/></div></div></figure><p id="f6bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测数字完全是随机的，以防你们任何人担心。然而，运行一次模型是不够的。我们必须做交叉验证。有些人认为我们不需要对随机森林进行交叉验证，但我强烈建议这样做，因为我们的训练/测试分割数据中可能存在偏差。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oz"><img src="../Images/d0c4d2dc3ebc693ba98b96b15966de1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fe2bk3x7OcDPLG-k.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">自举20次</figcaption></figure><p id="d984" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于这个例子，我们将不使用k-fold交叉验证，但是我们将使用bootstrapping。他们的结果几乎相似，但唯一的区别是交叉验证耗尽了数据集(使用数据集中的每个数据点至少一次作为训练数据，至少一次作为测试数据)。我们已经根据随机森林函数代码将测试/训练分割设置为随机的，因此我们必须多次运行该函数以进行引导。如果要做k重交叉验证或者其他的事情，就需要更改拆分部分(随机森林函数中的第7~9行)。然后，我们存储模型中的所有指标。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/7be3f168e41cc81475b6d5d0ab3aaf73.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/0*oeW5aojc5UfDr9D5.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">所有引导模型的平均指标</figcaption></figure><p id="c331" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们打印出所有自举模型的平均值，看看结果。如果你不熟悉上面的指标，我建议你去查一下。最容易也是最重要的一个解释就是MAE metric (Mean平均误差)，它表明我们每次预测，都有大约6.712的误差。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oy"><img src="../Images/1b5f189ead88820ba6ec306ae78f8793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Y0qqUYxt8ETrlPq9.png"/></div></div></figure><p id="448e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们对HCAHPS分数而不是<code class="fe nx ny nz nn b">tps</code>分数进行同样的分析，我们会得到这个结果。这个HCAHPS分数就是我在第一节中提到的分数，是我们要预测的第二个评级标准。分数的分布似乎与<code class="fe nx ny nz nn b">tps</code>大相径庭。我们在分布中有一个更小的方差。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi pb"><img src="../Images/12f7129b9704b3ed037f69eeaf0b4044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4f234Z87MwfaVBq-.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk translated">结果表</figcaption></figure><p id="c936" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">HCAHPS测量中较小的方差使得我们的MAE值相对小于预测的<code class="fe nx ny nz nn b">tps</code>值，但这并不意味着我们擅长预测HCAHPS分数。仅用HCAHPS评分的纯平均值进行预测，对HCAHPS给出了类似的预测结果。这意味着HCAHPS分数本身不包含太多信息。</p></div><div class="ab cl kp kq hx kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="im in io ip iq"><h1 id="5535" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">调整随机森林模型</h1><p id="04d2" class="pw-post-body-paragraph jq jr it js b jt nd jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj nh kl km kn im bi translated"><strong class="js iu">限制最大深度是我在五个大项目中使用随机森林所学到的最重要的事情。这叫做<strong class="js iu">修剪</strong>。随机森林非常容易过度拟合，因为在最坏的情况下，分支可能会分裂到完全过度拟合到单个值的终端节点(也称为叶节点)。Scikit-Learn的默认参数尽可能地防止用户试图过度拟合模型。然而，<code class="fe nx ny nz nn b">max_depth</code>选项默认设置为最大值。你必须修剪你的树，让它更适合你。不修剪该树将使其更适合您的训练数据。然而，对于测试数据，您的准确性指标将会受到影响。</strong></p><p id="632e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么，你如何修剪一棵树呢？很简单。让我们比较一下<code class="fe nx ny nz nn b">max_depth=8</code>和<code class="fe nx ny nz nn b">max_depth=40</code>。对于<code class="fe nx ny nz nn b">max_depth=8</code>，我们得到MAE预测<code class="fe nx ny nz nn b">tps</code>的6.7左右。不过，<code class="fe nx ny nz nn b">max_depth=40</code>给出的是6.8左右。在我们的例子中，这是一个稍微好一点的结果。</p><p id="27dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而<strong class="js iu">，数据的方差越大，修剪就变得越重要。</strong><code class="fe nx ny nz nn b">tps</code>与大多数数据集相比，评级值的差异并不大。一个极端的情况是数据集有许多高异常值，这些异常值有足够的数据点，会使随机森林过拟合。我的经验是挖掘数据。含金量高的景点不多。对于该数据集，将最大深度削减至12会显著降低MAE指标。</p><p id="0089" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其他参数呢？我说第二个最重要的是<code class="fe nx ny nz nn b">n_estimator</code> <em class="oa"> </em>这是要做装袋的决策树的数量。对于较大的数据集，您可能希望增加估计量。这种方法很容易调整，因为估计器数量越多，情况越糟。你只需要达到最低值，此时精度不再变高。我见过很多人对<code class="fe nx ny nz nn b">max_features</code>感到困惑。这个参数主要是为了计算速度。我建议将其作为默认选项，除非您的数据集非常大，并且模型需要很长时间才能运行。</p><h1 id="2677" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">动词 （verb的缩写）结论/考虑</h1><p id="cee9" class="pw-post-body-paragraph jq jr it js b jt nd jv jw jx ne jz ka kb nf kd ke kf ng kh ki kj nh kl km kn im bi translated">关于我们经历过的模式，有很多要考虑的。以下是重点。</p><ol class=""><li id="52d0" class="mk ml it js b jt ju jx jy kb mm kf mn kj mo kn mp mq mr ms bi translated">我们的模型只偏向于有TPS措施的医院。</li><li id="b076" class="mk ml it js b jt mt jx mu kb mv kf mw kj mx kn mp mq mr ms bi translated">我们的模型的一个强大部分是，我们将所有NA值设为0，随机森林将它们分支为不可用。这可能导致对0和实际值之间的几个分界点的奇怪解释。但是，我们仍然会获得比排除所有n a行更好的结果。</li><li id="49eb" class="mk ml it js b jt mt jx mu kb mv kf mw kj mx kn mp mq mr ms bi translated">我们可以分析异常值。(哪些医院很难预测？)</li><li id="96d2" class="mk ml it js b jt mt jx mu kb mv kf mw kj mx kn mp mq mr ms bi translated">我们可以利用特征重要性。(我将在第六节中作为一个额外的部分介绍这一点。)</li></ol><p id="2f89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一条很长的路，但是我希望您从这篇文章中获益匪浅。如有任何关注，请留言评论，我会尽量及时回答。谢谢你。</p><h1 id="026b" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">不及物动词特征重要性</h1><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi pc"><img src="../Images/847a61e829befbcb6c37fb750692754a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E7NzwUuwztDwGuny.png"/></div></div></figure><p id="d540" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过调用<code class="fe nx ny nz nn b">regressor.feature_importances_</code>,其中回归量是我们拟合的模型，我们可以获得一个具有所有特性重要性的numpy数组。如果我们将这些值从最高到最低排序，我们会得到下图。</p><figure class="ni nj nk nl gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oy"><img src="../Images/df97f75fab56ff5606f6bcc7e636e05c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OhzcFVqZXwvkmvUj.png"/></div></div></figure><p id="9b15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，有几个点对于预测总的绩效得分非常重要。如果我们使用full_XY数据集的99个测量值中的20或30个最重要的测量值，我们可以获得几乎相同的精度。通过1-MAE/Average度量，我们在30个最重要的度量上损失了大约1%的准确性，在20个最重要的度量上损失了2%的准确性。但是，注意<strong class="js iu">任何共线的点都可以代替那些重要的点</strong>。理解这一点至关重要。如果我们从该图中排除最重要的列，最共线的列将取代它的位置，并显示为新的最重要的点。我们如何计算所有的共线点？可惜我不知道最好的方法。我通常会通过数百个模型来找到所有共线的点。如果只有几列，我们需要尝试的组合就只有十几种。然而，对于这个数据集，我们有99列来测试所有的组合，这是很多的。对于线性回归，我们可以使用许多措施，如VIF(方差膨胀因子)，但对于随机森林，它更具经验性。在<a class="ae ko" href="https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e" rel="noopener" target="_blank">https://towards data science . com/explaining-feature-importance-by-example-of-a-random-forest-d 9166011959 e</a>中给出了使用蛮力的各种方法。</p><h1 id="c181" class="kw kx it bd ky kz my lb lc ld mz lf lg lh na lj lk ll nb ln lo lp nc lr ls lt bi translated">七。额外资源</h1><blockquote class="pd pe pf"><p id="0239" class="jq jr oa js b jt ju jv jw jx jy jz ka pg kc kd ke ph kg kh ki pi kk kl km kn im bi translated"><strong class="js iu"><em class="it">Scikit-Learn RandomForestRegressor</em></strong><a class="ae ko" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank"><em class="it">https://Scikit-Learn . org/stable/modules/generated/sk Learn . ensemble . RandomForestRegressor . html</em></a></p><p id="3dad" class="jq jr oa js b jt ju jv jw jx jy jz ka pg kc kd ke ph kg kh ki pi kk kl km kn im bi translated"><strong class="js iu"> <em class="it">随机森林简介</em></strong><a class="ae ko" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener" target="_blank"><em class="it">https://towardsdatascience . com/understanding-Random-Forest-58381 e 0602d 2</em></a></p><p id="350d" class="jq jr oa js b jt ju jv jw jx jy jz ka pg kc kd ke ph kg kh ki pi kk kl km kn im bi translated"><strong class="js iu"> <em class="it">更多关于特征重要性</em></strong><em class="it"/><a class="ae ko" href="https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e" rel="noopener" target="_blank"><em class="it">https://towardsdatascience . com/explaining-Feature-Importance-by-example-of-a-random-forest-d 9166011959 e</em></a></p></blockquote></div></div>    
</body>
</html>