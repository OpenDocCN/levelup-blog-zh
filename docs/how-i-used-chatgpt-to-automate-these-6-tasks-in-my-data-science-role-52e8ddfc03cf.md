# åœ¨æˆ‘çš„æ•°æ®ç§‘å­¦è§’è‰²ä¸­ï¼Œæˆ‘å¦‚ä½•ä½¿ç”¨ ChatGPT æ¥è‡ªåŠ¨åŒ–è¿™ 6 é¡¹ä»»åŠ¡

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/how-i-used-chatgpt-to-automate-these-6-tasks-in-my-data-science-role-52e8ddfc03cf>

## ChatGPT å°±åƒ Googleï¼ŒStackOverflow å’Œ Readthedocs çš„æ€»å’Œ

![](img/1f81c6f66889c50555cb594f73c9d528.png)

è©¹å§†æ–¯Â·aÂ·è«å°”çº³å°”åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

ä½ å¯èƒ½å¬è¯´è¿‡ ChatGPTã€‚

è¿™æ˜¯ä¸€ä¸ªæ–°çš„äººå·¥æ™ºèƒ½èŠå¤©æœºå™¨äººï¼Œç”± [OpenAI](https://openai.com/) å¼€å‘ï¼Œè¿™æ˜¯ GPT-3 èƒŒåçš„åŒä¸€å®¶å…¬å¸ï¼ŒDALLã€‚E2ï¼Œä»¥åŠå…¶ä»–ç–¯ç‹‚çš„äº§å“ã€‚

ChatGPT çœŸæ˜¯æ£’æäº†ã€‚è¿™å’Œæˆ‘ä»¥å‰ç”¨è¿‡çš„èŠå¤©æœºå™¨äººå®Œå…¨ä¸åŒã€‚å®ƒå¯¹å„ç§è¯é¢˜äº§ç”Ÿè¯¦ç»†è€Œå…¨é¢çš„ç­”æ¡ˆçš„èƒ½åŠ›ä»¤äººéš¾ä»¥ç½®ä¿¡ã€‚ä¾‹å¦‚ï¼Œè¿™ä¸ªå·¥å…·å¯ä»¥å›ç­”å“²å­¦ã€æ•°å­¦æˆ–è®¡ç®—æœºç§‘å­¦ä¸­çš„æŠ€æœ¯é—®é¢˜ã€‚å®ƒå¯ä»¥é—²èŠï¼Œå†™å…³äºæœºå™¨å­¦ä¹ çš„è¯—æ­Œ(ç”¨ rimesï¼)ï¼Œæç¬‘ï¼Œç”šè‡³æ”¹å˜å…¶å†™ä½œé£æ ¼ã€‚

ä½†æ˜¯ ChatGPT åœ¨å¦ä¸€ä¸ªé¢†åŸŸä¹Ÿå¾ˆå‡ºè‰²ï¼Œè¿™ä¸ªé¢†åŸŸç‰¹åˆ«æœ‰è¶£:**ç¼–å†™å’Œè§£é‡Šä»£ç ã€‚**

> åœ¨ ***è¿™ç¯‡å¸–å­é‡Œï¼Œæˆ‘ä¼šç”¨ä¸€äº›æ¶µç›–æœºå™¨å­¦ä¹ å’Œè½¯ä»¶å·¥ç¨‹çš„ç¼–ç¨‹é—®é¢˜æ¥æŒ‘æˆ˜ ChatGPTã€‚
> æˆ‘ä¼šè®©å®ƒå†™ä¸€äº›æˆ‘åœ¨å·¥ä½œä¸­ç»å¸¸ç”¨åˆ°çš„ä»£ç ç‰‡æ®µå’Œå‡½æ•°ï¼Œçœ‹çœ‹å®ƒèƒ½ä¸èƒ½æŠŠå®ƒä»¬è‡ªåŠ¨åŒ–ã€‚***

å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘éƒ½ä¼šä»¥äº¤äº’å¼ GIF çš„å½¢å¼æä¾› ChatGPT çš„ç­”æ¡ˆä»¥åŠå®ƒç”Ÿæˆçš„ä»£ç ã€‚

è®©æˆ‘ä»¬çœ‹ä¸€çœ‹ğŸ‘€

> æ–°åˆ°ä¸­ï¼Ÿä½ å¯ä»¥æ¯æœˆè®¢é˜… 5 ç¾å…ƒï¼Œè§£é”æˆ‘å†™çš„ä¸é™æ•°é‡çš„å…³äºç¼–ç¨‹ã€MLOps å’Œç³»ç»Ÿè®¾è®¡çš„æ–‡ç« ï¼Œä»¥å¸®åŠ©æ•°æ®ç§‘å­¦å®¶(æˆ– ML å·¥ç¨‹å¸ˆ)ç¼–å†™æ›´å¥½çš„ä»£ç ã€‚

[](https://ahmedbesbes.medium.com/membership) [## åŠ å…¥æˆ‘çš„ä»‹ç»é“¾æ¥åª’ä½“-è‰¾å“ˆè¿ˆå¾·è´æ–¯

### é˜…è¯» Ahmed Besbes çš„æ¯ä¸€ä¸ªæ•…äº‹(ä»¥åŠåª’ä½“ä¸Šæˆåƒä¸Šä¸‡çš„å…¶ä»–ä½œå®¶)ã€‚æ‚¨çš„ä¼šå‘˜è´¹ç›´æ¥æ”¯æŒâ€¦

ahmedbesbes.medium.com](https://ahmedbesbes.medium.com/membership) 

# **1 â€”åˆ›å»ºä¸€ä¸ª FastAPI ç«¯ç‚¹ï¼Œä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹æœåŠ¡**

å½“æˆ‘éœ€è¦ä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹æœåŠ¡æ—¶ï¼Œæˆ‘çš„é¦–é€‰ web æ¡†æ¶è‚¯å®šæ˜¯ [FastAPI](https://fastapi.tiangolo.com/) ã€‚ç„¶è€Œï¼Œå½“æˆ‘å†™åŸºæœ¬è·¯çº¿æ—¶ï¼Œæˆ‘æ€»æ˜¯å¿˜è®°è¯­æ³•ã€‚

ChatGPT å¯ä»¥åˆ·æ–°æˆ‘çš„è®°å¿†:ä¸‹é¢æ˜¯å½“æˆ‘è¦æ±‚å®ƒåˆ›å»ºä¸€ä¸ªé¢„æµ‹ç«¯ç‚¹æ—¶å®ƒç”Ÿæˆçš„å†…å®¹ã€‚

![](img/a32b67de752b21eb24878bea612e892b.png)

ä½œè€… GIF

ä¸é”™å§ï¼Ÿå®ƒä¸ä»…èƒ½æ­£ç¡®åœ°ç”Ÿæˆ API ä»£ç ï¼Œè¿˜èƒ½å¯¹å…¶è¿›è¡Œæ³¨é‡Šå¹¶ä¸¾ä¾‹è¯´æ˜ã€‚

å®ƒç”šè‡³ä½¿ç”¨ Pydantic è¿›è¡Œé”®å…¥å’Œè¾“å…¥éªŒè¯ã€‚

è¿™æ˜¯ä»£ç ã€‚å½“ç„¶ï¼Œæ‚¨å¯ä»¥æ ¹æ®æ‚¨çš„ç”¨ä¾‹æ¥è°ƒæ•´å®ƒã€‚

```
# Install FastAPI
!pip install fastapi

# Import necessary modules
from fastapi import FastAPI
from pydantic import BaseModel
import numpy as np
import joblib

# Load the trained machine learning model
model = joblib.load("model.pkl")

# Create a FastAPI app
app = FastAPI()

# Define the input schema for the endpoint
class Input(BaseModel):
    x1: float
    x2: float
    x3: float
    x4: float

# Define the endpoint
@app.post("/predict")
def predict(input: Input):
    # Use the model to make predictions
    prediction = model.predict(np.array([input.x1, input.x2, input.x3, input.x4]).reshape(1, -1))

    # Return the predictions in a JSON format
    return {"prediction": prediction[0]}
```

# 2 â€”ä½¿ç”¨ Python å’Œ Elasticsearch åˆ›å»ºæœç´¢å¼•æ“

å½“æˆ‘éœ€è¦å®ç°ä¸€ä¸ªæœç´¢å¼•æ“æ¥æŸ¥è¯¢æ–‡æœ¬æ•°æ®æ—¶ï¼Œæˆ‘é€šå¸¸ä¾é  [Elasticsearch](https://www.elastic.co/guide/index.html) ã€‚

ä¸ºäº†èƒ½å¤Ÿä½¿ç”¨ Elastisearchï¼Œå¿…é¡»é¦–å…ˆåˆ›å»ºä¸€ä¸ªç´¢å¼•å’Œä¸€ä¸ªæ˜ å°„ã€‚

è€Œä¸æ˜¯æµè§ˆæ–‡æ¡£(å†æ¬¡ï¼)è¦äº†è§£è¿™äº›å¯¹è±¡æ˜¯å¦‚ä½•å®šä¹‰å’Œåˆ›å»ºçš„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ ChatGPT å¯¹æ­¤èƒ½è¯´äº›ä»€ä¹ˆ:

![](img/61a43c0cd8a260852ede561ff4cecc7b.png)

ä½œè€… GIF

ä¸å‡ºæ‰€æ–™ï¼Œæ–‡æ¡£å’Œç¤ºä¾‹éƒ½ç›´æˆªäº†å½“ã€‚

ä¸‹é¢æ˜¯ç”Ÿæˆçš„ä»£ç :

```
from elasticsearch import Elasticsearch

# Create an Elasticsearch client
es = Elasticsearch()

# Index a document with an ID of 1
es.index(index="my_index", doc_type="my_type", id=1, body={"name": "John Doe", "age": 34})

# Perform a search query
results = es.search(index="my_index", doc_type="my_type", body={"query": {"match": {"name": "John"}}})

# Print the results
print(results)
```

# 3-ä½¿ç”¨ PyTorch è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¯¹å›¾åƒè¿›è¡Œåˆ†ç±»

å½“æˆ‘éœ€è¦è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘æ€»æ˜¯ä»ä»¥å‰çš„é¡¹ç›®ä¸­å¤åˆ¶ç²˜è´´æ ·æ¿ä»£ç ã€‚

é—® ChatGPT è¿™ä¸ªä¸æ˜¯æ›´å¥½å—ï¼Ÿ

![](img/28ff2b28c38f376117a1b3d46f9a4287.png)

ä½œè€… GIF

äº§ç”Ÿçš„ä»£ç å‡ ä¹æ˜¯å®Œç¾çš„:å‡ºäºæŸç§åŸå› ï¼ŒChatGPT åœæ­¢åœ¨å‰è¿›é˜¶æ®µï¼Œæ²¡æœ‰ä½¿ç”¨æ¸å˜æ›´æ–°æƒé‡ã€‚

æœ‰è¶£çš„æ˜¯ï¼Œè®­ç»ƒä¸­ä½¿ç”¨çš„å‚æ•°å€¼(å­¦ä¹ ç‡ã€æ—¶æœŸæ•°ã€å†…æ ¸æ•°å’Œå†…æ ¸å¤§å°)æ˜¯çœŸå®çš„ã€‚

ä»£ç :

```
# Import necessary libraries and modules
import torch
import torchvision
from torchvision import datasets, transforms

# Define hyperparameters
num_classes = 10
learning_rate = 0.001
num_epochs = 10

# Load and transform the dataset
train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor())
test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())

# Define the network architecture
class ConvNet(torch.nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = torch.nn.Linear(7*7*32, num_classes)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out

# Initialize the network and specify the loss function and optimization algorithm
model = ConvNet()
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Train the network
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_dataset):
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
```

# 4-ä¸º NLP ä»»åŠ¡è®­ç»ƒ XGBoost æ¨¡å‹

è®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ XGBoost æ„å»ºæ–‡æœ¬åˆ†ç±»å™¨æ¥æ£€æŸ¥ ChatGPT æ˜¯å¦èƒ½å¤Ÿå¯¹æ–‡æœ¬æ•°æ®æ‰§è¡Œç‰¹å¾å·¥ç¨‹ã€‚

åœ¨ä¸‹é¢çš„å“åº”ä¸­ï¼Œå®ƒä½¿ç”¨äº† Tfidf çŸ¢é‡å™¨ã€‚è¿˜ä¸é”™ï¼

![](img/faca7cc7072b07a2c1b0c92950088b2e.png)

ä½œè€… GIF

æˆ‘æƒ³çŸ¥é“å®ƒæ˜¯å¦å¯ä»¥æ”¹å˜å®ƒçš„ç­”æ¡ˆå¹¶ä½¿ç”¨å•è¯åµŒå…¥ğŸ¤”ã€‚

ä»£ç :

```
 import xgboost as xgb
from sklearn.feature_extraction.text import TfidfVectorizer

# Define the data and the labels
data = ["this is a sample text", "xgboost is a powerful tool", "this is another example"]
labels = [0, 1, 0]

# Extract features using a TF-IDF vectorizer
vectorizer = TfidfVectorizer()
features = vectorizer.fit_transform(data)

# Convert the features to a dense matrix
features = features.toarray()

# Train the xgboost model
model = xgb.XGBClassifier()
model.fit(features, labels)
```

# 5-ä½¿ç”¨ MLflow è·Ÿè¸ªæœºå™¨å­¦ä¹ å®éªŒ

å½“æˆ‘è¿è¡Œä¸åŒçš„æœºå™¨å­¦ä¹ å®éªŒå¹¶æƒ³è¦æ¯”è¾ƒå®ƒä»¬æ—¶ï¼Œæˆ‘é€šå¸¸ä¼šä½¿ç”¨ [MLflow](https://mlflow.org/) åœ¨ä¸­å¤®æœåŠ¡å™¨ä¸­è·Ÿè¸ªå®ƒä»¬ã€‚

ä»¥ä¸‹æ˜¯æˆ‘ä¼šå¤šæ¬¡é‡å¤ä½¿ç”¨çš„ç¡®åˆ‡ç‰‡æ®µã€‚(è°¢è°¢ ChatGPTğŸ™)

![](img/4c837a9840d67f50c04b8c3790455deb.png)

ä½œè€… GIF

ä»£ç :

```
import mlflow
import mlflow.sklearn

mlflow.start_run(experiment_id="my_experiment")

mlflow.log_param("param1", 5)
mlflow.log_param("param2", "value2")

# Train a model
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()
model.fit(x_train, y_train)

# Log model as artifact
mlflow.sklearn.log_model(model, "random-forest-model")

# Log metrics
mlflow.log_metrics("mse", mean_squared_error(y_test, model.predict(x_test)))
mlflow.log_metrics("mse", mean_absolute_error(y_test, model.predict(x_test))) 
```

# 6 â€”ç¼–å†™ä¸€ä¸ª GitHub åŠ¨ä½œï¼Œè‡ªåŠ¨éƒ¨ç½² FastAPI åº”ç”¨ç¨‹åº

å¦‚æœæ‚¨æ­£åœ¨å°†åº”ç”¨ç¨‹åºæ¨å‘ç”Ÿäº§ï¼Œé‚£ä¹ˆæ‚¨å¾ˆå¯èƒ½ä¾èµ–äºä¸€äº› CI/CD ç®¡é“æ¥è‡ªåŠ¨åŒ–å®ƒä»¬çš„éƒ¨ç½²ï¼Œæˆ–è€…åœ¨ä»£ç åº“ä¸Šè¿è¡Œä¸€å¥—é›†æˆæµ‹è¯•ã€‚

ä¸ºæ­¤ï¼Œæˆ‘é€šå¸¸ä½¿ç”¨ Github åŠ¨ä½œã€‚

ä»¥ä¸‹æ˜¯ ChatGPT å¯¹è¿™ä¸ªè¯é¢˜çš„çœ‹æ³•ã€‚

![](img/7834b94498df4cd118e3a6ff5fb6c994.png)

ä½œè€… GIF

ä»£ç :

```
name: Deploy FastAPI App

on:
  push:
    branches:
      - master

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - run: |
          python -m pip install -U pip
          pip install fastapi uvicorn
      - run: uvicorn main:app --host 0.0.0.0 --port 8080
      - uses: actions/deploy-to-azure@v1
        with:
          app-name: my-fastapi-app
          resource-group: my-resource-group
          package: .
```

# ç»“è®º

ChatGPT æä¾›äº†ä¼˜ç§€çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶æœ‰æœ›å¾ˆå¿«é›†æˆæ¯ä¸ªå¼€å‘äººå‘˜çš„å·¥å…·ç®±ã€‚

ç„¶è€Œï¼Œè¯·è®°ä½ï¼Œå®ƒè‚¯å®š(è¿˜)æ²¡æœ‰èƒ½åŠ›æ¨ç†æˆ–æä¾›å¤æ‚é—®é¢˜çš„ä¼˜åŒ–è§£å†³æ–¹æ¡ˆã€‚å¦‚æœå‡ºç°é—®é¢˜ï¼Œæ‚¨ä¸èƒ½ä¾é  ChatGPT æ¥ä¿®å¤æ‚¨çš„ç”Ÿäº§ä»£ç ã€‚

åœ¨æˆ‘çœ‹æ¥ï¼ŒChatGPT æ˜¯ä¸€ç§æµ“ç¼©çš„å¼€æ”¾çŸ¥è¯†ï¼Œä½ å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€ä»¥ä¸€ç§éå¸¸å¤æ‚çš„æ–¹å¼è¿›è¡ŒæŸ¥è¯¢ã€‚è¿™å¹¶ä¸æ„å‘³ç€ä½ ä¸èƒ½ç”¨å®ƒåšç–¯ç‹‚çš„äº‹æƒ…ã€‚è¿™å¹¶ä¸æ„å‘³ç€ä½ ä¹Ÿå¯ä»¥ç›²ç›®ä¾èµ–å®ƒã€‚

ç”¨ä½ æœ€å¥½çš„åˆ¤æ–­åŠ›å»é—®*æ­£ç¡®çš„*é—®é¢˜ã€‚

# æ–°åˆ°ä¸­ï¼Ÿæ‚¨å¯ä»¥æ¯æœˆè®¢é˜… 5 ç¾å…ƒï¼Œå¹¶è§£é”å„ç§ä¸»é¢˜çš„æ— é™æ–‡ç« (æŠ€æœ¯ã€è®¾è®¡ã€åˆ›ä¸šâ€¦â€¦)æ‚¨å¯ä»¥é€šè¿‡ç‚¹å‡»æˆ‘çš„æ¨èé“¾æ¥[æ¥æ”¯æŒæˆ‘](https://ahmedbesbes.medium.com/membership)

[](https://ahmedbesbes.medium.com/membership) [## åŠ å…¥æˆ‘çš„ä»‹ç»é“¾æ¥åª’ä½“-è‰¾å“ˆè¿ˆå¾·è´æ–¯

### é˜…è¯» Ahmed Besbes çš„æ¯ä¸€ä¸ªæ•…äº‹(ä»¥åŠåª’ä½“ä¸Šæˆåƒä¸Šä¸‡çš„å…¶ä»–ä½œå®¶)ã€‚æ‚¨çš„ä¼šå‘˜è´¹ç›´æ¥æ”¯æŒâ€¦

ahmedbesbes.medium.com](https://ahmedbesbes.medium.com/membership)