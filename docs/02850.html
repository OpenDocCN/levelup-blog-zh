<html>
<head>
<title>A simple introduction to semi-supervised learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">半监督学习的简单介绍</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/a-simple-introduction-to-semi-supervised-learning-e20b2fe29ca0?source=collection_archive---------11-----------------------#2020-04-07">https://levelup.gitconnected.com/a-simple-introduction-to-semi-supervised-learning-e20b2fe29ca0?source=collection_archive---------11-----------------------#2020-04-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="78dc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解并使用scikit</h2></div><p id="4fc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">半监督学习是一种结合有标记和无标记数据的分类方法。半监督学习的主要原因是缺乏标记数据，一旦标记过程昂贵且耗时。另一方面，有很多未标记的数据可用，但与它们没有太大关系<a class="ae lb" href="https://minds.wisconsin.edu/bitstream/handle/1793/60444/TR1530.pdf?sequence=1" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">【1】</strong></a>。冠状病毒数据的现状可以很好地描述这种情况，因为<strong class="kh ir">的标签取决于测试</strong>，而我们在一些国家(如<a class="ae lb" href="https://thehill.com/policy/international/americas/492644-coronavirus-cases-in-brazil-likely-12-times-higher-than" rel="noopener ugc nofollow" target="_blank">巴西</a>)只有很少的测试人员和大量未测试人员。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/1a8e714083735a31b6d38a1d508a4e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_Peo5ZfJtEOmbt8i9SLig.png"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk translated">克林特·王茂林在<a class="ae lb" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5631" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通常，当您没有足够的标记数据来使用监督学习解决问题时，替代方法是使用非监督学习。然而，一旦没有关于数据的先前信息(标签)，这种方法与许多假设一起工作，并且那些假设不总是代表真理<a class="ae lb" href="https://repositorio.unesp.br/handle/11449/191774" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">【2】</strong></a>。但是即使是少量的标记数据也可能包含非常重要的信息。这就是半监督学习的用武之地。</p><h1 id="0885" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">算法</h1><p id="7f09" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">想象一下一个分类器(例如SVM)，一个只有很少标记数据的训练集，和一个有很多未标记数据的数据集。目标是对整个数据集进行分类，但是我们的训练集太小了。为了避免这种情况，我们将提出以下策略:用所有已标记的数据进行训练，并预测所有未标记的数据。现在，使用一些度量标准，我们将对模型做出的最有信心的预测进行排名。让我们考虑离超平面距离最高的样本是最有把握的。那些最有把握的预测将不再是未标记集的一部分，而是将成为标记/训练集的一部分。然后使用新的训练集，我们再次预测整个数据集。重复该过程，直到没有未标记的样本留下。这种策略叫做自我训练，是最简单的半监督方法之一。</p><p id="1dd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有一堆半监督算法使用几种不同的方法。与自我训练相结合，其他常用的方法有基于图形的方法、协同训练、生成模型等。一些基于图的方法也非常容易理解，<a class="mp mq ep" href="https://medium.com/u/8002c1aed6e7?source=post_page-----e20b2fe29ca0--------------------------------" rel="noopener" target="_blank"> Vijini </a>在以下媒体出版物中明智地解释了<strong class="kh ir">标签传播算法</strong> ( <a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelPropagation.html" rel="noopener ugc nofollow" target="_blank">可在scikit-learn </a>获得):</p><div class="mr ms gp gr mt mu"><a href="https://towardsdatascience.com/label-propagation-demystified-cd5390f27472" rel="noopener follow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd ir gy z fp mz fr fs na fu fw ip bi translated">标签传播去神秘化</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">基于图的标签传播的简单介绍</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">towardsdatascience.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni lm mu"/></div></div></a></div><h1 id="7a9e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">使用Python进行半监督</h1><p id="00a9" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在，您对半监督学习有了一点了解，让我们使用古老的iris数据集，以便用scikit-learn测试标签传播算法。<strong class="kh ir">下面开发的代码在</strong> <a class="ae lb" href="https://github.com/caiocarneloz/sklearn-semi" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Github </strong> </a>上有。</p><p id="06bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不幸的是，scikit-learn上只有两种半监督算法。不过，你可以在Github上找到很多，只要找一下<a class="ae lb" href="https://github.com/topics/semi-supervised" rel="noopener ugc nofollow" target="_blank">“半监督”</a>标签。在我的硕士学位，我用Python编写了粒子竞争与合作算法，这是一种生物启发的半监督算法，由我的导师<a class="mp mq ep" href="https://medium.com/u/af19cb0d8900?source=post_page-----e20b2fe29ca0--------------------------------" rel="noopener" target="_blank"> Fabricio Breve </a>开发。你可以在这里找到关于这个算法<a class="ae lb" href="https://ieeexplore.ieee.org/document/5871621" rel="noopener ugc nofollow" target="_blank">的原始出版物，你也可以通过在</a><a class="ae lb" href="https://github.com/caiocarneloz/pycc" rel="noopener ugc nofollow" target="_blank"> Github </a>上克隆代码或者通过用PyPI安装包来使用它:</p><pre class="ld le lf lg gt nj nk nl nm aw nn bi"><span id="517b" class="no lt iq nk b gy np nq l nr ns">pip install pypcc</span></pre><p id="c73b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它的用法与scikit-learn算法的用法完全相同，Github存储库中有演示代码，可以随意使用。</p><h1 id="bf24" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">sci kit-学习</h1><p id="2998" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">为了测试scikit-learn上可用的半监督算法，我们首先需要安装sklearn包。所以使用PyPI，只需运行:</p><pre class="ld le lf lg gt nj nk nl nm aw nn bi"><span id="46f9" class="no lt iq nk b gy np nq l nr ns">pip install sklearn</span></pre><h2 id="c061" class="no lt iq bd lu nt nu dn ly nv nw dp mc ko nx ny me ks nz oa mg kw ob oc mi od bi translated">虹膜数据集</h2><p id="6cee" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">之后，我们需要虹膜数据集。我们可以使用sklearn的“数据集”模块来获得这个数据集，不需要下载任何文件。该数据集由150个涉及鸢尾属植物的样本组成。有3类，每类50个样品:刚毛藻、杂色藻和海滨藻。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="1b98" class="no lt iq bd lu nt nu dn ly nv nw dp mc ko nx ny me ks nz oa mg kw ob oc mi od bi translated">数据集目标</h2><p id="a2c0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">由于这个数据集是由带标签的样本组成的，我们将需要“取消标签”其中的一些来测试我们的半监督模型。下面的代码可以在我的<a class="ae lb" href="https://github.com/caiocarneloz/masksemi" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到并得到更好的解释。其目的是平等地取消每一类样本的标记。<strong class="kh ir">默认情况下，scikit-learn的半监督算法将“-1”视为无标签样本</strong>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/a8a4d5604e1ae5619ba1a5af25a9e70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jzcd89gp51hDBtCfuFCaCw.png"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@jruscello" rel="noopener ugc nofollow" target="_blank">杰西卡·鲁斯切洛</a>在<a class="ae lb" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5a6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“百分比”参数表示您想要的标记百分比。这意味着如果“百分比”等于0.05，则95%的数据集将是未标注的，5%将是已标注的。对于本例，标记数据的百分比将为5%。这样，每个班级将有2个带标签的样本(总共150个中的6个)。创建一个名为“utils.py”的文件，并粘贴这个掩码函数:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="ed32" class="no lt iq bd lu nt nu dn ly nv nw dp mc ko nx ny me ks nz oa mg kw ob oc mi od bi translated">主要功能</h2><p id="0a24" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">下一步是实例化<strong class="kh ir">标签传播</strong>模型，并使用该库中可用的大多数机器学习模型的相同语法来运行它。“拟合”函数不会像监督学习方法那样训练模型，因为该算法中没有训练步骤。但是，该函数将构建模型图，并准备标记过程所需的所有结构，该过程将由“预测”函数执行。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="c7aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行上面的代码后，我们已经得到了每个类的预测。为了评估这一点，因为这是一个分类问题，我们可以使用一个<a class="ae lb" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>。有必要注意这一步，因为带有预测的数组中有一些之前标记的样本(在本例中是5%)。我们不能认为这些都是正确标记的，所以最终的代码应该是这样的:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="8d62" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后可以保存在与“utils.py”相同的文件夹下，命名为“sklearn-semi.py”。现在你可以使用同样的结构，不仅使用sklearn算法，还可以使用你找到的任何其他半监督算法。</p><p id="07b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你学到了一些东西，感谢阅读。如有任何建议或问题，请随时通过这里或我的<a class="ae lb" href="https://www.linkedin.com/in/caiocarneloz/" rel="noopener ugc nofollow" target="_blank"> Linkedin个人资料</a>联系我。再见！</p><h1 id="8bbe" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="52e5" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">[1]朱晓军，<a class="ae lb" href="https://minds.wisconsin.edu/bitstream/handle/1793/60444/TR1530.pdf?sequence=1" rel="noopener ugc nofollow" target="_blank">半监督学习文献综述</a> <em class="og"> ( </em> 2005)，威斯康星大学麦迪逊分校计算机科学系</p><p id="01ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Caio Carneloz,<a class="ae lb" href="https://repositorio.unesp.br/handle/11449/191774" rel="noopener ugc nofollow" target="_blank"> 使用粒子间竞争与合作的磁共振成像辅助诊断阿尔茨海默病 </a> (2019), 保利斯塔州立大学 - UNESP</p></div></div>    
</body>
</html>