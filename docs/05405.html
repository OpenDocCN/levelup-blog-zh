<html>
<head>
<title>Building U-Net architecture for biomedical image segmentation.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建用于生物医学图像分割的U-Net体系结构。</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-u-net-architecture-for-biomedical-image-segmentation-4c53fc70d928?source=collection_archive---------7-----------------------#2020-08-25">https://levelup.gitconnected.com/building-u-net-architecture-for-biomedical-image-segmentation-4c53fc70d928?source=collection_archive---------7-----------------------#2020-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="deeb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">U-Net架构是使用全卷积网络构建的，其设计方式可以在医学成像中提供更好的分割结果。它最初是由Olaf Ronneberger，Philipp Fischer和Thomas Brox在2015年设计的，用于处理生物医学图像[<a class="ae ko" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1505.04597.pdf</a>]。卷积神经网络通常用于图像分类问题，但在生物医学案例中，我们也必须定位异常区域。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div></figure><p id="c12d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它呈“U”形。U-Net架构是对称的，其功能有点类似于自动编码器。它可以缩小为三个主要部分——收缩(下采样)路径、瓶颈和扩展(上采样)路径。在自动编码器中，神经网络的编码器部分将输入压缩成潜在空间表示，然后解码器从压缩或编码的表示中构造输出。但是有一个细微的区别，与常规的编码器-解码器结构不同，这两个部分没有解耦。跳过连接用于将细粒度信息从分析路径的低层传输到合成路径的高层，因为需要该信息来生成具有精确细粒度细节的重建。</p><h1 id="7f42" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">收缩路径</h1><p id="60d8" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">收缩路径由四个块组成，每个块包括:</p><ul class=""><li id="b2a7" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn mj mk ml mm bi translated">3x3卷积层+激活函数(relu) [Dropout可选]</li><li id="11ab" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">3x3卷积层+激活函数(relu) [Dropout可选]</li><li id="3762" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">2x2最大池层</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/63486992f1c0a684a14a5d95322f7361.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*f79cNR_d1C_SXDvhnTU5nQ.png"/></div></figure><p id="fdb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个块有两个卷积层和一个最大池层。然后，通道数量切换到64。此外，使用(3，3)的内核大小，这将维度从572x572 → 570x570→568x568进行更改。MaxPool2D层然后将维度减少到284x284，并且该过程重复三次以上，直到我们到达瓶颈部分。</p><h1 id="4dd1" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">扩展路径</h1><p id="1132" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">扩展路径也由4个块组成。每个模块都包括:</p><ul class=""><li id="999a" class="me mf it js b jt ju jx jy kb mg kf mh kj mi kn mj mk ml mm bi translated">用步长2反卷积或上采样2D层</li><li id="dc6f" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">图像与收缩路径中的相应图像连接在一起</li><li id="5c02" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">3x3卷积层+激活函数【漏失可选】</li><li id="09a3" class="me mf it js b jt mn jx mo kb mp kf mq kj mr kn mj mk ml mm bi translated">3x3卷积层+激活函数【漏失可选】</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/be4c8b2d84f94859211057e39a8d5cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*MCTVYLEuKdWm7g3i72-rYQ.png"/></div></figure><p id="b0d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该图像与相应的图像连接，并生成尺寸为56×56×1024的图像。这个过程之后是一组卷积层，最后一个Conv2D层有一个大小为1x1的滤波器。</p><h1 id="bd33" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">用Tensorflow和Keras构建U-Net</h1><p id="dde4" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">该过程的第一步是下载数据集。在这个例子中，我们将使用Kaggle的2018年数据科学碗，这是一个包含128x128个细胞核及其掩模图像的数据集。它可用于生物医学图像分割。如果您使用的是Kaggle API，可以通过以下方式下载:</p><pre class="kq kr ks kt gt mu mv mw mx aw my bi"><span id="665a" class="mz lc it mv b gy na nb l nc nd">!kaggle competitions download -c data-science-bowl-2018</span></pre><p id="3b11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入所需的包和工具。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="f6ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步是创建一个数据生成器函数，它加载数据，将图像调整到128x128的大小，并对它们进行归一化。我们的目标是创建一个数据生成器，返回图像及其遮罩。数据生成器的结构可能会有所不同，这取决于您的需求。在这之后，我们必须设置一些超参数，如图像大小、时期和批量大小。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="942e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以实现U-Net的架构，即收缩路径、瓶颈和扩展路径。</p><h1 id="71b6" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">U-Net模型与训练</h1><p id="6280" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">我们将重复down_block和up_block过程四次，然后是最后一个卷积层，它给出最终的预测掩码。在这种情况下，“Adam”优化器是优化器的一个好选择，并且“binary_crossentropy”可以用作我们的损失函数。模型编译成功后，查看它的摘要。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="4dd2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步是在相当数量的时期内训练模型并做出预测。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="883d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以将真实图像与它们的预测掩模进行比较。使用matplotlib来绘制这些图像，并更改cmap，这样我们就可以清楚地看到不同之处。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/ed4b4b8cc7e4d7ffe58da7d67d74c787.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*0bZoMAX1Ih9p0VMqmrVTWQ.png"/></div></figure><p id="67a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个例子只关注于构建U-Net模型。如果你想要这个分段任务的完整代码，你可以在我的<a class="ae ko" href="https://github.com/farazkhanfk7/dl-models/blob/master/UNet/UNet_Biomedical_segmentation.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub仓库中找到它。</a></p><h1 id="4a1f" class="lb lc it bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">优势</h1><p id="075d" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">U-Net的表现比FCN-8好得多。U-net是对称的，收缩和扩展路径之间的跳过连接将来自下采样路径的位置信息与上采样中的上下文信息相结合。此外，它没有任何密集层，这意味着不同的图像大小可以用作输入，因为在卷积层上学习的唯一参数是内核。U-Net模型可用于不同的图像集，结果相当令人满意。当我们只有几个训练样本时，像移位和旋转不变性这样的数据增强技术可以非常有助于教导网络期望的不变性和鲁棒性。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/a16c317bd6dc867b77ec5686f1df2e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C33zcR-Wz8R4-QL0y6UKsQ.png"/></div></div></figure><p id="eb2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">英特尔正在使用自己版本的U-Net来识别2D和3D模型中的肿瘤。英特尔的U-Net在BraTS(脑瘤分割)上接受培训，BraTS是医疗分割十项全能数据集的子集。你可以在这里查看他们的资料库<a class="ae ko" href="https://github.com/IntelAI/unet" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>