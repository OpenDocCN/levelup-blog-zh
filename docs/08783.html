<html>
<head>
<title>Transfer Learning On Images With Tensorflow 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Tensorflow 2的图像迁移学习</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/transfer-learning-on-images-with-tensorflow-2-3476ff5beb61?source=collection_archive---------5-----------------------#2021-06-04">https://levelup.gitconnected.com/transfer-learning-on-images-with-tensorflow-2-3476ff5beb61?source=collection_archive---------5-----------------------#2021-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5337" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">针对分类问题的图像迁移学习的演练示例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f811047afa9d6800bf9c3ec5a1889daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Pk7ewEfoWk9_gQfO.png"/></div></div></figure><p id="4b2c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本教程中，我们将为您提供一个示例，说明如何构建一个强大的神经网络模型，通过将ImageNet上训练的预训练模型视为基础模型，使用迁移学习对<strong class="kw iu">猫</strong>和<strong class="kw iu">狗</strong>的图像进行分类，然后我们将为我们的猫和狗分类模型训练额外的新层。</p><h1 id="6b66" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">数据</h1><p id="4126" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们将使用来自<a class="ae mn" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">狗与猫数据集</a>的600张图像样本，该数据集用于2013年的Kaggle比赛。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="8179" class="mt lr it mp b gy mu mv l mw mx">import tensorflow as tf<br/>from tensorflow.keras.models import  Sequential, Model, load_model<br/>from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout<br/>import numpy as np<br/>import os<br/>import pandas as pd<br/>from sklearn.metrics import confusion_matrix<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import seaborn as sns</span><span id="644f" class="mt lr it mp b gy my mv l mw mx"># load the train validation and test datasets<br/>images_train = np.load('data/images_train.npy') / 255.<br/>images_valid = np.load('data/images_valid.npy') / 255.<br/>images_test = np.load('data/images_test.npy') / 255.</span><span id="5b27" class="mt lr it mp b gy my mv l mw mx">labels_train = np.load('data/labels_train.npy')<br/>labels_valid = np.load('data/labels_valid.npy')<br/>labels_test = np.load('data/labels_test.npy')</span></pre><p id="f7b3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="a443" class="mt lr it mp b gy mu mv l mw mx">600 training data examples<br/>300 validation data examples<br/>300 test data examples</span></pre><p id="34c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">显示图像:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="59bf" class="mt lr it mp b gy mu mv l mw mx"># Display a few images and labels</span><span id="a38e" class="mt lr it mp b gy my mv l mw mx">class_names = np.array(['Dog', 'Cat'])</span><span id="08c6" class="mt lr it mp b gy my mv l mw mx">plt.figure(figsize=(15,10))<br/>inx = np.random.choice(images_train.shape[0], 15, replace=False)<br/>for n, i in enumerate(inx):<br/>    ax = plt.subplot(3,5,n+1)<br/>    plt.imshow(images_train[i])<br/>    plt.title(class_names[labels_train[i]])<br/>    plt.axis('off')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f448b92fa0521d945e1cda071009f946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1mSFGQFu8wcZpADW.png"/></div></div></figure><h1 id="65b7" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">加载基本模型</h1><p id="d3b7" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们的基本模型将是预培训的移动网络V2模型。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="0dca" class="mt lr it mp b gy mu mv l mw mx">base_model = tf.keras.applications.MobileNetV2()</span></pre><h2 id="aee3" class="mt lr it bd ls mz na dn lw nb nc dp ma ld nd ne mc lh nf ng me ll nh ni mg nj bi translated">使用预先训练的模型作为特征提取器</h2><p id="812f" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们将删除网络的最后一层，并用新的、未经训练的分类器层来代替它。我们将创建一个与MobileNetV2模型具有相同输入张量的新模型，并使用名为<code class="fe nk nl nm mp b">global_average_pooling2d_6</code>的层的输出张量作为模型输出。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="0d9b" class="mt lr it mp b gy mu mv l mw mx">feature_extractor = Model(inputs=base_model.input, <br/>                          outputs=base_model.get_layer('global_average_pooling2d_6').output)</span></pre><h1 id="a5d7" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">构建最终模型</h1><p id="1bc9" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">最终模型将:</p><ul class=""><li id="f7ec" class="nn no it kw b kx ky la lb ld np lh nq ll nr lp ns nt nu nv bi translated">从我们上面建立的特征提取器模型开始。</li><li id="7eae" class="nn no it kw b kx nw la nx ld ny lh nz ll oa lp ns nt nu nv bi translated">我们将添加32个单位的密集层和ReLU激活功能。</li><li id="00fe" class="nn no it kw b kx nw la nx ld ny lh nz ll oa lp ns nt nu nv bi translated">然后是退出层(50%)。</li><li id="0184" class="nn no it kw b kx nw la nx ld ny lh nz ll oa lp ns nt nu nv bi translated">最后一层是a 1神经元的密集层，激活函数是s形。</li></ul><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="3873" class="mt lr it mp b gy mu mv l mw mx">final_model = Sequential([<br/>                    feature_extractor,<br/>                    Dense(32, activation='relu'),<br/>                    Dropout(0.5),<br/>                    Dense(1, activation='sigmoid')<br/>                    ])</span><span id="1088" class="mt lr it mp b gy my mv l mw mx">final_model.summary()</span></pre><p id="7e24" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="4b73" class="mt lr it mp b gy mu mv l mw mx">Model: "sequential_1"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>model_1 (Model)              (None, 1280)              2257984   <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 32)                40992     <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 32)                0         <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 1)                 33        <br/>=================================================================<br/>Total params: 2,299,009<br/>Trainable params: 2,264,897<br/>Non-trainable params: 34,112</span></pre><h2 id="4ce5" class="mt lr it bd ls mz na dn lw nb nc dp ma ld nd ne mc lh nf ng me ll nh ni mg nj bi translated">冻结预训练模型的权重</h2><p id="afc5" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们将冻结预训练特征提取器的权重，以便只有我们添加的新层的权重会在训练期间改变。最后，我们将编译最终的模型。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="1091" class="mt lr it mp b gy mu mv l mw mx">final_model.layers[0].trainable = False</span><span id="fd65" class="mt lr it mp b gy my mv l mw mx">final_model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),<br/>              loss = 'binary_crossentropy',<br/>              metrics = ['acc'])</span><span id="c9f9" class="mt lr it mp b gy my mv l mw mx">final_model.summary()</span></pre><p id="93ee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="d1d8" class="mt lr it mp b gy mu mv l mw mx">Model: "sequential_1"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>model_1 (Model)              (None, 1280)              2257984   <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 32)                40992     <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 32)                0         <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 1)                 33        <br/>=================================================================<br/>Total params: 2,299,009<br/>Trainable params: 41,025<br/>Non-trainable params: 2,257,984</span></pre><p id="d6a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意<strong class="kw iu">不可训练</strong> <strong class="kw iu">参数</strong>如何从<strong class="kw iu"> 34，112 </strong>变为<strong class="kw iu"> 2，257，984 </strong></p><h1 id="f1e4" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">训练和评估模型</h1><p id="fbbc" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们将使用<code class="fe nk nl nm mp b">EarlyStopping.</code>训练模型</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="dc79" class="mt lr it mp b gy mu mv l mw mx">earlystopping = tf.keras.callbacks.EarlyStopping(patience=2)<br/>history_frozen_new_model = final_model.fit(images_train, labels_train, epochs=10, batch_size=32,<br/>                                                validation_data=(images_valid, labels_valid), <br/>                                                callbacks=[earlystopping])</span></pre><p id="ccf1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="0e8b" class="mt lr it mp b gy mu mv l mw mx">Train on 600 samples, validate on 300 samples<br/>Epoch 1/10<br/>600/600 [==============================] - 164s 273ms/sample - loss: 0.5017 - acc: 0.7517 - val_loss: 0.3234 - val_acc: 0.8467<br/>Epoch 2/10<br/>600/600 [==============================] - 155s 259ms/sample - loss: 0.3085 - acc: 0.8700 - val_loss: 0.2127 - val_acc: 0.8967<br/>Epoch 3/10<br/>600/600 [==============================] - 154s 256ms/sample - loss: 0.2082 - acc: 0.9083 - val_loss: 0.1998 - val_acc: 0.9167<br/>Epoch 4/10<br/>600/600 [==============================] - 153s 255ms/sample - loss: 0.2168 - acc: 0.9167 - val_loss: 0.1707 - val_acc: 0.9467<br/>Epoch 5/10<br/>600/600 [==============================] - 149s 249ms/sample - loss: 0.1765 - acc: 0.9367 - val_loss: 0.1550 - val_acc: 0.9500<br/>Epoch 6/10<br/>600/600 [==============================] - 152s 253ms/sample - loss: 0.2027 - acc: 0.9183 - val_loss: 0.1293 - val_acc: 0.9567<br/>Epoch 7/10<br/>600/600 [==============================] - 156s 260ms/sample - loss: 0.1557 - acc: 0.9350 - val_loss: 0.1828 - val_acc: 0.9300<br/>Epoch 8/10<br/>600/600 [==============================] - 155s 258ms/sample - loss: 0.1088 - acc: 0.9633 - val_loss: 0.1298 - val_acc: 0.9600</span></pre><h2 id="6be8" class="mt lr it bd ls mz na dn lw nb nc dp ma ld nd ne mc lh nf ng me ll nh ni mg nj bi translated">绘制学习曲线</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="d42c" class="mt lr it mp b gy mu mv l mw mx">plt.figure(figsize=(15,5))<br/>plt.subplot(121)<br/>try:<br/>    plt.plot(history_frozen_new_model.history['accuracy'])<br/>    plt.plot(history_frozen_new_model.history['val_accuracy'])<br/>except KeyError:<br/>    plt.plot(history_frozen_new_model.history['acc'])<br/>    plt.plot(history_frozen_new_model.history['val_acc'])<br/>plt.title('Accuracy vs. epochs')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Training', 'Validation'], loc='lower right')</span><span id="1c16" class="mt lr it mp b gy my mv l mw mx">plt.subplot(122)<br/>plt.plot(history_frozen_new_model.history['loss'])<br/>plt.plot(history_frozen_new_model.history['val_loss'])<br/>plt.title('Loss vs. epochs')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Training', 'Validation'], loc='upper right')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/ec6ae143e8d01431d88e69ea6d501988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JkUUniBRfrf138h5.png"/></div></div></figure><h2 id="683c" class="mt lr it bd ls mz na dn lw nb nc dp ma ld nd ne mc lh nf ng me ll nh ni mg nj bi translated">评估新模型</h2><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="fa29" class="mt lr it mp b gy mu mv l mw mx">new_model_test_loss, new_model_test_acc = final_model.evaluate(images_test, labels_test, verbose=0)</span><span id="1441" class="mt lr it mp b gy my mv l mw mx">print("Test loss: {}".format(new_model_test_loss))<br/>print("Test accuracy: {}".format(new_model_test_acc))</span></pre><p id="4b5c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="971b" class="mt lr it mp b gy mu mv l mw mx">Test loss: 0.10817002788186074<br/>Test accuracy: 0.9566666483879089</span></pre><p id="2e00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们得到了96%的准确率。还不错！</p><h1 id="fd5f" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">参考资料:</h1><p id="b091" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">[1] Coursera <a class="ae mn" href="https://www.coursera.org/learn/customising-models-tensorflow2/home/welcome" rel="noopener ugc nofollow" target="_blank">使用TensorFlow 2定制您的模型</a></p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="cfc0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最初发布于<a class="ae mn" href="https://predictivehacks.com/transfer-learning-on-images-with-tensorflow-2/" rel="noopener ugc nofollow" target="_blank">预测黑客</a></p></div></div>    
</body>
</html>