<html>
<head>
<title>Web Scraping 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网页抓取2.0</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/web-scraping-2-0-6600abca37de?source=collection_archive---------3-----------------------#2022-02-10">https://levelup.gitconnected.com/web-scraping-2-0-6600abca37de?source=collection_archive---------3-----------------------#2022-02-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b016314bcbeb73cbdcd43006604f2b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uNXt06GLrpBJXi-g"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@marjan_blan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Marjan Blan | @marjanblan </a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><div class=""/><div class=""><h2 id="f730" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用Scrapy进行顶层网络刮擦</h2></div><p id="dbdb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scrapy是一个用于web抓取的全栈python框架。是大规模网页抓取的工具。它有一个名为选择器的内置机制，用于从网络中提取数据。它是一个用python编写的开源免费使用的框架。它可以使用自动油门机构自动控制爬行速度。Scrapy在蜘蛛的帮助下从网站上抓取数据。它可以在几分钟内系统地爬遍整个网站。让我们来看看它的一些特性。</p><p id="85f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">功能:- </strong></p><ul class=""><li id="8dc0" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">CPU和内存使用率低。</li><li id="ce58" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">易于遵循的文档。</li><li id="78bf" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">可以同时报废多个网站。</li><li id="654d" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">异步的</li><li id="dafa" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">使用蜘蛛抓取网站。</li></ul><p id="ed58" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">安装:<code class="fe mi mj mk ml b">pip install scrapy</code></p><h1 id="9f7b" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">Scrapy的关键组件:-</h1><h2 id="6a60" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">1.粗糙的外壳</h2><p id="e3fa" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">Scrapy提供了一个交互式shell，可以用来非常快速地调试和测试您的抓取代码，而无需运行蜘蛛。蜘蛛是定义一个站点如何被废弃的类。scrapy shell是一种python shell，这意味着您也可以在shell中运行和测试您的python脚本。</p><p id="433d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它主要用于测试Xpath和CSS表达式，以检查它们是否正常工作。</p><p id="5e7a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">安装Scrapy后，您可以通过以下命令启动这个shell</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="7114" class="ne mn jj ml b gy od oe l of og">scrapy shell</span><span id="7fb8" class="ne mn jj ml b gy oh oe l of og">OR</span><span id="9586" class="ne mn jj ml b gy oh oe l of og">scrapy shell "URL"</span></pre><p id="1ef9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦外壳打开，你就可以用它从网上抓取任何数据。为了向web服务器发送一个爬行请求，我们使用了<code class="fe mi mj mk ml b">fetch(URL)</code></p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="8816" class="ne mn jj ml b gy od oe l of og">fetch(URL)</span><span id="abc5" class="ne mn jj ml b gy oh oe l of og">-----<br/>fetch('<a class="ae jg" href="http://books.toscrape.com/index.html" rel="noopener ugc nofollow" target="_blank">http://books.toscrape.com/index.html</a>')</span></pre><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="ab gu cl oi"><img src="../Images/498af8984c191f74ceecb6dc6ee58fc8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*vVJ7ORNjLwOb7TyRBLzJLA.png"/></div></figure><p id="1227" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">运行上述fetch命令后，您将会看到一条调试消息Crawled(200)表示您的网站正在运行，并且连接请求成功。</p><p id="37a5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在scrapy中，网站的源代码存储在一个变量<code class="fe mi mj mk ml b">response</code>中，你可以通过传递一个选择器表达式来提取数据。</p><p id="8158" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们用shell来抓取页面的标题—</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="647c" class="ne mn jj ml b gy od oe l of og">response.css("title")</span><span id="0747" class="ne mn jj ml b gy oh oe l of og">----------------<br/>[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;\n    All products | Books to S...'&gt;]</span></pre><p id="de2c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您运行该命令时，会返回一个选择器列表作为输出，其中包含您所请求的特定CSS元素。</p><p id="debf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们使用<code class="fe mi mj mk ml b">extract()</code>从列表中删除标签</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="a771" class="ne mn jj ml b gy od oe l of og">response.css("title").extract()</span><span id="6314" class="ne mn jj ml b gy oh oe l of og">---------------------------<br/>['&lt;title&gt;\n    All products | Books to Scrape - Sandbox\n&lt;/title&gt;'</span></pre><p id="8f56" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">返回的输出包含列表中的标签。为了从中获取文本，我们使用<code class="fe mi mj mk ml b">::text</code>，并在选择器表达式的末尾指定它。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="696f" class="ne mn jj ml b gy od oe l of og">response.css("title::text").extract()</span><span id="caf2" class="ne mn jj ml b gy oh oe l of og">-------------------------<br/>'\n    All products | Books to Scrape - Sandbox\n'</span></pre><p id="93ec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，为了更清楚地测试，我们可以使用strip()这样的字符串内置函数来删除空白，使用replace函数来替换某个关键字。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="97db" class="ne mn jj ml b gy od oe l of og">response.css('title::text').extract()[0].strip().replace('\n',' ')</span><span id="5592" class="ne mn jj ml b gy oh oe l of og">-----------------<br/>'All products | Books to Scrape - Sandbox'</span></pre><p id="9d6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们将尝试使用shell本身来抓取所有的书名。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/e4d579f6ed379df0bfe339fb466783a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*C7rNEVAFUmN4vf2f3FUB9w.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">第一本书标题的HTML片段</figcaption></figure><p id="e7c6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一本书的标题在anchor <code class="fe mi mj mk ml b">&lt;a&gt;</code>标签中，该标签是heading 3 <code class="fe mi mj mk ml b">&lt;h3&gt;</code>标签的子标签。为了抓取它，我们将首先瞄准&lt; h3 &gt;标签，然后瞄准&lt; a &gt;标签以从中获取文本。页面上所有标题的HTML结构都是一样的，所以如果我们抓取一个，所有标题都会自动抓取。抓取的数据存储在一个列表中。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="691b" class="ne mn jj ml b gy od oe l of og">response.css("h3 a::text").extract()</span></pre><p id="5b0c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的代码将从网页中抓取所有的书名。尝试自己使用字符串函数删除空白和换行符。</p><p id="238f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用这个shell来调试和测试大型抓取项目中的一些代码行。现在，让我们继续创建一个项目。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="a91f" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">2.项目结构</h2><p id="7057" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">Scrapy是一个完整的web抓取框架，遵循一个系统的方法来抓取数据。scrapy遵循一个适当的项目结构。</p><p id="62a7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用以下命令在scrapy中启动一个新项目。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="e9cf" class="ne mn jj ml b gy od oe l of og">scrapy startproject PROJECT_NAME</span><span id="cd27" class="ne mn jj ml b gy oh oe l of og">------<br/>scrapy startproject bookscraper</span></pre><p id="d777" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">运行该命令后，您的项目结构将被创建，如下所示</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/a4418823c71b69f442761c48165d3487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTGXJrS2KuacWOH7kEodsg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">项目结构</figcaption></figure><p id="6c4b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在你只需要关心一个文件夹，那就是<code class="fe mi mj mk ml b">spiders</code>文件夹，你会把所有的蜘蛛放在那里，这意味着以后会抓取代码。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="3c3a" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">3.第一只蜘蛛</h2><p id="ad33" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">打开spiders文件夹，创建一个名为<code class="fe mi mj mk ml b">book_scraper.py</code>的python文件并打开它。蜘蛛文件夹是你放置所有蜘蛛的地方。您可以创建多个抓取不同内容的蜘蛛，并将它们连接在一起。</p><p id="d17d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们从官方文件中借用一个<a class="ae jg" href="https://docs.scrapy.org/en/latest/intro/tutorial.html#:~:text=import%20scrapy%0A%0A%0Aclass,f%27Saved%20file%20%7Bfilename%7D%27)" rel="noopener ugc nofollow" target="_blank">的例子来更好地理解一切——</a></p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/6e6fb26912f2f747784f66117edd47a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JdMIBHnRwCjEYM4_mwd-Xg.png"/></div></div></figure><p id="a04b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们一行一行地理解上面的代码</p><p id="21c6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">第1行</strong>:导入库。<br/> <strong class="la jk">第二行</strong>:我们将创建一个类，scrapy使用它从web中抓取内容。你可以给它起任何名字，但重要的是它将继承类Spider。<br/> <strong class="la jk">第三行</strong> : <code class="fe mi mj mk ml b">name</code>是我们蜘蛛的名字。你也可以给它取任何名字，但是不要在文本之间添加任何空格，因为这个名字将会在你运行你的蜘蛛时使用。<br/> <strong class="la jk">第4行</strong>:是我们用来定义我们蜘蛛内部所有URL的函数。<br/> <strong class="la jk">第5行</strong> : <code class="fe mi mj mk ml b">URLs</code>是要抓取的URL列表。<br/> <strong class="la jk">第8，9行</strong>:一个for循环，在URL列表上运行，逐个提取每个URL，并传递给scrapy进行数据抓取。<br/> <strong class="la jk">第10行</strong> : <code class="fe mi mj mk ml b">parse</code>是一个类的方法，它有两个输入，一个是<code class="fe mi mj mk ml b">self</code>，另一个是<code class="fe mi mj mk ml b">response</code>，它包含了你想要抓取的网站的源代码。你也可以重新命名。<br/> <strong class="la jk">第11行</strong>:在这一行中，我们试图使用CSS选择器抓取网页的标题。<br/> <strong class="la jk"> Line12 </strong>:我们只是简单的打印标题。</p><p id="8585" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要运行上述代码，请运行以下命令—</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="6296" class="ne mn jj ml b gy od oe l of og">scrapy crawl quotes</span></pre><p id="379c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在命令中，<code class="fe mi mj mk ml b">scrapy</code>是基本库，<code class="fe mi mj mk ml b">crawl</code>是抓取的启动程序，<code class="fe mi mj mk ml b">quotes</code>是您在编写web抓取代码时初始化的蜘蛛的名称。它将返回列表中的所有标题。</p><p id="1ea1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们在下一节更深入地了解这些选择器。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="8086" class="mm mn jj bd mo mp os mr ms mt ot mv mw kp ou kq my ks ov kt na kv ow kw nc nd bi translated">4.元素选择器</h1><p id="b058" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">使用scrapy时，有两种方法可以选择web上的元素——CSS和Xpath。</p><h2 id="a927" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">1.CSS选择器</h2><p id="5169" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated"><code class="fe mi mj mk ml b">css()</code>中的条件被称为CSS选择器。让我们来看一些例子。</p><p id="31ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打开Scrapy Shell，编写以下代码，在Shell和服务器之间建立连接。我们将使用CSS选择器抓取网站上所有书籍的书名和价格。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="e60a" class="ne mn jj ml b gy od oe l of og">scrapy shell "<a class="ae jg" href="http://books.toscrape.com/index.html" rel="noopener ugc nofollow" target="_blank">http://books.toscrape.com/index.html</a>"</span></pre><p id="1983" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">价格是我们首先想从所有书籍中剔除的。打开网站，将鼠标悬停在一个价格上，然后右键单击&gt; inspect打开该元素的源代码。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/190b343b6e4e6f84ecd9135072b0ba1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*ys2rrWrrxFqDS4YWh4bqoQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">第一本书价格的HTML片段</figcaption></figure><p id="69a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的第一本书的价格在一个段落标签<code class="fe mi mj mk ml b">&lt;p&gt;</code>中，它是div标签的子标签。这个<code class="fe mi mj mk ml b">&lt;p&gt;</code>有一个<code class="fe mi mj mk ml b">price-color</code>类。价格的惟一标识符将是一个div，它有一个p标签作为子标签，类名为<code class="fe mi mj mk ml b">price-color</code>，让我们用它来收集所有的价格。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="ce36" class="ne mn jj ml b gy od oe l of og">response.css("div p<strong class="ml jk">.price_color::text</strong>").extract()</span></pre><p id="999b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在<code class="fe mi mj mk ml b">price_color</code>前用一个<code class="fe mi mj mk ml b">.</code>来表示它是一个类。如果是id，那么我们应该使用<code class="fe mi mj mk ml b">#price_color</code></p><p id="b8c4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们将借助下面的代码抓取这本书的所有标题</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="ac43" class="ne mn jj ml b gy od oe l of og">response.css("h3 a::text").extract()</span></pre><h2 id="4524" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">2.Xpath</h2><p id="4082" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">Xpath也是在XML文档中定位元素的一种方式。HTML是XML的实现，所以我们也可以用它来定位HTML中的元素。</p><p id="e249" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Xpath的基本语法是—</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="9fd2" class="ne mn jj ml b gy od oe l of og"><strong class="ml jk">Xpath = //tagname[@Attribute='Value']</strong></span><span id="eaea" class="ne mn jj ml b gy oh oe l of og">//       ➡ Select Current Node<br/>tagname  ➡ Tagname like input, div,td,tr<br/>@        ➡ Selects attribute<br/>Attribute➡ Attribute name (class,id,name,etc)<br/>value    ➡ value of the attribute</span></pre><p id="0ff2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们使用Xpath提取书籍的标题和价格。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="ceb6" class="ne mn jj ml b gy od oe l of og"><strong class="ml jk">## Scraping Titles<br/></strong>titles = response.xpath('//h3/a<strong class="ml jk">/text()</strong>').extract()</span><span id="657a" class="ne mn jj ml b gy oh oe l of og"><strong class="ml jk">## Scraping Prices</strong><br/>Prices = response.xpath('<strong class="ml jk">//div/p[@class="price_color</strong>"]<strong class="ml jk">/text()</strong>').extract()</span></pre><p id="2001" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Xpath与CSS略有不同，这里我们使用<code class="fe mi mj mk ml b">/text()</code>从抓取的文本中提取文本。</p><p id="c76e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来理解价格的Xpath，首先，我们有<code class="fe mi mj mk ml b">//div</code>表示顶层是一个div标签，然后我们有<code class="fe mi mj mk ml b">//div/p</code>表示在一个div标签中我们有一个段落标签。最后，我们使用了<code class="fe mi mj mk ml b">//div/p[@class="price_color"]</code>来定位一个段落元素，这个段落元素有一个price_color类和一个div标签的子元素。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="e763" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以使用两种方法中的任何一种从网上抓取数据。运行代码后，返回两个列表<code class="fe mi mj mk ml b">Titles, Prices</code>作为输出，其中包含第一页的标题和价格。</p><p id="a502" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是如果我们希望网站的每一页都有标题和价格呢？这里出现了多页抓取的概念。</p><h1 id="33e2" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">4.多页刮擦</h1><p id="ce38" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">多页抓取是通过操作URL一次抓取网站多个页面的过程。</p><p id="d3f2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们正在做的网站是http://books.toscrape.com/index.html的，</p><p id="a0a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你滚动到底部，你会看到下一步按钮。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/14aaa83bbdbea0c0c97cf36c5a502107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*TO_XhBUohWvX8KIBQ9NkAQ.png"/></div></figure><p id="a8fd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">点击它，你会被重定向到第2页，网站的网址会变成<a class="ae jg" href="http://books.toscrape.com/catalogue/page-2.html" rel="noopener ugc nofollow" target="_blank"><em class="oz">http://books.toscrape.com/catalogue/page-2.html</em></a></p><p id="3657" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在再次滚动到底部，点击下一步并检查网址，它会更新到<a class="ae jg" href="http://books.toscrape.com/catalogue/page-3.html" rel="noopener ugc nofollow" target="_blank"><em class="oz">http://books.toscrape.com/catalogue/page-3.html</em></a></p><p id="6822" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在再做一次，检查URL，这次它更新为<a class="ae jg" href="http://books.toscrape.com/catalogue/page-4.html" rel="noopener ugc nofollow" target="_blank"><em class="oz">http://books.toscrape.com/catalogue/page-4.html</em></a></p><p id="004b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以注意到，在第二页之后，只有一个地方发生了变化，那就是URL中的页码。我们可以用它来创建一个通用的URL，用一个f-string变量替换它们<code class="fe mi mj mk ml b">page-2</code>。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="69e3" class="ne mn jj ml b gy od oe l of og">for page_number in range(50):<br/>  url=f'http://books.toscrape.com/catalogue/<strong class="ml jk">page-{page_number}</strong>.html'<br/>  print(url)</span></pre><p id="a243" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个方法是一个通用的方法，即使下一个方法不起作用，你也可以使用。现在，让我们看一个更简单的方法。</p><p id="c0c7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">向下滚动到最后，查看主页上的<code class="fe mi mj mk ml b">next</code>按钮。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/4156c5aa9922caa5bd7774fe02dea6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*QRAf6-_IfdEjmUc99VWtQg.png"/></div></figure><p id="ccfe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mi mj mk ml b">&lt;a&gt;</code>标签包含了第二个网页的链接。现在，转到第二页，检查“next”按钮，您将看到这次它有第3页的链接。我们所需要的就是从这个标签上刮掉链接，scrapy会为我们做其他的事情。</p><p id="5495" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了抓取链接，我们首先定位按钮，然后使用XPath <code class="fe mi mj mk ml b">//li[@class='next']/a/<strong class="la jk">@href</strong></code>，<code class="fe mi mj mk ml b">@</code>从标签中提取属性的值。</p><p id="fbdd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们用这个来刮所有的网页。</p><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="0577" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用以下命令运行上述代码</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="0eef" class="ne mn jj ml b gy od oe l of og">scrapy crawl books</span></pre><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/46e124044dcf1a3f6ee257abf5422b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Ec-MEufP8X4ssIHhSLOvpA.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">作者抓取的数据输出Gif</figcaption></figure><p id="9915" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以在开始时运行以下命令，将抓取的数据保存在CSV、JSON或XML文件中</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="9054" class="ne mn jj ml b gy od oe l of og"> scrapy crawl books -o data.csv  <br/>or   <br/> scrapy crawl books -o data.json  <br/>or   <br/> scrapy crawl books -o data.xml</span></pre><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/8743cea7c7f1cc230a96cd10b1a48253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kv0sbizXjClQ8tfkVyl11w.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">data.json文件截图作者</figcaption></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="6360" class="mm mn jj bd mo mp os mr ms mt ot mv mw kp ou kq my ks ov kt na kv ow kw nc nd bi translated">5.有用的概念</h1><h2 id="02bc" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">1.项目容器</h2><p id="10e2" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">web抓取的主要目标是从web上抓取非结构化数据，并以结构化的方式存储。这些项目容器用于存储数据。默认情况下，Scrapy将数据作为项目返回。</p><p id="e5c9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">items提供了一个类似字典的API，可用于将非结构化数据转换为结构化数据。<code class="fe mi mj mk ml b">items.py</code>文件用于定义一个scrapy项目内部的容器。</p><p id="b759" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您使用scrapy创建一个项目时，会自动创建<code class="fe mi mj mk ml b">items.py</code>文件。您需要将它导入到您的spider上，以利用项目容器，就像我们在上面的图书抓取代码的第2行中所做的那样。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="9b92" class="ne mn jj ml b gy od oe l of og">from ..items item BookscraperItem</span></pre><p id="8d33" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">BookscraperItem是启动项目时自动创建的类名。该类的名称取决于您的项目名称。它用于定义您的项目容器。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="2fd8" class="ne mn jj ml b gy od oe l of og"><a class="ae jg" href="https://docs.scrapy.org/en/latest/topics/items.html" rel="noopener ugc nofollow" target="_blank"><strong class="ml jk">items.py</strong></a></span><span id="7ab2" class="ne mn jj ml b gy oh oe l of og"><strong class="ml jk">class BookscraperItem(scrapy.Item):</strong><br/># define the fields for your item here like:<br/># name = scrapy.Field()<br/>    <strong class="ml jk">link = scrapy.Field()<br/>    price = scrapy.Field()<br/>    title = scrapy.Field()</strong></span></pre><p id="1505" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦定义了容器，就可以用它们来存储数据。记住一件事，容器的名字应该和你的数据变量的名字一样。</p><h2 id="3279" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">2.从语法上分析</h2><p id="aa3b" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated"><code class="fe mi mj mk ml b">parse</code>是一个负责处理响应并返回抓取的数据或更多URL的方法。它将<code class="fe mi mj mk ml b">response</code>变量作为包含源代码的输入。此方法还用于将数据传递给项容器进行临时存储。</p><p id="66f5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">默认情况下，代码会将回调传递给parse方法，直到您指定其他内容。就像我们在图书抓取代码的第13行所做的那样。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="f0c1" class="ne mn jj ml b gy od oe l of og">def parse(self,response):<br/>      ...</span></pre></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="1fb6" class="mm mn jj bd mo mp os mr ms mt ot mv mw kp ou kq my ks ov kt na kv ow kw nc nd bi translated">项目1:亚马逊图书抓取</h1><p id="21de" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated"><strong class="la jk">任务</strong>:我们的任务是从<a class="ae jg" href="https://www.amazon.com/s?k=python+programming&amp;page=1&amp;crid=YZEI0VGEO20K&amp;qid=1644079860&amp;sprefix=python+programming&amp;ref=sr_pg_2" rel="noopener ugc nofollow" target="_blank">亚马逊</a>搜集所有关于python编程的书名、作者名和价格。</p><h2 id="4ade" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤0:创建项目</h2><p id="7505" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">运行<code class="fe mi mj mk ml b">scrapy startproject amazon</code>启动一个新项目并生成文件夹结构。</p><p id="18d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，定位到spiders文件夹，创建一个新的python文件<code class="fe mi mj mk ml b">scraper.py</code>，用于编写web抓取代码。</p><h2 id="9a87" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤1:导入库</h2><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="fa75" class="ne mn jj ml b gy od oe l of og">import scrapy<br/>from ..items import AmazonItem  <em class="oz">## class inside items.py</em></span></pre><h2 id="6115" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤2:创建类并命名蜘蛛</h2><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="6e5a" class="ne mn jj ml b gy od oe l of og">class Amazonbookscraper(scrapy.Spider):<br/>   name = "amazonbooks"</span></pre><h2 id="1f08" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤3:准备起始URL</h2><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="f1bd" class="ne mn jj ml b gy od oe l of og">start_urls = [<br/>"<a class="ae jg" href="https://www.amazon.com/s?k=python+programming&amp;page=1&amp;crid=YZEI0VGEO20K&amp;qid=1644079860&amp;sprefix=python+programming&amp;ref=sr_pg_2" rel="noopener ugc nofollow" target="_blank">https://www.amazon.com/s?k=python+programming&amp;page=1&amp;crid=YZEI0VGEO20K&amp;qid=1644079860&amp;sprefix=python+programming&amp;ref=sr_pg_2</a>" <br/>]</span></pre><p id="784d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe mi mj mk ml b">start_urls</code>是一个包含要抓取的URL列表的列表。这是一个更简单的方法来抓取你的URL。</p><h2 id="1572" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤4:收集数据</h2><ol class=""><li id="b3ab" class="lu lv jj la b lb nq le nr lh pe ll pf lp pg lt ph ma mb mc bi translated">抓取标题</li></ol><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/d2470682f781c1a168f7b12701d16e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*PlF9Fm8gzIBy4WBvksTMrg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">有三个类你可以任意使用</figcaption></figure><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="1f4a" class="ne mn jj ml b gy od oe l of og">titles = response.css('<strong class="ml jk">.a-size-base-plus</strong>::text').extract()</span></pre><p id="7772" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.削价</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/f72dc95c687db2f175a58d803b6f21e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*7Qiavt9YCOG-F1NV5C6fwg.png"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">a-price-whole类包含关于书籍价格的信息</figcaption></figure><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="4f5c" class="ne mn jj ml b gy od oe l of og">prices = response.css('<strong class="ml jk">.a-price-whole:</strong>:text').extract()</span></pre><p id="0b25" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们使用<a class="ae jg" href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">选择器小工具chrome扩展</strong> </a>来收集作者和评级。看看这个<a class="ae jg" href="https://www.youtube.com/watch?v=oqNTfWrGdbk" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> youtube视频</strong> </a>了解如何使用它来查找网页上特定元素的CSS或XPath。</p><p id="74ba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.抓取作者</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="2c71" class="ne mn jj ml b gy od oe l of og">authors = response.css('.a-color-secondary .a-size-base+ .a-size-base::text').extract()</span></pre><p id="4dd8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.刮擦评级</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="df9d" class="ne mn jj ml b gy od oe l of og">ratings = response.css('.s-link-style .s-underline-text::text').extract()</span></pre><h2 id="c29f" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">步骤5:在项目容器中存储数据</h2><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="f0cc" class="ne mn jj ml b gy od oe l of og">for i in list(zip(titles,prices,authors,ratings)):<br/>  title,price,author,rating = i<br/>  items['title']=title<br/>  items['price']=price<br/>  items['author']=author<br/>  items['rating']=rating</span><span id="dec7" class="ne mn jj ml b gy oh oe l of og">yield items</span></pre><h2 id="7706" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">第六步:抓取多个页面</h2><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="a81e" class="ne mn jj ml b gy od oe l of og">next_page_url = "https://www.amazon.com"+response.xpath('//*[contains(concat( " ", @class, " " ), concat( " ", "s-pagination-next", " " ))]/@href')[0].extract()</span><span id="c3fb" class="ne mn jj ml b gy oh oe l of og">if next_page_url is not None:<br/>  yield response.follow(next_page_url, callback=self.parse)</span></pre><h2 id="65fe" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">完整代码</h2><figure class="nv nw nx ny gt iv"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="5af1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用命令<code class="fe mi mj mk ml b">scrapy crawl amazonbooks</code>运行代码</p><p id="6818" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能会陷入亚马逊的连接错误。这是因为亚马逊阻止了你的连接请求。为了防止这种情况，我们可以使用用户代理。有一个由scrapy爱好者创建的库，包含超过2000个用户代理，并经常更换用户代理，以便您不会被阻止。您可以使用以下命令安装该库。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="01c3" class="ne mn jj ml b gy od oe l of og">pip install scrapy-user-agents</span></pre><p id="d941" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦安装完成，进入你的项目文件夹中的<code class="fe mi mj mk ml b">settings.py</code>文件。将以下代码粘贴到下载恶意软件注释的下方。</p><pre class="nv nw nx ny gt nz ml oa ob aw oc bi"><span id="5f33" class="ne mn jj ml b gy od oe l of og">DOWNLOADER_MIDDLEWARES = {<br/>    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,<br/>    'scrapy_user_agents.middlewares.RandomUserAgentMiddleware': 400,<br/>}</span></pre><p id="446e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，再次尝试运行代码。这一次它将成功运行并从amazon抓取数据。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/72dac8e6582e3da5793816ffff50d07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*0NlPArsKoFmlLA2QCnyrOg.gif"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">亚马逊图书刮刀输出</figcaption></figure><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/94470ce28977a92a6cc0dfcba95344d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RG3de-7VJ9wR3cTHipg-6A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">Books _细节. json文件</figcaption></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="c0f5" class="mm mn jj bd mo mp os mr ms mt ot mv mw kp ou kq my ks ov kt na kv ow kw nc nd bi translated">推荐读物</h1><div class="is it gp gr iu pl"><a href="https://medium.com/pythoneers/master-web-scraping-completly-from-zero-to-hero-38051423256b" rel="noopener follow" target="_blank"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">网络抓取大师从零到英雄🕸</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">用美汤和请求库同一个项目</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">medium.com</p></div></div><div class="pu l"><div class="pv l pw px py pu pz ja pl"/></div></div></a></div><div class="is it gp gr iu pl"><a rel="noopener  ugc nofollow" target="_blank" href="/master-the-art-of-writing-xpath-for-web-scraping-c14e2f7ee130"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">掌握为Web抓取编写Xpath的艺术</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">网络抓取规则的简单介绍</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pu l"><div class="qa l pw px py pu pz ja pl"/></div></div></a></div><div class="is it gp gr iu pl"><a href="https://medium.com/pythoneers/web-scraping-using-selenium-python-6c511258ab50" rel="noopener follow" target="_blank"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">使用Selenium Python进行Web抓取</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">一个项目的详细教程</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">medium.com</p></div></div><div class="pu l"><div class="qb l pw px py pu pz ja pl"/></div></div></a></div></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="22b6" class="ne mn jj bd mo nf ng dn ms nh ni dp mw lh nj nk my ll nl nm na lp nn no nc np bi translated">参考</h2><p id="62a3" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">[1]<a class="ae jg" href="https://docs.scrapy.org/en/latest/intro/tutorial.html" rel="noopener ugc nofollow" target="_blank">https://docs.scrapy.org/en/latest/intro/tutorial.html</a></p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="049c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢你读到这里，如果你喜欢我的内容并想支持我，最好的方式是—</p><ol class=""><li id="953a" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt ph ma mb mc bi translated">跟我上<a class="ae jg" href="http://abhayparashar31.medium.com/" rel="noopener"> <em class="oz">中</em> </a>。</li><li id="2e2f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt ph ma mb mc bi translated">在<a class="ae jg" href="https://www.linkedin.com/in/abhay-parashar-328488185/" rel="noopener ugc nofollow" target="_blank"> <em class="oz"> LinkedIn </em> </a>上联系我。</li><li id="2a2f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt ph ma mb mc bi translated">使用<a class="ae jg" href="https://abhayparashar31.medium.com/membership" rel="noopener"> <em class="oz">我的推荐链接</em> </a>成为中等会员。你会费的一小部分会归我。</li><li id="8408" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt ph ma mb mc bi translated">订阅<a class="ae jg" href="https://abhayparashar31.medium.com/subscribe" rel="noopener"> <em class="oz">我的邮件列表</em> </a>永远不会错过我的一篇文章。</li></ol></div></div>    
</body>
</html>