<html>
<head>
<title>A Short Introduction To PySpark Window Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark窗口函数简介</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/an-short-introduction-to-pyspark-window-functions-a60bcb28cc3b?source=collection_archive---------12-----------------------#2022-05-26">https://levelup.gitconnected.com/an-short-introduction-to-pyspark-window-functions-a60bcb28cc3b?source=collection_archive---------12-----------------------#2022-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a3a1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">避免缓慢而复杂的代码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3e61b20f76a745c752e6ca622778cdd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KIarzmEOkiwkvQTQ"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@zerotake?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">零点拍摄</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="58cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据Python的<a class="ae kv" href="https://peps.python.org/pep-0020/" rel="noopener ugc nofollow" target="_blank">禅</a></p><blockquote class="ls lt lu"><p id="e7ea" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">应该有一种——最好只有一种——显而易见的方法来做这件事。虽然这种方式一开始可能并不明显，除非你是荷兰人。</p></blockquote><p id="ccda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不是荷兰人，这可能解释了为什么我花了一段时间才发现<a class="ae kv" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank"> PySpark </a>中的窗口函数，即Apache Spark的Python API，当pandas的内存单节点处理开始显示其局限性时使用。在我发现之前，我有很多方法可以实现想要的功能，但是代码复杂，速度慢，可读性差。</p><p id="c5fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的目的是提供一个关于窗口函数的简单介绍。我并不认为我可以在介绍中涵盖所有可能的窗口函数的使用，这也不是我的目的。相反，本文的目的是展示实现相同结果的几种替代方法，旨在说明窗口功能的有用性和表现力。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="b01f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">导入并启动数据集</strong></p><p id="d481" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们从必要的进口开始</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="6379" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们创建一个包含学生成绩的合成数据集。数据集有200行，这并不证明使用PySpark是正确的，但它对于快速实验来说很方便。我更喜欢创建一个合成数据集，而不是提供数据链接，因为读者更容易试验代码片段。</p><p id="85bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">起始数据集可通过以下方式创建</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="58fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设<code class="fe mi mj mk ml b">spark</code>是spark会话。细节并不太重要。我们有三列，分别是学生姓名，年份(三年，即2020，2021，2022)和范围在[0.0，10.0]内的随机成绩。如果希望有意义地测试性能，可以通过增加学生人数和年数来创建更大的数据集，但在一定程度上，PySpark数据框是通过pandas数据框创建的。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="dc61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">不明显的方式</strong></p><p id="e297" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们展示了两种不使用窗口函数计算每年哪个学生分数最高的方法。</p><p id="d87b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一种方法依赖于聚合连接模式</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="8cc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先计算每年的最高分数，并将其存储在名为<code class="fe mi mj mk ml b">max_grade_in_year</code>的中间数据帧中。然后，我们使用这个数据框将原始数据框与学生成绩连接起来。请注意左侧半连接的使用，它保留了左侧数据框中与第二个匹配的行，其中连接条件同时使用了年份和年级。尽管它是可行的，但是将数据框与其自身(或其自身的衍生物)连接起来是一个信号，表明可能存在更好的方法。</p><p id="36b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一种可能是通过创建熊猫UDF来使用分离-聚集-组合模式。pandas UDFs的使用在Spark 3.x中有了显著的改进，这里显示的代码是在使用Spark 3.2.1中测试的</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="6864" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果与之前相同，连接已被消除。然而，这种解决方案并不理想，因为UDF应该只在必要时使用，即使它们是受益于矢量化执行的熊猫UDF。</p><p id="a9f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">显而易见的方式</strong></p><p id="5760" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用窗口函数解决问题要简洁得多</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="e298" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果是一样的，代码可读性大大提高了。该解决方案需要创建一个使用年份指定分区的窗口。通过使用直观的名称，窗口的应用程序读起来像英语。应用窗口函数不会改变行数，而只是增加了一个具有每年最高等级的列。剩下的都是简单的PySpark操作。</p><p id="632b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于更熟悉SQL的读者来说，使用</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="50ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在SQL查询执行之前，我们创建了一个名为<code class="fe mi mj mk ml b">grades</code>的本地临时视图。就我个人而言，我总是更喜欢PySpark API，但是具有长期SQL经验的数据分析师可能不会同意。火花迎合所有人！</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="1664" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">窗口函数对数据框的一部分进行操作，可用于聚合(如本文中所示)、排序或分析操作。它们返回具有相同行数的数据框，可以认为它们是一种创建新列的方法，然后可以对新列进行过滤或在其他操作中使用。窗口函数常常使代码更加简洁，但常常被数据分析师和数据科学家所忽视。一旦你掌握了它们，它们会成为你武器库中的有力工具。</p></div></div>    
</body>
</html>