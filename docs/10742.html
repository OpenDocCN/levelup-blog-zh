<html>
<head>
<title>Graph Convolutional Network Node Classification with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流的图卷积网络节点分类</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/graph-convolutional-network-node-classification-with-tensorflow-49d3e091ea15?source=collection_archive---------5-----------------------#2022-01-07">https://levelup.gitconnected.com/graph-convolutional-network-node-classification-with-tensorflow-49d3e091ea15?source=collection_archive---------5-----------------------#2022-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="ab41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图形神经网络实践教程入门</p><p id="f41a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇博文中，我们将通过一个完整的教程来训练一个图卷积网络(GCN)。本教程包含对GCN背后思想的简要解释，以及在Tensorflow中的逐行训练实现。</p><p id="54d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们先来看看我们今天要用的数据集。我们使用<a class="ae ko" href="https://graphsandnetworks.com/the-cora-dataset/" rel="noopener ugc nofollow" target="_blank"> Cora </a>数据集。这类似于图形神经网络中的MNIST。Cora数据集包含一个引用网络图。图中的每个节点是一篇论文，每条边是一篇引文。有<code class="fe kp kq kr ks b">2708</code>个节点和<code class="fe kp kq kr ks b">10556</code>条边。这些论文属于<code class="fe kp kq kr ks b">7</code>科学类。每篇论文都有一个相关的特征向量。特征向量是一个由<code class="fe kp kq kr ks b">1433</code>个元素组成的布尔数组，每个元素表示一个相应的词典单词是否出现在论文中。Cora数据集还包含训练、验证和测试掩码(每个掩码都包含<code class="fe kp kq kr ks b">2708</code>布尔元素),用于表示哪些节点在各自的分裂中。</p><p id="ee41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该任务可以被设计为给定一小组已知的标签(Cora案例中的<code class="fe kp kq kr ks b">140</code>论文的类别)，我们想要预测引用网络中其他论文的标签。在诸如欺诈检测的图节点分类任务中，相同类型的方案是常见的。直观上，节点的标签可以从节点特征本身及其与其他节点的连接(标签已知或未知)中导出。</p><p id="e3da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了比较，让我们首先训练一个完全基于节点特征的模型。我们知道它不会执行得很好，因为它没有考虑节点之间的连接。尽管如此，我们还是会以第一个为基线。</p><p id="3184" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们使用<a class="ae ko" href="https://docs.dgl.ai/install/index.html" rel="noopener ugc nofollow" target="_blank"> DGL </a>库加载数据集。DGL库是一组规范的图形神经网络构建块，我们稍后会用到。然后，我们使用整个数据集的要素和标签上的相应掩膜来准备训练、验证和测试数据集。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div></figure><p id="1583" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们创建一个具有两个完全连接的层和一个断开层的简单模型，并针对<code class="fe kp kq kr ks b">20</code>时期训练该模型。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div></figure><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi la"><img src="../Images/0be88d93475176153d33caf539ec717d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*DENFCMOGq6zOUULhMrXA7A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图1简单模型训练精度</figcaption></figure><p id="5ba7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图1中可以看出，训练和验证的准确性很差。我们在测试数据集上评估模型。精度更差，只有<code class="fe kp kq kr ks b">17%</code>。</p><p id="4a73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，是时候探索图卷积网络了。这个想法最初是在这篇<a class="ae ko" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank">论文</a>中形成的。<strong class="js iu">简而言之，模型被学习以利用节点特征及其邻居来完成节点分类任务。</strong>参见下图-2中的插图。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lh"><img src="../Images/72b975afdb7294a86b72b65d528affcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fu9sFEs8Ch24a5tvD9IhsQ.png"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图2 GCN插图</figcaption></figure><p id="a45d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个两层图卷积神经网络。节点<code class="fe kp kq kr ks b">A</code>的最终潜在表示取决于节点<code class="fe kp kq kr ks b">B</code>、<code class="fe kp kq kr ks b">C</code>和节点A <code class="fe kp kq kr ks b">itself</code>的先前潜在表示，其来自模型中的第一个隐藏层。这些依次依赖于层<code class="fe kp kq kr ks b">0</code>，这是原始的节点特征。参数<code class="fe kp kq kr ks b">W</code>和<code class="fe kp kq kr ks b">b</code>在层内是相同的，而在层之间是不同的。聚集机制可以是简单的平均或一些其他更复杂的方案。聚合通常基于源和目的节点的传出和传入边的数量进行归一化。这具有直观的意义，因为节点对接收节点的“影响”应该取决于该节点有多少出站连接以及接收节点有多少入站连接。公式如下。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/acc6a12aebcfc0d03874892f10d8625f.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*wRgOW3wJLVM76BjqJqhvaQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">一级方程式GCN模型</figcaption></figure><p id="264e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe kp kq kr ks b">N(i)</code>是节点<code class="fe kp kq kr ks b">i</code>的邻居集合。<code class="fe kp kq kr ks b">cij</code>是归一化项。它通常是节点<code class="fe kp kq kr ks b">i</code>的入站连接数乘以节点<code class="fe kp kq kr ks b">j</code>的出站连接数的平方根。</p><p id="5926" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们添加的层越多，模型就越能聚合信息。例如，如果模型中只有一层，就不会考虑节点<code class="fe kp kq kr ks b">D</code>。但是，要小心添加过多的层。<a class="ae ko" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank">论文</a>显示，当添加太多层时，模型性能会急剧下降，因为在这种情况下，我们实际上是在平滑整个图形的标签信息。</p><p id="5ed4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们使用来自DGL图书馆的GraphConv 构件来构建我们的模型。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div></figure><p id="5306" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们也为<code class="fe kp kq kr ks b">20</code>时代训练它。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="ky kz l"/></div></figure><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/209c0cb90f15719ee4b799a5904f7267.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*Vrff2UsKNkdYEs-VhIgVvQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">图-3 GCN训练精确度</figcaption></figure><p id="3dc4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图3来看，精确度看起来好了很多，尽管有点过拟合。测试精度为<code class="fe kp kq kr ks b">71%</code>，远高于之前的<code class="fe kp kq kr ks b">17%</code>。所以正如所料，网络中的连接确实具有很强的预测能力，尤其是考虑到训练集中实际上只有<code class="fe kp kq kr ks b">140</code>节点。</p></div></div>    
</body>
</html>