<html>
<head>
<title>Precision-Recall curve explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释精确召回曲线</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/precision-recall-curve-explained-fabfe58fb52e?source=collection_archive---------5-----------------------#2021-05-14">https://levelup.gitconnected.com/precision-recall-curve-explained-fabfe58fb52e?source=collection_archive---------5-----------------------#2021-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4b6e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据科学基础</h2><div class=""/><div class=""><h2 id="a626" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">学习用Python可视化精确召回曲线</h2></div><p id="038e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本帖中，我们将了解如何从概念上构建精确召回曲线(一种评估监督分类模型的有用工具),并在Python中以静态和交互格式显示该曲线。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/f92a0579e8e8ae8590d3cf65b2469c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N-Qmf5sGYpHIaiS9"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">Elena Mozhvilo 在<a class="ae md" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="a8c0" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">理解曲线</h1><p id="1fac" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">精确度-召回率(又名PR)曲线向我们展示了在不同的<em class="ni">阈值</em>下<em class="ni">精确度</em>和<em class="ni">召回率</em>之间的关系。让我们来理解这三个术语的含义。</p><p id="e07b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">首先，让我们回顾一下混淆矩阵是什么样子的:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nj"><img src="../Images/12b6b82e2369c55c5ef038ef22752d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ydCmaJOnEKqXO6cTn4g4fQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</figcaption></figure><p id="31d5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">刷新了我们对混淆矩阵的记忆后，让我们看看术语。</p><h2 id="f19e" class="nk mm it bd mn nl nm dn mr nn no dp mv la np nq mx le nr ns mz li nt nu nb iz bi translated">精确</h2><p id="d4fb" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">我们可以使用下面的简单公式计算精度:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ee7853d50687e85adc73ba1bf5b19c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*Xzlm2Yx_7wtdP57IhJpddw.png"/></div></figure><blockquote class="nw nx ny"><p id="5c4e" class="kr ks ni kt b ku kv kd kw kx ky kg kz nz lb lc ld oa lf lg lh ob lj lk ll lm im bi translated">精确度告诉我们正确的正面预测的百分比。换句话说，它告诉我们积极的预测有多精确。精度越高，假阳性越低，反之亦然。</p></blockquote><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oc"><img src="../Images/225cff35762fc5914c49cce34de99595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnmaIEBQnmyiO2Isa1LWKw.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</figcaption></figure><h2 id="f7a3" class="nk mm it bd mn nl nm dn mr nn no dp mv la np nq mx le nr ns mz li nt nu nb iz bi translated">回忆</h2><p id="631e" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">我们可以使用下面的简单公式找到回忆:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi od"><img src="../Images/6ace42cfbd9f7c4c862b54db14701110.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*_rdggG32vA0TAfjQ6SedAw.png"/></div></figure><blockquote class="nw nx ny"><p id="3f36" class="kr ks ni kt b ku kv kd kw kx ky kg kz nz lb lc ld oa lf lg lh ob lj lk ll lm im bi translated">回忆告诉我们正确预测的正面记录的百分比。这也被称为真阳性率或灵敏度。召回率越高，假阴性就越低，反之亦然。</p></blockquote><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oe"><img src="../Images/21678c9cad3fa06144ad7fc9150d1ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HO-F3h937gpjlSBAw-Xww.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</figcaption></figure><h2 id="af96" class="nk mm it bd mn nl nm dn mr nn no dp mv la np nq mx le nr ns mz li nt nu nb iz bi translated">阈值</h2><p id="5d14" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">通常，分类模型可以预测给定记录成为某个类别的概率。通过将概率值与我们设置的阈值进行比较，我们可以将记录分类。换句话说，您需要定义一个类似如下的规则:</p><blockquote class="nw nx ny"><p id="aa6e" class="kr ks ni kt b ku kv kd kw kx ky kg kz nz lb lc ld oa lf lg lh ob lj lk ll lm im bi translated">如果为正的概率大于或等于阈值，则记录被分类为正预测；否则，一个负面的预测。</p></blockquote><p id="c715" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在下面的小例子中，我们可以看到三个记录的概率得分。使用两个不同的阈值(0.5和0.6)，我们将每个记录分类到一个类中。正如您所看到的，预测的类根据我们选择的阈值而变化。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi of"><img src="../Images/6ab583ad7c038d728a2a3465683639fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3404EOaRMY9nERQJLcZxA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</figcaption></figure><p id="4321" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当构建混淆矩阵和计算准确率和召回率时，我们需要预测的类别而不是概率分数。</p><h2 id="284a" class="nk mm it bd mn nl nm dn mr nn no dp mv la np nq mx le nr ns mz li nt nu nb iz bi translated">精确回忆曲线</h2><p id="6e8c" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">现在我们知道了什么是精度、召回率和阈值，一旦我们计算了多个阈值的精度和召回率，我们就在x轴上绘制召回率，在y轴上绘制精度-召回率曲线。就是这样！✨</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c78da0fabca7f621b50e5ce1d444dbab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*KZu3UEBx3UIgOvdS6V_h_A.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</figcaption></figure><p id="5247" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该曲线显示了不同阈值下精确度和召回率之间的权衡。你也可以认为这条曲线显示了<em class="ni">假阳性</em>和<em class="ni">假阴性</em>之间的权衡。如果您的分类问题要求您拥有预测的类别而不是概率，则应在考虑了<em class="ni">假阳性</em>和<em class="ni">假阴性</em>的相对误分类成本后，选择要使用的正确阈值。此外，在某些用例中(例如，当您有严重不平衡的数据时)，精确-召回曲线下的面积是ROC曲线下面积的一个很好的替代度量。</p><p id="10b6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，是时候看看一些代码示例来巩固我们的知识了。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="13aa" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">在Python中构建静态精确召回曲线</h1><p id="d169" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">让我们首先导入本文剩余部分所需的库:</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="240d" class="nk mm it oi b gy om on l oo op">import numpy as np<br/>import pandas as pd<br/>pd.options.display.float_format = "{:.4f}".format</span><span id="5992" class="nk mm it oi b gy oq on l oo op">from sklearn.datasets import load_breast_cancer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve</span><span id="6049" class="nk mm it oi b gy oq on l oo op">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import plotly.express as px<br/>sns.set(palette='rainbow', context='talk')</span></pre><p id="2b9d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，我们将构建一个函数，在给定正确类别、预测为阳性类别的概率和阈值的情况下，该函数将找到<em class="ni">真阳性</em>和<em class="ni">阳性预测</em>的数量:</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="f306" class="nk mm it oi b gy om on l oo op">def get_tp_pp(y, proba, threshold):<br/>    """Return the number of true positives."""<br/>    # Classify into classes<br/>    pred = np.where(proba&gt;=threshold, 1, 0)<br/>   <br/>    # Count true positives<br/>    true_positives = np.sum((y==1) &amp; (pred==1))<br/>    positive_predictions = np.sum(pred==1)<br/>    return true_positives, positive_predictions</span></pre><p id="93f6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ni">请注意，您将在现实中使用分区数据集(如培训、测试)。但是为了简单起见，我们不会在本文中对数据进行划分。</em></p><p id="5732" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将在玩具数据集上构建一个简单的模型，并获得这些记录为正的概率(用值1表示):</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="1214" class="nk mm it oi b gy om on l oo op"># Load sample data<br/>X = load_breast_cancer()['data'][:,:2] # first two columns only<br/>y = load_breast_cancer()['target']</span><span id="4311" class="nk mm it oi b gy oq on l oo op"># Train a model<br/>log = LogisticRegression()<br/>log.fit(X, y)</span><span id="e141" class="nk mm it oi b gy oq on l oo op"># Predict probability<br/>proba = log.predict_proba(X)[:,1]</span></pre><p id="5703" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将使用1000个不同的阈值，从0到1，增量为0.001。换句话说，阈值看起来像0，0.001，0.002，… 0.998，0.999。让我们找出阈值的精度和召回率。</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="c587" class="nk mm it oi b gy om on l oo op"># Find precision &amp; recall for thresholds<br/>positives = np.sum(y==1)</span><span id="ccd6" class="nk mm it oi b gy oq on l oo op">columns = ['threshold', 'precision', 'recall']<br/>inputs = pd.DataFrame(columns=columns, dtype=np.number)<br/>thresholds = np.arange(0, 1, 0.001)</span><span id="5b45" class="nk mm it oi b gy oq on l oo op">for i, threshold in enumerate(thresholds):<br/>    inputs.loc[i, 'threshold'] = threshold<br/>    true_positives, positive_predictions = get_tp_pp(y, proba, threshold)<br/>    inputs.loc[i, 'precision'] = true_positives/positive_predictions<br/>    inputs.loc[i, 'recall'] = true_positives/positives<br/>inputs</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d6aa9c17c4a88cd277937eb62679df8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*yvyX3JHVQ6TnyY0_HSPK4A.png"/></div></figure><p id="649e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该地块的数据已准备好。让我们画出来:</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="081b" class="nk mm it oi b gy om on l oo op">def plot_static_precision_recall_curve(fpr, tpr):<br/>    plt.figure(figsize=[7,7])<br/>    plt.fill_between(fpr, tpr, alpha=.5)<br/>    plt.ylabel("Precision")<br/>    plt.xlabel("Recall")<br/>    plt.title("Precision-Recall curve");<br/>    <br/>plot_static_precision_recall_curve(inputs['recall'], inputs['precision'])</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f5da8b3e39c0d8ce564ef256f4512f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*DMshiScvlbLbppciRpyPdw.png"/></div></figure><p id="33a1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">虽然构建自定义函数有助于我们理解曲线及其输入，并更好地控制它们，但我们也可以利用<em class="ni"> sklearn的</em>功能进行更优化。例如，我们可以用一个<code class="fe ot ou ov oi b">precision_recall_curve()</code>函数得到精确度、召回率和阈值。我们可以使用自定义绘图功能以同样的方式绘制数据:</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="9243" class="nk mm it oi b gy om on l oo op">precision, recall, thresholds = precision_recall_curve(y, proba)<br/>plot_static_precision_recall_curve(recall, precision)</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/90c775aaf08cd1b6347986314deab195.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*sWiNLn5eyP9QOy5pQ_fJPA.png"/></div></figure><p id="2cbc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Sklearn 还提供了一个<code class="fe ot ou ov oi b">plot_precision_recall_curve()</code>函数，为我们完成所有的工作。您只需要一行代码(添加标题是可选的):</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="248a" class="nk mm it oi b gy om on l oo op">plot_precision_recall_curve(log, X, y)<br/>plt.title("Precision-Recall curve"); # Add a title for clarity</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/749fe563a99f6b9c4690c4dfb4bc48d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*gHaqYBLkjufSyCo_vxbpKw.png"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="2a86" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">用Python绘制交互式精确召回曲线</h1><p id="6846" class="pw-post-body-paragraph kr ks it kt b ku nd kd kw kx ne kg kz la nf lc ld le ng lg lh li nh lk ll lm im bi translated">使用静态图时，很难看到曲线上不同点的相应阈值。一种选择是仔细检查我们创建的<code class="fe ot ou ov oi b">inputs </code>数据框架。另一个选项是创建图形的交互式版本，以便当我们将鼠标悬停在图形上时，可以看到精度和相应阈值旁边的回忆:</p><pre class="lo lp lq lr gt oh oi oj ok aw ol bi"><span id="9143" class="nk mm it oi b gy om on l oo op">def plot_interactive_precision_recall_curve(df, precision, recall, thresholds):<br/>    fig = px.area(<br/>        data_frame=df, <br/>        x=recall, <br/>        y=precision,<br/>        hover_data=thresholds, <br/>        title='Precision-Recall Curve'<br/>    )<br/>    fig.update_layout(<br/>        autosize=False,<br/>        width=500,<br/>        height=500,<br/>        margin=dict(l=30, r=30, b=30, t=30, pad=4),<br/>        title_x=.5, # Centre title<br/>        hovermode = 'closest',<br/>        xaxis=dict(hoverformat='.4f'),<br/>        yaxis=dict(hoverformat='.4f')<br/>    )<br/>    hovertemplate = 'Recall=%{x}&lt;br&gt;Precision=%{y}&lt;br&gt;Threshold=%{customdata[0]:.4f}&lt;extra&gt;&lt;/extra&gt;'<br/>    fig.update_traces(hovertemplate=hovertemplate)<br/>    <br/>    # Add dashed line with a slope of 1<br/>    fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)<br/>    fig.show()</span><span id="ef4a" class="nk mm it oi b gy oq on l oo op">plot_interactive_precision_recall_curve(df=inputs, <br/>                           precision='precision', <br/>                           recall='recall', <br/>                           thresholds=['threshold'])</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/d8c79d5d67ee0ea476a98ab8c5e648d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/0*f1ZEhd-edib07kcp.gif"/></div></figure><p id="aefa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">互动性挺有用的吧？</p><p id="b126" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">希望你喜欢学习如何建立和可视化精确召回曲线。一旦理解了这条曲线，就很容易理解另一条相关曲线:<a class="ae md" href="https://towardsdatascience.com/roc-curve-explained-50acab4f7bd8" rel="noopener" target="_blank"> <em class="ni"> ROC曲线</em> e </a>。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oz"><img src="../Images/f5d8f0f8939c21cc7e874886240b26a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VGgcPOVtFyV975Tv"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated"><a class="ae md" href="https://unsplash.com/@zoltantasi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Zoltan·塔斯</a>在<a class="ae md" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="749f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ni">您想访问更多这样的内容吗？媒体会员可以无限制地访问媒体上的任何文章。如果您使用</em> <a class="ae md" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="ni">我的推荐链接</em> </a>，<em class="ni">成为会员，您的一部分会费将直接用于支持我。</em></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="80de" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">感谢您阅读这篇文章。如果你感兴趣，这里有我其他一些帖子的链接:</p><p id="1db9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">◼️ <a class="ae md" href="https://towardsdatascience.com/interesting-ways-to-use-punctuations-in-python-43205a0bd67d" rel="noopener" target="_blank">在Python中使用标点符号的有趣方法</a> <br/> ◼️ <a class="ae md" href="https://towardsdatascience.com/5-tips-to-learn-python-from-zero-e4f6a9106558" rel="noopener" target="_blank">从零开始学习Python的5个技巧</a><br/>◼️<a class="ae md" href="https://towardsdatascience.com/introduction-to-python-virtual-environment-for-data-science-3c216929f1a7" rel="noopener" target="_blank">python虚拟环境数据科学入门</a><br/>◼️<a class="ae md" href="https://towardsdatascience.com/introduction-to-git-for-data-science-ca5ffd1cebbe?source=your_stories_page-------------------------------------" rel="noopener" target="_blank">git数据科学入门</a> <br/> ◼️ <a class="ae md" href="https://towardsdatascience.com/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f" rel="noopener" target="_blank">用这些技巧整理你的Jupyter笔记本</a> <br/> ◼️ <a class="ae md" href="https://towardsdatascience.com/6-simple-tips-for-prettier-and-customised-plots-in-seaborn-python-22f02ecc2393" rel="noopener" target="_blank"> 6个简单技巧让你在Seaborn (Python)中的情节更漂亮、更定制</a><br/>◼️️<br/></p><p id="8050" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">再见🏃💨</p></div></div>    
</body>
</html>