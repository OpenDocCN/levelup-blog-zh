<html>
<head>
<title>Training a StyleGAN3 in Colab | GAN | Create an NFT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Colab | GAN中训练风格GAN |创建NFT</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/training-a-stylegan3-in-colab-gan-create-nft-6dd119774644?source=collection_archive---------3-----------------------#2021-11-17">https://levelup.gitconnected.com/training-a-stylegan3-in-colab-gan-create-nft-6dd119774644?source=collection_archive---------3-----------------------#2021-11-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="1061" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">动机</h1><p id="6ead" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们已经知道<a class="ae lm" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank">生成对立网络</a>ks(gan)及其用途。NVIDIA发布的流行GAN类型之一是StyleGAN。最近他们发布了一个名为StyleGAN3的新版本。本文将介绍如何在Google Colab中微调stylegan3，并创建新的图像/NFT的艺术作品</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/55377c72f5a780677cb1a215547e9870.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7sjhyE5lWdVwkFbFXgcnvg.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">作者的图像——现代艺术</figcaption></figure><h1 id="4fa3" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Stylegan3有什么新功能？</h1><p id="7755" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">Stylegan以创造超现实质量的图像而闻名。它越来越多地用于生成艺术或任何高分辨率的图像。大多数图像是人脸或动物。</p><p id="1737" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">根据论文<a class="ae lm" href="https://arxiv.org/pdf/2106.12423.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mi"/></a><em class="mi"/>他们在下面提到。检查粗体字。</p><blockquote class="mj mk ml"><p id="0d2f" class="ko kp mi kq b kr md kt ku kv me kx ky mm mf lb lc mn mg lf lg mo mh lj lk ll im bi translated">我们将根本原因追溯到<strong class="kq iu">粗心的信号处理</strong>，这导致了发电机网络中的混叠。将网络中的所有信号解释为连续的，我们得到普遍适用的、小的架构变化，保证不需要的信息不会泄漏到分层综合过程中。由此产生的网络与<strong class="kq iu"> StyleGAN2的FID相匹配，但其内部表示方式</strong>存在显著差异，即使在亚像素级，它们也完全等变于平移和旋转。我们的结果为更适合视频和动画的<strong class="kq iu">生成模型铺平了道路</strong></p></blockquote><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mp"><img src="../Images/d6ebd528916a5b29a22c6db47b176526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4qq4u2DUEu_1rrTFh7avVA.png"/></div></div></figure><p id="23a1" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">通过评估，该团队在六个数据集(FFHQ-U、FFHQ、METFACES-U、METFACES、AFHQV2和BEACHES)上使用了StyleGAN2及其无别名StyleGAN3-T和StyleGAN3-R生成器。结果显示，StyleGAN3-T和StyleGAN3-R在弗雷歇初始距离(FID)图像质量度量方面与StyleGAN2保持竞争力，同时还表现出非常高水平的翻译等价性。</p><h1 id="244c" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">在Google Colab中训练</h1><p id="7ee6" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这些模型非常庞大，需要大量的GPU。如果你要对模型进行预训练，你需要成为Google Colab pro或pro+会员。它提供了更高的GPU。</p><p id="7864" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">用Colab提供的GPU从头开始训练StyleGAN几乎是不可能的。此外，我们不应该试图从零开始训练它。这里，好消息是我们可以使用StyleGAN2中使用的任何预训练模型。所以你花在培养时尚达人上的时间没有白费。</p><blockquote class="mj mk ml"><p id="2189" class="ko kp mi kq b kr md kt ku kv me kx ky mm mf lb lc mn mg lf lg mo mh lj lk ll im bi translated">StyleGAN3兼容使用<a class="ae lm" href="https://github.com/NVlabs/stylegan2-ada" rel="noopener ugc nofollow" target="_blank"> stylegan2-ada </a>和<a class="ae lm" href="https://github.com/NVlabs/stylegan2-ada-pytorch" rel="noopener ugc nofollow" target="_blank"> stylegan2-ada-pytorch </a>创建的旧网络pickles。(注意:在StyleGAN3代码上运行旧的StyleGAN2模型将产生与在style gan 2-ada/style gan 2-ada-py torch上运行它们相同的结果。</p><p id="2898" class="ko kp mi kq b kr md kt ku kv me kx ky mm mf lb lc mn mg lf lg mo mh lj lk ll im bi translated">为了从StyleGAN3架构中获得真正的好处，<strong class="kq iu">你需要重新培训。</strong></p></blockquote><p id="25f0" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">所以我们有以下选择。</p><ol class=""><li id="3ed9" class="mq mr it kq b kr md kv me kz ms ld mt lh mu ll mv mw mx my bi translated">从头开始训练一个模型</li><li id="d397" class="mq mr it kq b kr mz kv na kz nb ld nc lh nd ll mv mw mx my bi translated">使用NVIDIA的训练在stylegan2中提供了预训练模型</li><li id="2932" class="mq mr it kq b kr mz kv na kz nb ld nc lh nd ll mv mw mx my bi translated">获取预训练的stylegan2模型，并在stylegan3上进行微调</li></ol><h1 id="7fd0" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">设置</h1><p id="0aa2" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们将使用google colab。我们需要colab和一些额外的包，并将其与google drive连接，因为有一个会话运行时间限制。</p><h1 id="8f30" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">预处理</h1><p id="4b74" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">代码带有数据集处理工具。我们需要提到转换后的zip文件的目的地，并提供分辨率作为参数。该型号支持512x512或1024x1024图像尺寸。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ne"><img src="../Images/75880fc4debc2f4ccb684a6f2cf1e25b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WP7ZWuCLskbg4JsLBIxVyQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">图像预处理</figcaption></figure><h1 id="3bc5" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">模特培训</h1><p id="e0d5" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">一旦有了输入数据集，我们就可以开始模型训练过程了。让我们看看一些必需的培训参数</p><p id="b50f" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">outdir —保存结果的位置<br/> cfg —模型的基本配置。可以是stylegan3-t、stylegan3-r、stylegan2 <br/>数据—训练数据图像<br/>gpu—要使用的GPU数量<br/>批次—总批次大小<br/>伽马— R1正则化权重</p><p id="d426" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">有大量可选参数。我将要求你检查一下<strong class="kq iu"> train.py </strong>的文档</p><h2 id="30bd" class="nf jr it bd js ng nh dn jw ni nj dp ka kz nk nl ke ld nm nn ki lh no np km nq bi translated"><strong class="ak">从零开始训练一个模型</strong></h2><p id="939b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这个选项很简单，我们需要在没有简历的情况下用参数运行它。除非你知道自己在做什么，否则我不会推荐这种方法。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ne"><img src="../Images/fcf21c9cf62c19ddf0bf1f4fac48170b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8n5jBNZw6TwHx6Ft774cxQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">训练模型</figcaption></figure><h2 id="334d" class="nf jr it bd js ng nh dn jw ni nj dp ka kz nk nl ke ld nm nn ki lh no np km nq bi translated">从预训练模型训练模型</h2><p id="1f17" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这里，我们将使用之前训练过的任何模型，并从NVIDIA模型开始。下面是提供的一些模型。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nr"><img src="../Images/1627bf2ed33ca7c8b727e2f95860de5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Usy8Nh5RBMmyWoHqaKbzRQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">NVIDIA提供的型号</figcaption></figure><p id="7132" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">要使用预先训练的模型，请使用以下方法。这里的resume_from是我们需要传递的参数。此外，kimg是一个重要参数，它涉及GAN的总训练持续时间。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ne"><img src="../Images/537833e9591f6c68f818ac44e1ebb651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qqb6D60HcCaUJ-CwkgMxag.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">训练模型</figcaption></figure><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ns"><img src="../Images/9c7ee819f2d68302d259c85f4d140fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XECYnlSXif1Q39X3EVebGQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">模型训练日志。来源:作者</figcaption></figure><h2 id="fbf3" class="nf jr it bd js ng nh dn jw ni nj dp ka kz nk nl ke ld nm nn ki lh no np km nq bi translated">生成图像</h2><p id="37a9" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">一旦你对模型进行了足够长时间的训练，我们就可以生成图像并进行检查。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ne"><img src="../Images/806fbbc4cebeed68434de1b432e8382b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89JU9zpI1zdyi098ui82PA.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">生成图像</figcaption></figure><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/db238080e150c0a81b4c73f695990f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5F46rMIkHQWFUDpOY2TnNQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated">生成的图像</figcaption></figure><p id="338c" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">有了足够的训练和输入数据集，我们可以根据需要创建图像。</p><h1 id="c709" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">最后的想法</h1><p id="4751" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在本文中，我们看到了如何使用google colab环境运行stylegan3。生成的图像可以在NFT等各种地方使用，生成不同的对象，用例是无限的。</p><h1 id="a9d0" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">密码</h1><p id="6c69" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">本文中使用的所有代码都可以在G <a class="ae lm" href="https://colab.research.google.com/drive/1Nal3M-wjv6BeIgyTgvxhaccPFGEP6cbk?usp=sharing" rel="noopener ugc nofollow" target="_blank"> oogle colab </a>中找到。</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="2ffb" class="jq jr it bd js jt oa jv jw jx ob jz ka kb oc kd ke kf od kh ki kj oe kl km kn bi translated">订阅</h1><p id="ad9c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><em class="mi">请订阅我的</em> <a class="ae lm" href="https://codesprout.substack.com/welcome" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu"> <em class="mi">简讯</em> </strong> </a> <em class="mi">获取我的</em> <strong class="kq iu"> <em class="mi">文章的更新以及我的文章的免费代码。</em></strong></p><p id="c0db" class="pw-post-body-paragraph ko kp it kq b kr md kt ku kv me kx ky kz mf lb lc ld mg lf lg lh mh lj lk ll im bi translated">我在不同的数据科学相关产品上写作，并通过应用程序尝试新代码。在<a class="ae lm" href="https://www.linkedin.com/in/shyambv/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae lm" href="https://twitter.com/shyambv" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上联系我。</p></div></div>    
</body>
</html>