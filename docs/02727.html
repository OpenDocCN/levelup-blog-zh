<html>
<head>
<title>Centralize Your Docker Logging With FluentD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用FluentD集中您的Docker日志记录</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/centralize-your-docker-logging-with-fluentd-a2b7e0a379ce?source=collection_archive---------1-----------------------#2020-04-01">https://levelup.gitconnected.com/centralize-your-docker-logging-with-fluentd-a2b7e0a379ce?source=collection_archive---------1-----------------------#2020-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b1a2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">集中记录</h2><div class=""/><div class=""><h2 id="2ae8" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用FluentD开始将容器日志传送到集中的日志服务器</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/497834f789bf5364d6f35a0386362b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tLxVNgr7k7ymqdgd"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@htn_films?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">休伯特·纽菲尔德</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="bf48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我的上一篇文章<a class="ae lh" href="https://medium.com/@wshihadeh/docker-centralized-logging-with-syslog-97b9c147bd30" rel="noopener">中，我解释了如何使用Syslog为Docker服务实现一个集中的日志系统。所描述的方法仅适用于可用于构建基础设施的资源有一些限制或者运行现代测井系统有限制的情况。另一方面，目前有几种选择来构建一个集中的日志系统，其中之一是使用Fluentd、Elasticsearch和Kibana，也称为EFK堆栈。</a></p><div class="me mf gp gr mg mh"><a href="https://medium.com/better-programming/docker-centralized-logging-with-syslog-97b9c147bd30" rel="noopener follow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">使用Syslog集中您的Docker日志记录</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">了解我们的系统及其成功或失败的最佳方式是通过大量的日志记录</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv lb mh"/></div></div></a></div><blockquote class="mw mx my"><p id="b745" class="li lj mz lk b ll lm kd ln lo lp kg lq na ls lt lu nb lw lx ly nc ma mb mc md im bi translated">Fluentd是一个跨平台的开源数据收集软件项目，最初是在Treasure Data开发的。它主要是用Ruby编程语言编写的。<a class="ae lh" href="https://en.wikipedia.org/wiki/Fluentd" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><p id="da17" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Fluentd可用于收集应用程序日志并解析它们，以便发送到远程目的地(在我们的例子中，这将是Elasticsearch实例)或将日志存储在本地日志文件中。</p><p id="6c42" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我将演示如何在Docker Swarm中构建一个集中式日志系统，并使用Fluentd解析应用程序日志。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="8fb9" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">测井堆栈应用:</h2><p id="025a" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated"><strong class="lk jd">演示应用</strong></p><p id="35ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们需要部署的第一个应用程序是演示应用程序，它模拟为运行在集群中的服务生成日志。该应用程序可以是任何能够作为docker群服务运行并向STDOUT写入日志的应用程序。出于简单的原因，我为一个轻量级容器准备了一个Docker映像，该容器生成描述当前系统状态的日志消息。该容器的Docker图像是<code class="fe oh oi oj ok b">wshihadeh/busylogbox</code>。这个应用程序将生成如下所示的日志。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="a595" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">应用程序背后的逻辑如下所示</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="b03b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">弹性搜索</strong></p><p id="c801" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">栈需要的第二个应用程序是Elasticsearch。这个应用程序将作为日志和日志索引的数据库。换句话说，我们将配置<code class="fe oh oi oj ok b">FluentD</code>将日志转发给Elasticsearch实例，由服务存储和索引。Elasticsearch允许查看和查找基于所有可用属性的日志。我将使用官方Docker图像<code class="fe oh oi oj ok b">elastic/elasticsearch:7.5.1</code>来部署服务。</p><p id="d3ef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">基巴纳</strong></p><p id="1a48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个应用程序为我们提供了一个简单而直观的web界面来连接到Elasticsearch服务，查看日志，查询日志，使用多种类型的图表和更多功能来可视化日志。为了部署Kibana，我将使用最新的官方Docker图片<code class="fe oh oi oj ok b">elastic/kibana:7.5.1</code>。</p><p id="81ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">流体化</strong></p><p id="3f23" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用Fluentd来收集应用程序日志，解析它们，然后将它们转发给Elatsicsearch实例。为了实现这个目标，我决定构建一个Docker映像，其中包含运行Fluentd和解析日志所需的所有库和配置。下面是转换Flunetd配置和构建Docker映像的逐步说明。</p><p id="bb05" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">流体配置</strong></p><p id="bc71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">FlunetD配置中的第一部分是源部分，该部分定义了将由Flunetd解析的日志文件。在docker世界中，容器被期望将日志写到容器的<strong class="lk jd"> STDOUT </strong>中，Docker还提供了一种为每个容器配置日志驱动程序的方法。这意味着我们可以配置docker将日志直接转发到Fluentd实例，然后使用<strong class="lk jd"> forward source部分配置Fluentd，</strong>但是，我不喜欢这种想法，原因如下:</p><ul class=""><li id="67c8" class="on oo it lk b ll lm lo lp lr op lv oq lz or md os ot ou ov bi translated">Docker集群上的命令行将不提供日志。</li><li id="ce9e" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated">如果Flunetd服务关闭，会有丢失一些日志的风险。</li></ul><p id="c0d7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">出于以上原因，我建议继续使用Docker默认日志驱动程序<code class="fe oh oi oj ok b">json-file</code>，并使用一个<strong class="lk jd">尾源部分。</strong>默认情况下，每个docker容器都会在下面的路径下有一个日志文件<strong class="lk jd">/var/lib/Docker/containers</strong>该文件中的日志与发送到Docker容器的STDOUT的日志相同，也与使用<code class="fe oh oi oj ok b">docker logs</code>命令显示的日志相同。下面是指示Flunetd开始跟踪所有部署的docker容器的日志文件所需的配置，并简要描述了配置中使用的最重要的键</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><ul class=""><li id="a7ee" class="on oo it lk b ll lm lo lp lr op lv oq lz or md os ot ou ov bi translated"><strong class="lk jd"> @type </strong>:该属性定义了输入插件的类型，如上所述Flunetd支持多个<a class="ae lh" href="https://docs.fluentd.org/input" rel="noopener ugc nofollow" target="_blank">输入插件</a>。</li><li id="5215" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><strong class="lk jd"> @id </strong>:代表输入源的唯一标识符。</li><li id="2dbe" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><strong class="lk jd">路径</strong>:要读取的文件的路径。</li><li id="0b2b" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><strong class="lk jd">位置文件</strong>:位置文件的路径。用于存储最后一次读取位置的文件。</li><li id="616f" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><strong class="lk jd">标签</strong>:用于标记来自该输入的日志消息的标签。</li><li id="834c" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><strong class="lk jd">格式</strong>:输入数据的预期格式。</li></ul><p id="e621" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦配置了输入源，我们就可以开始处理日志消息并对这些消息执行操作。我通常做的第一件事是将Docker元数据添加到日志消息中，比如服务名称空间、服务名称和容器名称。这个任务可以使用<a class="ae lh" href="https://github.com/wshihadeh/fluent-plugin-filter-docker_metadata" rel="noopener ugc nofollow" target="_blank"> docker_metadata </a>插件来完成。下面是将这些属性附加到从定义的输入源读取的所有日志消息所需的配置(标记是选择这些日志的关键)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="2f54" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下一步是根据属性对日志进行分类，以便能够单独处理它们。在swarm集群托管具有不同日志格式的应用程序，并且需要不同地解析来自这些应用程序的日志的情况下，这是非常重要的一步。这也适用于我们试图构建的堆栈，因为上述每个应用程序都有不同的日志格式，因此我们需要分别处理它们。为了简单起见，我决定只解析和转发演示应用程序的日志。来自其他应用程序的日志将被忽略。下面是我用来根据Docker属性<code class="fe oh oi oj ok b">container_name</code>对日志进行分类的配置。如图所示，<code class="fe oh oi oj ok b">busylogbox</code>日志将被标记为<code class="fe oh oi oj ok b">row.busyboxlog.*</code>标签，而其他应用程序的日志将被标记为<code class="fe oh oi oj ok b">ignore.dlog</code>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="c3dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们需要处理应用程序的日志。一方面，我们会忽略所有带有<code class="fe oh oi oj ok b">ignore.**</code>标签的日志消息。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="be64" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一方面，需要解析<code class="fe oh oi oj ok b">busylogbox</code>日志，并从日志消息中提取更多的属性，以便能够在Kibana中使用它们，并基于提取的属性构建图表和可视化。为了完成这个任务，我将使用<code class="fe oh oi oj ok b">record_reformer</code>插件来修改日志消息并给消息添加属性。此外，需要Ruby Regex来提取每个属性的值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="f990" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦我们完成了对应用程序日志消息的解析，我们就可以对日志消息执行最终检查，以删除所有空属性并为已定义的属性提供默认值。以下是可用于完成此任务的配置。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="68b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后一步是配置Flunetd将日志转发给Elasticsearch实例。这个任务可以通过使用Elasticsearch插件来完成，下面是实现forward特性所需的配置。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="fdd6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在一段时间内与Elasticsearch的连接不可用的情况下，配置缓冲区对于不断重试向Elasticsearch发送日志非常重要。在这些情况下，Flunetd会将日志消息写入定义的缓冲区，并不断尝试将这些日志发送到Elasticsearch实例。</p><p id="6888" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">建立基础码头工人形象</strong></p><p id="0bd2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们已经完成了Fluentd配置的编写，下一步是将Fluentd服务部署到docker swarm。因此，我们首先需要构建一个定制的docker映像，其中包含解析日志所需的所有依赖项(Flunetd插件和配置)。</p><p id="bc38" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于安装这些库和插件需要一些时间，我决定构建一个包含这些库的Fluentd基础映像，然后使用这个基础映像构建Fluentd docker映像来收集日志。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="3e9a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上述Docker文件用于生成基于官方Fluentd Docker图像<code class="fe oh oi oj ok b">fluent/fluentd:v1.2.2-onbuild</code>的Fluentd基本图像。基本映像的docker文件包括安装解析日志所需的插件的指令，例如<strong class="lk jd">fluent-plugin-filter-docker _ metadata、</strong>，这是一个将docker元数据附加到记录的消息的插件，例如容器名称，插件"<strong class="lk jd">fluent-plugin-elasticsearch "</strong>用于将日志转发到elastic search实例。</p><p id="fbf0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">构建浮动Docker图像</strong></p><p id="40ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用Flunetd的基本映像可以非常容易、快速和简单地构建包含所需配置的Flunetd Docker映像。下面是这样一个映像的docker文件示例，它只负责将Flunetd配置和入口点包含到docker映像中。这种方法的主要好处是，在更改只影响Flunetd配置的情况下，构建docker映像会快得多。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="4b06" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">部署演示堆栈</strong></p><p id="8475" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面提到的所有应用程序都可以简单地使用下面的Docker堆栈文件部署到Swarm集群。下面的堆栈文件包括Fluentd、Busylogbox、Elasticsearch和Kibana的服务定义。关于Fluentd配置的一个重要注意事项是，需要使用<code class="fe oh oi oj ok b">global</code>模式部署服务，以确保我们在每个Docker swarm主机上部署Fluentd容器，以便从这些节点上的所有容器中收集日志。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="fbc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过在Docker Swarm manager节点上执行下面的命令，可以简单地部署上面的堆栈。</p><pre class="ks kt ku kv gt pb ok pc pd aw pe bi"><span id="1214" class="nk nl it ok b gy pf pg l ph pi">$ docker stack deploy -c docker-stack-fke.yml logging</span></pre><p id="9862" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">查看基巴纳的日志</strong></p><p id="d8e7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦部署了服务，并且Elasicsearch和Kibana是健康的和可访问的，我们就可以通过配置Kibana来查看日志。为此，我们需要在以下URL <code class="fe oh oi oj ok b"><a class="ae lh" href="http://127.0.0.1:5601." rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:5601</a></code>下连接到Kibana web界面。然后添加一个新的索引对象，如下图所示</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/e4dfc5be24db6016934431bed8a9d024.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E56YKlCrdSJ-71Z7Enh3Jg.png"/></div></div></figure><p id="7ee7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦创建了索引，搜索页面中的日志将是可行的，您可以开始基于解析的属性过滤日志</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/67493b4bf66c8c67afef5eee9189c0a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VI4SoaJDDC_JY22tsgVFQQ.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pl"><img src="../Images/3d3d74691e728cdfedd0eec4d75d5244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1o0bqQq6CLsEUKpWYibE0Q.png"/></div></div></figure><p id="9f72" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如上图所示，经过解析的属性将出现在Kibana web界面中，最终用户可以根据这些属性过滤日志、构建可视化、图表和仪表板。</p><p id="7c41" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">结论</strong></p><p id="4ee0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">系统日志不是实现集中式日志记录系统的唯一方式😆事实上，还有其他几种选择来实现它。Fluentd结合Elasticsearch和Kibana被认为是构建集中式日志系统的另一种方法。此外，Fluentd为我们提供了一种从日志消息中分析、解析和提取属性的简单方法，因此基于这些属性可视化和查询日志变得更加容易。</p></div></div>    
</body>
</html>