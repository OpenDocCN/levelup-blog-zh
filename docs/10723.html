<html>
<head>
<title>Artificial Intelligence Project: Pose Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能项目:姿态检测</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/artificial-intelligence-project-pose-detection-564dead6f10c?source=collection_archive---------10-----------------------#2022-01-04">https://levelup.gitconnected.com/artificial-intelligence-project-pose-detection-564dead6f10c?source=collection_archive---------10-----------------------#2022-01-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d149" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我被问了很多问题，如何使用人工智能来检测特定的posepostures，以及是否有可能从中获得情感。</p><p id="aeb1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗯，我和我的同事决定试试人工智能追踪。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/f7cde772d6bddabf7650211e0a1ac4c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*uQfcLAM1HwXrS_v6p6BovQ.png"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kv"><img src="../Images/2911d5dca123a3919bc7f7c8752701ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*0OaZ-pRyETLDnSHG0-Mleg.png"/></div></figure><p id="fd12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图是最终目标，使用人工智能识别姿势并最终识别情绪。</p><h1 id="ae5a" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">设置我们的环境</h1><p id="5db6" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">我们将使用open CV进行图像识别，使用media pipe进行姿势识别。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="cbb9" class="me kx iq ma b gy mf mg l mh mi">!pip install mediapipe opencv-python</span></pre><p id="273a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将只使用两个依赖项和时间来设置opencv中的实时提要。</p><p id="1533" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了设置我们的实时提要，我们需要导入我们的依赖项；</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="2099" class="me kx iq ma b gy mf mg l mh mi">import mediapipe as mp<br/>import cv2</span></pre><p id="40bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从设置媒体管道开始</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="4ca1" class="me kx iq ma b gy mf mg l mh mi">mp_drawing = mp.solutions.drawing_utils<br/>mp_holistic = mp.solutions.holistic</span></pre><p id="ef37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们设置了绘图工具，通过open cv将我们整体模型中的不同检测绘制到屏幕上。</p><p id="83b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么整体性只是引入了我们的整体性模型。</p><p id="7b28" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在媒体管道中，我们有各种各样的模型可以使用，即:</p><p id="8832" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人脸网格，虹膜，手，姿势，整体，自拍分割。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/c18e29695a068e2b8105fe96322547bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VBMNqFmh3IGw-xN-733c7g.png"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mo"><img src="../Images/e08c8c1f9e5114a5992d0a25ae3315eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XK_qj3dk9KJ_sGjkknewKg.png"/></div></div></figure><p id="9e78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们要设置开放的实时成像cv；</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="885e" class="me kx iq ma b gy mf mg l mh mi">cap = cv2.VideoCapture(0)<br/>while cap.isOpened():<br/>    ret, frame = cap.read()<br/>    cv2.imshow('Real Time Imaging', frame)<br/>    <br/>    if cv2.waitKey(10) &amp; 0xFF == ord('q'):<br/>        break</span><span id="b3e3" class="me kx iq ma b gy mp mg l mh mi">cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="be72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将第一行代码声明为变量cap，并将cv2(调用open cv的别名)分配给VideoCapture，并选择0作为默认摄像头端口。</p><p id="325e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们开始我们的wile循环，通过告诉open cv当cap，我们的变量是开放的，然后返回frame并读取/渲染cap到屏幕上。</p><p id="90f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们使用imshow函数来渲染帧中的图像，并将该帧标记为实时成像。</p><p id="f661" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的条件if语句开始语句的break部分，我们对cv2说等待10毫秒，然后当我按q时，中断正在运行框架的while循环。</p><p id="bea5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后释放程序，打破所有窗口。</p><p id="88a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有时从if语句中，break和q不起作用，因此我们可以只使用下面的代码。只是为了确保密码被破解。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="04ce" class="me kx iq ma b gy mf mg l mh mi">cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="44cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们想将我们的媒体管道整体组件覆盖到opencv上。</p><p id="cbb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先将开放的cv代码复制到下一个Jupyter单元格，然后我们将整体代码添加到其中。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="ba85" class="me kx iq ma b gy mf mg l mh mi">cap = cv2.VideoCapture(0)<br/>with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:<br/>    while cap.isOpened():<br/>         ret, frame = cap.read()<br/>         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<br/>         results = holistic.process(image)<br/>         print(results)<br/>         cv2.imshow('Real Time Imaging', frame)<br/>    <br/>         if cv2.waitKey(10) &amp; 0xFF == ord('q'):<br/>             break</span><span id="08c6" class="me kx iq ma b gy mp mg l mh mi">cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="dc4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们添加的新代码，使用了wit语句和我们之前导入的MP _ global。在MP . global方法中，我们添加了min_detection_confidence和min_tracking_confidence，并将其赋值为0.5。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="b18f" class="me kx iq ma b gy mf mg l mh mi">with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:</span></pre><p id="c12b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们会将整个行设置为整体，因为我们不想每次都键入整体。</p><p id="4ba0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于具有高跟踪置信度的模型，我们可以将min_detection置信度和min_tracking_confidence设置为更高的值。</p><p id="1b16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还添加了以下代码行:</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="410c" class="me kx iq ma b gy mf mg l mh mi">image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<br/>         results = holistic.process(image)<br/>         print(results)</span></pre><p id="d5c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一行代码我们重新着色我们的图像，抓取我们上面的框架，并使用cv2重新着色框架中返回的内容。COLOR-BGR2RGB，我们希望模型的颜色用RGB表示。</p><p id="ef2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将正在重新着色的图像传递给整体模型，并分配一个名为results的变量。然后我们打印出我们的结果，因为我们还没有在屏幕上画任何东西。</p><p id="51dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们运行代码时，我们会看到一个弹出窗口。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/65fc46757b78e48e877d384610cbd75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*KdCXo8lhUs9_tE3L71PuDQ.png"/></div></figure><p id="5934" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后打印出我们需要的东西，只是为了检查我们是否还在按计划进行。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mr"><img src="../Images/59cb8a679f663bae2803ef3c1285b4e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QN8m2hHVXlhFTX3Cp0UuJw.png"/></div></div></figure><p id="5e6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们已经检查了所有工作正常，我们可以继续前进，并绘制到我们的屏幕上，从面部标志开始，我们可以删除打印并添加绘制。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="7f21" class="me kx iq ma b gy mf mg l mh mi">image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)<br/>mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)<br/>         cv2.imshow('Real Time Imaging', frame)</span></pre><p id="82ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一行代码image = cv2.cvtColor(image，cv2。COLOR_RGB2RGB2)将图像的渲染从BGR(我们在上面进行了转换)转换回RGB，因为这是open cv想要的图像。</p><p id="bf51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们继续绘制，使用mp_drawing.draw_landmarks，我们从上面传入图像变量，从我们的face_landmarks和MP . overall . face mesh _ TESSELATION模型传入结果。</p><p id="4629" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们想改变我们正在渲染的图像，所以我们想把我们的原始帧图像改变成我们的图像变量。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ms"><img src="../Images/caf03ee711f4616716e01a422e206711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*abIfRvA1zIJauGz0a7qZ8g.png"/></div></div></figure><p id="4185" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们在屏幕上画出了我们所有不同的面部标志，这很酷也很吓人，我向任何方向移动我的脸，它都会跟踪我的脸。</p><p id="5ab0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们要画出我们的其他标志，也就是姿势，右手和左手。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/1ca25f9dc90e9fdd2b71be773041afc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*bP1n9mzN5kZrRq91hMjo8Q.png"/></div></figure><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="ac74" class="me kx iq ma b gy mf mg l mh mi">mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)<br/>         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)<br/>         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)<br/>         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)<br/>         cv2.imshow('Real Time Imaging', image)</span></pre><p id="fd17" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如上面看到的，这个模型正在跟踪我的脸，左右手，包括我的姿势，非常准确，非常快。我们也可以用姿态跟踪来跟踪整个身体。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/e639e8283fda1d03ce998b54948a9dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*eFFxSQJlQPreCgjGCgrRWA.png"/></div></figure><p id="7bbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有白色和红色，我们想给我们的地标上色，我们将通过使用绘图规范模型来完成。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="9ae4" class="me kx iq ma b gy mf mg l mh mi">mp_drawing<strong class="ma ir">.</strong>DrawingSpec(color<strong class="ma ir">=</strong>(0,0,255), thickness<strong class="ma ir">=</strong>2, circle_radius<strong class="ma ir">=</strong>2)</span></pre><p id="2064" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们能够传递颜色、粗细和圆的半径，我们要传递线条和圆的颜色。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="0ce8" class="me kx iq ma b gy mf mg l mh mi">mp_drawing<strong class="ma ir">.</strong>DrawingSpec(color<strong class="ma ir">=</strong>(0,0,255), thickness<strong class="ma ir">=</strong>2, circle_radius<strong class="ma ir">=</strong>2)</span></pre><p id="1805" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将这样做的脸，姿势和手。</p><pre class="ko kp kq kr gt lz ma mb mc aw md bi"><span id="9bda" class="me kx iq ma b gy mf mg l mh mi">cap = cv2.VideoCapture(0)<br/># Initiate holistic model<br/>with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:<br/>    <br/>    while cap.isOpened():<br/>        ret, frame = cap.read()<br/>        <br/>        # Recolor Feed<br/>        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<br/>        # Make Detections<br/>        results = holistic.process(image)<br/>        # print(results.face_landmarks)<br/>        <br/>        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks<br/>        <br/>        # Recolor image back to BGR for rendering<br/>        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)<br/>        <br/>        # 1. Draw face landmarks<br/>        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, <br/>                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),<br/>                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)<br/>                                 )<br/>        <br/>        # 2. Right hand<br/>        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, <br/>                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),<br/>                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)<br/>                                 )</span><span id="f7d5" class="me kx iq ma b gy mp mg l mh mi"># 3. Left Hand<br/>        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, <br/>                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),<br/>                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)<br/>                                 )<br/> # 4. Pose Detections<br/>        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, <br/>                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),<br/>                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)<br/>                                 )<br/>                        <br/>        cv2.imshow('Raw Webcam Feed', image)</span><span id="d5fb" class="me kx iq ma b gy mp mg l mh mi">if cv2.waitKey(10) &amp; 0xFF == ord('q'):<br/>            break</span><span id="0cb1" class="me kx iq ma b gy mp mg l mh mi">cap.release()<br/>cv2.destroyAllWindows()</span></pre><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/eeb28ce6641c4a7f7d337482bdcf0d28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*BCP0j9Ryo8SY2O9st7AdoA.png"/></div></figure><p id="7584" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它看起来颜色更好，这是我们跟踪的第一步。</p><h1 id="8bef" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">附加阅读</h1><div class="mw mx gp gr my mz"><a href="https://google.github.io/mediapipe/" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">主页</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">MediaPipe为直播和流媒体提供跨平台、可定制的ML解决方案。</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">google.github.io</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn kt mz"/></div></div></a></div><div class="mw mx gp gr my mz"><a href="https://colab.research.google.com/drive/1LXvSRpg0hNMT9u00p3sJmUweaXGYmtVW?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">谷歌联合实验室</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">编辑描述</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">colab.research.google.com</p></div></div><div class="ni l"><div class="no l nk nl nm ni nn kt mz"/></div></div></a></div></div></div>    
</body>
</html>