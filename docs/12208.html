<html>
<head>
<title>An Introduction to Web Scraping in Python with Practical Examples</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中Web抓取的介绍及实例</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/an-introduction-to-web-scraping-in-python-with-practical-examples-aa6adee93487?source=collection_archive---------15-----------------------#2022-05-23">https://levelup.gitconnected.com/an-introduction-to-web-scraping-in-python-with-practical-examples-aa6adee93487?source=collection_archive---------15-----------------------#2022-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a877" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何用Python构建Web Scraper</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/32e7b96dca30fda124b314d9fa4d96d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ptgEgd-MZ4d3pHFxiLTFfg.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jacksonsophat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Jackson So </a>在<a class="ae ky" href="https://unsplash.com/s/photos/html?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><h2 id="1303" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">什么是网络抓取</h2><p id="7e59" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">根据维基百科，</p><blockquote class="mo mp mq"><p id="2c74" class="lv lw mr lx b ly ms ju ma mb mt jx md mu mv mf mg mw mx mi mj my mz ml mm mn im bi translated">Web抓取、web采集或web数据提取是用于从网站提取数据的数据抓取。网络抓取软件可以使用超文本传输协议或网络浏览器直接访问万维网。虽然web抓取可以由软件用户手动完成，但该术语通常指的是使用bot或web crawler实现的自动化过程。这是一种复制形式，从web上收集并复制特定数据，通常复制到本地中央数据库或电子表格中，以供以后检索或分析。</p></blockquote><h2 id="8deb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">网络报废合法吗</h2><p id="dd39" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在您开始删除任何网页上的数据之前，您应该查看该网站上关于网络抓取的指南。清理指南位于名为robots.txt的文件中。Robots.txt是由网站管理员创建的文件，用于指定允许清理的数据类型。比如这里是Instagram的<code class="fe na nb nc nd b">robots.txt </code>文件截图。</p><p id="43bc" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">确保您在任何刮擦活动之前总是检查该文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/a17e62742b81dc00c062ff2b6a42a3c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fWiT38_CDTpXnNtiIPrlVg.png"/></div></div></figure><p id="3ac3" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">需要注意的几个重要事项是:</p><ul class=""><li id="b65d" class="nf ng it lx b ly ms mb mt li nh lm ni lq nj mn nk nl nm nn bi translated">每隔一段时间刮一下，以免服务器不堪重负。</li><li id="4a4b" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">缓存重新请求的数据，这样您就不必继续获取它。</li></ul><h2 id="7ca4" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">网页是如何工作的？</h2><p id="8ba0" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在开始web抓取之前，您需要了解web页面是如何构造的。</p><p id="7fae" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">标准网页包含以下元素:</p><ul class=""><li id="2a4a" class="nf ng it lx b ly ms mb mt li nh lm ni lq nj mn nk nl nm nn bi translated">文本</li><li id="c88e" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">形象</li><li id="2e84" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">录像</li><li id="f878" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">不同文件格式的文件</li></ul><p id="0954" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">您可以通过右键单击并选择查看页面源代码来检查任何网页的源代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/6a6142c75a0e73d2f58e1355abd08fba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RnulucSRG-7BMwzTJucfWQ.png"/></div></div></figure><p id="6bc4" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">单击查看页面源代码选项后，您应该会看到类似这样的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/f3d4e58e6961ceb2fde1d7e3cb62e7d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COwMDvMT9PJh1_vrGoJfyQ.png"/></div></div></figure><h2 id="2b73" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">请求库</h2><p id="7e42" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">Requests是一个简单的python库，用于执行HTTP请求。首先，用pip安装请求。</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="d75f" class="kz la it nd b gy nz oa l ob oc">pip install requests</span></pre><p id="2cd2" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">例如，假设您的某个网页出现宕机，您希望确保该网站仍然正常运行，您可以这样做:</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="225a" class="kz la it nd b gy nz oa l ob oc">import requests<br/>url = '<a class="ae ky" href="https://github.com/'" rel="noopener ugc nofollow" target="_blank">https://github.com/'</a><br/>resp = requests.get(url)<br/>print(resp.status_code)</span></pre><p id="d075" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将是:</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="fa5a" class="kz la it nd b gy nz oa l ob oc">200</span></pre><p id="eda2" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">状态代码200表示请求已经成功。一旦得到响应，就从其内容中获取数据。<br/>响应将是HTML格式的，要获取所需的数据，您需要一个更强大的工具，即Beautiful soup。</p><h2 id="d480" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">美丽的声音</h2><p id="8a9d" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">根据文件显示，</p><blockquote class="mo mp mq"><p id="fd75" class="lv lw mr lx b ly ms ju ma mb mt jx md mu mv mf mg mw mx mi mj my mz ml mm mn im bi translated"><a class="ae ky" href="http://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank"> Beautiful Soup </a>是一个Python库，用于从HTML和XML文件中提取数据。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。它通常为程序员节省数小时或数天的工作。</p></blockquote><p id="59b4" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">数据搜集包括3个步骤:</p><ul class=""><li id="7272" class="nf ng it lx b ly ms mb mt li nh lm ni lq nj mn nk nl nm nn bi translated">发送GET请求以获取网页内容</li><li id="108c" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">过滤网页内容</li><li id="46d0" class="nf ng it lx b ly no mb np li nq lm nr lq ns mn nk nl nm nn bi translated">从网页元素中提取数据</li></ul><p id="f006" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">第一步，用pip安装美汤。</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="4e19" class="kz la it nd b gy nz oa l ob oc">pip install beautifulsoup4</span></pre><p id="d7c2" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">假设您有一个包含以下数据的简单html页面:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="13f1" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">使用beautifulsoup，让我们开始搜集数据。假设您想要获得页面上每个元素的所有细节。您需要从标签中提取文本</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="020a" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">在上面的代码中，我们首先导入漂亮的soup，创建一个对象并解析页面细节。现在可以使用soup对象从元素标记中获取数据。</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="05b9" class="kz la it nd b gy nz oa l ob oc">print(soup.h1)</span><span id="b1ac" class="kz la it nd b gy of oa l ob oc">print(soup.h3)</span><span id="f75d" class="kz la it nd b gy of oa l ob oc">print(soup.ul)</span></pre><p id="669d" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将是:</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="b1b1" class="kz la it nd b gy nz oa l ob oc">&lt;h1&gt;My First Heading&lt;/h1&gt;<br/>&lt;h3&gt;My Third Heading&lt;/h3&gt;<br/>&lt;ul&gt;<br/>&lt;li&gt;Liam James&lt;/li&gt;<br/>&lt;li&gt;William Jones&lt;/li&gt;<br/>&lt;li&gt;Charlotte wesly&lt;/li&gt;<br/>&lt;li&gt;Carol Lucas&lt;/li&gt;<br/>&lt;li&gt;Harper James&lt;/li&gt;<br/>&lt;li&gt;Theodo</span></pre><p id="ee5b" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">假设您想获得页面上每个元素的所有细节，即html页面中包含的人名，您需要从标签中提取文本。<br/>因为我们知道我们的名字包含在<code class="fe na nb nc nd b">&lt; li&gt; t</code> ag中，所以我们可以指定属性并立即获得所有实例。</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="4041" class="kz la it nd b gy nz oa l ob oc">print(soup.find_all('li'))</span></pre><p id="449a" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将会是</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="0e33" class="kz la it nd b gy nz oa l ob oc">[&lt;li&gt;Liam James&lt;/li&gt;, &lt;li&gt;William Jones&lt;/li&gt;, &lt;li&gt;Charlotte wesly&lt;/li&gt;, &lt;li&gt;Carol Lucas&lt;/li&gt;, &lt;li&gt;Harper James&lt;/li&gt;, &lt;li&gt;Theodore Mason&lt;/li&gt;]</span></pre><p id="fe30" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">正如您所看到的，我们得到了所有的名字，而soup在一个列表中返回数据。为了去掉上面的<code class="fe na nb nc nd b"> li </code>标签，我们使用<code class="fe na nb nc nd b">soup.get_text()</code></p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="a443" class="kz la it nd b gy nz oa l ob oc">all_names = [name.get_text() for name in names]</span><span id="fac0" class="kz la it nd b gy of oa l ob oc">print(all_names)</span></pre><p id="bbf7" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将是:</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="5356" class="kz la it nd b gy nz oa l ob oc">['Liam James', 'William Jones', 'Charlotte wesly', 'Carol Lucas', 'Harper James', 'Theodore Mason']</span></pre><p id="47bb" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">正如您所看到的，我们已经成功地将HTML中的名字提取到一个更容易操作的列表中。</p><h2 id="c6c3" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">如何刮维基百科</h2><p id="2845" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在这一节中，我们将从维基百科中搜集数据。下面一页展示了我最喜欢的电视剧《吸血鬼日记》的所有演员阵容。<br/>演员阵容分为主要角色和循环角色。要检查源代码并获取元素，右键单击您想要抓取的元素并选择“inspect ”,如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/dacb6fba142931c3036cce4a99449bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zgYrxTWEh50YedqVcYaPTg.png"/></div></div></figure><p id="9265" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">正如您在上面看到的，演员的数据包含在<code class="fe na nb nc nd b">&lt;span class = “toctext”&gt;</code>中。所以让我们用美丽的汤来寻找那个特定的元素。</p><p id="81b9" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">为了使用beautiful soup按类进行搜索，我们使用<code class="fe na nb nc nd b"> .find_all() </code>并指定类名作为参数，就像我们前面使用<code class="fe na nb nc nd b">li</code>标签所做的那样</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="4d0c" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将是:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="2bbf" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">因为我们只需要主要字符，所以让我们截断列表。</p><pre class="kj kk kl km gt nv nd nw nx aw ny bi"><span id="e205" class="kz la it nd b gy nz oa l ob oc">print(names[:15])</span></pre><p id="f336" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">结果将会是，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="093b" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">然后，您可以将数据加载到数据帧中。</p><div class="oh oi gp gr oj ok"><a href="https://betterprogramming.pub/how-to-use-pandas-to-consume-data-and-perform-data-analysis-76e000ad5480" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">如何使用熊猫消费数据和执行数据分析</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">熊猫数据分析导论</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">better编程. pub</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><h2 id="0e37" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h2><p id="2ab4" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">本教程只是触及了你可以用漂亮的汤做些什么的表面。美丽的汤<a class="ae ky" href="https://beautiful-soup-4.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">文档</a>非常广泛，将涵盖你做更多数据搜集所需的一切。</p><p id="bc54" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">如果你喜欢这个，你可能也会喜欢？</p><div class="oh oi gp gr oj ok"><a href="https://medium.com/codex/how-to-read-and-write-to-csv-files-in-python-380dabec30b4" rel="noopener follow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">如何在Python中读写CSV文件</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">了解如何使用Pandas和CSV库操作CSV文件</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">medium.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy ks ok"/></div></div></a></div><p id="3aee" class="pw-post-body-paragraph lv lw it lx b ly ms ju ma mb mt jx md li mv mf mg lm mx mi mj lq mz ml mm mn im bi translated">我每周发布Python教程，<a class="ae ky" href="https://essyking.medium.com/" rel="noopener">关注</a>了解更多。</p></div></div>    
</body>
</html>