<html>
<head>
<title>Actor-critic Algorithm, Simplified: Essential for Finance and Financial Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">演员-评论家算法，简化:金融和金融工程的基本</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/actor-critic-algorithm-simplified-essential-for-finance-and-financial-engineering-3ebc9ec78467?source=collection_archive---------8-----------------------#2022-08-18">https://levelup.gitconnected.com/actor-critic-algorithm-simplified-essential-for-finance-and-financial-engineering-3ebc9ec78467?source=collection_archive---------8-----------------------#2022-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="5391" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对算法及其应用和缺点的简单介绍</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/705244af197b0b18369c3aa4547391d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9nI8kvFgHRGRSe-Mj7x8Q.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由来自Pexels的<a class="ae le" href="https://www.pexels.com/@pixabay/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><p id="63a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">行动者-批评家算法是一种强化学习方法，它将价值函数估计与策略搜索结合起来[3][4]。行动者-批评家算法的目标是学习什么行动是最优的，以及如何最优地执行这些行动[6][7]。</p><p id="d074" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">强化学习中的行动者-评论家算法可以应用于金融，因为它们能够学习和改进政策，这是因为行动者-评论家方法可以逼近价值函数，将它们设置为估计回报的用例，并改进这些政策。此外，这些算法可能比其他方法收敛得更快(例如，与Q-learning相比)[8][9]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lf"><img src="../Images/5a72e9dbfc8d80bfb3a56cd533994517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-g5q8hC0uKrh5x0mHFZJbQ.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Pexels的<a class="ae le" href="https://www.pexels.com/@rodolfoclix/" rel="noopener ugc nofollow" target="_blank"> Rodolfo Clix </a></figcaption></figure><p id="44a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">算法背后的目标</strong></p><p id="614a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">演员-评论家算法背后的关键思想是，代理人可以通过使用类似于这种两步方法的过程来改善其行为[10]:首先，它估计每个动作(“演员”)的预期回报。随后，它根据该评估执行最佳行动(“批评家”)。</p><p id="f9d2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在许多情况下，如在线学习或当存在高维连续状态空间时，这一两步过程可以通过为每项任务使用单独的神经网络来完成:一个网络学习预测回报(“参与者”)[16]。相比之下，另一个网络通过选择给定估计值的动作来学习(“批评家”)[10]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lg"><img src="../Images/b64439c81c854f64a8ab2ad0e4af92d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OAMfoU_tjIK7jNVUsZf0dw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Pexels的照片</figcaption></figure><p id="b56b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">潜力</strong></p><p id="a1ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">后者中概述的这种分离有几个优点。价值函数可能比政策收敛得更慢，因为它们致力于预期的未来回报[17]；平均而言，额外的时间步长[18]影响时间范围内<em class="lh"> n </em>增加的每个因素。这意味着，如果我们希望我们的代理人有长远的眼光[19]，我们可能需要识别非常慢的学习者或多个抽象层次[19]，这两者都会产生影响(如计算费用)[3]。除了这种影响之外，由于维度复杂性增加，收敛速度可能会呈指数级增长。</p><p id="1f64" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">结合价值函数估计和策略搜索可能有助于克服演员-评论家算法的一些缺点。例如，虽然纯粹的策略搜索方法可能会陷入局部最优[20]，但添加价值函数[21]可以提供指导，帮助代理逃离这些次优[22]区域。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi li"><img src="../Images/c8958cab6588df0f2a0fa0acb9d1bacd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZuGpem9O_o6ug8eLD4V2Og.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Pexels的照片</figcaption></figure><p id="e7e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">小心接近</strong></p><p id="6166" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">演员-评论家算法并非没有缺点。特别是，它们往往比其他强化学习方法更复杂——无论是在概念上还是在计算上——并且可能需要更多的努力才能正确实现。尽管有一些缺点，这些算法在一些环境中还是很有前途的——包括投资组合管理、风险规避和定价。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lj"><img src="../Images/edd32770621f578849702f2bdd4a6630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8iAxfku7NvYotIlmbwwqXA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由来自Pexels的<a class="ae le" href="https://www.pexels.com/@pixabay/" rel="noopener ugc nofollow" target="_blank">皮克斯贝</a></figcaption></figure><p id="2711" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">还有:优势演员评论家(A2C)和异步优势演员评论家(A3C) </strong></p><p id="a020" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一般了解强化学习算法的类型:基于值的和基于策略的。Advantage Actor Critic)是一种基于策略的算法，已成功用于许多具有挑战性的任务，如下围棋和国际象棋[25]。异步优势行动者批评家(A3C)是A2C的一个扩展，它使用多个工作者来并行化训练过程[26]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lk"><img src="../Images/cf59b373a523bdacf2e73695ba7c60b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-QuaCBJs7R_51nY5AuVjkQ.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Pexels的玛格达·埃勒斯</figcaption></figure><p id="b5ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">金融领域的用例</strong></p><p id="c1d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">演员-评论家算法可以应用于金融应用，如投资组合管理和定价(如衍生品)。在投资组合管理的情况下，参与者可以是预测股票价格的神经网络，而评论家将根据实际价格数据评估预测的价格以训练网络。类似地，在衍生产品定价中，参与者可以根据过去的价格数据预测未来的股票价格，而批评家可以将这些预测与市场价格进行比较，以评估准确性。一般来说，用例包括预测价格和优化投资组合。</p><p id="3978" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">金融业的实施仍在继续，因为该算法可以帮助识别价值——是被高估的投资吗？传统的分析方法可以用于这种算法整合:估值过高的投资是对研究资产当前价格与其估计公允价值之间差异的评估。总的来说，潜力在于从以前的数据中学习(描述性分析),并将这些知识应用于未来的定价决策。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ll"><img src="../Images/430d59bcf8a29a272f0460b0f3a32dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UX5cs6g5nJtTk9NnPv5Qmg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Pexels的cottonbro</figcaption></figure><p id="5f82" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">离别的思念</strong></p><p id="4fe7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你对这篇文章的编辑有任何建议，或者对进一步扩展这个主题领域有什么建议，请和我分享你的想法。</p><p id="af29" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另外，请考虑订阅我的每周简讯 </p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="baaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">我创建了这个列表，把我所有的金融工程文章放在一起:</strong></p><div class="lt lu gp gr lv lw"><a href="https://medium.com/@AnilTilbe/list/1bc857a2c2d4" rel="noopener follow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">金融工程:我的帖子</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">我关于金融工程的帖子。</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">medium.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ky lw"/></div></div></a></div><p id="952b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我看来，这里有一些你应该考虑阅读的</p><h2 id="61bd" class="ml mm it bd mn mo mp dn mq mr ms dp mt kb mu mv mw kf mx my mz kj na nb nc nd bi translated">金融工程的学习方法:你需要知道的一切</h2><div class="lt lu gp gr lv lw"><a href="https://medium.datadriveninvestor.com/q-learning-methods-for-financial-engineering-all-you-need-to-know-ae730ae8b0b" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">金融工程的学习方法:你需要知道的一切</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">如何开发和部署Q-learning方法，包括强化学习中的应用程序、用例、最佳实践…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="mf l"><div class="ne l mh mi mj mf mk ky lw"/></div></div></a></div><h2 id="c50e" class="ml mm it bd mn mo mp dn mq mr ms dp mt kb mu mv mw kf mx my mz kj na nb nc nd bi translated">金融工程十大基本深度学习模型</h2><div class="lt lu gp gr lv lw"><a href="https://medium.datadriveninvestor.com/top-10-essential-deep-learning-models-for-financial-engineering-ca550fcff91" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">金融工程十大基本深度学习模型</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">金融工程中这些方法的10个基本深度学习(DL)模型和用例。</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="mf l"><div class="nf l mh mi mj mf mk ky lw"/></div></div></a></div><h2 id="e51a" class="ml mm it bd mn mo mp dn mq mr ms dp mt kb mu mv mw kf mx my mz kj na nb nc nd bi translated">金融工程的5大基本机器学习库</h2><div class="lt lu gp gr lv lw"><a href="https://pub.towardsai.net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad6d7a8195" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">金融工程的5大基本机器学习库</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">五个机器学习库，其中一个是最重要的库，用于金融工程用例</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">pub.towardsai.net</p></div></div><div class="mf l"><div class="ng l mh mi mj mf mk ky lw"/></div></div></a></div><h2 id="bd67" class="ml mm it bd mn mo mp dn mq mr ms dp mt kb mu mv mw kf mx my mz kj na nb nc nd bi translated">金融工程的10大基本NLP模型</h2><div class="lt lu gp gr lv lw"><a href="https://medium.com/mlearning-ai/top-10-essential-nlp-models-for-financial-engineering-f78f2536a2a9" rel="noopener follow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">金融工程的10大基本NLP模型</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">金融工程中这些方法的10个基本NLP模型和用例。</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">medium.com</p></div></div><div class="mf l"><div class="nh l mh mi mj mf mk ky lw"/></div></div></a></div><p id="958f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh">参考文献:</em></p><p id="1da5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 1。</em> <em class="lh">强化学习的不当行为。(未注明)。IEEE Xplore。检索到2022年8月4日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/6767062" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://ieeexplore.ieee.org/abstract/document/6767062</em></a></p><p id="74fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 2。</em> <em class="lh">佐藤H. (2008)。高维动作空间的强化学习——基于主成分分析的动作空间压缩。IEICE技术报告；IEICE理工大学。众议员，108(276)，37–42。</em><a class="ae le" href="https://doi.org/https:/ken.ieice.org/ken/download/20081106XaHi/eng/" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://doi . org/https://ken . ieice . org/ken/download/2008 11 06 xahi/eng/</em></a></p><p id="a007" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 3。</em><em class="lh">&amp;# 38；萨顿，R. S .(未注明)。渐进式自然演员-评论家算法。神经信息处理系统进展，20。</em></p><p id="c555" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 4。</em> <em class="lh"> Kobayashi等人利用资格痕迹的演员/评论家算法分析:价值函数不完美的强化学习。</em><a class="ae le" href="http://users.umiacs.umd.edu/~hal/courses/2016F_RL/Kimura98.pdf" rel="noopener ugc nofollow" target="_blank"><em class="lh">http://users . umi ACS . UMD . edu/~ Hal/courses/2016 f _ RL/Kimura 98 . pdf</em></a></p><p id="189a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 5。</em> <em class="lh">老林。(2018年4月27日)。高频做市的强化学习。</em><a class="ae le" href="https://discovery.ucl.ac.uk/id/eprint/10116730/" rel="noopener ugc nofollow" target="_blank"><em class="lh"/></a></p><p id="88b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 6。</em><em class="lh">【38】&amp;# 38；陆(未注明)。ECCV 2018开放存取知识库。检索2022年8月4日，来自</em><a class="ae le" href="https://openaccess.thecvf.com/content_ECCV_2018/html/Boyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.html" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://open access . the CVF . com/content _ ECCV _ 2018/html/于波_陈_实时_演员-评论家_追踪_ ECCV _ 2018 _论文. html </em> </a></p><p id="b897" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 7。</em><em class="lh">【Flet-Berliac，y .】Ferret，j .【Piet quin，o .】Preux，p .&amp;# 38；m .艾斯特(2021年2月8日)。敌对导向的演员兼评论家。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/2102.04376" rel="noopener ugc nofollow" target="_blank">【https://arxiv.org/abs/2102.04376】T21</a></p><p id="5173" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">8。<em class="lh">&amp;# 38；莱文，S. (2018年7月3日)。带有随机参与者的非策略最大熵深度强化学习。PMLR。</em><a class="ae le" href="https://proceedings.mlr.press/v80/haarnoja18b" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://proceedings.mlr.press/v80/haarnoja18b</em></a></p><p id="4e89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 9。</em> <em class="lh">增量多步q学习。(未注明)。科学指导。2022年8月4日检索，来自</em><a class="ae le" href="https://www.sciencedirect.com/science/article/pii/B9781558603356500350" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://www . science direct . com/science/article/pii/b 9781558603356500350</em></a></p><p id="fa84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 10。</em> <em class="lh">彼得斯，维贾古玛，&amp;# 38；沙尔。(2005年1月1日)。天生的演员兼评论家。施普林格柏林海德堡。</em><a class="ae le" href="https://link.springer.com/chapter/10.1007/11564096_29" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://link.springer.com/chapter/10.1007/11564096_29</em></a></p><p id="74c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 11。</em> <em class="lh">蒂尔贝，阿尼尔。(2022年8月3日)。金融工程顶级q-learning深度学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/q-learning-methods-for-financial-engineering-all-you-need-to-know-ae730ae8b0b" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://medium . datadriveninvestor . com/q-learning-methods-for-financial-engineering-all-you-need-to-know-you-need-to-know-AE 730 AE 8 b 0b</em></a></p><p id="f045" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 12。</em> <em class="lh">蒂尔贝，安尼尔。(2022年8月3日)。金融三大基本无监督学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/top-3-essential-unsupervised-learning-methods-for-financial-engineering-fb5356a7a401" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://medium . datadriveninvestor . com/top-3-essential-unsupervised-learning-methods-for-financial-engineering-FB 5356 a7a 401</em></a></p><p id="69cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 13。</em> <em class="lh">蒂尔贝，阿尼尔。(2022年7月28日)。金融工程中10个必不可少的深度学习。数据驱动投资者。</em><a class="ae le" href="https://medium.datadriveninvestor.com/top-10-essential-deep-learning-models-for-financial-engineering-ca550fcff91" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://medium . datadriveninvestor . com/top-10-essential-deep-learning-models-for-financial-engineering-ca 550 fcff 91</em></a></p><p id="10e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 14。</em> <em class="lh">蒂尔贝，阿尼尔。(2022年7月26日)。金融工程5大AI ML库。走向AI。</em><a class="ae le" href="https://pub.towardsai.net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad6d7a8195" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://pub . toward sai . net/top-5-essential-machine-learning-libraries-for-financial-engineering-d1ad 6d 7a 8195</em></a></p><p id="8a36" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">15。 <em class="lh">蒂尔贝，阿尼尔。(2022年7月27日)。金融工程的10个基本NLP模型。</em><a class="ae le" href="https://medium.com/mlearning-ai/top-10-essential-nlp-models-for-financial-engineering-f78f2536a2a9" rel="noopener"><em class="lh">https://medium . com/mlearning-ai/top-10-essential-NLP-models-for-financial-engineering-f78f 2536 a 2 a 9</em></a></p><p id="bf2a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">16岁。 <em class="lh">哈尔诺贾、t、周、a、哈蒂凯宁、k、塔克、g、哈、s、谭、j、库马尔、v、朱、h、古普塔、a、阿比尔、p、&amp;# 38；莱文，S. (2018年12月13日)。软演员-评论家算法和应用。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/1812.05905" rel="noopener ugc nofollow" target="_blank"><em class="lh"/></a></p><p id="9162" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 17。</em> <em class="lh">【黑斯·n·西尔维】&amp;# 38；Teh，Y. W. (2013年1月12日)。基于能量的政策强化学习。PMLR。</em><a class="ae le" href="https://proceedings.mlr.press/v24/heess12a" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://proceedings.mlr.press/v24/heess12a</em></a></p><p id="efaf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 18。</em> <em class="lh">格雷斯比，j .，&amp;# 38；齐，于(2021年6月16日)。走向持续控制的自动演员-评论家解决方案。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/2106.08918" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://arxiv.org/abs/2106.08918</em></a></p><p id="cfed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">19。 <em class="lh">萨恩科，A. L .，罗伯特·普拉特，凯特。(未注明)。等级演员-评论家。</em></p><p id="4572" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">20。 <em class="lh">托马斯·p .(2014年1月27日)。自然演员-评论家算法中的偏见。PMLR。</em><a class="ae le" href="https://proceedings.mlr.press/v32/thomas14.html" rel="noopener ugc nofollow" target="_blank"><em class="lh"/></a></p><p id="19bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 21。</em> <em class="lh">【邵、刘亦菲、尤、杨、阎、米、袁、s、孙、&amp;# 38；Bohg，J. (2022年1月11日)。GRAC:自我引导和自我规范的演员兼评论家。PMLR。</em><a class="ae le" href="https://proceedings.mlr.press/v164/shao22a.html" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://proceedings.mlr.press/v164/shao22a.html</em></a></p><p id="4574" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 22。</em> <em class="lh">【莫汉蒂，n .】&amp;# 38；南卡罗来纳州孙达拉姆(2020年11月13日)。禁闭逃生问题强化学习框架中的支架反射。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/2011.06764" rel="noopener ugc nofollow" target="_blank">【https://arxiv.org/abs/2011.06764】T21</a></p><p id="7628" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">23。 <em class="lh"> Mnih，v .，Badia，A. P .，Mirza，m .，Graves，a .，Lillicrap，T. P .，Harley，t .，Silver，d .，&amp;# 38；k . kavukcuoglu(2016年2月4日)。深度强化学习的异步方法。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/1602.01783" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://arxiv.org/abs/1602.01783</em></a></p><p id="dc28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">24。 <em class="lh">优势演员评论家(A2C)。(未注明)。检索到2022年8月4日，转自</em><a class="ae le" href="https://huggingface.co/blog/deep-rl-a2c" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://huggingface.co/blog/deep-rl-a2c</em></a></p><p id="cfdb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 25。</em>、【周、王、王、胡、&amp;# 38；邓，K. (2021)。改进的异步优势行动者批判强化学习模型在异常检测中的应用。熵，23(3)。<a class="ae le" href="https://doi.org/10.3390/e23030274" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://doi.org/10.3390/e23030274</em></a></p><p id="794b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lh"> 26。</em> <em class="lh">沈，h，张，k，洪，m，&amp;# 38；陈(2020年12月31日)。走向理解异步优势行动者-批评家:收敛和线性加速。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/2012.15511" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://arxiv.org/abs/2012.15511</em></a></p></div></div>    
</body>
</html>