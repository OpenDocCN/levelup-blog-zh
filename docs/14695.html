<html>
<head>
<title>PyTorch Official Blog: Detailed PyTorch Profiler v1.9</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch官方博客:详细的PyTorch Profiler v1.9</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/pytorch-official-blog-detailed-pytorch-profiler-v1-9-7a5ca991a97b?source=collection_archive---------1-----------------------#2022-12-18">https://levelup.gitconnected.com/pytorch-official-blog-detailed-pytorch-profiler-v1-9-7a5ca991a97b?source=collection_archive---------1-----------------------#2022-12-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d0b1a2843b6574644f80cdd54584dfda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jRtsXKEwncqzNViO"/></div></div></figure><div class=""/><p id="b614" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">PyTorch Profiler v1.9版现已推出。该版本旨在为用户提供新的工具，以便更容易地诊断和修复机器学习性能问题，无论是在单台机器上还是在多台机器上。</p><p id="a8db" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Profiler v1.9的改进集中在运行时和/或内存中最耗能的执行步骤，同时可视化GPU和CPU之间的工作负载分布。</p><p id="8d0e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> Profiler v1.9增加了五大功能，包括:</strong></p><p id="c788" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">1.<strong class="kd jf">分布式训练视图</strong>:帮助你掌握分布式训练任务所消耗的时间和内存。假设您有一个训练模型，当您将负载划分到工作节点上并行运行时，各种问题可能会像黑盒一样出现。该模型的总体目标是提高训练速度。这种分布式培训视图有助于您诊断和调试单个节点中的问题。</p><p id="aec8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2.<strong class="kd jf">内存视图</strong>:通过该视图，您可以更好地了解内存的使用情况。这个工具可以显示程序在不同运行阶段的活动内存分配，从而帮助您避免内存不足的错误。</p><p id="c010" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3.<strong class="kd jf"> GPU应用可视化</strong>:这个工具可以保证GPU得到充分利用。</p><p id="5b35" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">4.<strong class="kd jf">云存储支持</strong>:tensor board插件现在可以从Azure Blob Storage、亚马逊S3和谷歌云平台读取解析后的数据。</p><p id="2ae1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">5.<strong class="kd jf">跳转到源代码</strong>:该函数支持堆栈跟踪信息的可视化，可以直接跳转到源代码。这有助于您根据分析结果快速优化和迭代您的代码。</p><p id="724d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> PyTorch Profiler Colab门户:</strong><em class="kz"/><a class="ae la" href="https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html" rel="noopener ugc nofollow" target="_blank"><em class="kz">https://py torch . org/tutorials/intermediate/tensor board _ Profiler _ tutorial . html</em></a></p><p id="dc8c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">Colab门户中文版:</strong></p><p id="6666" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://openbayes.com/console/open-tutorials/containers/TA5H0qvm5rw" rel="noopener ugc nofollow" target="_blank"><em class="kz">https://open Bayes . com/console/open-tutorials/containers/ta 5h 0 qvm 5 rw</em></a></p><p id="3cd7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> Colab内容一览:</strong></p><p id="6cc5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-准备数据和模型</p><p id="fc5a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-使用事件探查器记录执行事件</p><p id="36be" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-运行探查器</p><p id="e2b2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-使用TensorBoard查看结果并分析模型性能</p><p id="e2e4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-使用探查器提高性能</p><p id="7faa" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">-使用其他高级功能分析性能</p><p id="9e20" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">【PyTorch分析工具入门</p><p id="c69a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先:</p><p id="e50d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">$ pip安装torch-tb-profiler</p><pre class="lb lc ld le gt lf lg lh bn li lj bi"><span id="bd9e" class="lk ll je lg b be lm ln l lo lp">import torch.profiler as profilerWith profiler.profile(XXXX)</span></pre><p id="e00b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">注:有关CUDA和CPU的分析，请参见:</p><p id="ef69" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://github.com/pytorch/kineto/blob/master/tb_plugin/examples/resnet50_profiler_api.py" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://github . com/py torch/kineto/blob/master/TB _ plugin/examples/resnet 50 _ profiler _ API . py</em></strong>T5】</a></p><pre class="lb lc ld le gt lf lg lh bn li lj bi"><span id="856d" class="lk ll je lg b be lm ln l lo lp">with torch.profiler.profile( activities=[ torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],</span></pre><p id="2134" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">* profiler . record _ function(" $ NAME "):允许为一个功能块添加一个装饰器(decorator，指的是与名称相关联的标签)。</p><p id="531c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">profiler.profile下的Profile_memory=True参数可以分析CPU和GPU的内存使用情况。</p><p id="e86a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">可视化PyTorch模型性能</strong></p><p id="a77f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">分布式培训</strong></p><p id="ab02" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">深度学习的最新进展证明了大数据集和大模型的价值，这也意味着模型训练需要更多的计算资源。</p><p id="89cb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">分布式数据并行(DDP)和NVIDIA多卡通信框架(NCCL)是PyTorch中广泛采用的加速深度学习训练的范例。</p><p id="d822" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在PyTorch Profiler的这个版本中，现在支持NCCL后端的DDP。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/894c9a8a5c5a0d291781543faac7ef4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ur78KeBn7KruJWMA"/></div></div></figure><p id="74ae" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">计算/通信概述</strong></p><p id="fabc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在分布式训练视图的“计算/通信概述”中，用户可以观察到“负载平衡器”节点在所有工作人员中的计算和通信比率，这是根据粒度测量的。</p><p id="1ad2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">负载平衡器相关链接:</strong></p><p id="d534" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Load_balancing_(computing)" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://en . Wikipedia . org/wiki/Load _ balancing _(计算)</em> </strong> </a></p><p id="b80f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">情景一:</strong></p><p id="58cb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果一个工作者比其他工作者花费更长的时间来计算和重叠，这可能指示工作负载平衡中的问题，或者其中一个节点是落后的。计算是GPU内核时间的总和，减去重叠时间。重叠时间是指计算过程中交错通信节省的时间。</p><p id="68de" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">越长的重叠表明计算和通信之间的并行性越好。理想情况下，计算和通信完全相互重叠。通信是总通信时间减去重叠时间。</p><p id="59d5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的例子展示了这是如何在Tensorboard上发生的。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lr"><img src="../Images/fb7cdc9e12eba50caf7d434afe7190e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ubVRrUP6FB-XhpNZ"/></div></div></figure><p id="7014" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">散兵游勇的例子</strong></p><p id="c594" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">情景二:</strong></p><p id="2ea9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果批量较小(即所有工作线程上的计算相对较小)，或者要传输的数据较大，则计算与通信的比率也可能较小，您可以在Profiler中看到GPU利用率较低，等待时间较长。</p><p id="18a9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">用户可以从这个计算/通信视图中查看代码，通过使用梯度累积来减少通信，或者通过增加批处理大小来减少通信比率。DDP通信时间取决于型号大小。批量大小与模型大小无关。因此，增加批处理大小会导致更长的计算时间和更大的计算通信实例。</p><p id="655d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">同步/通信概述</strong></p><p id="66c6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在同步/通信视图中，用户可以观察通信效率。这是通过从步进时间中减去计算和通信时间来计算的。同步时间是等待和与其他工作人员同步的总通信时间的一部分。同步/通信视图包括初始化、数据加载器、CPU计算等等。</p><p id="8c84" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从这个视图中，我们可以知道:<strong class="kd jf">总流量中有多少比例实际用于交换数据，还有多少空闲时间等待其他工作人员提供数据。</strong></p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/b50c26008bf3c93ea3f6e42ce930939d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S2ACjgON6HWsOett"/></div></div></figure><p id="81f9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，如果存在低效的工作负载平衡或掉队问题，可以在同步/通信视图中找到。该视图将显示一些工人比其他人等待的时间更长。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/4028a97d032277d8275d2a8f0574b89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uu5-zkwulWqfODPT"/></div></div></figure><p id="9d0f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从上表可以知道各个节点所有通信运营商的详细统计数据。通过这个表可以知道调用了哪些操作符类型，每个操作符被调用了多少次，每个操作符传输的数据大小等等。</p><p id="9494" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">记忆查看</strong></p><p id="31ee" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用该工具，可以了解模型中运营商的硬件资源消耗情况。了解操作符级别的时间和内存消耗有助于解决性能瓶颈并加速模型执行。<strong class="kd jf">鉴于GPU内存大小有限，优化内存使用效率会有所帮助:</strong></p><p id="f912" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*允许运行更大的模型，在终端级任务上表现更好。</p><p id="1ca9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*允许更大的批量，提高训练速度。</p><p id="f4f7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">探查器记录探查间隔期间的所有内存分配。选择“设备”查看GPU端或主机端每个操作员的内存使用详情。</p><p id="0c51" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">注:必须启用profile_memory=True，以生成以下存储器数据。</strong></p><p id="2003" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">相关链接:</p><p id="c312" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://github.com/pytorch/kineto/blob/master/tb_plugin/examples/resnet50_profiler_api.py#L39" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://github . com/py torch/kineto/blob/master/TB _ plugin/examples/resnet 50 _ profiler _ API . py # L39</em></strong></a></p><pre class="lb lc ld le gt lf lg lh bn li lj bi"><span id="c06a" class="lk ll je lg b be lm ln l lo lp">With torch.profiler.profile(Profiler_memory=True # this will take 1 – 2 minutes to complete. )</span></pre><p id="c05d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">重要定义:</strong></p><p id="6e5a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*“大小增加”显示所有已分配字节的总和减去所有已释放字节。</p><p id="8a4c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*“分配大小”显示所有已分配字节的总和，不包括内存释放。</p><p id="5407" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*“Self”表示分配的内存不是来自任何子运算符，而是由运算符自己分配的。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/764bad04ce8fbc3a609e29e06f60b5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3WW4D5-Mjl-seQcX"/></div></div></figure><p id="cd02" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">时间轴上的GPU指标</strong></p><p id="7793" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当一个或多个GPU未得到充分利用时，此功能允许您轻松调试性能问题。理想情况下，您的程序应该具有高GPU利用率(如果可能，100%的GPU利用率)，最小的CPU到GPU通信成本，并且没有功耗。</p><p id="7fba" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">概述:</strong>概述页面突出显示了三个重要的GPU使用指标(即GPU利用率，Est。SM效率和Est。达到的占有率)。</p><p id="8e42" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本质上，每个GPU都有许多SM，每个SM都有许多可以同时执行许多线程的warps。Warp使用许多线程执行，因为它的数量取决于GPU。从更高的角度来看，时间轴上的GPU指标可以帮助开发人员对整个堆栈有一个全局的看法，这非常重要。</p><p id="8196" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">GPU利用率低表明模型存在潜在问题。常见原因如下:</strong></p><p id="5571" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*内核中的并行性不足，即批量太小</p><p id="185b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">*循环调用小内核，即启动开销不摊销</p><p id="13cc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">* CPU或I/O瓶颈导致工作内容不足，GPU利用率低</p><p id="fb29" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在概述页面上，性能建议部分包含一些提高GPU利用率的可行建议。在本例中，GPU利用率较低，因此性能建议是增加批处理大小。正如性能所表明的，将批处理大小从4增加到32将GPU利用率提高了60.68%。</p><p id="6804" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> GPU利用率:</strong>在Profiler中，GPU引擎执行一个工作负载有一个步长间隔时间。利用率越高越好。仅以GPU利用率来判断性能瓶颈是不准确的。你不能用这个来知道有多少个流处理器(流多处理器)在运行。</p><p id="7cce" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">请注意，虽然这一指标对于检测空闲时间很有用，但高数值并不一定表示高GPU利用率。例如，单线程连续运行的内核将拥有100%的GPU利用率。</p><p id="0dd0" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">估计的流处理器效率(Est。SM效率)是一个更细粒度的指标，即</strong>代表整个跟踪过程中正在使用的SM的百分比、SM上至少有一个活动wrap的时间百分比以及空闲wrap的时间百分比。</p><p id="89bb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">NVIDIA文档:</p><p id="6187" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://forums.developer.nvidia.com/t/nvprof-question-about-the-sm-efficiency-metric/72640" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://forums . developer . NVIDIA . com/t/NV prof-question-about-the-sm-efficiency-metric/72640</em></strong></a></p><p id="dd7a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">估计的SM效率也有局限性。每个模块只有一个线程的内核无法充分利用所有的SMs。仅仅基于SM效率不可能知道每个SM的利用率，只能知道每个SM正在进行的操作，包括等待内存加载结果时的暂停。</p><p id="db76" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了保持SMs的高利用率，无论何时出现停顿，都必须保证运行足够数量的就绪包装。</p><p id="7062" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于性能诊断问题。实际占用率比预计占用率更准确。SM效率和GPU利用率。预计达到的占用率表示每个SM有多少条经线可以同时处于活动状态。拥有足够数量的活动经纱通常是获得良好吞吐量的关键。与GPU利用率和SM效率不同，让这个值尽可能高并不是终极目标。</p><p id="026f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据经验，将这一指标提高到15%或更高可以获得良好的吞吐量增益。但在某个时候，回报会递减。例如，如果该值已经达到30%，则下一个增益变得不确定。此指标显示内核执行期间所有warp调度程序的平均值</p><p id="5799" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">NVIDIA文档:</p><p id="61f8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://docs . NVIDIA . com/gameworks/content/developer tools/desktop/analysis/report/cuda experiments/kernellevel/achievedoccupancy . htm</em></strong>T5】</a></p><p id="3e8c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Est值较高。达到入住更好。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ls"><img src="../Images/99c4df25e58f3d8142590dee55ee7c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*go-b-lFCPDcD7bYw1kaGtQ.png"/></div></div></figure><p id="ba12" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">详细信息:Resnet50_batchsize4 </strong></p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/5394642f1b2d6c1a89646da65997c09d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KgzPkvH_k2moEisY"/></div></div></figure><p id="9b75" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">详细信息:Resnet50_batchsize32 </strong></p><p id="4ea2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">内核视图:内核有“每个SM的块数”和“Est”。实现入住”。</p><p id="f740" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">估计的实现的占用率是比较模型健康状况的有用工具。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/14592491fb293e6830c7c30ddba53bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wdOWugMdmj7Ubtl4"/></div></div></figure><p id="ff8c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">每个SM的平均块数(每个SM的平均块数):</strong></p><p id="3e26" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每条短信的块数=该内核的块数/该GPU的短信数。如果这个数字小于1，说明GPU多处理器没有得到充分利用。“Mean Blocks per SM”是该内核名称的所有运行的加权平均值，使用每次运行的长度作为权重。</p><p id="5216" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">平均预计。实现入住率(平均预计。实现入住率:</strong></p><p id="4bde" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">估计的已实现入住率的定义与上述定义相同。平均Est。实现的占用率是该内核名称的所有运行的加权平均值，使用每次运行的持续时间作为权重。</p><p id="1305" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">轨迹视图:</strong></p><p id="16bd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">trace视图显示一个时间线，该时间线显示模型中操作符的持续时间以及执行该操作的系统。这个视图可以帮助您识别高消耗和长执行是由输入还是模型训练引起的。目前，跟踪视图显示GPU利用率和预计时间。一段时间内的SM效率。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/6078d20d989b025bc55d2d6bb0a1cc64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cmQdLfmYAysVt_nj"/></div></div></figure><p id="d4a3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在上面的示例中，“ProfilerStep5”在线程28022期间的GPU利用率高于“Optimizer.step”。你可以放大看原因。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/5b3ef2420eba5120109d8c00ae808c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b8kR-ZQ0qVr7SQtG"/></div></div></figure><p id="c014" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从上图可以看出，前者的内核比后者长。后者内核执行时间太短，导致GPU利用率低。</p><p id="ab5b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">美国东部时间。SM效率:每个内核都有一个计算出来的EST。SM效率在0–100%之间。比如下面这个内核只有64块，这个GPU的SM是80，那么它的“Est。SM效率”是64/80，也就是0.8。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/6266fa187d8edb8fa0068a38df1efbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zq7aKXRLIMdemMLG"/></div></div></figure><p id="2ab7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">云存储支持</strong></p><p id="19e1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">运行pip install tensorboard后，要通过云提供商读取数据，您可以运行:</p><pre class="lb lc ld le gt lf lg lh bn li lj bi"><span id="091f" class="lk ll je lg b be lm ln l lo lp">torch-tb-profiler[blob] torch-tb-profiler[gs] torch-tb-profiler[s3]</span></pre><p id="7116" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在pip安装torch-tb-profiler[blob]、pip安装torch-tb-profiler[gs]或pip安装torch-tb-profiler[S3]的帮助下，可以通过云服务提供商读取数据。</p><p id="3a42" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有关更多信息，请参考:</p><p id="ed39" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">【https://github.com/pytorch/kineto/tree/main/tb_plugin】<strong class="kd jf"><em class="kz"/></strong></p><p id="9bab" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">跳转到源代码</strong></p><p id="dcb4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">将TensorBoard和PyTorch Profiler直接集成到Visual Studio代码(VS代码)中的一个巨大好处是，您可以从分析器的堆栈跟踪直接跳转到源代码(文件和行)。VS代码Python扩展现在支持TensorBoard集成。</p><p id="5b2a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">仅当Tensorboard在VS代码中运行时，跳转到源代码才可用。如果profiling with_stack=True，那么插件UI上会出现一个堆栈跟踪。在PyTorch Profiler中点击堆栈跟踪，VS代码会打开相应的文件，直接跳转到相应的代码进行调试。这使得基于分析结果和建议的快速代码优化和修改成为可能。</p><figure class="lb lc ld le gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lq"><img src="../Images/09384fe997cf9d50f6222efa9d12a7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*v--hrLddJayEaqaA"/></div></div></figure><p id="fa20" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">在UI中使用Visual Studio代码插件跳转到源代码</strong></p><p id="b37c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">关于如何优化批量性能，请查看详细教程:</p><p id="d2ca" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://opendatascience.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler/" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://opendata science . com/optimizing-py torch-performance-batch-size-with-py torch-profiler/</em></strong></a></p><p id="fc83" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">PyTorch Profiler也可以与PyTorch Lightning集成，只需使用trainer.profiler=pytorch启动Lightning训练任务生成trace即可。</p><p id="651d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">详细示例:</p><p id="0dfa" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/basic_examples/profiler_example.py" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="kz">https://github . com/PyTorchLightning/pytorch-lightning/blob/master/pl _ examples/basic _ examples/profiler _ example . py</em></strong></a></p><p id="64d9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">原地址:</strong></p><p id="2ace" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae la" href="https://pytorch.org/blog/pytorch-profiler-1.9-released/" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf">【https://pytorch.org/blog/pytorch-profiler-1.9-released/】</strong></a></p><p id="a99d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">喜欢这篇文章吗？成为一个媒介成员，通过无限制的阅读继续学习。如果你使用<a class="ae la" href="https://machinelearningabc.medium.com/membership" rel="noopener">这个链接</a>成为会员，你将支持我，不需要额外的费用。提前感谢，再见！</p></div></div>    
</body>
</html>