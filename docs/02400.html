<html>
<head>
<title>What Is A Service Mesh?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是服务网格？</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/what-is-a-service-mesh-ee7d6291478b?source=collection_archive---------21-----------------------#2020-03-10">https://levelup.gitconnected.com/what-is-a-service-mesh-ee7d6291478b?source=collection_archive---------21-----------------------#2020-03-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="bf29" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">本文最初发表于https://www.magalix.com/blog/what-is-a-service-mesh</em><a class="ae kp" href="https://www.magalix.com/blog/what-is-a-service-mesh" rel="noopener ugc nofollow" target="_blank"/></p><p id="26e1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了理解一种工具或技术是如何或为什么出现的，你可以从它试图解决的问题的起源开始，看看如果没有这种新技术，世界会是什么样子。微服务已经存在了一段时间——这是一种旨在将大型单片应用程序分解为通过HTTP协议相互通信的小单元的架构。它也是为解决可伸缩性和可用性问题而创建的模型。</p><p id="833f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">微服务应用程序比单片应用程序更具可伸缩性，因为您可以轻松地选择负载较重的服务，并创建它们的更多副本，而不是创建整个庞大系统的副本。类似地，通过相同的机制，微服务应用程序更容易获得，因为我们可以拥有同一服务的多个副本。像Kubernetes这样的容器化和容器编排系统使得微服务更加健壮。容器是非常轻量级的，启动只需要几毫秒。使用像Kubernetes这样的系统，容器也可以很容易地从一个节点(机器)移动到另一个节点(机器)。这本身就很棒，然而，随着越来越多的环境采用微服务，新的挑战也出现了。让我们来看看。</p><h1 id="b233" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">微服务挑战</h1><p id="c597" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated"><strong class="js iu">负载平衡的需求:</strong>因为将有多个副本负责同一服务，所以必须有一个负载平衡器来接收来自客户端的初始请求，并将其路由到一个健康的<em class="ko">后端服务。</em></p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/146f101e8f4a4cb706e24c74d785739b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_fTOa10eWvTlXi_l.png"/></div></div></figure><p id="51c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">对智能负载平衡的需求:</strong>在现代微服务和期望服务在几分之一秒内响应的客户端世界中，<a class="ae kp" href="https://www.nginx.com/resources/glossary/round-robin-load-balancing/" rel="noopener ugc nofollow" target="_blank">循环负载平衡</a>已经不够了。负载平衡器应该足够智能，以便向高延迟的服务发送较少的流量。在极端情况下，它应该停止路由到过载的服务，这样它就不会在负载增加的情况下崩溃。此外，智能负载平衡可用于高级路由场景，如<a class="ae kp" href="https://whatis.techtarget.com/definition/canary-canary-testing" rel="noopener ugc nofollow" target="_blank">金丝雀测试</a>，其中流量应根据特定条件(如自定义HTTP报头)路由至特定后端。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/1dca13c2c0c0d05b2c8628baa13aabd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nLZN4Q_g3_Xxn2_V.png"/></div></div></figure><p id="a2a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">断路模式:</strong>假设我们有一个应用需要用户登录。前端页面由webserver服务显示。一旦用户输入他们的凭据，web服务器就会联系身份验证API(位于另一个服务上)来验证这些凭据，并将用户路由到仪表板，或者显示“拒绝访问”消息。</p><p id="7fcf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，如果身份验证服务负担过重，并且在处理请求时遇到一些困难，该怎么办呢？该请求将通过网络传输，并等待身份验证API做出响应。由于后者不能正常工作，请求将一直等到I/O超时，然后抛出服务不可用的错误。在服务恢复之前，每个身份验证请求都会发生这种情况。然而，至少可以说，无所事事地等待请求超时提供了糟糕的用户体验。断路模式旨在通过将连接分为三种状态来消除故障报告延迟:</p><ul class=""><li id="9a36" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated"><strong class="js iu">关闭:</strong>连接正常。在我们的示例中，身份验证API返回了一个有效的响应。</li><li id="f523" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><strong class="js iu">打开:</strong>请求失败多次。在我们的示例中，如果设置的数量是3，那么在3次请求失败后，服务将不再尝试与身份验证服务通信。相反，它会立即报告后端服务没有响应，或者有问题。</li><li id="edce" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><strong class="js iu">半开:</strong>在指定的持续时间之后，服务重新检查目标。如果仍然不可达(或不按预期工作)，连接状态保持<em class="ko">打开</em>。否则，故障计数被重置，连接返回到<em class="ko">关闭</em>状态。</li></ul><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/6e2fade8071a23b2eb7f11c784ebe5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9RNJOrmkU8D_rBs1.png"/></div></div></figure><p id="ec9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> HTTPS通信要求:</strong>尽管在内部隔离网络中运行，微服务应始终使用HTTPS进行内部通信。然而，HTTPS带来了自己的运营负担。容器中的应用程序需要实现证书、终止TLS流量等等。</p><p id="da8f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">安全策略要到位:</strong>微服务在内部网络中与外部互联网隔离，并不意味着它们不能被攻破。如果入侵者能够侵入应用程序的薄弱部分，比如说一个与数据库没有通信业务的服务，他们不应该能够通过损害这个服务来连接到数据库。</p><p id="5974" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些只是现代微服务架构今天面临的众多挑战的一部分，服务网格是一种旨在解决这些问题的技术。</p><h1 id="1d51" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">但我认为Kubernetes服务已经做到了这一点？</h1><p id="93ca" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">第一次研究服务网格时，脑海中最常见的问题之一是:我已经知道Kubernetes，它有处理这些需求的组件，如<a class="ae kp" href="https://kubernetes.io/docs/concepts/services-networking/service/" rel="noopener ugc nofollow" target="_blank">服务</a>、<a class="ae kp" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/" rel="noopener ugc nofollow" target="_blank">活性探测器</a>和<a class="ae kp" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/" rel="noopener ugc nofollow" target="_blank">就绪探测器</a>。那是部分正确的。Kubernetes通过其服务组件提供了自己的基本服务网络。服务提供循环负载平衡和服务发现。然而，它只能让你走这么远。服务无法实现智能负载平衡、回退逻辑(在满足特定条件时停止向后端pod发送流量)以及服务网格提供的其他高级功能。事实上，服务网格被认为是容器编排系统的扩展。把它想象成类固醇上的Kubernetes。</p><h1 id="5736" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">服务网格部署模式</h1><p id="dfac" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">部署服务网格框架时，通常有两种选择:</p><ul class=""><li id="45ed" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated"><strong class="js iu">每台主机:</strong>工具在主机上的部署位置。如果我们使用Kubernetes，它可以通过Daemonset部署。这种方法的优点是，您可以通过部署更少的代理来节省资源。然而，缺点是其中一个代理的故障会影响在该节点上运行的所有容器。</li><li id="3773" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><strong class="js iu">每个集装箱:</strong>其中代理被部署为每个集装箱的边车。pod定义包含应用程序容器和代理容器(sidecar)——这样，sidecar容器与应用程序紧密耦合。它们可以通过环回接口相互通信。</li></ul><h1 id="057d" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">实践示例:使用Envoy实现Sidecar代理</h1><p id="92ef" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">在本实验中，我们将演示服务网格技术提供的功能之一，即流量控制。在这个实验中，我们将使用一个用Go编写的非常简单的API。API期望POST请求的主体中包含用户的生日。它会回应“你好，用户名。如果当前日期与用户的生日匹配，则为“生日快乐”，或者只是“你好，用户名”。让我们来试驾一下:</p><blockquote class="mt mu mv"><p id="075e" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">docker run-d-p 8080:8080 magalixcorp/birthday greeter</strong></p></blockquote><p id="9dcd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们发送一个POST请求:</p><blockquote class="mt mu mv"><p id="f3c2" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ curl-XPOST—data ' { " dateOfBirth ":" 2020–01–25 " } ' localhost:8080/Hello/abohmeed<br/>{ " message ":"你好，abohmeed！生日快乐" } </strong></p></blockquote><p id="fca7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">既然它似乎正在工作，那么让我们将它部署到一个正在运行的Kubernetes集群:</p><blockquote class="mt mu mv"><p id="4f92" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu"> apiVersion: apps/v1 <br/>种类:部署<br/>元数据:<br/>名称:bdgreeter <br/>标签:<br/> app: bdgreeter <br/>规格:<br/>副本:1 <br/>选择器:<br/>matchLabels:<br/>app:BD greeter<br/>模板:<br/>元数据:<br/>标签:<br/> app: bdgreeter <br/>规格:<br/>容器:<br/> —名称:app <br/></strong></p></blockquote><p id="9dfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该定义包含一个部署和一个NodePort类型的服务，用于将外部请求路由到Pod。让我们针对集群重新运行请求:</p><blockquote class="mt mu mv"><p id="b9ce" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ curl-XPOST—data ' { " dateOfBirth ":" 2020–01–25 " } ' 35.188.81.116:32000/hello/abohmeed<br/>{ " message ":"你好，阿布米德！生日快乐" } </strong></p></blockquote><p id="e46f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里，35.188.81.116是我们的一个Kubernetes节点的外部IP地址。</p><p id="0aae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们修改部署以包括一个运行Envoy的sidecar容器。</p><h1 id="5934" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">特使是什么？</h1><p id="2cd7" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">根据文档，Envoy代理可以定义为“为大型现代面向服务架构设计的L7代理和通信总线。”该项目的主要目标是明确区分应用程序和它所运行的网络。当问题发生时，根本原因应该很简单。用C++编写的Envoy利用了本地语言的速度和可靠性。它工作在HTTP第7层，执行通常委托给Nginx等web服务器的任务，即路由、速率限制等。它还在较低的L3和L4层运行，在那里可以对IP地址和端口做出明智的决定。Envoy还提供了应用程序的统计可见性和报告。它非常受欢迎，现在每当需要实现应用程序sidecar时，它都是首选的解决方案。让我们看看特使是如何工作的。其核心包括以下组件:</p><ul class=""><li id="825f" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated"><strong class="js iu"> TCP监听器:</strong>这是Envoy接受流量的地方。一个特使实例可以有多个侦听器。它只接受TCP流量。</li><li id="b203" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><strong class="js iu">滤镜:</strong>这是系统的肉和土豆。Envoy收到的消息可能会通过一个或多个过滤器，经历多次操作，直到最终被路由到应用程序。每个听众可以有自己的一套过滤器，形成一个<em class="ko">过滤器链</em>。Envoy提供了许多可以在其配置中使用的本机过滤器。例如:</li><li id="5c2a" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">侦听器过滤器:在建立通信的早期阶段调用。例如，<a class="ae kp" href="https://www.envoyproxy.io/docs/envoy/latest/api-v2/config/filter/listener/http_inspector/v2/http_inspector.proto" rel="noopener ugc nofollow" target="_blank"> HTTP inspector过滤器</a>用于检测连接中使用的协议是否是HTTP。另一个例子是<a class="ae kp" href="https://www.envoyproxy.io/docs/envoy/latest/configuration/listeners/listener_filters/tls_inspector#config-listener-filters-tls-inspector" rel="noopener ugc nofollow" target="_blank"> TLS检查过滤器</a>，它检测连接是使用TLS还是纯文本。如果使用TLS，它会提取重要信息，如<a class="ae kp" href="https://en.wikipedia.org/wiki/Server_Name_Indication" rel="noopener ugc nofollow" target="_blank">服务器名称指示</a>。</li><li id="472d" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">网络过滤器:一旦连接建立，这些过滤器就应用于TCP消息。他们可以执行一些与应用程序相关的任务，如速率限制、身份验证和授权。还有一些特定于应用程序的过滤器，如Mongo Proxy、MySQL proxy和Kafka proxy，它们提供了特定于这些系统的特性。</li><li id="3be7" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">HTTP过滤器:它们有各种各样的工具来处理HTTP消息。例如，CSRF保护，gRPC到JSON的转换，健康检查，gzip压缩等等。</li><li id="53d2" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><strong class="js iu">集群:</strong>集群代表Envoy连接到的一个或多个上游服务。这些服务可以直接添加到配置文件中。它们也可以由Envoy通过服务发现机制自动检测到。</li></ul><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/e327b0918420c8c7ae052249a7202aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NL1E2AUG_RdqMRnI.png"/></div></div></figure><p id="d3e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">理论到此为止，让我们看看特使的行动。</p><h1 id="3289" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">在本地部署特使</h1><p id="761e" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">Envoy有不同的风格:它可以作为二进制文件在本地机器上编译和运行，也可以直接通过Docker容器运行。因为我们的最终目标是将它作为边车部署在Kubernetes上，所以我们将采用第二种方法。为了演示它是如何工作的，我们将在本地机器上部署Envoy容器。新建一个名为envoy.yaml的文件(名字无所谓)，粘贴以下内容:</p><blockquote class="mt mu mv"><p id="af75" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">static _ resources:<br/>listeners:<br/>—address:<br/>socket _ address:<br/>address:0 . 0 . 0 . 0<br/>port _ value:80<br/>filter _ chains:<br/>—filters:<br/>—name:envoy . http _ connection _ manager<br/>typed _ config:<br/>“@ type”:type . Google APIs . com/envoy . config . filter . network . http _ connection _ manager . v2 . httpconnection manager<br/>codec _ codec <br/>集群:<br/> —名称:local _ service<br/>connect _ time out:0.25s<br/>类型:strict _ DNS<br/>lb _ policy:round _ robin<br/>load _ assignment:<br/>集群名称:local_service <br/>端点:<br/> — lb_endpoints: <br/> —端点:<br/>地址:<br/> socket_address: <br/>地址:172 . 17 . 0 . 1<br/>port _端口</strong></p></blockquote><p id="50a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">既然我们已经有了Envoy配置，我们可以使用以下命令启动容器:</p><blockquote class="mt mu mv"><p id="ec2f" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ docker run-d-v $(pwd)/envoy . YAML:/envoy-config/envoy . YAML-p 80:80-p 8081:8081 envoy proxy/envoy-alpine-c/envoy-config/envoy . YAML</strong></p></blockquote><p id="4b2e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，我们为流量公开了端口80，为管理仪表板公开了端口8081。让我们尝试建立HTTP请求，以确认一切按预期运行:</p><blockquote class="mt mu mv"><p id="6a80" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ curl-XPOST—data ' { " dateOfBirth ":" 2020–01–25 " } ' localhost/Hello/abohmeed<br/>{ " message ":"你好，abohmeed！生日快乐" } </strong></p></blockquote><p id="fc0e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，这证明系统工作正常。现在，让我们看看当应用程序关闭时会发生什么:</p><blockquote class="mt mu mv"><p id="09bf" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu"> $ docker容器ls <br/>容器ID镜像命令创建状态端口名称<br/>dc5f 22 befa 84 magalixcorp/birthday greeter "。/app" 25分钟前Up 25分钟0 . 0 . 0:3000-&gt;3000/TCP recursing _ sino ussi<br/>35559394 d244 envoy proxy/envoy-alpine "/docker-entry point…"46分钟前涨46分钟0.0.0:80- &gt; 80/tcp，0.0.0:8081- &gt; 8081/tcp，10000/TCP laughing _ wes coff<br/>$ docker RM-f DC 5f 22 befa 84<br/>DC 5f 22 befa 84<br/>$ curl-XPOST—data ' { " dateOfBirth ":" 2020–01–201复位原因:连接失败</strong></p></blockquote><p id="bdba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您所看到的，一旦应用程序关闭，Envoy就会报告一个重要的错误消息，即上游服务在响应请求时遇到了问题。客户端不必等到连接超时，消息会立即显示。</p><p id="605d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在将sidecar部署到我们的Kubernetes集群之前，让我们花点时间看看配置文件。</p><ul class=""><li id="8e51" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated">listeners部分包含Envoy监听传入连接的地址(第5行)。</li><li id="d98b" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">过滤器部分在第7层运行，它使用HTTP过滤器。注意，由于它运行在第7层，它可以检测请求的URL。这里，我们将任何以“/hello”为目标的请求定向到一个名为“local_service”的服务(第17–24行)。</li><li id="e5d2" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">为了定义“local_service ”,我们使用集群部分(从第29行开始)。我们可以在集群中添加多个上游服务，并选择负载平衡机制。在我们的例子中，它是round_robin(第34行)。</li><li id="d596" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">集群需要知道上游服务在网络上的位置。由于我们通过Docker在本地机器上运行这个实验，所以我们不能声明127.0.0.1，因为它被转换为容器上的环回接口。相反，我们需要编写网桥接口172.17.0.1，这是容器用来访问主机环回接口的网关。</li><li id="3882" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">管理部分(从第42行开始)定义了管理界面设置。除了统计数据，管理界面还提供了许多有用的工具。可以通过端口8081访问它。在我们的实验室中，这将是http://127.0.0.1:8081。</li></ul><p id="f864" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们实验室的最后一部分是将上述设置应用到一个真实的Kubernetes集群。我们首先要做一些改变:</p><ul class=""><li id="1155" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated">创建一个配置图来保存特使配置。这可以通过几种方式来实现，我们选择了声明方式，这样我们可以将资源置于版本控制之下。创建一个YAML文件，并添加以下内容:</li></ul><blockquote class="mt mu mv"><p id="6e32" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">API version:v1<br/>kind:config map<br/>metadata:<br/>name:envoyconfig<br/>namespace:default<br/>data:<br/>envoy . YAML:|-<br/>static _ resources:<br/>listeners:<br/>—address:<br/>socket _ address:<br/>address:0 . 0 . 0 . 0<br/>port _ value:80<br/>filter _ chains:<br/>—filters:<br/>—name:envoy . http cluster:local _ service<br/>http _ filters:<br/>—name:envoy . router<br/>typed _ config:{ }<br/>clusters:<br/>—name:local _ service<br/>connect _ time out:0.25s<br/>type:strict _ DNS<br/>lb _ policy:round _ robin<br/>load _ assignment:<br/>cluster _ name:local _ service<br/>endpoints:<br/>—lb _ endpoints:<br/>—endpoints:【T46</strong></p></blockquote><ul class=""><li id="6f00" class="mf mg it js b jt ju jx jy kb mh kf mi kj mj kn mk ml mm mn bi translated">我们对Envoy配置所做的唯一更改是将上游服务的socket_address切换到127.0.0.1，而不是Docker桥地址。原因是因为特使现在是作为一个边车集装箱；它可以访问本地主机上的应用程序容器。</li><li id="47bb" class="mf mg it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated">我们需要做的第三个更改是在部署文件中；我们需要把边车集装箱加到豆荚里。此外，我们需要配置我们的服务，以连接到sidecar容器作为其后端，而不是应用程序容器。最后，我们将第二条路由添加到端口8081上的管理接口。我们的部署文件应该如下所示:</li></ul><blockquote class="mt mu mv"><p id="5b62" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu"> apiVersion: apps/v1 <br/>种类:部署<br/>元数据:<br/>名称:bdgreeter <br/>标签:<br/> app: bdgreeter <br/>规格:<br/>副本:1 <br/>选择器:<br/>matchLabels:<br/>app:BD greeter<br/>模板:<br/>元数据:<br/>标签:<br/> app: bdgreeter <br/>规格:<br/>容器:<br/> —名称:app <br/> 名称:envoyconfig<br/>—<br/>API version:v1<br/>种类:服务<br/>元数据:<br/>名称:bdgreeter-svc <br/>规格:<br/>选择器:<br/> app: bdgreeter <br/>端口:<br/>名称:http <br/>端口:80 <br/>目标端口:80 <br/>协议:TCP <br/>名称:admin <br/>端口:8081 <br/></strong></p></blockquote><p id="cf1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们需要将这两个文件应用到我们的集群:</p><blockquote class="mt mu mv"><p id="c71b" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ kube CTL apply-f config map . yml<br/>$ kube CTL apply-f bdaygreeter . YAML</strong></p></blockquote><p id="7dc4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这次我们使用负载平衡器作为服务类型，让我们获取外部IP:</p><blockquote class="mt mu mv"><p id="2622" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ kubectl get SVC<br/>NAME TYPE CLUSTER-IP EXTERNAL-IP PORT AGE<br/>BD greeter-SVC load balancer 10 . 0 . 26 . 74 20.185.12.166 80:30652/TCP，8081:30957/TCP 24m<br/>kubernetes CLUSTER IP 10 . 0 . 0 . 1&lt;none&gt;443/TCP 86m</strong></p></blockquote><p id="f565" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们测试我们的工作:</p><blockquote class="mt mu mv"><p id="e95a" class="jq jr ko js b jt ju jv jw jx jy jz ka mw kc kd ke mx kg kh ki my kk kl km kn im bi translated"><strong class="js iu">$ curl-XPOST—data ' { " dateOfBirth ":" 2020–01–26 " } ' 20.185.12.166/hello/abohmeed<br/>{ " message ":"你好，阿布米德！生日快乐" } </strong></p></blockquote><p id="4d09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您也可以在<a class="ae kp" href="http://20.185.12.166:8081/" rel="noopener ugc nofollow" target="_blank">http://20.185.12.166:8081/</a>查看管理仪表板</p><h1 id="07b6" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="37a1" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">服务网格是当今一些最新、最热门的技术话题。在本文中，我们讨论了什么是服务网格的概述，以及它们通常是如何使用的。我们还有一个实际动手实验室，在那里我们使用了非常流行的sidecar软件:Envoy。通过实验室，我们将Envoy作为独立容器部署在本地环境中，并将sidecar容器部署到Kubernetes Pod部署中。特使是用C++写的，所以它非常快，并提供了无数的功能。在其核心部分，Envoy使用过滤器在TCP消息到达时对其应用各种操作，并且它能够使用多种负载平衡协议将流量分配给多个上游服务。</p><p id="25a8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们推出了“为云原生而写”计划，与快速增长的云原生社区分享您的经验和知识。我们每天都有成千上万的读者。我们还为每篇发表的文章提供一笔奖金。</p></div><div class="ab cl mz na hx nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="im in io ip iq"><p id="3009" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">原载于2020年3月10日https://www.magalix.com</em><a class="ae kp" href="https://www.magalix.com/blog/what-is-a-service-mesh" rel="noopener ugc nofollow" target="_blank"><em class="ko"/></a><em class="ko">。</em></p></div></div>    
</body>
</html>