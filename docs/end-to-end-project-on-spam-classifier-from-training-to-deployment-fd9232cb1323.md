# ä½¿ç”¨ MLã€NLP å’Œ Heroku æ„å»ºå’Œéƒ¨ç½²åƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ğŸš€

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/end-to-end-project-on-spam-classifier-from-training-to-deployment-fd9232cb1323>

ç«¯åˆ°ç«¯ NLP é¡¹ç›®ï¼Œç›´åˆ°éƒ¨ç½²

![](img/ee39548301f0f4fc92cf4e5fbdbaeb61.png)

ç…§ç‰‡ç”± [Nghia Le](https://unsplash.com/@lephunghia?utm_source=medium&utm_medium=referral) åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

æ ¹æ®ã€Šç¦å¸ƒæ–¯ã€‹ä¸Šçš„ä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬æ¯å¤©äº§ç”Ÿå¤§çº¦ 2.5 ä¸‡äº¿å­—èŠ‚çš„æ•°æ®ï¼Œå¹¶ä¸”è¿™äº›æ•°æ®åœ¨æœªæ¥äº”å¹´å†…å°†å¢åŠ  5 å€ã€‚åœ¨å¦‚æ­¤åºå¤§çš„æ•°æ®é‡ä¸­ï¼Œå‡ ä¹ 90%çš„æ•°æ®æ˜¯æœªæ ‡è®°çš„å’Œæ— ç”¨çš„ã€‚å®ƒæ˜¯æ— ç”¨çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“å¦‚ä½•ä½¿ç”¨å®ƒã€‚æ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ ä¸“å®¶çš„è§’è‰²æ¥äº†ã€‚æ•°æ®ç§‘å­¦å®¶æœ‰èƒ½åŠ›å°†æ— ç”¨çš„æ•°æ®è½¬æ¢æˆæœ‰ç”¨çš„å½¢å¼ï¼Œä»¥ä¾¿ä»»ä½•äººéƒ½èƒ½ç†è§£ã€‚

è¿™äº›æ•°æ®ä¸­å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯æ–‡æœ¬æ•°æ®ï¼Œæ— è®ºæ˜¯è¯„è®ºã€æ¶ˆæ¯ã€æŠ•è¯‰è¿˜æ˜¯å…¶ä»–å½¢å¼ã€‚ç›®å‰ï¼Œä¸»è¦ä»»åŠ¡ä¹‹ä¸€æ˜¯è®¾è®¡æŸç§æŠ€æœ¯ï¼Œä½¿ç”¨è¯¥æŠ€æœ¯æˆ‘ä»¬å¯ä»¥å®¹æ˜“åœ°å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»å¹¶æ›´å¥½åœ°ç†è§£å®ƒã€‚[çš„ä½œç”¨æ¥äº†**è‡ªç„¶è¯­è¨€å¤„ç†**](https://medium.com/swlh/basics-of-natural-language-processing-in-10-minutes-2ed51e6d5d32) ã€‚è‡ªç„¶è¯­è¨€å¤„ç†å¯ä»¥è®©æˆ‘ä»¬å¾ˆå¥½åœ°ç†è§£æ–‡æœ¬æ•°æ®ã€‚å®ƒç»™äº†æˆ‘ä»¬å°†æ–‡æœ¬åˆ†ç±»åˆ°ä¸åŒç±»åˆ«çš„èƒ½åŠ›ã€‚å¦‚æœä½ ä»äº‹è®¡ç®—æœºç§‘å­¦çš„èŒä¸šï¼Œé‚£ä¹ˆä½ å¿…é¡»å¾ˆå¥½åœ°å­¦ä¹ è¿™äº›ä¸œè¥¿å’Œå®ƒä»¬çš„æ¦‚å¿µã€‚

ä¸è¦ç­‰å¾…åˆé€‚çš„æ—¶æœºåˆ°æ¥ï¼Œæ— è®ºä½ ä»€ä¹ˆæ—¶å€™å¼€å§‹ï¼Œé‚£ä¸ªæ—¶æœºéƒ½ä¼šæˆä¸ºä½ åˆé€‚çš„æ—¶æœºã€‚

å½“ä½ å¼€å§‹å­¦ä¹ å’Œè¿›å…¥äººå·¥æ™ºèƒ½é¢†åŸŸæ—¶ï¼Œä½ ç»å¸¸ä¼šçœ‹åˆ°è®¸å¤šæ•™ç¨‹å’Œåšå®¢å‘ä½ è§£é‡Šä¸åŒçš„ç®—æ³•å’Œæ–¹æ³•ï¼Œä½†ä½ å¾ˆéš¾æ‰¾åˆ°ä¸€äº›åšå®¢æˆ–æ•™ç¨‹ä¼šæ•™ä½ ä½¿ç”¨ä¸€äº›é¡¹ç›®çš„æ¦‚å¿µã€‚å¥½å§ï¼Œæˆ‘ä¸æ˜¯æ‰€æœ‰è¿™äº›äººã€‚

åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†ä»å¤´å¼€å§‹å®ç°ä¸€ä¸ªåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ï¼Œä¹‹åä½¿ç”¨ flask å’Œ journal HTML å’Œ CSSï¼Œæˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„æ¨¡å‹åˆ›å»ºä¸€ä¸ª web åº”ç”¨ç¨‹åºï¼Œç¨åæˆ‘ä»¬è¿˜å°†ä½¿ç”¨ Heroku éƒ¨ç½²å®ƒã€‚

æ‰€ä»¥å¦‚æœæˆ‘ä»¬å¯¹è‡ªç„¶è¯­è¨€å¤„ç†ä¸€æ— æ‰€çŸ¥ï¼Œå…ˆå»çœ‹çœ‹æˆ‘çš„åšå®¢å§ã€‚

[](https://medium.com/swlh/basics-of-natural-language-processing-in-10-minutes-2ed51e6d5d32) [## 10 åˆ†é’Ÿè‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€

### ä½ ä¹Ÿæƒ³å°½å¿«å­¦ä¼š NLP å—ï¼Ÿï¼Ÿï¼Ÿ

medium.com](https://medium.com/swlh/basics-of-natural-language-processing-in-10-minutes-2ed51e6d5d32) 

## æˆ‘ä»¬å°†åˆ†å››æ­¥å®Œæˆæˆ‘ä»¬çš„é¡¹ç›®ã€‚

1.  ***ä½¿ç”¨ ML å’Œ NLP åˆ›å»ºæ¨¡å‹***
2.  ***ä½¿ç”¨ flask åˆ›å»ºä¸€ä¸ª web åº”ç”¨ç¨‹åºå¹¶å°†å…¶ä¸æ¨¡å‹*** è¿æ¥
3.  ***å°†é¡¹ç›®æäº¤ç»™ Github***
4.  ***ä½¿ç”¨ Heroku*** éƒ¨ç½²æˆ‘ä»¬çš„æ¨¡å‹

# åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥è®¾ç½®ä¸€ä¸‹æˆ‘ä»¬çš„ç¯å¢ƒ

1.  ***ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„ Python***

[](https://www.python.org/downloads/) [## ä¸‹è½½ Python

### å…³äºç‰¹å®šç«¯å£çš„ä¿¡æ¯ã€å¼€å‘äººå‘˜ä¿¡æ¯æ¥æºå’ŒäºŒè¿›åˆ¶å¯æ‰§è¡Œæ–‡ä»¶ç”±å‘å¸ƒç»ç†æˆ–â€¦â€¦

www.python.org](https://www.python.org/downloads/) 

2. ***å®‰è£…éœ€è¦çš„åŒ…***

æ‰€æœ‰è½¯ä»¶åŒ…éƒ½å¯ä»¥ä½¿ç”¨ cmd(ç»ˆç«¯)ä¸­çš„ pip è¿›è¡Œå®‰è£…ã€‚

```
pip install pandas,numpy,scikit-learn,matplotlib,nltk,seaborn
```

3. ***å®‰è£… Jupyter ç¬”è®°æœ¬***

```
pip install jupyter-notebookjupyter notebook ## For running
```

å®Œæˆæ‰€æœ‰ä¸‰ä¸ªæ­¥éª¤åï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹æˆ‘ä»¬çš„é¡¹ç›®ã€‚

# åœ¨ jupyter ä¸­æ‰“å¼€ä¸€ä¸ªæ–°ç¬”è®°æœ¬ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œ

# 1.ä½¿ç”¨ ML å’Œ NLP åˆ›å»ºæ¨¡å‹

## **å¯¼å…¥å¿…è¦çš„åº“**

```
import numpy as np **## scientific computation**import pandas as pd **## loading dataset file**import matplotlib.pyplot as plt **## Visulization**import nltk  **## Preprocessing our text**from nltk.corpus import stopwords **## *removing all the stop words***from nltk.stem.porter import PorterStemmer **## stemming of words**
```

**NLTK:** è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŒ…æ˜¯ä¸€ä¸ª python åº“ï¼Œç”¨äºæ‰§è¡Œæ‰€æœ‰çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚è¯å¹²æå–ã€è¯æ±‡åŒ–æˆ–åˆ é™¤åœç”¨è¯ç­‰ã€‚

æ³¢ç‰¹Â·æ–¯ç‰¹æ¢…å°”:è¿™æ˜¯ä¸€ç§ç”¨äºå µå¡çš„å»æ¢—å™¨ã€‚è¯å¹²æå–åŸºæœ¬ä¸Šæ˜¯ä¸€ç§å°†å•è¯è½¬æ¢æˆå…¶è¯æ ¹çš„æŠ€æœ¯ã€‚
ä¾‹:å­¦ä¹ â†’å­¦ä¹ 

# æ•°æ®é›†

æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ Kaggle ä¸Šçš„å¼€æºæ•°æ®é›†ã€‚

æ•°æ®é›†: [spam_ham_dataset.csv](https://www.kaggle.com/venky73/spam-mails-dataset)

## **å…³äºæ•°æ®é›†**

æ•°æ®é›†åŒ…å«ä¸‰åˆ—ã€‚æ•°æ®é›†çš„å¤§å°çº¦ä¸º 5.65mbï¼Œæ€»å…±çº¦æœ‰ 5000 è¡Œã€‚

## åˆ—

Label: hamï¼Œspam
Text:æ–‡æœ¬æˆ–ç”µå­é‚®ä»¶çš„é›†åˆ
Label_num: 0 è¡¨ç¤ºç«è…¿ï¼Œ1 è¡¨ç¤ºåƒåœ¾é‚®ä»¶

## å·¥ä½œ

> æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯åˆ›å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥å‡†ç¡®é¢„æµ‹ä¸€å°ç”µå­é‚®ä»¶æ˜¯å¦æ˜¯åƒåœ¾é‚®ä»¶ã€‚

## å°†æ•°æ®é›†åŠ è½½åˆ°ç¬”è®°æœ¬ä¸­

```
df = pd.read_csv("spam_ham_dataset.csv")
```

# æ•°æ®é›†ä¸Šçš„ EDA

```
print(data.shape)  ### Return the shape of data 
print(data.ndim)   ### Return the n dimensions of data
print(data.size)   ### Return the size of data 
print(data.isna().sum())  ### Returns the sum fo all na values
print(data.info())  ### Give concise summary of a DataFrame
print(df.head())  ## top 5 rows of the dataframe
print(df.tail()) ## bottom 5 rows of the dataframe
```

è¿è¡Œä¸Šè¿°ä»£ç å—åï¼Œæ‚¨å°†ä¼šçœ‹åˆ°æˆ‘ä»¬çš„æ•°æ®é›†ä¸­æ²¡æœ‰ä»»ä½•ç©ºå€¼ã€‚å¦å¤–ï¼Œéœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œæˆ‘ä»¬çš„ä¸­åªæœ‰ä¸€åˆ—æœ‰æ•°å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬åªèƒ½å¯è§†åŒ–è¯¥åˆ—ã€‚

## è®©æˆ‘ä»¬å¯è§†åŒ–åˆ— *label_num*

æˆ‘ä»¬åªèƒ½çœ‹åˆ°åˆ—ä¸­ä¸¤ä¸ªç±»åˆ«çš„æ•°é‡ã€‚

```
df["label_num"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2), ('Non spam', 'spam'),rotation=0);
```

![](img/ff387df71462e67fffe9db21c9937ac6.png)

â€œä½œè€…æä¾›çš„å›¾åƒâ€

åœ¨è¯¥å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡ ä¹ 3500 æ¡ä¸æ˜¯åƒåœ¾é‚®ä»¶ï¼Œå¤§çº¦ 1500 æ¡æ˜¯åƒåœ¾é‚®ä»¶ã€‚

# æ¸…ç†æ–‡æœ¬

åœ¨ä»»ä½• NLP é—®é¢˜ä¸­ï¼Œæœ€é‡è¦çš„æ­¥éª¤æ˜¯æ¸…ç†æ–‡æœ¬ã€‚æ¸…ç†æ–‡æœ¬æ„å‘³ç€åˆ é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ã€åˆ é™¤åœç”¨è¯ã€æ‰§è¡Œè¯å¹²åˆ†æã€è¯æ±‡åŒ–ï¼Œå¹¶å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚

```
import re
corpus = []
length = len(df)
for i in range(0,length):
    text = re.sub("[^a-zA-Z0-9]"," ",df["text"][i])
    text = text.lower()
    text = text.split()
    pe = PorterStemmer()
    stopword = stopwords.words("english")
    text = [pe.stem(word) for word in text if not word in set(stopword)]
    text = " ".join(text)
    corpus.append(text)print(corpus)
```

**è§£é‡Š:**

ç¬¬ 1 è¡Œ:æˆ‘ä»¬æ­£åœ¨å¯¼å…¥ re åº“ï¼Œå®ƒç”¨äºåœ¨ python ä¸­æ‰§è¡Œ regexã€‚ç¬¬ 2 è¡Œ:å®šä¹‰ä¸€ä¸ªç©ºçš„è¯­æ–™åº“åˆ—è¡¨ï¼Œå¯ä»¥ç”¨æ¥å­˜å‚¨æ‰€æœ‰æ¸…ç†åçš„æ–‡æœ¬ã€‚
ç¬¬ 3 è¡Œ:ç”¨æ•°æ®å¸§çš„é•¿åº¦åˆå§‹åŒ– var lengthã€‚
ç¬¬ 4 è¡Œ:è¿è¡Œä¸€ä¸ªä» 0 åˆ°æ•°æ®å¸§é•¿åº¦çš„å¾ªç¯ã€‚
ç¬¬ 5 è¡Œ:åˆ é™¤é™¤å°å†™å­—æ¯ã€å¤§å†™å­—æ¯å’Œæ•°å­—ä¹‹å¤–çš„æ‰€æœ‰å­—ç¬¦ã€‚
ç¬¬ 6 è¡Œ:å°†æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ã€‚
ç¬¬ 7 è¡Œ:æŒ‰ç©ºæ ¼åˆ†å‰²æ–‡æœ¬ã€‚
ç¬¬ 8 è¡Œ:åˆ›å»º porter stemmer çš„å¯¹è±¡ã€‚
ç¬¬ 9 è¡Œ:å°†è‹±è¯­è¯å…¸ä¸­çš„æ‰€æœ‰åœç”¨è¯åˆå§‹åŒ–ä¸º var åœç”¨è¯
ç¬¬ 10 è¡Œ:åœ¨å¥å­çš„é•¿åº¦ä¸Šè¿è¡Œä¸€ä¸ªå¾ªç¯ï¼Œç„¶åå¯¹å¥å­ä¸­çš„æ¯ä¸ªè¯åœ¨åœç”¨è¯ä¸­è¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœåœ¨åœç”¨è¯ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œåˆ™å¯¹æ–‡æœ¬åº”ç”¨è¯å¹²å¹¶å°†å…¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
ç¬¬ 11 è¡Œ:å°†æ‰€æœ‰å•è¯è¿æ¥èµ·æ¥ç»„æˆä¸€ä¸ªå¥å­
ç¬¬ 12 è¡Œ:å°†å¥å­é™„åŠ åˆ°è¯­æ–™åº“åˆ—è¡¨
ç¬¬ 13 è¡Œ:æ‰“å°è¯­æ–™åº“åˆ—è¡¨ã€‚

åœ¨æ¸…ç†è¿‡ç¨‹ä¸­ï¼Œä¸‹ä¸€æ­¥æ˜¯å°†å¥å­åˆ—è¡¨(è¯­æ–™åº“)è½¬æ¢ä¸ºå‘é‡ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ•°æ®è¾“å…¥åˆ°æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ã€‚ä¸ºäº†å°†æ–‡æœ¬è½¬æ¢æˆå‘é‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå•è¯åŒ…ï¼Œå®ƒå°†æ–‡æœ¬è½¬æ¢æˆäºŒè¿›åˆ¶å½¢å¼ã€‚'

```
from sklearn.feature_extraction.text import CountVectorizercv = CountVectorizer(max_features=35000)X = cv.fit_transform(corpus).toarray()
```

ç¬¬ 1 è¡Œ:æˆ‘ä»¬ä» sklearn å¯¼å…¥ CountVectorizerã€‚
ç¬¬ 2 è¡Œ:ä¸ºè®¡æ•°çŸ¢é‡å™¨åˆ›å»ºä¸€ä¸ªå¯¹è±¡ï¼Œæœ€å¤§ç‰¹å¾æ•°ä¸º 35000ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬åªè·å–å‰ 35000 åˆ—ã€‚
ç¬¬ 3 è¡Œ:ä½¿ç”¨ CVï¼Œæˆ‘ä»¬æ­£åœ¨æ‹Ÿåˆ are è¯­æ–™åº“ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå‘é‡ã€‚

## **è½¬å‚¨ç®€å†ä»¥å¤‡å°†æ¥ä½¿ç”¨**

ä¸ºäº†é¢„æµ‹æ–°é‚®ä»¶ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹å’Œè®¡æ•°çŸ¢é‡å™¨ã€‚

```
import pickle ## importing pickle used for dumping modelspickle.dump(cv, open('cv.pkl', 'wb')) ## saving to into cv.pkl file
```

# å»ºæ¨¡å’ŒåŸ¹è®­

## ä½¿ç”¨ train_test_split å°†æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†

```
from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)##train size 80% and test size 20%
```

## ä½¿ç”¨å¤šé¡¹å¼è´å¶æ–¯æ–¹æ³•åˆ›å»ºæ¨¡å‹

```
from sklearn.naive_bayes import MultinomialNBmodel = MultinomialNB()
```

## å°†æ¨¡å‹æ‹Ÿåˆåˆ°è®­ç»ƒé›†

```
model.fit(X_train, y_train)
```

## é¢„è¨€ï¼›é¢„æµ‹ï¼›é¢„å‘Š

```
y_pred=model.predict(X_test)y_pred
```

# è¯„ä¼°æ¨¡å‹

æˆ‘ä»¬å°†ä½¿ç”¨æ··æ·†çŸ©é˜µå’Œå‡†ç¡®åº¦åˆ†æ•°æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
from sklearn.metrics import confusion_matrix,accuracy_scorecm = confusion_matrix(y_test, y_pred)score = accuracy_score(y_test,y_pred)print(cm,score*100)
```

***è¾“å‡º:***

```
[[716  16]
 [ 18 285]] 96.71497584541063
```

> **å¤ªå¥½äº†ï¼Œæˆ‘ä»¬å¾—åˆ°äº† 96.71%çš„å‡†ç¡®ç‡**

# ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹

ä¸ºäº†ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ pickleã€‚

```
import pickle
pickle.dump(model, open("spam.pkl", "wb"))
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡åŠ è½½å’Œæµ‹è¯•æµ‹è¯•æ•°æ®æ¥æµ‹è¯•æˆ‘ä»¬çš„ä¿å­˜æ¨¡å‹ã€‚

```
loaded_model = pickle.load(open("spam.pkl", "rb"))
loaded_model.predict(X_test)
loaded_model.score(X_test,y_test)#####OUTPUT######
96.71497584541063
```

# æ–°é‚®ä»¶çš„é¢„æµ‹

```
def new_review(new_review):
  new_review = new_review
  new_review = re.sub('[^a-zA-Z]', ' ', new_review)
  new_review = new_review.lower()
  new_review = new_review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not') new_review = [ps.stem(word) for word in new_review if not word in   set(all_stopwords)]
  new_review = ' '.join(new_review)
  new_corpus = [new_review]
  new_X_test = cv.transform(new_corpus).toarray()
  new_y_pred = loaded_model.predict(new_X_test)
return new_y_prednew_review = new_review(str(input("Enter new review...")))
if new_review[0]==1:
  print("SPAM")
else :
  print("NOT SPAM")
```

å°è¯•è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œé”®å…¥ä¸€å°éšæœºçš„ç”µå­é‚®ä»¶ï¼Œå¹¶æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹å°†å¦‚ä½•æ­£ç¡®åœ°é¢„æµ‹åƒåœ¾é‚®ä»¶å’Œéåƒåœ¾é‚®ä»¶ã€‚

```
Enter new review...
IMPORTANT - You could be entitled up to Â£3,160 in compensation from mis-sold PPI on a credit card or loan. Please reply PPI for info or STOP to opt out. SPAMEnter new review...
hi scott, i was wondering you have submitted your project or notNOT SPAM
```

# 2.ä½¿ç”¨ flask åˆ›å»º web åº”ç”¨ç¨‹åºå¹¶å°†å…¶ä¸æ¨¡å‹è¿æ¥

å› æ­¤ï¼Œè¦åˆ›å»ºä¸€ä¸ª web åº”ç”¨ç¨‹åºï¼Œè®©æˆ‘ä»¬é¦–å…ˆå‡†å¤‡ä¸€ä¸ªå¦‚ä¸‹æ‰€ç¤ºçš„æ–‡ä»¶å¤¹ç»“æ„

```
email_spam(root)
    |____templates
            |___index.html  ## homepage file
            |___result.html ## to show prediction
    |____static
            |____style.css  ## css file 
    |____app.py  ## main flask file
    |_____spam.pkl ## ml model
    |______cv.pkl  ## count vectorizer
```

***index . html:*** åˆ›å»ºä¸€ä¸ªä¾›ç”¨æˆ·è¾“å…¥æ–°é‚®ä»¶çš„è¾“å…¥æ¡†ï¼Œä»¥åŠä¸€ä¸ªå°†æ–‡æœ¬å‘é€åˆ°æœåŠ¡å™¨çš„æŒ‰é’®ã€‚

***result . html:*** ä½ æƒ³æ˜¾ç¤º gif è¿˜æ˜¯çº¯æ–‡æœ¬è¿˜æ˜¯ä¸¤è€…éƒ½æ˜¾ç¤ºæ¥ä»£æ›¿åƒåœ¾é‚®ä»¶å’Œéåƒåœ¾é‚®ä»¶ï¼Œè¿™æ˜¯ä½ çš„æ„¿æœ›ã€‚

***style . css* å®ƒæ˜¯ä¸€ä¸ª CSS æ–‡ä»¶ï¼Œç”¨æ¥è®©ç½‘é¡µå¥½çœ‹ã€‚è¿™å–å†³äºä½ ï¼Œåªè¦æŒ‰ç…§ä½ çš„æ„æ„¿å»è®¾è®¡ã€‚**

ä½ å¯ä»¥ä»æˆ‘çš„ Github å¸æˆ·ä¸‹è½½å¹¶ä½¿ç”¨æˆ‘çš„æ¨¡æ¿å’Œé™æ€ç›®å½•ã€‚

[](https://github.com/Abhayparashar31/email_spam) [## Abhayparashar31/email_spam

### é€šè¿‡åœ¨ GitHub ä¸Šåˆ›å»ºä¸€ä¸ªå¸æˆ·ï¼Œä¸º Abhayparashar31/email_spam å¼€å‘åšè´¡çŒ®ã€‚

github.com](https://github.com/Abhayparashar31/email_spam) 

***app.py:***

ç°åœ¨è®©æˆ‘ä»¬åœ¨æœ¬åœ°ä¸»æœºä¸Šè¿è¡Œä»£ç 

æ‰“å¼€ CMD å¹¶è½¬åˆ°æ ¹(email_spam)æ–‡ä»¶å¤¹ï¼Œç„¶åä½¿ç”¨`python app.py`è¿è¡Œ app.pyï¼Œç„¶åæ‚¨ä¼šçœ‹åˆ°å¦‚ä¸‹æ¶ˆæ¯ğŸ‘‡

![](img/03776b6868ee7141b27c75d5adebf688.png)

åªéœ€åœ¨ä»»æ„æµè§ˆå™¨ä¸­æ‰“å¼€ç½‘å€( [http://127.0.0.1:5000/](http://127.0.0.1:5000/) )ï¼Œä½¿ç”¨ä¸€äº›æ–°çš„éšæœºé‚®ä»¶æµ‹è¯• web app å³å¯ã€‚

# 3.å°†é¡¹ç›®æäº¤ç»™ Github

åœ¨å°†é¡¹ç›®æäº¤ç»™ Github ä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜è¦åˆ›å»ºä¸¤ä¸ªæ–‡ä»¶ã€‚

**1ã€‚Profile:** Heroku åº”ç”¨ç¨‹åºåŒ…å«ä¸€ä¸ª Procfileï¼Œå®ƒæŒ‡å®šäº†åº”ç”¨ç¨‹åºåœ¨å¯åŠ¨æ—¶æ‰§è¡Œçš„å‘½ä»¤ã€‚

```
web: gunicorn app:app
```

**2ã€‚requires . txt:**è¦æ±‚ã€‚txt æ–‡ä»¶ç”¨äºæŒ‡å®šè¿è¡Œé¡¹ç›®æ‰€éœ€çš„ python åŒ…ã€‚

```
Flask==1.1.1
gunicorn==19.9.0
itsdangerous==1.1.0
Jinja2==2.10.1
MarkupSafe==1.1.1
Werkzeug==0.15.5
numpy>=1.9.2
scipy>=0.15.1
scikit-learn>=0.18
matplotlib>=1.4.3
pandas>=0.19
```

ç°åœ¨ä¹‹åï¼Œå»ä½ çš„ Github è´¦æˆ·ä¸Šä¼ æ–‡ä»¶ï¼Œç„¶åæäº¤ç»™åˆ†æ”¯æœºæ„ã€‚

å¦‚æœä½ ä¸çŸ¥é“æ€ä¹ˆåšï¼Œå°±æŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤å»åšã€‚

![](img/27f7904e28e62aa7699b3efbaf0aa682.png)

â€œä½œè€…æä¾›çš„å›¾åƒâ€

# 4.ä½¿ç”¨ Heroku éƒ¨ç½²æ¨¡å‹

è®¿é—® [Heroku](https://signup.heroku.com/) å¹¶åˆ›å»ºä¸€ä¸ªå…è´¹å¸æˆ·ï¼Œç„¶åç™»å½•æ‚¨çš„å¸æˆ·ã€‚

ç™»å½•åï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„åº”ç”¨ç¨‹åºï¼Œå¹¶è¿æ¥åˆ°ä½ çš„ Githubï¼Œç„¶åæ‰‹åŠ¨éƒ¨ç½²ã€‚æ‚¨å°†çœ‹åˆ°ä¸€ä¸ª URLï¼Œæ‚¨å¯ä»¥é€šè¿‡è¯¥ URL è®¿é—®æ‚¨çš„åº”ç”¨ç¨‹åºã€‚

å¦‚æœä½ ä¸çŸ¥é“æ€ä¹ˆåšï¼Œå°±æŒ‰ç…§å›¾ä¸­æ‰€ç¤ºçš„æ­¥éª¤å»åšã€‚

![](img/a40a48c1d7a4dec3ef7b24ada6b1865d.png)

â€œä½œè€…æä¾›çš„å›¾åƒâ€

![](img/fb269d9f5ff023271510236f817e007c.png)

â€œä½œè€…å›¾ç‰‡:

***ä½ å¯ä»¥åœ¨æˆ‘çš„ Github ç®€ä»‹é‡Œæ‰¾åˆ°æ‰€æœ‰çš„æºä»£ç ***[***abhayparashar 31***](https://github.com/Abhayparashar31/Diabetes-prediction)

## æ„Ÿè°¢é˜…è¯»ğŸ˜ƒ

# å…³äºä½œè€…

æˆ‘æ˜¯ Abhay Parasharï¼Œä¸€ä¸ªè¿·ä¸Š AI çš„ python çˆ±å¥½è€…ã€‚æˆ‘æ˜¯ä¸€åè®¡ç®—æœºä¸“ä¸šçš„å­¦ç”Ÿã€‚ä¸€ä¸ªç‹‚çƒ­çš„ä½œå®¶å’Œç¨‹åºå‘˜ã€‚æˆ‘å‘å¸ƒå…³äº pythonï¼Œæœºå™¨å­¦ä¹ ï¼ŒNLPï¼Œä»¥åŠæ›´å¤šä¸ AI ç›¸å…³çš„æ–‡ç« ã€‚æˆ‘ä¹Ÿå¼ è´´ä¸åŒç§ç±»çš„å…³äºæœºå™¨å­¦ä¹ çš„ç«¯åˆ°ç«¯é¡¹ç›®ã€‚

# æœªæ¥è¯»ç‰©

[](https://towardsdatascience.com/build-deploy-diabetes-prediction-app-using-flask-ml-and-heroku-2de07cbd902d) [## ä½¿ç”¨ Flaskã€ML å’Œ Heroku æ„å»ºå’Œéƒ¨ç½²ç³–å°¿ç—…é¢„æµ‹åº”ç”¨ç¨‹åº

### é¢å‘æœºå™¨å­¦ä¹ çˆ±å¥½è€…çš„ç«¯åˆ°ç«¯é¡¹ç›®éƒ¨ç½²ğŸ‘

towardsdatascience.com](https://towardsdatascience.com/build-deploy-diabetes-prediction-app-using-flask-ml-and-heroku-2de07cbd902d) [](https://medium.com/10-minutes-data-science/cuda-installation-in-windows-2020-638b008b4639) [## windows ä¸­çš„ Cuda å®‰è£…(2020)-é€æ­¥è¿‡ç¨‹

### ä½¿ç”¨ GPU è®­ç»ƒæ‚¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹

medium.com](https://medium.com/10-minutes-data-science/cuda-installation-in-windows-2020-638b008b4639)