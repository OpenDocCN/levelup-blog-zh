<html>
<head>
<title>Understanding and optimization of Google App Engine's automatic scaling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对Google App Engine自动缩放的理解和优化</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/understanding-and-optimization-of-google-app-engines-automatic-scaling-95674910da3b?source=collection_archive---------6-----------------------#2022-01-03">https://levelup.gitconnected.com/understanding-and-optimization-of-google-app-engines-automatic-scaling-95674910da3b?source=collection_archive---------6-----------------------#2022-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="5f3e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文将研究Google App Engine的自动缩放，并通过其<code class="fe ko kp kq kr b">app.yaml</code>文件更改自动缩放的配置来优化其缩放行为。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/2c5f10405f55260a988f9fc9af4040e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZhQEZX-ID2fotKsS"/></div></div><figcaption class="le lf gj gh gi lg lh bd b be z dk translated">照片由<a class="ae li" href="https://unsplash.com/@sigmund" rel="noopener ugc nofollow" target="_blank">西格蒙德</a>在<a class="ae li" href="https://www.unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="a25a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">采用云的一个重要原因是易于扩展。但是，即使有内置的扩展，许多也可能出错，如果处理不当，会累积大量成本。此外，如何“正确扩展”并不明显，因为简单地增加“更多”并不总是正确的选择。</p><h1 id="045d" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">自动缩放</h1><p id="3606" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">尽管Google App Engine有三种不同的缩放类型(自动、基本、手动)，我们将只看自动的一种，因为它提供了最细粒度的选项。</p><p id="a009" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在进一步了解如何优化几个服务之前，我们先来看看您可以设置的不同选项，以定义App Engine的自动缩放行为。</p><p id="1743" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请记住，自动缩放仅适用于类型为<code class="fe ko kp kq kr b">F</code>的App Engine实例类。此外，标准环境和灵活环境之间也存在一些差异。在本文中，我们将使用标准环境。</p><p id="5d9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">缩放元素</strong></p><p id="6b09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在应用引擎配置文件的顶部——我将在后面的实践部分提供一个完整的代码示例——元素<code class="fe ko kp kq kr b">automatic_scaling</code>可以作为根对象来定义自动缩放行为。</p><p id="8729" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面的子元素是可选的，不需要设置，尽管我强烈建议您这样做。</p><p id="fe65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">max_instances</code>—Google应该启动的最大实例数。该值可以介于0和2147483647之间，其中0表示禁用该设置。在繁忙的一天，您应该将这个值设置得比预期值高几倍，以便为用户和流量的突然增加做好准备。我们通常会去6次左右。因此，如果我们从监控中知道，在一个典型的日子里，我们有大约20个实例在运行，那么我们将使用120个max_instances。</p><p id="0798" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">min_instances</code>—Google在任何时候应该运行的最小实例数。有效值介于0和1000之间，其中0表示允许“缩放到零”。但请记住，调整到零总是会导致冷启动。此外，无论实例是否收到任何流量，您都将为实例的运行数量付费。所以如果你要设置的话，不要设置的太高。我们喜欢将这个值设置为几个实例，最多20个实例，特别是对于我们的业务关键型实时系统，我们知道在这些系统中，请求量可能会突然激增。然而，对于大多数非关键系统，0或1的min_instances应该是合适的。</p><p id="a838" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">max_idle_instances</code> —空闲实例的最大数量。有效值从1到1000，或自动，后者是默认值。</p><p id="b99e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">min_idle_instances</code> —空闲实例的最小数量。Google将运行此处指定的实例数，以及Google根据自动缩放算法加速运行的活动实例数。有效值从1到1000，或自动，后者是默认值。</p><p id="5a32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">target_cpu_utilization</code> —指定AppEngine启动新实例时的CPU利用率。有效值范围为0.5到0.95，默认值为0.6。如果您将0.6作为默认值，那么当当前实例的CPU利用率达到60%时，Google会增加新的实例。</p><p id="c82a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">target_throughput_utilization</code> —该设置只能与<code class="fe ko kp kq kr b">max_concurrent_requests</code>配合使用。有效值范围为0.5到0.95，默认值为0.6。当AppEngine上的并发请求数量达到由<code class="fe ko kp kq kr b">target_throughput_utilization * max_concurrent_requests</code>定义的值时，调度程序会尝试启动一个新实例。</p><p id="e592" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">max_concurrent_requests</code> —定义在调度程序产生新实例之前，一个实例可以接受的最大并发请求数。默认值为10，最大值为80。如上所述，该参数需要与<code class="fe ko kp kq kr b">target_throughput_utilization</code>一起使用。将该值设置得太高可能会导致额外的延迟和性能下降，因为每个实例要处理更多的请求。另一方面，如果您希望每个请求产生一个实例，将它设置为1会有所帮助。此外，值得一提的是，高于10的值仅适用于F2或更高的实例类。F1不支持十个以上的并发请求。</p><p id="403b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">max_pending_latency</code> —允许请求停留在挂起队列中的最长时间。如果请求停留的时间更长，调度程序将启动一个新的实例。因此，较高的值意味着，如果当前没有可用于处理请求的实例，应用程序引擎可能需要更长的时间来开始处理用户的请求。另一方面，较低的值会更快地触发应用程序引擎的扩展，并减少延迟，但会由于更多实例的增加而增加成本。有效值的范围是从0.01到15.0秒，而根据您在提供无效值时将收到的错误消息，提供的值必须与下面的RegEx <code class="fe ko kp kq kr b">^(?:^(\d+((\.\d{1,3}?s|ms)|automatic)$)$</code>匹配。值得一提的是，不要把这个值误认为请求从服务器返回的实际时间，而是负载平衡找到服务器来分配请求的时间。</p><p id="a4fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">min_pending_latency</code> —在调度程序创建新的实例来处理请求之前，允许请求停留在挂起队列中的最短时间。与<code class="fe ko kp kq kr b">max_pending_latency</code>完全一样，有效值范围从0.01到15.0秒，而提供的值必须与下面的正则表达式<code class="fe ko kp kq kr b">^(?:^(\d+((\.\d{1,3}?s|ms)|automatic)$)$</code>匹配。</p><p id="c304" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">min_pending_latency</code>与<code class="fe ko kp kq kr b">max_pending_latency</code>协同工作，它们一起创建了以下自动缩放行为:</p><ol class=""><li id="3984" class="mm mn it js b jt ju jx jy kb mo kf mp kj mq kn mr ms mt mu bi translated">一个请求到达应用程序，但是没有实例可以为它服务，所以Google将它放在挂起的请求队列中。</li><li id="7edb" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn mr ms mt mu bi translated">直到请求到达<code class="fe ko kp kq kr b">min_pending_latency</code> : App Engine试图找到一个可用的实例来服务请求，并且不创建新的实例。</li><li id="b8f4" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn mr ms mt mu bi translated">在队列中的时间超过<code class="fe ko kp kq kr b">min_pending_latency</code>之后，到达<code class="fe ko kp kq kr b">max_pending_latency</code>之前:App Engine试图找到一个可用的实例来服务请求。</li><li id="518d" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn mr ms mt mu bi translated">超过请求等待时间后<code class="fe ko kp kq kr b">max_pending_latency</code> : App Engine停止搜索一个可用的实例来服务请求，并产生一个新的实例。</li></ol><p id="5f07" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以看到一个<code class="fe ko kp kq kr b">app.yaml</code>文件的例子，我在下面的代码片段中定义了所有上述参数。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="43e8" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">亲自动手</h1><p id="55a4" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">现在我们已经快速检查了Google App Engine提供的所有可能的自动缩放参数，让我们检查几个典型的真实场景，看看我们如何使用上述参数优化缩放行为。</p><p id="b0b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为我们比较的“起点”，我们将始终使用上面提到的<code class="fe ko kp kq kr b">app.yaml</code>文件，然后稍微调整一下参数，以改善我们应用程序的缩放行为。</p><p id="5943" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们将在所有后续测试中使用“斜坡到达率”来创建流量。这意味着我们可以定义一个时间范围(例如，2分钟)和虚拟用户的目标数量(VU)，负载测试脚本将自动调整其vu，直到它在时间范围结束时达到目标。通过链接这些定义，我们可以快速创建自定义场景来模拟流量变化。此外，我们定义VUs每秒发出一个请求。</p><p id="2ad8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您会注意到，在后面的图片中有两行显示了我们的App Engines实例数。绿色的代表当前活动的实例，粉色的代表空闲的实例。</p><p id="41d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在这个<a class="ae li" href="https://github.com/Abszissex/uc-8-appengine-scaling" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到以下例子的代码。</p><p id="d242" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们要看的场景:</p><ul class=""><li id="af0a" class="mm mn it js b jt ju jx jy kb mo kf mp kj mq kn nc ms mt mu bi translated">许多长期运行的请求</li><li id="5767" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn nc ms mt mu bi translated">计算密集型请求</li><li id="6c10" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn nc ms mt mu bi translated">内存密集型请求</li></ul><p id="257e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">许多长期运行的请求</strong></p><p id="1cbf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们想看的第一个场景是“许多长时间运行的请求”不管它们是短期的还是长期的。它们只需要CPU价格低廉。这里的一个典型用例是一个服务器向许多客户端提供简单的数据，它从一些数据库中获取数据，不需要做很多修改，对CPU和内存的要求也很低。</p><p id="15be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出于演示目的，我们用每个vu触发的端点是一个简单的<code class="fe ko kp kq kr b">/longRunning </code>端点，它在返回之前等待五秒钟，除此之外什么也不做。</p><p id="c1f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下面，你可以看到端点的定义。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="a6cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的场景:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nd"><img src="../Images/89872c50918326f7f80400e2de68514f.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*xcPuDKJ93yZyAUlRIjZiMw.png"/></div></div></figure><p id="2423" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面的场景中，您可以看到我们从两个用户开始，停留两分钟，然后在两分钟内扩展到五个和十个用户。之后，我们在两分钟内保持十个用户，然后再逐渐减少。</p><p id="9208" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用我们的初始<code class="fe ko kp kq kr b">app.yaml </code>配置运行上述场景(总共12分钟)，我们在Google云监控中获得了以下指标:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ne"><img src="../Images/d244c00b3d47ebf46cef321abc35f3e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JS3zi7h_rCLqzirnJZj-Pg.png"/></div></div></figure><p id="9eae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">响应和CPU指标非常简单，随着请求数量的增加而增加/减少。在响应指标中，我们可以看到我们精确地达到了之前定义的每秒十个请求，因为在我们的场景中我们定义了每秒一个请求的10个vu。</p><p id="2e58" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在延迟图中，您可以很好地看到，除了一些最初的高和小问题之外，服务需要五秒多一点的时间来响应，考虑到五秒的等待时间加上一些处理/网络开销，这绝对有意义。实例的冷启动，如果你熟悉无服务器，你应该已经经常经历过，是最初高的原因。因为当第一个请求到达URL时，根本没有服务器在运行，因为我们的<code class="fe ko kp kq kr b">app.yaml</code>定义了一个缩小到零的比例，所以在实例可以处理任何请求之前，Google必须加速第一个请求，这需要一点时间。</p><p id="c147" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">内存使用与我们的总实例(活动+空闲)相一致，每个实例都有一些运行服务器代码和操作系统的开销。</p><p id="3bdf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是这里最有趣/最重要的部分是实例图。这里我们可以看到，Google在收到第一个请求后会立即旋转多达三个实例，过了一小段时间后，这三个实例中只有两个会主动为请求提供服务。这是因为，在开始时，根本没有实例可以处理任何请求，所以Google会不断增加实例，直到有实例可以处理请求。</p><p id="2838" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们达到发送请求的峰值之前，我们可以观察到伸缩工作得非常好，并且只有一个额外的情况，其中一个实例是空闲的，但是除此之外，所有的实例都是活动的并且响应请求。就在我们再次开始减少请求时，我们可以看到我们在相当长的时间里一直有空闲的实例。在这个例子中，Google在上午7:45左右关闭了空闲实例，大约在最后一个请求发送后12分钟。但是这没关系，因为App Engine不是“处理一个请求然后立即关闭”情况的解决方案。此外，您不希望这里有太多的冷启动，所以让实例多存活几分钟也没问题。</p><p id="880c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为一种解决方法，如果您想提前关闭实例，可以重新部署应用程序并覆盖以前的版本。这样，谷歌关闭旧实例的速度会更快。</p><p id="cbba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">仔细看一下图表，您会注意到，您必须运行7个App Engine实例，这样才能每秒处理10个请求，这听起来有些过分，主要是因为您根本没有利用CPU和内存，因为只有长时间运行的请求。但是，您仍然要为为实例保留的资源付费。</p><p id="9f02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe ko kp kq kr b">app.yaml</code>文件提供的配置可能性，我们可以很容易地在这里进行优化。我们的默认配置使用0.6的<code class="fe ko kp kq kr b">target_throughput_utilization</code>和10的<code class="fe ko kp kq kr b">max_concurrent_requests</code>，这意味着如果请求的数量大于6个并发请求的阈值，App Engine将向上扩展。由于我们的服务器只处理请求，不会对CPU或内存造成任何影响，因此我们可以放心地将<code class="fe ko kp kq kr b">max_concurrent_requests</code>增加到80(可用的最大值),从而在App Engine基于并发请求进行扩展之前创建48 (80 * 0.6)个并发请求的阈值。当然，您不应该盲目地增加自动伸缩参数，而是应该持续监视您的服务在新配置下的行为，并检查日志中出现的任何错误。</p><p id="3f74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，让我们看看在更改了<code class="fe ko kp kq kr b">max_concurrent_requests</code>之后，我们的实例缩放表现如何:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nf"><img src="../Images/92c26bfe814d6d0f615c570a04b31235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4ZX-ivDEYnQWx-0L_uaEg.png"/></div></div></figure><p id="c0ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与上一次观察相比，您应该会立即注意到一些差异:</p><ul class=""><li id="3706" class="mm mn it js b jt ju jx jy kb mo kf mp kj mq kn nc ms mt mu bi translated">最大CPU利用率约为4%，而不是2%</li><li id="8893" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn nc ms mt mu bi translated">使用的内存非常稳定，而且比以前少了很多</li><li id="6888" class="mm mn it js b jt mv jx mw kb mx kf my kj mz kn nc ms mt mu bi translated">实例数量非常一致，并且比以前低了很多</li></ul><p id="3047" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们快速检查一下为什么我们会看到上述差异。</p><p id="63aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们期望CPU有所增加，因为我们现在每个实例有更多的请求，并且每个请求消耗一点点CPU。</p><p id="4d5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">内存消耗减少且更加稳定也是合理的，因为消耗内存的实例减少了。此外，我们没有太多的向上/向下缩放，因此，不断消耗内存。</p><p id="5bab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">查看我们的实例计数，我们注意到我们从单个活动实例开始，并坚持到测试结束。即使我们总是有至少一个额外的实例空闲运行。总有一个实例是空闲的，这一开始听起来可能有点混乱，但是如果你计算一下，这是有意义的。</p><p id="d89e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们告诉App Engine，根据上面的配置更改，当超过48 (80 * 0.6)个并发请求的阈值时，我们希望进行扩展。然而，我们也知道一个请求至少需要5秒钟外加一些开销。此外，我们知道我们每秒发送多达10个请求，这意味着App Engine将需要处理至少50个(5秒* 10个请求/秒= 50个请求)并发请求，而阈值约为每个实例48个。因此，有两个可用的实例是绝对有意义的，即使其中一个是空闲的。</p><p id="89df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下图显示了两种配置的比较及其对彼此下方缩放行为的影响。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ng"><img src="../Images/b5e2292abd6dd7097e6aae347afc8484.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nshRcfSPBoqvDewSWm6UPQ.png"/></div></div></figure><p id="c4bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您所看到的，如果您知道您的服务器需要处理什么样的负载，那么通过适当的配置来削减成本是相对容易的——也就是说，运行七个实例的成本是运行两个实例的成本的数倍。</p><p id="dc27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">计算密集型请求</strong></p><p id="56b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了通过调整并发请求来改变伸缩行为之外，还可以通过CPU阈值来定义伸缩行为。在本文的开始，我们了解了可以在我们的<code class="fe ko kp kq kr b">app.yaml</code>文件中修改的<code class="fe ko kp kq kr b">target_cpu_utilization</code>属性。默认情况下，该属性的值为0.6。因为我们现在想看看如何调整这个属性来减少实例/成本，让我们将我们的应用程序与我们的默认YAML配置和相同的配置(增加了0.9的<code class="fe ko kp kq kr b">target_cpu_utilization</code>)进行比较。</p><p id="dc95" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下图中，您可以看到该测试的场景。正如您将注意到的，我们比并发请求方法的步骤少得多，并且在稍微加速之后，我们更加关注稳定数量的请求。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/58aadcbd2ddc8857285749a6273f9f98.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*WTdNLjlccqrZcqdZeMvf2A.png"/></div></figure><p id="ec9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以在下面的代码片段中看到我们为此场景调用的端点定义。代码运行一个小但CPU密集型的方法，并在我们调用端点时返回。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="c2bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们看看如何使用默认的YAML配置来扩展我们的应用程序。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nh"><img src="../Images/81d8a0d65cd1e8862eb3764c12b977f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnNCQylPcKxyP3t_kT6TYA.png"/></div></div></figure><p id="90c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑到上面的监控，我们可以看到CPU利用率在60–70%左右波动，这绝对有意义，因为我们的CPU阈值是0.6 (60%)。此外，我们最初看到短暂的100%峰值，但这是由于冷启动。在最初的峰值之后，应用程序引擎“稳定下来”。</p><p id="ea10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样需要注意的是，99%的请求延迟大约是10秒。</p><p id="d55a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们来看看增加了<code class="fe ko kp kq kr b">target_cpu_utilization</code> <em class="ni">的相同场景。</em></p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nj"><img src="../Images/11617eeadf50be29dcc3990034fb6a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*22ZqKkKCwegFjjoHFs4hYQ.png"/></div></div></figure><p id="ff51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">并直接比较这两种方法。在下图中，你可以首先看到我们的“默认”配置，然后第二次使用增加的<code class="fe ko kp kq kr b">target_cpu_utilization</code> <em class="ni">运行我们的设置。</em></p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nk"><img src="../Images/ae05fde8eb241125b40c6b01e659755c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmCn6ykkrzwPasYAy29SvQ.png"/></div></div></figure><p id="67fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">比较这两种方法，您会注意到三件事。</p><p id="1e23" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，第二次设置在CPU方面更加“冷静”，但实际上，这并不意味着太多，因为第一次运行中CPU的大多数波动都是在冷启动发生的最开始。正如我们所知，App Engine在冷启动后需要一点时间来“稳定”。</p><p id="b1f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第二，也是更重要的一点，两次运行之间的实例总数变化不大。但是，同样，在将阈值从60%提高到90%之后，这并不是人们所期望的。</p><p id="1153" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第三，即使我们将阈值提高到90%，CPU利用率也只有50%左右，远远低于预期。当实例达到阈值时，将阈值调整为90%的App Engine应该会向上扩展，因此我们预计CPU利用率在80–90%左右。</p><p id="15d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">加上我们从“许多长时间运行的请求”一节学到的知识，并考虑到我们的请求需要很长时间才能返回，我们可以得出第二次和第三次意外观察的一个可能原因。</p><p id="7452" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基于CPU的App Engine似乎没有适当扩展的假定原因可能是并发请求配置。正如我们所知，我们已经使用了我们的“默认”配置作为上述测试的基础。在这个配置中，<code class="fe ko kp kq kr b">max_concurrent_requests</code>属性仍然是10。因此，显而易见的假设是，App Engine是由于这个属性而不是CPU阈值而缩放的，这可以解释上面的观察结果。</p><p id="0022" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了验证我们的假设，让我们重新运行上面的场景。但是这一次，<code class="fe ko kp kq kr b">max_concurrent_requests</code>属性设置为80。</p><p id="5232" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ko kp kq kr b">max_concurrent_requests</code>设置为80的默认配置:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nl"><img src="../Images/d409a4b030379cbe85420aaec0412cee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FqiVJaYeh2fbtW6YTJQajg.png"/></div></div></figure><p id="130a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe ko kp kq kr b">max_concurrent_requests</code> = 80且<code class="fe ko kp kq kr b">target_cpu_utilization</code>设置为0.9的配置:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nm"><img src="../Images/9ad91c4412a06c558c99fd6452c1150f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqo4Z7zeXevXLF4TLRTmVw.png"/></div></div></figure><p id="fbbf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">两种配置进行了比较:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nl"><img src="../Images/aba25fd2065fea7e8a1ab8b97833d797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Hmi8UGCxxX4twEmktiDSw.png"/></div></div></figure><p id="1223" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您在上面的图片中所看到的，尽管我们的假设可能是正确的，但是增加并发请求不仅没有帮助，反而极大地损害了我们的服务，尤其是在目标CPU利用率增加的情况下。</p><p id="af81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于高负载，现在允许每个实例接收8倍数量的请求，这大大降低了实例的速度，当您比较图形的延迟时可以看到这一点。</p><p id="ee7e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了便于比较，您可以看到下图，显示了我们在上面测试的四种不同的配置。在这里，您可以特别看到<code class="fe ko kp kq kr b">max_concurrent_requests</code> <em class="ni"> =10 </em>情况下的延迟非常一致并且在合理的范围内，而<code class="fe ko kp kq kr b">max_concurrent_requests</code> <em class="ni"> =80 </em>使服务器过载，延迟增加了1分钟以上，而不是大约10秒。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nn"><img src="../Images/01d416425d60886eb6296830f987fd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAP8tY_VYr82sZAWeL0Emw.png"/></div></div></figure><p id="cfa9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了上述延迟增加之外，我还观察到在高并发(80)高CPU阈值(0.9)的情况下，相当多的失败请求(3.44%的失败请求超过了<em class="ni">上下文截止时间</em>错误)，我假设这是由于HTTP超时。查看官方的<a class="ae li" href="https://cloud.google.com/appengine/docs/standard/nodejs/how-instances-are-managed#timeout" rel="noopener ugc nofollow" target="_blank">应用引擎文档</a>，Google声明“自动缩放”的默认HTTP超时是1分钟，这与我刚才提供的假设一致，因为我们有几个请求超过了1分钟。</p><p id="a2fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以我们现在知道，仅仅增加并发请求并没有帮助，反而会大大降低性能。因此，除了增加并发请求，降低并发请求也是可能的。</p><p id="e93d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下面的例子中，我将CPU阈值保持在0.9，并将最大并发请求数减少到5。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nn"><img src="../Images/628209e292a7062bfa7cd4a3d7a8af16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMfQysAXt2DaKk3rgJuRNA.png"/></div></div></figure><p id="1a73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将这一次与前几次相比，几乎没有明显的区别。这意味着默认配置对于CPU密集型负载来说已经足够好，可以在大部分时间使用。当然，如果性能发生变化，尝试不同的配置和测试总是值得的。还值得一提的是，我在所有示例中都使用了F2实例类，这对于计算密集型任务来说绝不是最好的。当执行无法并行化的单线程CPU密集型任务时，我总是建议先垂直扩展，再水平扩展。</p><p id="aa32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">内存密集型请求</strong></p><p id="f29a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不幸的是，没有基于内存消耗来扩展应用引擎的配置。然而，您也可以使用适当的监控来优化内存密集型应用程序引擎。因此，我想简单介绍一下如何扩展这些高内存服务。</p><p id="0d92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以做的第一件事是检查F4_1G实例类。这个实例类的内存是常规F4的两倍，因此是目前您可以选择的最高内存实例类。F4 1g可能是用于高内存应用的一个很好的候选。但是当然，这可能还不能解决缩放问题。</p><p id="5784" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">选择适当的实例类后，您应该确保不要在同一个应用程序引擎上混合使用高内存端点和低内存端点。例如，高内存端点可以包括返回几千个元素的列表，而低内存端点可能只返回计算结果或一个元素。当然，世界上大多数服务都混合了这两者，但是如果您想为内存密集型服务优化伸缩，您应该考虑将它们分开。</p><p id="1e35" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当您的服务中只剩下高内存端点时，您可以通过GCP监控来监控一段时间内的内存使用情况，并检查内存使用情况是否接近最大值。当然，您也可以使用“混合”端点来实现这一点，但是这会使内存消耗更加不稳定，这取决于负载平衡器如何在实例之间分配请求。例如，一个实例可能获得所有高内存请求，而其他实例主要对低内存请求感到厌烦。</p><p id="5e4d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过将当前实例数乘以实例类的内存限制，可以很容易地计算出最大内存。例如，F2实例类的内存限制是512 MB，所以如果运行10个活动实例，当超过5 GB (~ 10 * 512MB)时，我们就会遇到问题。当然，您应该更早地进行测量，因为您永远也不想耗尽内存。</p><p id="b2f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您发现您达到了特定的内存使用阈值，我建议使用70%左右，并且定期地，是时候做点什么了。除了通常的代码优化(在任何一种情况下都应该这样做)，最好的解决方案是减少并发请求的最大数量，因为更少的请求当然意味着更少的总内存消耗。</p><p id="3376" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，如果您的服务配置了40个最大并发请求，并且您经常达到70%的内存使用率，那么您应该考虑在第一步将最大并发请求减少到35个甚至30个。但是，我不会建议直接到20甚至更低。因为在您的服务基于最大并发请求扩展的情况下，这是很常见的，降低到20将导致实例数量翻倍，从而增加100%的成本。当然，你的内存使用量也会减少不少。但是请记住，每个实例至少需要一点内存来运行服务器和底层操作系统，因此即使您将实例增加一倍，内存使用也不会减少50%。</p><h1 id="9858" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">摘要</h1><p id="6176" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">您已经看到，有相当多的属性可以配置您的应用程序引擎的扩展行为，尽管并不是每个指标(如内存使用量)都可以用作扩展的阈值。</p><p id="d384" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe ko kp kq kr b">target_throughput_utilization</code>和<em class="ni"> </em> <code class="fe ko kp kq kr b">max_concurrent_requests</code>属性可以最好地扩展CPU廉价请求。只要不消耗可用的CPU，请求是短时间的还是长时间的都没关系。</p><p id="0b6c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用<code class="fe ko kp kq kr b">target_cpu_utilization</code>属性进行缩放是可行的，但这取决于代码必须完成的实际底层工作。根据一般经验，保持默认值0.6或0.7是避免服务过载和降低性能的最佳选择。</p><p id="6b36" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在CPU密集型应用程序上允许大量并发请求通常不是一个好主意，在许多情况下可能会导致请求失败和很长的响应时间。如果性能下降，减少最大并发请求数是减少负载和提高性能的一种方法。</p><p id="eec9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了“用硬件杀死它”和内部代码优化，减少内存密集型应用程序的最大并发请求是防止内存不足错误的最佳方法。</p><h2 id="ab3e" class="no lk it bd ll np nq dn lp nr ns dp lt kb nt nu lx kf nv nw mb kj nx ny mf nz bi translated">你想联系吗？</h2><p id="6350" class="pw-post-body-paragraph jq jr it js b jt mh jv jw jx mi jz ka kb mj kd ke kf mk kh ki kj ml kl km kn im bi translated">如果你想联系我，请通过LinkedIn 联系我。</p><p id="c598" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另外，请随意查看我的书籍推荐<a class="ae li" href="https://medium.com/@mr-pascal/my-book-recommendations-4b9f73bf961b" rel="noopener">📚。</a></p></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><div class="kt ku kv kw gt oh"><a href="https://mr-pascal.medium.com/my-book-recommendations-4b9f73bf961b" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">我的书籍推荐</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">在接下来的章节中，你可以找到我对所有日常生活话题的书籍推荐，它们对我帮助很大。</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">mr-pascal.medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov lc oh"/></div></div></a></div><div class="ow ox gp gr oy oh"><a href="https://mr-pascal.medium.com/membership" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">通过我的推荐链接加入Medium—Pascal Zwikirsch</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">mr-pascal.medium.com</p></div></div><div class="oq l"><div class="oz l os ot ou oq ov lc oh"/></div></div></a></div></div></div>    
</body>
</html>