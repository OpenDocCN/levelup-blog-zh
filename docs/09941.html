<html>
<head>
<title>Why TCP/IP Stack is Highly Inefficient for High-Performance Computing Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么TCP/IP协议栈对于高性能计算系统效率很低</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/why-tcp-ip-stack-is-highly-inefficient-for-high-performance-computing-systems-e294003e1cf7?source=collection_archive---------7-----------------------#2021-10-05">https://levelup.gitconnected.com/why-tcp-ip-stack-is-highly-inefficient-for-high-performance-computing-systems-e294003e1cf7?source=collection_archive---------7-----------------------#2021-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e6e9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">人工智能训练集群中TCP/IP的性能低效</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0540ac21081d6ba45bc4c635ba8059e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VrTqtH08ARhuYCXX"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">阿纳斯塔塞·马拉戈斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="47f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的十年中，数据量一直在快速增长。单台计算机已无法胜任这些大型数据计算任务。多台计算机被放在一起处理数据和进行计算。但是高计算能力只是在人工智能训练集群中实现低作业完成时间的一部分。这些系统之间的网络互连也应该是高性能的。否则，总的作业完成时间将总是受到网络的瓶颈限制。</p><p id="5f87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的二十年里，以太网已经从100Mbps发展到400Gbps。随着硬件和网卡的发展，数据可以通过网络以非常高的速度快速传输。但要实现这一点，系统还应该能够足够快地处理数据包。否则，我们将永远无法利用完整的网络带宽。</p><h1 id="d2df" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">TCP处理开销</h1><p id="c472" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" rel="noopener ugc nofollow" target="_blank">传输控制协议(TCP) </a>是当今网络世界中网络堆栈中被广泛接受的传输层协议。由于其可靠性、适应性和健壮性，TCP在广泛的应用中继续占据主导地位。</p><p id="45b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦数据通过网络传输，传输层就要进行大量的处理。这种处理是实现TCP协议的可靠性和健壮性所必需的。其中很少包括流量控制、拥塞控制、校验和计算以及将数据传递给应用程序。</p><p id="e5f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去几年中，千兆速度网络的发展主要在两个方面对TCP提出了挑战——性能和CPU要求。</p><p id="436d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看协议处理对CPU的要求。理论上，传输协议处理1位传输每秒需要1个CPU周期。随着网卡传输带宽的增加和更多数据通过网络传输，系统将消耗大量CPU周期进行协议处理。CPU的大部分将被网络协议处理而不是应用计算所消耗。</p><p id="e238" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们进入与协议处理相关的性能问题。影响性能的一个协议处理开销是操作系统。</p><p id="1269" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协议处理需要在操作系统中做很多事情，比如接受中断、分配包缓冲区、释放包缓冲区、重启IO设备、唤醒进程以及管理定时器。这些会造成一部分处理开销，但不是主要的。</p><p id="c4c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协议处理中影响性能的主要瓶颈是该过程中涉及的多个内存副本。</p><p id="0793" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在IP协议组中，当传输数据时，在接收端会发生以下步骤，</p><ul class=""><li id="b7c2" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Network_interface_controller" rel="noopener ugc nofollow" target="_blank">网络接口控制器</a>将接收数据【1读操作】并将中断内核</li><li id="eb6e" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">内核识别哪个应用程序数据属于哪个应用程序，并将唤醒那个应用程序</li><li id="1933" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">应用程序会将数据从套接字缓冲区复制到应用程序缓冲区[1次读取和1次写入操作]</li><li id="e349" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">将计算校验和[1次读取操作]</li></ul><p id="777f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，从网络接收数据包需要四次内存访问操作。当今动态ram的典型周期时间为250 ns的32位存储器意味着存储器限制为32 Mb/s，因此存储器访问必须变得更快，以便有效利用网络带宽速率。这些内存副本是TCP协议中最显著的性能低效之处。</p><p id="2260" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多年来，开发了其他技术来避免IP网络堆栈中的处理开销和多个副本— InfiniBand和远程直接内存访问。</p><h1 id="b5c0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">无限带宽和RDMA</h1><p id="5d47" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/InfiniBand#:~:text=InfiniBand%20%28IB%29%20is%20a%20computer,both%20among%20and%20within%20computers.&amp;text=It%20is%20designed%20to%20be,a%20switched%20fabric%20network%20topology." rel="noopener ugc nofollow" target="_blank"> InfiniBand </a>是一种网络通信标准，用于高性能计算系统以实现高吞吐量和低延迟。它用作计算机之间的数据互连。它相当于以太网，一种物理层标准，以太网提供高达400Gbps的连接，而Infiniband仅提供高达200Gbps的连接。</p><p id="b95a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Infiniband支持<a class="ae ky" href="https://en.wikipedia.org/wiki/Remote_direct_memory_access#:~:text=In%20computing%2C%20remote%20direct%20memory,in%20massively%20parallel%20computer%20clusters." rel="noopener ugc nofollow" target="_blank"> RDMA </a>，这是一种零拷贝技术。它在通信过程中绕过内核，不涉及CPU。这减少了大量的CPU开销，并且在性能上比TCP好得多。</p><p id="89f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RDMA提供对另一个系统内存的访问，而不涉及任何一个系统的操作系统。使用RDMA通常需要实现InfiniBand的专用网络硬件。RDMA技术使网络接口控制器能够在数据包到达时了解以下信息——该数据包属于哪个应用程序，以及该数据包应放在哪个应用程序缓冲存储器中。有了这些信息，数据将直接写入应用程序缓冲区，而不经过网络堆栈或涉及操作系统。这个过程需要InfiniBand API动词来执行RDMA操作，应用程序应该支持这个API。</p><p id="f944" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">近年来，<a class="ae ky" href="https://en.wikipedia.org/wiki/RDMA_over_Converged_Ethernet" rel="noopener ugc nofollow" target="_blank"> RoCE </a> —融合以太网上的RDMA得到了发展，在标准以太网网络接口控制器上提供RDMA功能，而无需支持Infiniband的专用硬件。</p><h1 id="e621" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="ea4d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">由于操作系统的开销和内存中数据的多个副本，TCP具有很高的处理开销。这使得它对于高性能和低延迟网络来说效率非常低。</p><p id="fdaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RDMA广泛应用于高速、低延迟网络，如人工智能训练集群。RDMA有它的缺点，不适合各种工作负载，而且不如TCP灵活，也更复杂。</p><p id="15e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并非所有工作负载都需要高性能、低延迟，并且可能不会有繁重的数据传输，从而导致较高的处理开销。选择TCP还是RDMA取决于系统的工作负载和性能要求。</p><p id="2036" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一定要看看我下面的其他相关文章。</p><div class="ng nh gp gr ni nj"><a href="https://medium.com/mlearning-ai/how-do-processes-communicate-in-parallel-computing-collective-communications-4419d90529c6" rel="noopener follow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">并行计算中的进程是如何通信的？集体通信</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">集体通信导论</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">medium.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx ks nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a href="https://blog.devgenius.io/cuda-and-parallel-programming-on-gpu-dd698d2bd73d" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">CUDA与GPU上的并行编程</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">CUDA和GPU上的并行编程如何加速计算能力</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">blog.devgenius.io</p></div></div><div class="ns l"><div class="ny l nu nv nw ns nx ks nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a href="https://medium.com/@getting.better.everyday/what-is-message-passing-interface-mpi-e5cf61d2bcde" rel="noopener follow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">什么是消息传递接口(MPI)？</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">平均弹着点</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">) ?MPImedium.com</p></div></div><div class="ns l"><div class="nz l nu nv nw ns nx ks nj"/></div></div></a></div><h1 id="0281" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">资源</h1><ol class=""><li id="7b3c" class="ms mt it lb b lc mn lf mo li oa lm ob lq oc lu od my mz na bi translated"><a class="ae ky" href="https://ieeexplore.ieee.org/author/37086746368" rel="noopener ugc nofollow" target="_blank"/>，<a class="ae ky" href="https://ieeexplore.ieee.org/author/37289600400" rel="noopener ugc nofollow" target="_blank">，</a>，<a class="ae ky" href="https://ieeexplore.ieee.org/author/37085760778" rel="noopener ugc nofollow" target="_blank">王芳</a>，<a class="ae ky" href="https://ieeexplore.ieee.org/author/38487017100" rel="noopener ugc nofollow" target="_blank">梁明</a>，<a class="ae ky" href="https://ieeexplore.ieee.org/author/37534447500" rel="noopener ugc nofollow" target="_blank">谢雨来</a>，TCP和RDMA在现代服务器平台上的性能深度分析(2010)<a class="ae ky" href="https://ieeexplore.ieee.org/document/6310890" rel="noopener ugc nofollow" target="_blank">，</a></li><li id="21b6" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu od my mz na bi translated">大卫·d·克拉克，范·雅各布森，约翰·罗姆基，霍华德·萨尔温，TCP处理开销分析(1989)，<a class="ae ky" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=29545" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;ar number = 29545</a></li><li id="2da3" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu od my mz na bi translated">雷纳托·约翰·雷西奥，万兆网络上的套接字与RDMA接口:对内存流量瓶颈的深入分析(2003年)，<a class="ae ky" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.3915&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/download?doi = 10 . 1 . 1 . 77 . 3915&amp;rep = re P1&amp;type = pdf</a></li></ol></div></div>    
</body>
</html>