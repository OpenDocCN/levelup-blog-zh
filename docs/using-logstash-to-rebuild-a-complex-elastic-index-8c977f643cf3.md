# 使用 logstash 重建复杂弹性指数

> 原文：<https://levelup.gitconnected.com/using-logstash-to-rebuild-a-complex-elastic-index-8c977f643cf3>

## 对于复杂对象，Logstash 是 rest 客户端的替代方案

![](img/67530498b8c0fff9bf335ab35406a6a8.png)

Maksym Kaharlytskyi 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

两年前，我们开始使用弹性搜索将我们的一个主要应用程序的用户体验提升到一个新的水平——一个带有**关系数据库模型**的基本 CRUD 应用程序。

在获得第一个用例的积极反馈后，我们开始更深入地整合它。

# 问题是

一切看起来都很好，直到我们有了一个新功能，我们必须向现有文档添加一些数据，我们需要重建我们的索引。

简单的任务…至少我们是这样认为的。

在我们的关系数据库模型中添加新字段，并将其添加到 UI 和 Beans 中，这和以前一样简单。

当我们开始用数据填充新字段时，问题就出现了。我们必须用来自不同数据源的迁移值填充它。这意味着我们现在不得不将这些新数据放入我们现有的索引中，其中包含许多大型文档。

当我们第一次使用这个指数时，它非常小。我们编写了一些简单的服务将数据读入我们的对象，通过调用一些其他服务来准备和丰富它们，然后使用 **RestHighLevelClient 将它们放入我们的索引中。**

但是现在这项服务成了我们的瓶颈。重建索引需要超过 16 个小时。这对于一次性重建来说是可以的，但是了解我们的利益相关者和我们项目的性质后，我们意识到这将很快再次发生。

由于白天进行部分更新不是我们的用户和利益相关者也同意的选项，我们必须找到一个不同的解决方案。

# Logstash 来救援？

当然，我们的第一次尝试是优化现有服务的性能，但很快我们就看到它已经达到了极限。经过一番调查后，我们决定尝试一下 **logstash** 。

在我们的环境中设置它并查看 jdbc 插件之后。我们从一个管道开始，有一个巨大的声明。对于我们来说，性能比从我们的服务中推送我们的对象要好得多并不奇怪。

管道示例:

简单管道

使用 logstash 的优点:

*   索引重建可以快得多
*   减少我们后端服务的负载

缺点是:

*   你创建一个新层。现在，您必须在源代码和 logstash 管道中维护您的对象/类
*   用户在看到对象之前可能会有一段延迟时间(取决于您的管道配置)

# 多管道

我们仍然对结果不完全满意。我们速度更快，但是语句太复杂，对我们的数据库影响太大，所以我们尝试了另一种解决方案。基于我们的关系数据模型，我们在 logstash 中创建了多个管道。

例如，一个项目包含一个客户和一个报价。因此，我们创建了三个管道来镜像这三个元素。当然，一个元素可以包含多个表。

该项目的管道如下所示:

多管道示例

**输出**插件是这里最有趣的部分。

*动作*参数和 *doc_as_upsert* 参数允许我们插入不存在的新文档。但是如果文档已经存在，那么来自我们的输入插件的值会被添加到现有的文档中。因此，我们现在可以创建多个管道，写入同一文档的同一索引。您只需要确保在所有管道上使用相同的 **id** 。

一个文档有多个管道的优点是:

*   部分重建是可能的
*   更好的性能
*   更容易理解 SQL 语句

缺点是:

*   您将不得不维护多个语句和管道。如果您要维护多个环境，这将变得更加困难

# 结论

去掉中间层，在我们的例子中是 Java 服务，可以大大减少索引的重建时间。但是这也带来了在项目中引入新的层次和复杂性的代价。