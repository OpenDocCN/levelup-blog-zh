<html>
<head>
<title>Implement Naive Bayes Classifier from Scratch using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python从头实现朴素贝叶斯分类器</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/implement-naive-bayes-classifier-from-scratch-using-python-11f0ad137600?source=collection_archive---------1-----------------------#2020-04-12">https://levelup.gitconnected.com/implement-naive-bayes-classifier-from-scratch-using-python-11f0ad137600?source=collection_archive---------1-----------------------#2020-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b9d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的灵感来自于MCS-DS项目(来自UIUC)的课程作业(CS412:数据挖掘导论)。此外，感谢杰森·布朗利关于机器学习掌握的<a class="ae kl" href="https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/" rel="noopener ugc nofollow" target="_blank">帖子</a>。</p><p id="0e7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用于演示的数据集是来自UCI机器学习<a class="ae kl" href="https://archive.ics.uci.edu/ml/datasets/Zoo" rel="noopener ugc nofollow" target="_blank">数据集</a>的动物园动物分类数据集，这是分类数据。在Jason的文章中，他使用了著名的鸢尾花物种数据集，其中包含连续值数据。但是概念非常相似，两个帖子使用的唯一库是Random(用于分割训练和测试数据)。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="b933" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">朴素贝叶斯分类器</h2><p id="5940" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">首先，让我们了解朴素贝叶斯分类的基础知识。</p><p id="60cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们将特征表示为X，将标注表示为y。作为生成模型，朴素贝叶斯分类器基于联合概率P(X，y)的估计进行预测。</p><p id="63bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个示例，预测标签由下式确定:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/24cb67191542066c860cda1cff20199f.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*X_lVyFeDri_5d6KSSgjlRQ.png"/></div></figure><p id="f01f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在朴素贝叶斯分类器中，我们假设给定类别标签，所有特征都是独立的。这意味着:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/8646b4f1801cca259ba248e7cb455636.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*D61qKWps2DPhXv7TzqCLig.png"/></div></figure><p id="55fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了进行预测，我们需要跟踪P(y)和P(Xi|y)。</p><h2 id="e2c6" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">缓和</h2><p id="f6ce" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">由于一些数据组合没有出现在我们的数据集中，我们平滑的概率和拉普拉斯校正。具体来说，由于动物园动物数据集很小，我们用伪计数0.1来平滑概率。</p><p id="80ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">也就是说，</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ma"><img src="../Images/5e4fabfd4c3ba20b24a3a230eb3a2300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TqYfJzI9Z98iFt4b7e6GA.png"/></div></div></figure></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="193c" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">动物园动物分类数据集</h2><p id="d587" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">动物园数据库是由理查德·福赛思在1990年创建的。这是一个简单的数据库，包含来自动物园的101只动物。有16个不同特征的变量来描述动物。这7类类型是:哺乳动物、鸟类、爬行动物、鱼类、两栖动物、昆虫和无脊椎动物。“类型”属性似乎是类属性。以下是哪种动物属于哪种类型的分类:</p><p id="b56d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类别# —动物组:</p><p id="77d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =<br/>1—(41)土豚、羚羊、熊、野猪、水牛、小牛、豚鼠、猎豹、鹿、海豚、大象、果蝠、长颈鹿、女孩、山羊、大猩猩、仓鼠、野兔、豹、狮子、猞猁、水貂、鼹鼠、猫鼬、负鼠、大羚羊、鸭嘴兽、矮种马、鼠海豚、美洲狮、猫、浣熊、驯鹿、海豹、海狮、松鼠、吸血鬼、田鼠、小袋鼠 大蜥蜴<br/> 4 — (13)鲈鱼、鲤鱼、鲶鱼、鲢鱼、狗鱼、黑线鳕、鲱鱼、狗鱼、食人鱼、海马、鳎鱼、黄貂鱼、金枪鱼<br/> 5 — (4)青蛙、青蛙、蝾螈、蟾蜍<br/> 6 — (8)跳蚤、昆虫、蜜蜂、家蝇、瓢虫、蛾、白蚁、黄蜂<br/> 7 — (10)蛤蜊、螃蟹、小龙虾、章鱼、蝎子、海黄蜂、蛞蝓、海星、蠕虫</p><p id="6df1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">属性信息:</p><p id="6c48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.动物名称:每个实例的唯一名称<br/> 2。头发:布尔<br/> 3。羽毛:布尔<br/> 4。彩蛋:布尔<br/> 5。牛奶:布尔<br/> 6。空降:布尔<br/> 7。水生:布尔<br/> 8。捕食者:布尔<br/> 9。有齿:布尔<br/> 10。主干:布尔<br/> 11。呼吸:布尔型<br/> 12。剧毒:布尔<br/> 13。鳍:布尔型<br/> 14。腿:数字(一组值:{0，2，4，5，6，8}) <br/> 15。tail:布尔型<br/> 16。国产:布尔<br/> 17。catsize: Boolean <br/> 18。类型:数值(范围[1，7]内的整数值)</p><p id="aab5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">显然这是一个多类分类任务。动物的名字不应该被用来预测。15个属性是布尔值(0或1)。“腿”属性有数值(0，2，4，5，6，8)。在我们的代码中，我们将把它们分别翻译成(0，1，2，3，4，5)。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="59c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们深入到编码部分。</p><h2 id="2481" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">加载库</h2><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="182a" class="kt ku iq mg b gy mk ml l mm mn">import random</span></pre><p id="e229" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如前所述，random是我们唯一需要的库，用于拆分训练和测试数据。</p><h2 id="378a" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">加载数据和数据清理</h2><p id="a69c" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">在这里，我们假设您已经从<a class="ae kl" href="https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data" rel="noopener ugc nofollow" target="_blank">这里</a>下载了数据，并将其保存在与python代码或Jupyter笔记本相同的目录下。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="940e" class="kt ku iq mg b gy mk ml l mm mn"># read in the file<br/>file = open('zoo.data', 'r')</span><span id="7ace" class="kt ku iq mg b gy mo ml l mm mn"># create a list to include all the lines in the text file<br/>data = []<br/>for line in file:<br/>    data.append(line)<br/>    <br/># close file<br/>file.close()</span><span id="0d9e" class="kt ku iq mg b gy mo ml l mm mn"># remove /n from end of each line<br/>data = [i.strip() for i in data]</span></pre><p id="ab53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用列表来存储数据，列表的长度是101，因为数据库中有101只动物。现在我们显示数据中的前5条记录。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="3fab" class="kt ku iq mg b gy mk ml l mm mn">data[0:5]<br/>['aardvark,1,0,0,1,0,0,1,1,1,1,0,0,4,0,0,1,1',<br/> 'antelope,1,0,0,1,0,0,0,1,1,1,0,0,4,1,0,1,1',<br/> 'bass,0,0,1,0,0,1,1,1,1,0,0,1,0,1,0,0,4',<br/> 'bear,1,0,0,1,0,0,1,1,1,1,0,0,4,0,0,1,1',<br/> 'boar,1,0,0,1,0,0,1,1,1,1,0,0,4,1,0,1,1']</span></pre><p id="97f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在用“，”分割每条记录，并将每条记录从字符串转换为列表。然后我们去掉动物的名字，因为它对预测没有用。最后，我们使用一个定义的函数，将legs属性值转换为(0，1，2，3，4，5)。这样做的原因是更容易进行后续计算，因为我们可以直接使用属性值作为索引来从模型中检索可能性。代码如下:</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="fbc1" class="kt ku iq mg b gy mk ml l mm mn">split_data = [d.split(",") for d in data]</span><span id="db8b" class="kt ku iq mg b gy mo ml l mm mn">animal_names = []<br/>for row in split_data:<br/>    name = row.pop(0)<br/>    animal_names.append(name)</span><span id="26e0" class="kt ku iq mg b gy mo ml l mm mn"># define a function to convert legs attribute to 0 - 5<br/>def convert_legs_value(data):<br/>    value_list = ['0', '2', '4', '5', '6', '8']<br/>    convert_list = ['0', '1', '2', '3', '4', '5']<br/>    for row in data:<br/>        row[12] = convert_list[value_list.index(row[12])]<br/>    return data</span><span id="a6fa" class="kt ku iq mg b gy mo ml l mm mn">split_data = convert_legs_value(split_data)</span></pre><p id="3fdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们再来看一下数据。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="51bf" class="kt ku iq mg b gy mk ml l mm mn">for i in range(5):<br/>    print(split_data[i])</span></pre><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/8d50739e5f1ab6fd4d327f998343486b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*PNH9jUYAPCYfPkwpOnVi9w.png"/></div></figure><p id="d4a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住每条记录的最后一个元素是标签。我们成功地翻译了“腿”值(属性13)。例如，对于前两个动物，原始值是4，现在是2。</p><h2 id="389b" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">分割训练和测试数据</h2><p id="1e89" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">首先，我们定义一个数据分割函数。实际上对于test_size参数，我们可以输入样本数(int)或百分比(float)。函数可以处理这两种情况。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="e92c" class="kt ku iq mg b gy mk ml l mm mn">def train_test_split(data, test_size):<br/>    <br/>    if isinstance(test_size, float):<br/>        test_size = round(test_size * len(data))</span><span id="bfff" class="kt ku iq mg b gy mo ml l mm mn">    test_indices = random.sample(range(len(data)), k=test_size)<br/>    train_indices = [i for i in range(len(data)) if i not in test_indices]<br/>    <br/>    test_df = []<br/>    for index in test_indices:<br/>        test_d = data[index]<br/>        test_df.append(test_d)<br/>    <br/>    train_df = []<br/>    for index in train_indices:<br/>        train_d = data[index]<br/>        train_df.append(train_d)<br/>    <br/>    return train_df, test_df</span></pre><p id="8f8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们可以使用这个函数，将数据随机分成训练数据(71)和测试数据(30)。行random.seed(0)有助于确保每次运行代码时都能得到相同的结果。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="3a35" class="kt ku iq mg b gy mk ml l mm mn">random.seed(0)<br/>train_data, test_data = train_test_split(split_data, test_size = 30)</span><span id="e0f9" class="kt ku iq mg b gy mo ml l mm mn">train_sample_num = len(train_data)<br/>attr_num = len(train_data[0])-1</span></pre><p id="c636" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还分配了两个全局变量:train_sample_num和attr_num，它们将用于后面的计算。attr_num有一个“-1”，因为每个动物的最后一个值是标签，而不是属性。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="d099" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们完成了数据准备部分，现在我们可以转移到朴素贝叶斯模型训练和测试。</p><h2 id="aaa3" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">按类分隔数据</h2><p id="69d3" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">第一步，我们定义一个函数来按类分离训练数据。这里我们使用字典来存储数据。字典键是显示在训练数据集中的类，而字典值是属于每个类的记录。这很重要，因为稍后我们将依赖分离的数据来计算P(y)和P(Xi|y)。</p><p id="2355" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">代码如下:</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="a9a1" class="kt ku iq mg b gy mk ml l mm mn"># Split the dataset by class values, returns a dictionary<br/>def separate_by_class(dataset):<br/>    separated = dict()<br/>    for i in range(len(dataset)):<br/>        vector = dataset[i]<br/>        class_value = vector[-1]<br/>        if (class_value not in separated):<br/>            separated[class_value] = list()<br/>        separated[class_value].append(vector)<br/>    return separated</span><span id="3c6a" class="kt ku iq mg b gy mo ml l mm mn">separated = separate_by_class(train_data)</span></pre><p id="77fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看一下分离出来的部分数据，你就明白了。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="ebfe" class="kt ku iq mg b gy mk ml l mm mn">for key, value in separated.items():<br/>    print(key)<br/>    print(value)</span></pre><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mq"><img src="../Images/af89fbde31e1306d6034d7b2803c09fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYZwqBAKioyzGlMeQYyzGg.png"/></div></div></figure><h2 id="736c" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">通过计算可能性训练模型</h2><p id="54c7" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">我们在这里定义的第一个辅助函数用于计算P(y)。这真的很简单。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="77f8" class="kt ku iq mg b gy mk ml l mm mn">def calculate_class_py(label):<br/>    count = len(label)<br/>    py = count/train_sample_num<br/>    return py</span></pre><p id="626b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一个辅助函数是用来计算P(Xi|y)的。这部分有点棘手，因为“腿”属性不同于所有其他属性，它有6个不同的独特功能。所以，我们用不同的方式处理了这件事。此外，当计算P(Xi|y)时，我们向每个分子添加0.1，并向分母添加0.1 * #的独特特征。这是平滑的，因为我们不希望一个单一的0可能性值破坏整个计算。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="544c" class="kt ku iq mg b gy mk ml l mm mn">def calculate_pxy(label):<br/>    pxy = []<br/>    for i in range(attr_num):<br/>        if i != 12:<br/>            count0 = 0<br/>            count1 = 0<br/>            for row in label:<br/>                if row[i] == '0':<br/>                    count0 += 1<br/>                else:<br/>                    count1 += 1<br/>            cal = ((count0 + 0.1)/(len(label) + 0.2), (count1 + 0.1)/(len(label) + 0.2))<br/>            pxy.append(cal)<br/>        else:<br/>            count0 = 0<br/>            count1 = 0<br/>            count2 = 0<br/>            count3 = 0<br/>            count4 = 0<br/>            count5 = 0<br/>            for row in label:<br/>                if row[i] == '0':<br/>                    count0 += 1<br/>                elif row[i] == '1':<br/>                    count1 += 1<br/>                elif row[i] == '2':<br/>                    count2 += 1<br/>                elif row[i] == '3':<br/>                    count3 += 1<br/>                elif row[i] == '4':<br/>                    count4 += 1<br/>                else:<br/>                    count5 += 1<br/>            cal = ((count0 + 0.1)/(len(label) + 0.6), (count1 + 0.1)/(len(label) + 0.6), (count2 + 0.1)/(len(label) + 0.6),<br/>                   (count3 + 0.1)/(len(label) + 0.6), (count4 + 0.1)/(len(label) + 0.6), (count5 + 0.1)/(len(label) + 0.6))<br/>            pxy.append(cal)<br/>            <br/>    return pxy</span></pre><p id="1a6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们可以使用这两个辅助函数来构建我们的模型，并将其存储到字典中。代码如下:</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="8a82" class="kt ku iq mg b gy mk ml l mm mn">def summarize_by_class(separated):<br/>    model = dict()<br/>    for class_value, rows in separated.items():<br/>        pxy = calculate_pxy(rows)<br/>        py = calculate_class_py(rows)<br/>        model[class_value] = [pxy, py]<br/>    return model</span><span id="dc25" class="kt ku iq mg b gy mo ml l mm mn">model = summarize_by_class(separated)</span></pre><p id="b59a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们打印模型并展示部分结果，让您对模型有所了解。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="121d" class="kt ku iq mg b gy mk ml l mm mn">for key, possibilities in model.items():<br/>    print(key)<br/>    print(possibilities)</span></pre><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mr"><img src="../Images/a740fe3da927e5ff0e598785a7e08376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VkJFh7td-_w5cE4MkVF6yg.png"/></div></div></figure><p id="c4aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面你可以看到，我们将P(Xi|y)作为元组存储在每个类下。一个独特特征的一种可能性。这使得下面的预测很容易，因为我们可以根据要预测的数据直接选择我们需要的可能性。</p><h2 id="0df3" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">进行预测和模型评估</h2><p id="689d" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">使用训练模型预测的想法很简单，我们计算每个类别(在我们的例子中是7个类别)的可能性，并选择具有最高可能性值的一个作为我们的获胜者。</p><p id="89f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们还需要一个辅助函数来计算类的可能性。请向上滚动到背景部分，在此处检查计算公式:</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="f3f5" class="kt ku iq mg b gy mk ml l mm mn">def calculate_class_probabilities(model, sample):<br/>    probabilities = dict()<br/>    for class_value, class_summaries in model.items():<br/>        probabilities[class_value] = class_summaries[1]<br/>        for i in range(attr_num):<br/>            probabilities[class_value] *= class_summaries[0][i][int(sample[i])]<br/>    return probabilities</span></pre><p id="7ead" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以用一个测试样本来检查函数，看看结果如何:</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="5675" class="kt ku iq mg b gy mk ml l mm mn">calculate_class_probabilities(model, test_data[0])</span></pre><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/cf691f6da6ef39904af3a69701817315.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*wbIhykLPf7HQS4O8v6C24Q.png"/></div></figure><p id="d92d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算出的可能性表明，从测试数据来看，这种动物属于1类，这是正确的。</p><p id="c947" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面这个函数叫做预测。基本上，它使用上述函数的结果，为我们选择最佳的标签(类)。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="dfeb" class="kt ku iq mg b gy mk ml l mm mn"># Predict the class for a given sample<br/>def predict(model, sample):<br/>    probabilities = calculate_class_probabilities(model, sample)<br/>    best_label, best_prob = None, -1<br/>    for class_value, probability in probabilities.items():<br/>        if best_label is None or probability &gt; best_prob:<br/>            best_prob = probability<br/>            best_label = class_value<br/>    return best_label</span></pre><p id="72be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，让我们对测试数据中的所有动物进行预测，并通过计算整体准确性来评估我们的模型。</p><pre class="ls lt lu lv gt mf mg mh mi aw mj bi"><span id="ebe4" class="kt ku iq mg b gy mk ml l mm mn"># get all the predictions<br/>predictions = []<br/>for row in test_data:<br/>    best_label = predict(model, row)<br/>    predictions.append(best_label)</span><span id="bf5b" class="kt ku iq mg b gy mo ml l mm mn"># get all the real labels<br/>actual = []<br/>for row in test_data:<br/>    real_label = row[-1]<br/>    actual.append(real_label)<br/>    <br/># Calculate accuracy percentage<br/>def accuracy_metric(actual, predicted):<br/>    correct = 0<br/>    for i in range(len(actual)):<br/>        if actual[i] == predicted[i]:<br/>            correct += 1<br/>    return correct / float(len(actual)) * 100.0</span><span id="f09a" class="kt ku iq mg b gy mo ml l mm mn">accuracy = accuracy_metric(actual, predictions)<br/>print("The accuracy of predcition is: %.2f percent!" %accuracy )</span></pre><p id="c280" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">96.67%我们成功了！</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="9cd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我相信几乎所有的机器学习爱好者，像我一样，以前都使用过朴素贝叶斯分类器。我们都知道，对于垃圾邮件过滤等许多应用来说，这是一个很好的模型。但是通常我们直接使用scikit-learn这样的库，大多数时候我们并不关心，也不真正知道模型的底层是什么。</p><p id="3667" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过完成这个作业，我学到了很多东西，对模型有了更好的理解。通过写这篇文章，我想记录我的经历，同时与任何需要的人分享这些知识。</p><p id="76a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个拥有4年多编码经验的数据科学家，我仍然认为自己是一个初学者。所以我上面列出的代码离完美还差得很远。即使对于朴素贝叶斯模型本身，也有很多东西可以改进:</p><p id="aa65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，它不能处理连续值的特征。</p><p id="041b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其次，除了我们使用的动物园动物数据集之外，它还不足以处理其他数据集。</p><p id="fe73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">无论如何，如果你有任何建议或问题，请随时留下评论。如果您对UIUC的数据科学硕士项目有任何疑问，也请告诉我。</p></div></div>    
</body>
</html>