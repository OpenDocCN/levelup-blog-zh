<html>
<head>
<title>Tabular Q-learning: A Prominent Reinforcement Learning (RL) Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">表格Q学习:一种重要的强化学习算法</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/tabular-q-learning-a-prominent-reinforcement-learning-rl-algorithm-db364fe2d474?source=collection_archive---------10-----------------------#2022-08-21">https://levelup.gitconnected.com/tabular-q-learning-a-prominent-reinforcement-learning-rl-algorithm-db364fe2d474?source=collection_archive---------10-----------------------#2022-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3160258fb0fe29020f4e9cc06b1b592e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0wD0JafgCU74o5V3k0zeQ.jpeg"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@possessedphotography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">附身摄影</a>在<a class="ae kf" href="https://unsplash.com/s/photos/robot-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="f3c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在以前的一篇文章中，我介绍了有限贴现马尔可夫决策过程(MDP):</p><div class="le lf gp gr lg lh"><a href="https://medium.com/@CalebMBowyer/markov-decision-processes-mdps-for-reinforcement-learning-rl-47d4a56d76f" rel="noopener follow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">用于强化学习的马尔可夫决策过程</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">马尔可夫决策过程(MDP)是所有强化学习中最重要的模型之一。它允许…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">medium.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv jz lh"/></div></div></a></div><p id="da64" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，你将学习如何通过使用表格Q-learning来优化解决上述模型的任何实例。提醒一下，任何有限贴现MDP环境都有有限数量的状态和有限数量的控制，因此我们可以在内存中存储一个Q表，其中行代表可能的状态，列代表可能的控制。</p><h1 id="5576" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">q函数符号</h1><p id="0ad0" class="pw-post-body-paragraph kg kh it ki b kj mv kl km kn mw kp kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">Q函数依赖于一个策略管理单元，并将一个状态控制对映射到一个实数，该实数是永远遵循策略管理单元的代理的期望回报。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/fb5ae97427590fb841a923639330d929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sia2lA8SmBDDWUkeUBE29A.png"/></div></div></figure><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/7c799cea56d855e0f4430ef2631cc555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ngVFa5BYj8Vm1xmFW6j1WQ.png"/></div></div></figure><h1 id="df04" class="lx ly it bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">Q-学习Q-表更新</h1><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/65d5d2b100624c6cd1b90c9faa0a4c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GDvOC30dPMxxPhV_Yhpxtw.png"/></div></div></figure><p id="1e4b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于上面的数学更新，需要注意的真正重要的是1)它可以用一行代码实现，2)我们正在为每个状态控制对更新Q表中的特定条目，以及3)更新是无模型的，因此它不依赖于奖励函数或转换动态的知识。这种更新是使用来自代理-环境交互的状态、控制和回报的样本来执行的。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="d6ec" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lw">首先关注本博客，从今天开始学习RL、Python和其他高价值主题；如果你想留在圈子里，永远不会错过我的故事，然后订阅我的电子邮件列表。</em> <strong class="ki iu"> <em class="lw">考虑成为媒介会员，以获得对我和其他作者作品的无限制访问:</em> </strong></p><div class="le lf gp gr lg lh"><a href="https://medium.com/@CalebMBowyer/membership" rel="noopener follow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">用我的推荐链接加入灵媒——凯莱布·鲍耶，理学硕士</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">阅读凯莱布·m·鲍耶和(媒体上许多其他天才作家)的每一个故事。您的会员费直接…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">medium.com</p></div></div><div class="lq l"><div class="no l ls lt lu lq lv jz lh"/></div></div></a></div><p id="9099" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lw">下次见，</em></p><p id="17d7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lw">迦</em></p></div></div>    
</body>
</html>