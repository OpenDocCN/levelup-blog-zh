# 随机森林分类器—预测森林

> 原文：<https://levelup.gitconnected.com/random-forest-classifier-a-forest-of-predictions-6ee30b59de8c>

![](img/60053a226e91a2a03f8a9efa18872785.png)

[https://unsplash.com/photos/sMQiL_2v4vs](https://unsplash.com/photos/sMQiL_2v4vs)

我 **想象你最后做的决定**。可能是你该不该买辆新车，或者晚饭该吃什么。独自做出任何类型的决定都是困难的，因为你需要考虑的事情太多了。对我来说，花 1 个小时来决定吃什么(不是很好的利用时间😅)!如果我告诉你，你不需要自己做决定，而其他东西可以引导你做这些决定，那会怎么样？这就是随机森林分类器的作用，但它是什么呢？

**决策树**

为了理解随机森林分类器是如何工作的，我们首先需要理解一个基本概念，决策树。决策树是一种工具，用于生成洞察力并找到可能的结果，如偶然事件结果、资源成本和效用函数。

![](img/67b014533c0b1a79c0f25f4c23aa1109.png)

假设我们有一组 6 个形状，其中 2 个是正方形，4 个是三角形。两个正方形都是红色的，两个三角形也是红色的。让我们也想象剩下的三角形是蓝色的。现在我们有了数据集，我们想把它们分成不同的类。我们如何做到这一点？

![](img/9f80ac5702ecea9b26210f616bee30ec.png)

首先，我们可以根据形状的不同颜色来分割数据集。所以我们可以用这个问题，“是红色的吗？”来分割我们的第一个节点。节点是数据集一分为二的地方。符合标准的归入“是”类，不符合标准的归入“否”类。

![](img/1d319a0ebd8a9a208d674e70dcb3ef1a.png)

在这种情况下，2 个红色方块和 2 个红色三角形属于“是”类别，而剩余的蓝色三角形属于“否”类别。现在在我们的“是”类别中，我们有 2 个红色正方形和 2 个红色三角形，所以我们可以问一个问题来分开它们，“它是正方形吗？”。这意味着 2 个红色方块将进入“是”类别，2 个红色三角形将进入“否”类别。现在我们的决策树完成了！！

**什么是随机森林分类器？**

![](img/388381d9cba2c0a332e259ce812941cb.png)

随机森林分类器只是一堆单独的决策树，它们一起工作。随机森林中的每棵树都进行类别预测，投票最多的类别成为模型的整体预测。随机森林工作得非常好的原因是因为有大量不相关的模型(树)作为一个委员会工作。这个委员会可以胜过任何一个单独的模型。

不相关模型是让随机森林如此有效的关键。产生这种惊人效果的原因是这些树相互保护，避免了各自的错误。有些树可能是错误的，但许多树将是正确的，所以这些树可以一起朝着正确的方向移动。

为了让随机森林分类器正常工作，特征中需要有实际信号，这样模型就不会只是猜测。此外，由单个树做出的预测彼此之间必须具有低相关性。

**未砍伐树木的重要性**

为了理解为什么有一个不相关的模型真的很重要，让我们用一个例子。假设我们在玩一个游戏，我掷骰子，它可以是奇数也可以是偶数。如果骰子落在偶数上，你得到一些点数，如果骰子落在奇数上，你失去相同数量的点数。现在让我们假设你有以下三个游戏选项:

1.  玩 1 回合，下注 100 分
2.  玩 10 轮，每次下注 10 分
3.  玩 100 轮，每次押 1 分

以下是每场比赛的终点(得分或失分的概率为 50%):

游戏 1 = .50 * 100 + .50 * -100 = 0

第二场= (.50 * 10 + .50 * -10) * 10 = 0

第三场= (.50 * 1 + .50 * -1) * 100 = 0

![](img/d042daabce0d9e15326bd4b3829d2119.png)

在上面的三个游戏中，你都没有得分。然而，这并不是全部情况，因为这是预期的结果，而不是收到的分数分布。现在让我们想象我们每场比赛都打了 100 分钟。第一场打了 100 次，我赢了 10%的比赛。玩了 100 次游戏 2，我赢了 40%的游戏。最后 100 打完第三场，赢了 52%的比赛。

在开始的时候，游戏预计会给我们相同的胜率，但在我们分发游戏后，我们有了一个更清晰的选择。随机森林分类器就像这样，我们尝试的次数越多，决策就越清晰。

**保持树木不相关**

为了保持决策树彼此不相关，随机森林分类器使用 Bagging 和特征随机性。

***装袋***

决策树在很大程度上依赖于它们被训练的数据，因此对其进行的微小改变会导致不同的树结构。随机森林分类器利用这一点创建不相关的树，方法是允许单棵树从数据集中随机采样，从而产生不同的树。让我们想象一下，我们正在使用上面的同一个数据集。如果我们把一个三角形变成一个正方形，这棵树看起来会和原来的有很大的不同。这种方法叫做装袋。

***特征随机性***

通常在决策树中，当我们分割一个节点时，我们会查看可以将数据集分割成的每个可能的特征。然后，我们选择最能分割数据集的要素。为了保持树不相关，随机森林分类器将从一组特征中随机选取一个特征。这迫使树与众不同，彼此之间有更多的差异。这导致树之间的低相关性。这种方法叫做特征随机性。

**随机森林分类器的缺点**

尽管随机森林分类器是一个非常好的决策分类器，但它也有一些局限性。

*   随机森林分类器在对大型数据集进行实时预测时非常慢且效率低下，因为它使用了大量的树。这种类型的分类器可以快速训练，但在训练时要花很多时间来进行预测。为了有一个更精确的模型，模型需要有很多树，这可能需要很长时间。在大多数实际应用中，使用它就足够了，但是，在某些情况下，另一个模型会更好。

**随机森林分类器的使用案例**

尽管随机森林分类器有其局限性，但由于其简单性，它在现实应用中被广泛使用。

*   ***金融:*** 在金融中，它目前被用来预测客户是否可能按时偿还债务或更频繁地使用银行的服务。在交易中，它被用来决定股票的未来行为。
*   ***医疗保健:*** 在医疗保健中，它被用来识别药物中成分的正确组合。它还被用来分析病人的病史，以确定疾病。
*   ***电子商务:*** 在电子商务中，目前被用来判断一个客户是否会真正喜欢该产品，并做出推荐。

这只是 Random Forest 使用的一小部分，应用程序的数量每天都在增长。

**随机森林在做预测的最前沿**

随机森林分类器是一个神奇而简单的分类器，可以进行实时预测。做一个快速准确的分类器来做决策，确实是一个不错的选择。随机森林分类器正以各种方式在各部门得到利用，并在这些领域产生积极影响。

让我们回顾一下你们可能来到这里的原因。什么是随机森林分类器？

> 随机森林是一种预测分类器，由许多单独的决策树组成。它使用 Bagging，特征随机性来使它的树彼此不相关。

随机森林分类器目前是一种关键的预测算法，与其他同伴一起，机器学习工具正在对现实世界的场景产生深刻的影响。

Nivan 是一名 14 岁的人工智能开发者，他希望利用技术来帮助解决世界上的问题。他目前正在建立一家名为 Lemonaid 的公司，这是一个将青少年与需要志愿者/实习生招聘帮助的组织联系起来的平台。如果你想进一步讨论这篇文章或只是谈谈，请发邮件到 nivangujral@gmail.com 给我。