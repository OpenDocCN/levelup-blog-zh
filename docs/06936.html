<html>
<head>
<title>Using GridSearchCV to optimize your Machine Learning model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GridSearchCV优化您的机器学习模型</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/using-gridsearchcv-to-optimize-your-machine-learning-models-1ebb3b054cd7?source=collection_archive---------23-----------------------#2021-01-12">https://levelup.gitconnected.com/using-gridsearchcv-to-optimize-your-machine-learning-models-1ebb3b054cd7?source=collection_archive---------23-----------------------#2021-01-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5ea5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">超参数调整可以帮助您获得模型的最佳性能</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/6d2e56e01a1fa89ae3c499a8c793495b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D1ZjHdThqQ4CGzZL"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">Jorge Salvador 在<a class="ae lc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="38f9" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">当训练你的机器学习模型时，创建一个基线，或没有任何特定调整的“香草”模型是最常见的协议。我们这样做是为了测试我们的模型在数据上的表现。因此，当我们调整超参数时，我们可以知道是否正在进行改进。但是我们如何改进我们的模型呢？</p><p id="71bd" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">加快改进模型过程的一个方法是使用一个叫做GridSearch的交叉验证工具。使用GridSearch CV，我们可以为所选参数定义一系列值。然后，我们迭代这些参数的每个组合，以查看哪个组合对我们选择的成本函数的改善最大。点击这里查看GridSearchCV <a class="ae lc" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank">的文档。</a></p><p id="089a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">例如，我在下面提供了一个随机森林的三重分类模型的代码。我将演示如何有效地使用GridSearch并提高我的模型的性能</p><blockquote class="lz ma mb"><p id="9e85" class="ld le mc lf b lg lh jr li lj lk ju ll md ln lo lp me lr ls lt mf lv lw lx ly ij bi translated">随机森林模型的快速总结:随机森林本质上是决策树的集合。决策树被戏称为“贪婪算法”,因为它在信息增益最大的地方做出分割特征的“决定”。</p></blockquote><h2 id="5843" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lm mp mq mr lq ms mt mu lu mv mw mx my bi translated">首先，导入必要的库:</h2><p id="e3b7" class="pw-post-body-paragraph ld le iq lf b lg mz jr li lj na ju ll lm nb lo lp lq nc ls lt lu nd lw lx ly ij bi translated">我们将依靠sklearn库来训练/测试拆分我们的数据gridsearch，以及创建一个具有标准缩放和随机森林模型本身的管道。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="7798" class="mg mh iq nf b gy nj nk l nl nm">from sklearn.model_selection import train_test_split, GridSearchCV<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import StandardScaler</span></pre><p id="92f4" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们将使用“status_group”作为标签来拆分数据。这些是水井功能的状态。有三种状态标签:功能性、非功能性和功能性需要维修。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="2acd" class="mg mh iq nf b gy nj nk l nl nm">X = final_model_data.drop(labels=['id', 'status_group'], axis=1)<br/>y = final_model_data.status_group</span><span id="54e5" class="mg mh iq nf b gy nn nk l nl nm">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)</span></pre><p id="7fb7" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后，我创建一个管道来简化我们的流程。管道的想法是整合步骤以节省时间。在这里，我运行StandardScaler(在相同的尺度上获得我们的数字特征)和随机森林集成分类器模型。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="30d2" class="mg mh iq nf b gy nj nk l nl nm">def machine_learn(model) :<br/>    model_pipeline = Pipeline([('ss', StandardScaler()), <br/>                              ('model', model)])<br/>    fitted_model = model_pipeline.fit(X_train, y_train)<br/>    print("Accuracy Score:", fitted_model.score(X_test, y_test))<br/>    model_preds = fitted_model.predict(X_test)<br/>    print(classification_report(y_test, model_preds))<br/>    print(confusion_matrix(y_test, model_preds))</span></pre><p id="31d0" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后，我们使用管道函数快速运行基线模型，为再现性设置random_state，n_estimators为200。“n_estimators”本质上是我们的随机森林中决策树的数量。关于决策树如何运作的更多信息，请看Chirag Sehra 的文章<a class="ae lc" href="https://chiragsehra42.medium.com/decision-trees-explained-easily-28f23241248" rel="noopener">。</a></p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="522f" class="mg mh iq nf b gy nj nk l nl nm">machine_learn(RandomForestClassifier(random_state=123, n_estimators=200))</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi no"><img src="../Images/ed9841dbf4d48eb0a85e3bffdf975844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-P-tG7gjR7t-ka9BOBhHsg.png"/></div></div></figure><p id="78ae" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们的基线模型具有0.802的精度。这真的很不错。注意，这可能是因为我的数据集已经被大范围清理了，但那是另一篇完整的博文！这里我们只关注如何使用GridSearch。</p><p id="acf3" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，让我们看看是否有可能提高我们模型的准确性。我将输入大范围的值，GridSearch将对这些值进行彻底搜索，以得出最佳的准确度分数。</p><p id="728a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这里的想法是首先从广泛的值开始，然后在每次迭代中找到最佳值。</p><h2 id="f5af" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lm mp mq mr lq ms mt mu lu mv mw mx my bi translated">网格搜索</h2><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="b7eb" class="mg mh iq nf b gy nj nk l nl nm">newer_grid = [{'RF__max_depth': [8, 12, 16], <br/>         'RF__min_samples_split': [12, 16, 20], <br/>         'RF__criterion': ['gini', 'entropy']}]</span><span id="09a1" class="mg mh iq nf b gy nn nk l nl nm">gridsearch = GridSearchCV(estimator=rf_pipeline, <br/>                          param_grid=newer_grid, <br/>                          scoring='accuracy', <br/>                          cv=5)</span><span id="8108" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.fit(X_train, y_train)</span><span id="9cfd" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.score(X_test, y_test)</span><span id="35bf" class="mg mh iq nf b gy nn nk l nl nm">#0.7978050982843647 - accuracy</span><span id="5265" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.best_params_</span><span id="28aa" class="mg mh iq nf b gy nn nk l nl nm"># returns: {'RF__criterion': 'entropy', 'RF__max_depth': 16, 'RF__min_samples_split': 12</span></pre><p id="e089" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们的准确度分数甚至低于基线！如果您想知道这怎么可能，这是因为我已经为某些参数输入了特定的值，这些值限制了模型的操作。我们较低的精度告诉我们，我们想要的参数可能超出了我指定的范围。</p><p id="8725" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">因为最大深度最佳参数是最高的，让我们试着把它保留为默认值，这意味着树的深度没有限制。这可能倾向于过度拟合模型，但是我们是基于我们的测试集值进行判断的，所以我们可以忽略它。另一方面，Min_samples_split是分割内部节点所需的最小样本数。让我们在这个参数上工作，同时将“RF_criterion”留在“熵”上。这些标准测量每个节点的杂质。“基尼系数”和“熵”之间唯一真正的区别是“熵”测量使用对数函数来计算杂质，这在计算上更加昂贵。</p><p id="4a31" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我仍然将min_samples_split的范围留得有点宽。如果我们的best_params在这个范围内给出一个值，那么我们就缩小我们的值。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="28d7" class="mg mh iq nf b gy nj nk l nl nm">newer_grid = [{ <br/>         'RF__min_samples_split': [8, 10, 12], <br/>         'RF__criterion': ['entropy']<br/>         }]</span><span id="848d" class="mg mh iq nf b gy nn nk l nl nm"><br/>gridsearch = GridSearchCV(estimator=rf_pipeline, <br/>                          param_grid=newer_grid, <br/>                          scoring='accuracy', <br/>                          cv=5)</span><span id="ccb0" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.fit(X_train, y_train)</span><span id="a4dd" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.score(X_test, y_test)</span><span id="94c9" class="mg mh iq nf b gy nn nk l nl nm">#accuracy: 0.8083628533722303</span><span id="3611" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.best_params_</span><span id="d067" class="mg mh iq nf b gy nn nk l nl nm">#{'RF__criterion': 'entropy', 'RF__min_samples_split': 8}</span></pre><p id="448f" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">但是有点进步！让我们再尝试一次迭代。因为我们的min_samples_split的best_param在我的值范围内是最低的，所以更好的值可能仍然低于这个值。我将在这一轮中输入6、7和8，比上一轮缩小更多。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="ae43" class="mg mh iq nf b gy nj nk l nl nm">last_grid = [{ <br/>         'RF__min_samples_split': [6, 7, 8],<br/>         'RF__criterion': ['entropy']<br/>        }]</span><span id="1ec0" class="mg mh iq nf b gy nn nk l nl nm">gridsearch = GridSearchCV(estimator=rf_pipeline, <br/>                          param_grid=last_grid, <br/>                          scoring='accuracy', <br/>                          cv=5)<br/>gridsearch.fit(X_train, y_train)</span><span id="3fbd" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.score(X_test, y_test)</span><span id="47cc" class="mg mh iq nf b gy nn nk l nl nm">#accuracy: 0.8083628533722303</span><span id="661f" class="mg mh iq nf b gy nn nk l nl nm">gridsearch.best_params_</span><span id="482d" class="mg mh iq nf b gy nn nk l nl nm">#{'RF__criterion': 'entropy', 'RF__min_samples_split': 7}</span></pre><p id="1762" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在我们在非常窄的范围内有了一个“最佳”值。因此，让我们将GridSearch中的这些值插回到我们有200个评估者的模型中，并使用相同的random_state作为基线来计算一些汇总统计数据。</p><pre class="kn ko kp kq gt ne nf ng nh aw ni bi"><span id="bfc3" class="mg mh iq nf b gy nj nk l nl nm">machine_learn(RandomForestClassifier(random_state=123, n_estimators=200,<br/>                                min_samples_split=7, criterion='entropy'))</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi np"><img src="../Images/887100392d678deb130bd70b3fe35209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucLSZXvwmLS4Gr5RoxBybA.png"/></div></div></figure><p id="7ec8" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">略有改善！GridSearch并不总是突飞猛进，但任何百分比的改进都是值得的。我希望你至少能从这篇文章中学到一些东西。</p><p id="046a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">如果你对我的方法或过程有任何问题，请评论！我一直在寻求学习。</p><p id="ca04" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">-奥林</p></div></div>    
</body>
</html>