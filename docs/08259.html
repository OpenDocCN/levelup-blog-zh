<html>
<head>
<title>Visualize Linear Regression with Matplotlib, Pandas, and Sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Matplotlib、Pandas和Sklearn可视化线性回归</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/visualize-linear-regression-with-matplotlib-pandas-and-sklearn-f5d65bc61dfe?source=collection_archive---------7-----------------------#2021-04-15">https://levelup.gitconnected.com/visualize-linear-regression-with-matplotlib-pandas-and-sklearn-f5d65bc61dfe?source=collection_archive---------7-----------------------#2021-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6510" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">只用了9行代码！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bda11fdece7918dc24677683d63b3b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ucO2g75Ams8AdZ5W"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@chrisliverani?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯·利维拉尼</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="b78a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您将学到的内容:</p><ul class=""><li id="3c97" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">如何做一个简单的线性回归模型？</li></ul><p id="3661" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您需要什么:</p><ul class=""><li id="7ceb" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">对Python的基本理解</li></ul><p id="fa29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">推荐:</p><ul class=""><li id="a586" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">与熊猫相处的经历</li><li id="570c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">您选择的IDE</li></ul><h1 id="c081" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">包装</h1><p id="179a" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">对于本教程，我们需要<code class="fe ng nh ni nj b">matplotlib.pyplot</code>、<code class="fe ng nh ni nj b">pandas</code>和<code class="fe ng nh ni nj b">sklearn.linear_model</code>。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="7020" class="no mk it nj b gy np nq l nr ns">pip install matplotlib<br/>pip install pandas<br/>pip install scikit-learn</span></pre><p id="a479" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将它们导入Python文件:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="2607" class="no mk it nj b gy np nq l nr ns">import matplotlib.pyplot as plt  </span><span id="8ac6" class="no mk it nj b gy nt nq l nr ns">import pandas as pd  </span><span id="d9a0" class="no mk it nj b gy nt nq l nr ns">from sklearn.linear_model import LinearRegression</span></pre><h1 id="05b7" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">正在检索数据集</h1><p id="d3b7" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">你可以从<a class="ae ky" href="https://github.com/chasinginfinity/ml-from-scratch/blob/master/03%20Linear%20Regression%20in%202%20minutes/data.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集或者做一个叫<code class="fe ng nh ni nj b">data.csv</code>的文件，把下面的几行复制进去。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="96a1" class="no mk it nj b gy np nq l nr ns">32.502345269453031, 31.70700584656992</span><span id="6b30" class="no mk it nj b gy nt nq l nr ns">53.426804033275019, 68.77759598163891</span><span id="d540" class="no mk it nj b gy nt nq l nr ns">61.530358025636438, 62.562382297945803</span><span id="5206" class="no mk it nj b gy nt nq l nr ns">47.475639634786098, 71.546632233567777</span><span id="ff10" class="no mk it nj b gy nt nq l nr ns">59.813207869512318, 87.230925133687393</span><span id="b282" class="no mk it nj b gy nt nq l nr ns">55.142188413943821, 78.211518270799232</span><span id="9a1a" class="no mk it nj b gy nt nq l nr ns">52.211796692214001, 79.64197304980874</span><span id="b87c" class="no mk it nj b gy nt nq l nr ns">39.299566694317065, 59.171489321869508</span><span id="6105" class="no mk it nj b gy nt nq l nr ns">48.10504169176825,  75.331242297063056</span><span id="51ce" class="no mk it nj b gy nt nq l nr ns">52.550014442733818, 71.300879886850353</span><span id="12ca" class="no mk it nj b gy nt nq l nr ns">45.419730144973755, 55.165677145959123</span><span id="371c" class="no mk it nj b gy nt nq l nr ns">54.351634881228918, 82.478846757497919</span><span id="ce91" class="no mk it nj b gy nt nq l nr ns">44.164049496773352, 62.008923245725825</span><span id="08a8" class="no mk it nj b gy nt nq l nr ns">58.16847071685779,  75.392870425994957</span><span id="1974" class="no mk it nj b gy nt nq l nr ns">56.727208057096611, 8.43619215887864</span><span id="9808" class="no mk it nj b gy nt nq l nr ns">48.955888566093719, 60.723602440673965</span><span id="048f" class="no mk it nj b gy nt nq l nr ns">44.687196231480904, 82.892503731453715</span><span id="6699" class="no mk it nj b gy nt nq l nr ns">60.297326851333466, 97.379896862166078</span><span id="4095" class="no mk it nj b gy nt nq l nr ns">45.618643772955828, 48.847153317355072</span><span id="b543" class="no mk it nj b gy nt nq l nr ns">38.816817537445637, 56.877213186268506</span><span id="25c5" class="no mk it nj b gy nt nq l nr ns">66.189816606752601, 83.878564664602763</span><span id="6000" class="no mk it nj b gy nt nq l nr ns">65.41605174513407,  118.59121730252249</span><span id="0c35" class="no mk it nj b gy nt nq l nr ns">47.48120860786787,  57.251819462268969</span><span id="52ac" class="no mk it nj b gy nt nq l nr ns">41.57564261748702,  51.391744079832307</span><span id="6b2b" class="no mk it nj b gy nt nq l nr ns">51.84518690563943,  75.380651665312357</span><span id="f58f" class="no mk it nj b gy nt nq l nr ns">59.370822011089523, 74.765564032151374</span><span id="e5a0" class="no mk it nj b gy nt nq l nr ns">57.31000343834809,   95.455052922574737</span><span id="f10a" class="no mk it nj b gy nt nq l nr ns">63.615561251453308, 95.229366017555307</span><span id="6432" class="no mk it nj b gy nt nq l nr ns">46.737619407976972, 79.052406169565586</span><span id="6649" class="no mk it nj b gy nt nq l nr ns">50.556760148547767, 83.432071421323712</span><span id="3e63" class="no mk it nj b gy nt nq l nr ns">52.223996085553047, 63.358790317497878</span><span id="d8da" class="no mk it nj b gy nt nq l nr ns">35.567830047746632, 41.412885303700563</span><span id="a853" class="no mk it nj b gy nt nq l nr ns">42.436476944055642, 76.617341280074044</span></pre><p id="df57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="ba57" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">读取数据集</h1><p id="8a77" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">让我们加载数据集</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="e381" class="no mk it nj b gy np nq l nr ns">data = pd.read_csv('data.csv')</span></pre><p id="c0ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并用以下方式重塑它</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="60c9" class="no mk it nj b gy np nq l nr ns">x = data.iloc[:, 0].values.reshape(-1, 1) </span><span id="7706" class="no mk it nj b gy nt nq l nr ns">y = data.iloc[:, 1].values.reshape(-1, 1)</span></pre><p id="8028" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将把数据转换成这样的格式，程序可以从中学习:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="2c97" class="no mk it nj b gy np nq l nr ns">[[53.42680403]<br/> [61.53035803]<br/> [47.47563963]<br/> [59.81320787]<br/> [55.14218841]<br/> [52.21179669]<br/> [39.29956669]<br/> [48.10504169]<br/> [52.55001444]<br/> [45.41973014]<br/> [54.35163488]<br/> [44.1640495 ]<br/> [58.16847072]<br/> [56.72720806]<br/> [48.95588857]<br/> [44.68719623]<br/> [60.29732685]<br/> [45.61864377]<br/> [38.81681754]<br/> [66.18981661]<br/> [65.41605175]<br/> [47.48120861]<br/> [41.57564262]<br/> [51.84518691]<br/> [59.37082201]<br/> [57.31000344]<br/> [63.61556125]<br/> [46.73761941]<br/> [50.55676015]<br/> [52.22399609]<br/> [35.56783005]<br/> [42.43647694]]</span></pre><h1 id="a539" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">拟合模型</h1><p id="f6dd" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们将定义另一个变量来拟合模型，并将<code class="fe ng nh ni nj b">x</code>和<code class="fe ng nh ni nj b">y</code>作为参数传入:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="7e69" class="no mk it nj b gy np nq l nr ns">linear_regressor = LinearRegression().fit(x, y)</span></pre><p id="be70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以用<code class="fe ng nh ni nj b">.predict()</code>预测结果，我们将<code class="fe ng nh ni nj b">x</code>作为参数传入。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="ad6c" class="no mk it nj b gy np nq l nr ns">y_pred = linear_regressor.predict(x)</span></pre><h1 id="70d3" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">绘制图表</h1><p id="4ae2" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们将用<code class="fe ng nh ni nj b">plt.scatter</code>标出所有的点，</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="02c3" class="no mk it nj b gy np nq l nr ns">plt.scatter(x, y)</span></pre><p id="044e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且用<code class="fe ng nh ni nj b">x</code>和我们的预测值<code class="fe ng nh ni nj b">y_pred</code>画一条线。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="729b" class="no mk it nj b gy np nq l nr ns">plt.plot(x, y_pred, color='green')</span></pre><p id="3962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们展示图表。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="66eb" class="no mk it nj b gy np nq l nr ns">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/121b2a0705b2669e32dce880b8bc46cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8tA6fHC8JOTZ1LcRMZ929w.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ml">图1: </strong>成品图</figcaption></figure><p id="5644" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归成功了！</p><p id="7e6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="dd9e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">资源</h1><p id="be7f" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">代码灵感来自<a class="ae ky" href="https://towardsdatascience.com/linear-regression-in-6-lines-of-python-5e1d0cd05b8d" rel="noopener" target="_blank">阿达什·梅农</a>。</p><p id="1641" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank"> Sckit-Learn的线性回归文档。</a></p><h1 id="45de" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="0576" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">谢谢！</p><p id="a0e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢读这篇文章，并且它教会了你更多关于线性回归的知识。如果您有任何问题、建议、一般反馈或您的代码不工作，请在评论中提出！</p><p id="797c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续编码！</p></div></div>    
</body>
</html>