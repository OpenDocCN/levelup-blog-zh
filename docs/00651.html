<html>
<head>
<title>Clustering GPS Coordinates and Forming Regions with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python聚类GPS坐标和形成区域</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/clustering-gps-co-ordinates-forming-regions-4f50caa7e4a1?source=collection_archive---------0-----------------------#2019-06-19">https://levelup.gitconnected.com/clustering-gps-co-ordinates-forming-regions-4f50caa7e4a1?source=collection_archive---------0-----------------------#2019-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/89b3b36f2d8b0cc6f0f2bc5e74521bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*23ipyrdektz36G1v.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">聚类GPS位置</figcaption></figure><p id="851b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我最近在处理一些包含GPS纬度和经度的数据时遇到了一个挑战。为了从现有的数据中获取尽可能多的信息，我有了这个想法。这不是什么新鲜事，但绝对是令人兴奋的事。</p><p id="465f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">热图和聚类图很好，但是如果我们可以用GPS坐标做更多的事情呢？让我们想象一下，如果人口统计学和其他数据点之间有关系会怎么样。例如，客户流失受地区影响吗？</p><p id="2743" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里有一个简单而强大的方法，用Python对GPS位置进行聚类。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="8e5f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为此，我使用了来自卡格尔的Zillow奖的数据:Zillow的房屋价值预测(Zestimate) 。我用的是‘properties _ 2016 . CSV’。<strong class="ke ir">真大！</strong></p><h2 id="0744" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">导入先决条件。</h2><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="f404" class="li lj iq mg b gy mk ml l mm mn">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans<br/>import seaborn as sns; sns.set()<br/>import csv</span></pre><h2 id="2618" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">加载文件并读取前几行</h2><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="63b9" class="li lj iq mg b gy mk ml l mm mn">df = pd.read_csv('properties_2016.csv')<br/>df.head(10)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/954fb9ed917242e9d83903f2565fd5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BaLgYkOsuTC8JCmZp4e7Vg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">所有数据</figcaption></figure><h2 id="9815" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">删除经度和/或纬度为空值的行</h2><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="4a61" class="li lj iq mg b gy mk ml l mm mn">df.dropna(axis=0,how='any',subset=['latitude','longitude'],inplace=True)</span></pre><p id="a3f9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">创建一个只有我们需要的变量。我们需要“parcelid ”,这样我们就可以在以后连接到原始数据，经度和纬度。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="cd6a" class="li lj iq mg b gy mk ml l mm mn"># Variable with the Longitude and Latitude<br/>X=df.loc[:,['parcelid','latitude','longitude']]<br/>X.head(10</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/c6f58ae6f0dab58ad920dbb354729b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*gRHyce8n03wIef2Rtpk02A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">KMeans的切片数据</figcaption></figure><h1 id="afb1" class="mq lj iq bd lk mr ms mt ln mu mv mw lq mx my mz lt na nb nc lw nd ne nf lz ng bi translated">肘形曲线</h1><p id="71f8" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">哇，等等我！这是什么约瑟夫？</p><p id="4dda" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">K-means有些天真——它将数据聚类成k个簇，即使k不是要使用的正确簇数。当我们谈到聚类时，很难知道有多少个聚类是最佳的…在我们的数据集中，有多少个聚类是最佳的，即有意义的，我们现在不想猜测，不是吗？因此，在使用k-means聚类时，我们需要一种方法来确定我们是否使用了正确的聚类数。</p><blockquote class="nm nn no"><p id="af3f" class="kc kd np ke b kf kg kh ki kj kk kl km nq ko kp kq nr ks kt ku ns kw kx ky kz ij bi translated">让我们变得有趣一些——猜猜最佳聚类的数量，写在某个地方……现在让我们看看你是否真的能赢得彩票。</p></blockquote><p id="708b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">验证集群数量的一种方法是<strong class="ke ir">肘方法</strong>。肘方法的思想是对k值范围(比如k从1到10)的数据集运行k均值聚类，并对k的每个值计算误差平方和(SSE)。</p><p id="0e1b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当K增加时，质心更靠近簇质心。这种改善会在某一点上迅速下降，形成肘形。这是k的最佳值。</p><p id="c4ce" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这可能需要一段时间..稍微伸展一下。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="32df" class="li lj iq mg b gy mk ml l mm mn">K_clusters = range(1,10)</span><span id="b5e0" class="li lj iq mg b gy nt ml l mm mn">kmeans = [KMeans(n_clusters=i) for i in K_clusters]</span><span id="d8e8" class="li lj iq mg b gy nt ml l mm mn">Y_axis = df[['latitude']]<br/>X_axis = df[['longitude']]</span><span id="7a43" class="li lj iq mg b gy nt ml l mm mn">score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]</span><span id="a275" class="li lj iq mg b gy nt ml l mm mn"># Visualize<br/>plt.plot(K_clusters, score)<br/>plt.xlabel('Number of Clusters')</span><span id="1223" class="li lj iq mg b gy nt ml l mm mn">plt.ylabel('Score')</span><span id="82ee" class="li lj iq mg b gy nt ml l mm mn">plt.title('Elbow Curve')</span><span id="8546" class="li lj iq mg b gy nt ml l mm mn">plt.show()</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/677fc895f2c290b3c4dc208151d76a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*m0gZSqlYVtsfwLclLGOnag.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">显示最佳聚类数的肘形曲线</figcaption></figure><p id="dc28" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当我们绘制图表时，我们看到图表在<strong class="ke ir"> 3 </strong>簇之后缓慢变平。这意味着添加更多的集群对我们没有多大帮助。</p><h2 id="7108" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">使用K-Means进行聚类并将聚类分配给我们的数据</h2><p id="4eff" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">先来看看<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> KMeans函数</a>的一些参数。</p><h2 id="7c61" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">KMeans参数</h2><ul class=""><li id="03ea" class="nv nw iq ke b kf nh kj ni kn nx kr ny kv nz kz oa ob oc od bi translated">int，可选，默认8。要形成的簇的数量以及要生成的质心的数量。</li><li id="d18a" class="nv nw iq ke b kf oh kj oi kn oj kr ok kv ol kz oa ob oc od bi translated"><code class="fe oe of og mg b">init</code> <code class="fe oe of og mg b">{‘k-means++’, ‘random’ or an ndarray}</code>。<code class="fe oe of og mg b">k-means++</code>’:智能选择k-means聚类的初始聚类中心，加快收敛速度。<code class="fe oe of og mg b">random</code>:从初始质心的数据中随机选择<code class="fe oe of og mg b">k</code>个观测值(行)。如果通过了一个<code class="fe oe of og mg b">ndarray</code>，它应该是形状(<code class="fe oe of og mg b">n_clusters</code>，<code class="fe oe of og mg b">n_features</code>)，并给出初始中心。</li></ul><h1 id="57a3" class="mq lj iq bd lk mr ms mt ln mu mv mw lq mx my mz lt na nb nc lw nd ne nf lz ng bi translated">让我们开始吧</h1><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="9429" class="li lj iq mg b gy mk ml l mm mn">kmeans = KMeans(n_clusters = 3, init ='k-means++')<br/>kmeans.fit(X[X.columns[1:3]]) # Compute k-means clustering.</span><span id="924b" class="li lj iq mg b gy nt ml l mm mn">X['cluster_label'] = kmeans.fit_predict(X[X.columns[1:3]])</span><span id="aef1" class="li lj iq mg b gy nt ml l mm mn">centers = kmeans.cluster_centers_ # Coordinates of cluster centers.</span><span id="852e" class="li lj iq mg b gy nt ml l mm mn">labels = kmeans.predict(X[X.columns[1:3]]) # Labels of each point</span><span id="b7fb" class="li lj iq mg b gy nt ml l mm mn">X.head(10)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e35dcedf07d6cc30a1b71f073d5ae8e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*wSd7YBHNrKnt7IdCX1Ch-A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">聚类数据</figcaption></figure><h2 id="0d27" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">将结果可视化</h2><p id="42f9" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">让我们通过绘制用这些标签着色的数据来可视化结果。我们还将绘制由k-means估计器确定的聚类中心:</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="1e42" class="li lj iq mg b gy mk ml l mm mn">X.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')<br/>plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi on"><img src="../Images/466ce636640ec2779494dd0a0960bcc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*DN2qdHGi3LLyaJsNFl6sKA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">可视化结果</figcaption></figure><p id="96ba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">你可以试着用你选择的数字运行<code class="fe oe of og mg b">k_means</code>并想象它。我选了5个，看起来像这样:没那么漂亮，是吧？</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2d7fd22b90ee784d8041566f54207fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*HR82i-cjAxF7x6ajX4YE7w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">来自猜测聚类的可视化结果</figcaption></figure><h2 id="6de8" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">将结果与所有数据合并</h2><p id="baef" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">我们必须合并我们现有的数据，以包括集群，这样我们就可以做更多的分析。我们有两个变量包含我们的数据，<code class="fe oe of og mg b">df</code>和<code class="fe oe of og mg b">X</code>。让我们看看他们以前是什么样子。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="3c5c" class="li lj iq mg b gy mk ml l mm mn">df.head(5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/ecd51147ea674a80dcd81fdbd9a9708e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IW3KhgFF_-5ZMPFBbSKPcA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">主数据框</figcaption></figure><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="f4c4" class="li lj iq mg b gy mk ml l mm mn">X.head(5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/7fce2eaea5a167144a20d1c2f486daa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*TRigzzUdhIH-phEytpU3Qw.png"/></div></figure><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/534a31a9a49675b2ce80d13f1de1b682.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*LJC6oZ452rUHdViULk1UTQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">具有分类的数据子集</figcaption></figure><p id="c07a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们从<code class="fe oe of og mg b">X</code>中删除经度和纬度，因为它们已经存在于<code class="fe oe of og mg b">df</code>中。如果我们不删除经度和纬度列，我们将在数据框中为经度和纬度创建另外2列。我们不想那样。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="a25f" class="li lj iq mg b gy mk ml l mm mn">X = X[['parcelid','cluster_label']]<br/>X.head(5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8caaac3cd104037b976f7881f2e8dc66.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*rQY5F0yvfLYPXF_TSXicAg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">聚类数据的修剪子集</figcaption></figure><p id="b3f9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们现在合并数据。合并后，新列将被添加到您的数据集的右侧。</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="8dc4" class="li lj iq mg b gy mk ml l mm mn">clustered_data = df.merge(X, left_on='parcelid', right_on='parcelid')</span><span id="7a98" class="li lj iq mg b gy nt ml l mm mn">clustered_data.head(5)</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/00882178f95d2441107408fb909c4dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKZvDtLaxsDN4HACH0jPuA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">具有聚类的数据</figcaption></figure><h2 id="b125" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">将数据框导出到CSV</h2><p id="02c7" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">幸运的是，有一个<code class="fe oe of og mg b">pandas.DataFrame.to_csv</code>函数，非常简单:</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="eef6" class="li lj iq mg b gy mk ml l mm mn">clustered_data.to_csv ('clustered_data.csv', index=None, header = True)</span></pre></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h2 id="0158" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated"><strong class="ak">奖励——如何获得中心。</strong></h2><p id="4102" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated"><code class="fe oe of og mg b">centers = kmeans.cluster_centers_</code> <br/> <code class="fe oe of og mg b">print(centers)</code></p><h2 id="cd90" class="li lj iq bd lk ll lm dn ln lo lp dp lq kn lr ls lt kr lu lv lw kv lx ly lz ma bi translated">下一步是什么？</h2><p id="816f" class="pw-post-body-paragraph kc kd iq ke b kf nh kh ki kj ni kl km kn nj kp kq kr nk kt ku kv nl kx ky kz ij bi translated">对位置进行聚类后，我们现在可以从不同的角度来看待我们所拥有的数据。</p><p id="fa82" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae lh" href="https://github.com/JosephMagiya/Clustering-GPS-Co-ordinates--Forming-Regions./blob/master/Clustering-GPS-Co-ordinates--Forming-Regions.ipynb" rel="noopener ugc nofollow" target="_blank"> Github链接</a></p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h1 id="5fa3" class="mq lj iq bd lk mr ou mt ln mu ov mw lq mx ow mz lt na ox nc lw nd oy nf lz ng bi translated">感谢您的阅读，祝您好运</h1></div></div>    
</body>
</html>