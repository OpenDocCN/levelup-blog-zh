<html>
<head>
<title>Facial Landmark Detection in OpenCV4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenCV4中的人脸标志检测</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/facial-landmark-detection-in-opencv4-616f9c1737a5?source=collection_archive---------1-----------------------#2019-03-05">https://levelup.gitconnected.com/facial-landmark-detection-in-opencv4-616f9c1737a5?source=collection_archive---------1-----------------------#2019-03-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="698e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">在这篇由Roy Shilkrot撰写的文章中了解OpenCV4中的面部标志检测，他是石溪大学计算机科学的助理教授，领导着人类交互小组。Shilkrot博士的研究领域是计算机视觉、人机界面以及这两个领域的交叉，由美国联邦政府、纽约州和行业拨款资助。</em></p><h1 id="202b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">面部标志和姿势与面部模块</h1><p id="6fd0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">人脸标志检测是在人脸图像中寻找兴趣点的过程。它最近在计算机视觉领域发展迅速，因为它有许多引人注目的应用。例如，我们已经展示了通过面部姿态来检测情绪的能力，估计凝视方向，改变面部外观(<strong class="jp ir">面部交换</strong>)，用图形增加面部，以及操纵虚拟角色。</p><p id="d75f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以在今天的智能手机和PC网络摄像头程序中看到许多这样的应用。为了实现这一点，地标探测器必须找到面部的几十个点，如嘴角、眼角、下颚的轮廓等等。许多算法都是在OpenCV中开发和实现的。在本文中，我们将讨论使用<code class="fe lp lq lr ls b">cv::face</code>模块检测面部标志(也称为<strong class="jp ir">面部标志</strong>)的过程，该模块提供了一个用于推理的API，以及面部标志检测器的训练。我们将看到如何应用面部标志检测器来定位三维人脸的方向。</p><p id="1947" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文的代码文件可以从<a class="ae lt" href="https://github.com/PacktPublishing/Mastering-OpenCV-4-Third-Edition" rel="noopener ugc nofollow" target="_blank">https://github . com/packt publishing/Mastering-OpenCV-4-Third-Edition</a>下载。您将需要以下技术和安装来构建代码:</p><ul class=""><li id="117b" class="lu lv iq jp b jq jr ju jv jy lw kc lx kg ly kk lz ma mb mc bi translated">OpenCV v4(用<code class="fe lp lq lr ls b">face contrib</code>模块编译)</li><li id="187b" class="lu lv iq jp b jq md ju me jy mf kc mg kg mh kk lz ma mb mc bi translated">升压版本1.66+</li></ul><p id="83ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要运行facemark检测器，需要一个预先训练好的模型。尽管使用OpenCV中提供的API来训练检测器模型是完全可能的，但还是提供了一些预先训练好的模型供下载。一个这样的模型可以从<a class="ae lt" href="https://raw.githubusercontent.com/kurnianggoro/GSOC2017/master/data/lbfmodel.yaml" rel="noopener ugc nofollow" target="_blank">https://raw . githubusercontent . com/kurnianggoro/gsoc 2017/master/data/lbf model . YAML</a>获得，由算法实现的贡献者提供给OpenCV。</p><p id="492a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">面部标志检测器可以处理任何图像。然而，我们可以使用面部照片和视频的指定数据集，用于测试facemark算法。这样一个数据集是<strong class="jp ir"> 300-VW </strong>，可以通过<strong class="jp ir">智能行为理解小组</strong> ( <strong class="jp ir"> iBUG </strong>)，一个伦敦帝国理工学院的计算机视觉小组<a class="ae lt" href="https://ibug.doc.ic.ac.uk/resources/300-VW/" rel="noopener ugc nofollow" target="_blank">https://ibug.doc.ic.ac.uk/resources/300-VW/</a>获得。它包含了媒体中数百个面部出现的视频，并仔细标注了68个面部标志点。该数据集可用于训练facemark检测器，以及了解我们使用的预训练模型的性能水平。以下节选自300-VW视频中的一段，带有地面真相注释:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mi"><img src="../Images/8b9c4ef0c2db55be67a418df78b6a0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYTEiIkbUympmq_XAlS0LQ.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk translated">图像在知识共享许可下复制</figcaption></figure><h1 id="6333" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">OpenCV中的人脸标志检测</h1><p id="c884" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">地标检测从<strong class="jp ir">面部检测</strong>开始，在图像中寻找面部及其范围(边界框)。面部检测长期以来一直被认为是一个已解决的问题，OpenCV包含了第一批免费向公众提供的健壮的面部检测器之一。事实上，在早期，OpenCV主要因其快速人脸检测功能而为人所知和使用，实现了规范的Viola-Jones boosted级联分类器算法(Viola et al. 2001，2004)，并提供了预训练模型。虽然人脸检测在早期已经有了很大的发展，但是在OpenCV中检测人脸的最快和最简单的方法仍然是通过<code class="fe lp lq lr ls b">core</code>模块中提供的<code class="fe lp lq lr ls b">cv::CascadeClassifier</code>类来使用捆绑的级联分类器。</p><p id="ef43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们实现了一个简单的助手函数来使用级联分类器检测人脸，如下所示:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="68c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可能需要调整控制人脸检测的两个参数:金字塔比例因子和邻居数量。金字塔比例因子用于创建图像金字塔，检测器将尝试在其中查找人脸。这就是多尺度检测的实现方式，因为裸检测器具有固定的孔径。</p><p id="4bca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在图像金字塔的每一步中，图像都按此因子缩小，因此较小的因子(接近1.0)将产生许多图像，运行时间更长，但结果更准确。我们还可以控制多个邻居的下限。当级联分类器具有多个非常接近的正面人脸分类时，这就起作用了。</p><p id="cd92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，我们指示总体分类只返回一个人脸边界，如果它至少有三个相邻的正面人脸分类。较低的数字(接近1的整数)将返回更多检测，但也会引入误报。</p><p id="9531" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们必须从OpenCV提供的模型中初始化级联分类器(序列化模型的XML文件在<code class="fe lp lq lr ls b">$OPENCV_ROOT/data/haarcascades</code>目录中提供)。我们在正面人脸上使用标准训练的分类器，如下所示:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="872b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的屏幕截图显示了人脸检测器的可视化结果:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi na"><img src="../Images/acbfad284e10cfb7a4c8fc17475633ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGLFeFrb4kU-Ru7ajKI7mA.png"/></div></div></figure><p id="fed8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">面部标志检测器将在检测到的面部周围工作，从边界框开始。但是，我们必须首先初始化<code class="fe lp lq lr ls b">cv::face::Facemark</code>对象，演示如下:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="71f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe lp lq lr ls b">cv::face::Facemark</code>抽象API用于所有的地标检测器风格，并根据特定算法为推理和训练的实现提供基础功能。加载后，<code class="fe lp lq lr ls b">facemark</code>对象可通过其<code class="fe lp lq lr ls b">fit</code>函数找到脸型，如下图所示:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="8d5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">地标检测器(使用<code class="fe lp lq lr ls b">cv::face::drawFacemarks</code>)结果的可视化显示如下截图所示:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nb"><img src="../Images/dd6bfb4160055a33f4cb8682d862b86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c8H9NNk9HKW6wEiHvZfMDw.png"/></div></div></figure><h2 id="5267" class="nc kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">测量误差</h2><p id="834e" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">从视觉上看，效果似乎非常好。然而，由于我们有地面真实数据，我们可以选择分析比较它与检测，并得到一个误差估计。我们可以使用标准的平均欧几里德距离度量( )来判断每个预测的地标平均有多接近地面真实情况:</p><pre class="mj mk ml mm gt no ls np nq aw nr bi"><span id="0af4" class="nc kn iq ls b gy ns nt l nu nv">float MeanEuclideanDistance(const vector<!-- -->&lt;Point2f&gt;<!-- -->&amp; A, const vector<!-- -->&lt;Point2f&gt;<!-- -->&amp; B) {</span><span id="b07b" class="nc kn iq ls b gy nw nt l nu nv">float med = 0.0f;</span><span id="1482" class="nc kn iq ls b gy nw nt l nu nv">for (int i = 0; i &lt; A.size(); ++i) {</span><span id="9902" class="nc kn iq ls b gy nw nt l nu nv">   med += cv::norm(A[i] - B[i]);</span><span id="a805" class="nc kn iq ls b gy nw nt l nu nv">}</span><span id="4964" class="nc kn iq ls b gy nw nt l nu nv">return med / (float)A.size();</span><span id="286f" class="nc kn iq ls b gy nw nt l nu nv">}</span></pre><p id="109f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">叠加了预测(红色)和地面实况(绿色)的可视化结果，如以下屏幕截图所示:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nx"><img src="../Images/2c213594826bd37ac22ab565ff9edc7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Af5eJzDvtqdQyBYzoiVSBQ.png"/></div></div></figure><p id="c261" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，对于这些特定的视频帧，所有界标的平均误差大约只有一个像素。</p><h1 id="33c7" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">从地标估计面部方向</h1><p id="9caa" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">获得面部标志后，我们可以尝试找到面部的方向。2D面部标志点基本上符合头部的形状。因此，给定一个普通人类头部的3D模型，我们可以找到一些面部标志的近似对应3D点，如下图所示:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/054bb58305e3d6487735265112f98de2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*FDzrq02MJwoXwafYcCU0iQ.png"/></div></figure><h2 id="2f49" class="nc kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">估计姿态计算</h2><p id="99f2" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">从这些2D-3D对应关系中，我们可以通过<strong class="jp ir">点n透视</strong> ( <strong class="jp ir"> PnP </strong> ) <strong class="jp ir"> </strong>算法计算头部相对于摄像机的3D姿态(旋转和平移)。拍摄前一张照片的相机有一个<strong class="jp ir">刚性</strong>变换，这意味着它已经从对象移动了一定的距离，并且相对于对象有所旋转。从广义上讲，我们可以将图像上的点(靠近相机)和物体之间的关系写成如下:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/5f27b456031d38ec9dc7dca617704265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*wNy7w5bTQap9KqSgzYGvcg.png"/></div></figure><p id="967e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个等式</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/3c12cbdced01dd28614dfad2a75b01b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*u1PlaIVpy05EFh55ZJDwtg.png"/></div></figure><p id="264e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是对象的3D位置，而</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/adb0d44ddc2ac67d3b869df5117551fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/1*NCCmddPidkF1qUwggAj-Kw.png"/></div></figure><p id="a542" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是图像中的点。这个方程还包括一个投影，由摄像机固有参数(焦距<strong class="jp ir"> <em class="kl"> f </em> </strong>和中心点<strong class="jp ir"> <em class="kl"> c </em> </strong>)控制，将3D点转换为2D图像点，达到比例<strong class="jp ir"><em class="kl"/></strong>。假设我们通过校准摄像机获得了固有参数，或者我们对它们进行了近似，我们需要为旋转和平移找到12个系数。</p><p id="1a6f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们有足够的2D和3D对应点，我们可以写一个线性方程组，其中每个点可以贡献两个方程，来求解所有这些系数。事实上，我们不需要六个点，因为旋转的自由度少于九个，我们只需要四个点就可以了。OpenCV提供了一个实现，通过<code class="fe lp lq lr ls b">calib3d</code>模块的<code class="fe lp lq lr ls b">cv::solvePnP</code>函数找到旋转和平移。</p><p id="31d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们排列三维和2D点，并使用<code class="fe lp lq lr ls b">cv::solvePnP</code>:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="7aad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相机固有的<strong class="jp ir"> <em class="kl"> K </em> </strong>矩阵我们根据前面图像的大小进行估计。</p><h2 id="fc80" class="nc kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">将姿势投影到图像上</h2><p id="736a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">获得旋转和平移后，我们从物体坐标空间向前面的图像投影四个点:鼻尖，<strong class="jp ir"> <em class="kl"> x </em> </strong>轴方向，<strong class="jp ir"> <em class="kl"> y </em> </strong>轴方向，<strong class="jp ir"> <em class="kl"> z </em> </strong>轴方向，并绘制前面图像中的箭头:</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="5727" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这导致面部所指方向的可视化:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oc"><img src="../Images/7a0e76ccccf44d9ceeee70f800ff6b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v_fImHh7RRUAgFu6liJRJg.png"/></div></div></figure><p id="1d26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">如果你觉得这篇文章很有趣，你可以探索</em> <a class="ae lt" href="https://www.amazon.com/Mastering-OpenCV-comprehensive-processing-applications-ebook/dp/B07LCNRC8S?utm_source=levelup.gitconnected&amp;utm_medium=referral&amp;utm_campaign=ThirdPartyPromotions" rel="noopener ugc nofollow" target="_blank"> <em class="kl">掌握OpenCV 4 </em> </a> <em class="kl">从事实用的计算机视觉项目，涵盖高级对象检测器技术和现代深度学习和机器学习算法。</em> <a class="ae lt" href="https://www.packtpub.com/application-development/mastering-opencv-4-third-edition?utm_source=levelup.gitconnected&amp;utm_medium=referral&amp;utm_campaign=ThirdPartyPromotions" rel="noopener ugc nofollow" target="_blank"> <em class="kl">掌握OpenCV 4 </em> </a> <em class="kl">，现在是第三版，目标是计算机视觉工程师朝着掌握OpenCV迈出第一步。</em></p></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><figure class="mj mk ml mm gt mn gh gi paragraph-image"><a href="https://levelup.gitconnected.com"><div class="gh gi ok"><img src="../Images/9914c5dd23ac08b70eea6f4f9ba6fed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E6CoI_MRyZ1JInNPsBSHtA.png"/></div></a></figure><div class="ol om gp gr on oo"><a href="https://gitconnected.com/learn/c-plus-plus" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd ir gy z fp ot fr fs ou fu fw ip bi translated">学习C++ -最佳C++教程(2019) | gitconnected</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">20大C++教程-免费学习C++。课程由开发者提交并投票，使您能够找到…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">gitconnected.com</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc ms oo"/></div></div></a></div></div></div>    
</body>
</html>