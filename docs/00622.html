<html>
<head>
<title>Training a Single Perceptron</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练单个感知器</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/training-a-single-perceptron-405026d61f4b?source=collection_archive---------0-----------------------#2019-06-09">https://levelup.gitconnected.com/training-a-single-perceptron-405026d61f4b?source=collection_archive---------0-----------------------#2019-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f2c2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">它的学习规则是从零开始的</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d411a96f1bb2966088a269f39303493d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LxK-OVZ7POQvolWW0irefQ.jpeg"/></div></div></figure><p id="a2d1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我之前的文章中，我介绍了感知器的结构和功能——每一个神经网络的构建模块。我在这篇文章的结尾提醒大家注意这样一个事实，虽然我定义了进入感知器的大多数变量和函数，但我没有提到任何关于权重的事情。嗯，权重本身以及它们如何设置或改变实际上是对<strong class="kt ir"> <em class="ln">训练一个感知机</em> </strong>意味着什么的核心。我的目标是解释如何训练一个单一的感知器。如果你明白这是如何在单个感知器上工作的，那么你应该能够建立一个坚实的直觉，知道一个具有更复杂架构的神经网络通常是如何被训练的。</p><p id="74b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想复习一下或者没有看过我关于感知器的结构和功能的帖子，可以看看下面这篇文章，尽管在开始训练感知器之前我会快速总结一下要点。</p><div class="lo lp gp gr lq lr"><a href="https://blog.usejournal.com/the-perceptron-the-building-block-of-neural-networks-5a428d3f451d" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">感知器——神经网络的构建模块</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">以及它如何计算一个逻辑语句</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">blog.usejournal.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf kp lr"/></div></div></a></div><p id="0056" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意:这篇文章推荐一些微积分方面的经验。</p><h2 id="40b3" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">1.先决条件</h2><h2 id="8ee4" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">1.1.感知器的快速复习</h2><p id="3302" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">这张图直接取自我之前的<a class="ae ne" href="https://blog.usejournal.com/the-perceptron-the-building-block-of-neural-networks-5a428d3f451d" rel="noopener ugc nofollow" target="_blank">文章:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/656cc570ed708cad605cd4c00bdcd258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Na5QShwTC68ngMDsSikyw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">单感知器模型图，其中x1、x2是输入，w1和w2是分别将输入x1和x2连接到感知器的权重(用圆圈表示)，θ是偏差项。A是活动函数值，f(A)是产生感知器最终二进制输出的激活函数值。这里f是sigmoid函数。</figcaption></figure><p id="36d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是图表中所显示内容的概述:</p><ol class=""><li id="3608" class="nk nl iq kt b ku kv kx ky la nm le nn li no lm np nq nr ns bi translated">这个图是一个二元分类感知器，可以计算简单的逻辑语句。</li><li id="ed0e" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">活动函数A是输入变量x和一些偏差θ的加权和。它定义了可以将输入空间一分为二的直线或线性边界，从而可以分离二进制数据点。直线能够在空间中分离这样的点的性质叫做<strong class="kt ir"> <em class="ln">线性可分性。</em>T9】</strong></li><li id="438e" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated"><strong class="kt ir"> <em class="ln">偏置</em> </strong>项决定线条在输入空间的垂直位置。</li><li id="6554" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated"><strong class="kt ir"> <em class="ln">激活函数f </em> </strong>是一个以活动值为自变量的函数(<strong class="kt ir"> <em class="ln">活动函数A </em> </strong>的输出)，并将其映射为0或1，以保证感知器的最终输出为二进制。</li></ol><h2 id="8c98" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">1.2.方便的符号</h2><p id="aa36" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">让我们介绍一下上面感知器的一个稍微精炼和一般化的表示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/79d1d2943f5453707826bc3999cf48f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NCarYilSqeXnKeHIqTtMlg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">感知器模型的更一般化的图表。</figcaption></figure><p id="208e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我采用这种新的符号是为了让这篇文章接下来的部分更容易理解。这里我们有以下新的符号:</p><ol class=""><li id="73e1" class="nk nl iq kt b ku kv kx ky la nm le nn li no lm np nq nr ns bi translated"><em class="ln"> w_ij — </em>将输入<em class="ln"> x_i </em>链接到感知器<em class="ln"> j </em>的权重(图中间的节点)。</li><li id="bc4f" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated"><em class="ln"> y_j — </em>感知器<em class="ln"> j </em>的输出。</li></ol><h2 id="0e95" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">1.3.权重——感知机学习的东西</h2><p id="8d4c" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">回想一下，组成感知器的组件是输入、权重、偏置、活动函数和激活函数，而输出是取决于所有这些东西的最终量。输入是固定的——它们就是数据！我们不能对数据做任何更改。活度函数和激活函数仅仅是函数，而不是可以改变的量。所以在训练感知器时，我们唯一能控制改变的是<strong class="kt ir"> <em class="ln">权重</em> </strong>。这意味着…</p><blockquote class="nz oa ob"><p id="2d87" class="kr ks ln kt b ku kv jr kw kx ky ju kz oc lb lc ld od lf lg lh oe lj lk ll lm ij bi translated"><strong class="kt ir"><em class="iq">…当我们训练一个感知器时，我们迭代地改变权重，直到我们找到最佳的权重集，以便活动函数产生直线的正确斜率和方向，从而利用线性可分性。</em> </strong></p></blockquote><h2 id="7069" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">1.4.监督学习</h2><p id="7eda" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">让我们在监督学习的背景下考虑一个感知机。假设我们有一个感知器j的输出y_j需要是什么的标签:让我们称之为我们的<strong class="kt ir"> <em class="ln">期望输出d_j </em> </strong>。这个期望输出d_j是基础事实，我们知道感知机应该产生的目标输出。换句话说，这个期望的输出<strong class="kt ir"> <em class="ln">监督我们的感知器应该学习什么样的权重，以便产生某个输出</em></strong>——因此有监督学习这个术语。</p><p id="0eea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们知道期望的输出是什么，我们可以使用一些数学来定义一些函数，允许我们将期望的输出d_j与感知器产生的<strong class="kt ir"> <em class="ln">实际输出y_j </em> </strong>。但是我们也希望这个函数依赖于权重，因为权重是我们在训练感知器时想要更新的。让我们称这个函数为<strong class="kt ir"> <em class="ln">误差函数</em> </strong>因为如果实际输出不等于期望输出，那么误差函数的值是非零的，我们可以说感知器出错了！我在这里称它为误差函数，以坚持直观的语言，但这就是通常所说的<strong class="kt ir"> <em class="ln">损失函数</em> </strong>。</p><p id="a96d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们的目标是找到这个函数的最小值——因为误差是我们希望最小化的。</p><blockquote class="nz oa ob"><p id="54f6" class="kr ks ln kt b ku kv jr kw kx ky ju kz oc lb lc ld od lf lg lh oe lj lk ll lm ij bi translated">我们可以定义一些依赖于权重的函数，这将允许我们将感知器的实际输出与一些期望的输出联系起来。这个函数是误差函数，目标是通过迭代更新权重来最小化它。T3】</p></blockquote><p id="d918" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦误差最小化，我们就可以说感知机已经被训练好了。</p><h2 id="a773" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">2.训练感知器</h2><h2 id="b70f" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">2.1.初始化权重并计算实际输出</h2><p id="f080" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">让我们再来看看感知器:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/79d1d2943f5453707826bc3999cf48f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NCarYilSqeXnKeHIqTtMlg.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">感知器模型的更一般化的图表。</figcaption></figure><p id="0131" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输入x_i乘以随机初始化的权重w_ij，并与偏差和所有其他加权输入一起被馈送到感知器。在感知器内部，活动函数被应用于输入加上偏差的加权和，然后其值作为参数被馈送到激活函数f。激活函数的值产生感知器j的输出y_j。</p><h2 id="fe4f" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">2.2.定义并计算误差</h2><p id="2bb7" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">在计算误差之前，我们首先需要定义误差。记得我提到过，误差函数必须依赖于权重，并且需要将实际输出y_j与期望输出d_j相关联，因此我们将其定义为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/02aa413de35a6485c0d13b140e166129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pvXoGnihpUEnWZtAOEA0AQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">感知器误差函数的先决条件</figcaption></figure><p id="9ff1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个函数e_j确实把d_j和y_j联系起来，事实上它依赖于权重，因为我们知道y_j项本身依赖于权重。我们知道需要最小化e_j，但根据d_j和y_j的值，我们可能会得到误差e_j的负值，因此我们对其求平方，以确保误差始终为正数，并将其定义为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/fe3feccba5b1f66036bf28bb990618df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j9qFUgKpDmTG3C93enjhfQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">感知器的误差函数</figcaption></figure><p id="d7e2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，我们重新定义误差函数e_j为E_j，以确保它永远不会为负。但我也包含了1/2的因素。正如我最喜欢的一位教授曾经说过的，“我们做数学中方便的事情”。1/2的因素是为了以后办事方便。我很快会回到这个话题。</p><h2 id="b7ed" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">2.3.梯度下降-更新权重以进一步减少误差</h2><p id="4d57" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">现在我们有了一个误差函数，可以用它来帮助我们确定如何更新w_ij，这样我们就可以进一步减少误差。让我们基于当前电流和误差函数E_j来定义更新后的权重的数学表达式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/9bbda0b341188d8e3a5f5ca696432c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mTftkLEujPqm8efPxUvgKQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">梯度下降的表示</figcaption></figure><p id="2c0f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">框中的等式是用于使用以下等式找到<strong class="kt ir"> <em class="ln">更新权重w_ij(k+1) </em> </strong>的表达式</p><ol class=""><li id="dca4" class="nk nl iq kt b ku kv kx ky la nm le nn li no lm np nq nr ns bi translated"><strong class="kt ir"> <em class="ln">当前权重w_ij(k) </em> </strong></li><li id="a536" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">有的<strong class="kt ir"> <em class="ln">步长由希腊字母<strong class="kt ir"> <em class="ln"> eta </em> </strong>给出</em> </strong></li><li id="57e9" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">误差函数E_j关于w_ij的<strong class="kt ir"> <em class="ln">导数。</em> </strong></li></ol><p id="e69f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">换句话说，这就是<strong class="kt ir"> <em class="ln">梯度下降的公式——</em></strong>求函数最小值的迭代方法。</p><blockquote class="nz oa ob"><p id="8494" class="kr ks ln kt b ku kv jr kw kx ky ju kz oc lb lc ld od lf lg lh oe lj lk ll lm ij bi translated"><strong class="kt ir"/></p></blockquote><h2 id="edc0" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">为什么偏导数？</h2><p id="6b07" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">一个问题出现了:为什么我用<strong class="kt ir"> <em class="ln">偏导数</em> </strong>表示误差函数的导数？上面的图表是一个误差与一个<strong class="kt ir"><em class="ln"/></strong>单个权重的函数关系图。在更现实的情况下，感知器会有多个权重。例如，如果我们有2个权重，误差函数的图形将是3维空间中的3维表面，因此误差函数的两个偏导数将需要相对于两个权重来计算。更一般地，如果我们有n个权重，那么误差函数将是n+1维空间中的n+1维超曲面，并且其导数将在具有n个分量的<strong class="kt ir"><em class="ln"/></strong>梯度向量的帮助下计算，每个分量表示误差函数在单个权重方向上的偏导数。</p><p id="4e30" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是让我们回到一个更新的权重w_ij(k+1)的表达式。由此我们实际上可以推导出在下一次迭代中我们需要改变当前权重的量(增加或减少一定量)以进一步减少E_j。当前权重的这个改变量在下面的框中用术语<strong class="kt ir"><em class="ln">δw _ ij</em></strong>表示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/9c29c340ace8db1baca9daf21083c29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBIMCJ-lrNuWOX8KoWN-cw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">权重更新方程</figcaption></figure><p id="9edc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">上图中的表达式是梯度下降法在感知器环境中的应用，我们试图修改权重以降低误差函数值。</p><h2 id="f626" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">误差函数的导数和链式法则</h2><p id="6b5c" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">那么我们如何计算误差函数的导数呢？为了计算这个导数，我们必须承认误差函数E_j非常复杂<strong class="kt ir"> <em class="ln">复合函数</em> </strong>由函数e_j组成，而函数E _ j又由另一个函数y_j组成，等等。更具体地说，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/0fbca0cccb7d78c493f8e1ae9f1d3291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciEQtLf7EzXeE2A-EWzNSA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">误差函数是由其他函数组成的复杂函数，而其他函数又由其他函数组成，因此需要应用链式法则</figcaption></figure><p id="7d41" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们需要利用<strong class="kt ir"> <em class="ln">链式法则</em> </strong>对E_j相对于权重w_ij求导。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/a9b1cd8590af97e283933f0ee6db922c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1fr1Xxd2rlb3jxqbXtCxlA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">应用于误差函数的链式法则</figcaption></figure><p id="7fd8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们需要计算上式右侧的四个偏导数项，但这并不是一个非常困难的任务，因为我们知道E_j、e_j、y_j和A_j:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/a6ba9ee5dfc6e22bc1343964b7dfc3d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYL9kBJa4lvQ9v0Z5Z_cqw.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">构成误差函数梯度向量的各个项</figcaption></figure><p id="1c89" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们已经计算了每一项，我们可以将它们插回到E_j导数的链式法则方程中，我们将得到以下表达式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/916bdbb23e2d8de19bcbddf3b8d2939c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h99ky4BqC7B9WxhAWh833Q.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">用于计算误差函数的梯度向量的清理版本</figcaption></figure><h2 id="bfb0" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">2.4.感知器Delta函数——把它们放在一起</h2><p id="787d" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">同样，在上述表达式中，权重的下标i_j指示这是将输入I链接到感知器j的权重。这里E_j的偏导数仅在权重w_ij的方向上，因此该导数仅是感知器j的E_j的梯度向量的元素之一。注意，除x_i之外的所有项都具有相同的下标j，指示它们都与感知器j的输出相关！</p><p id="dd4a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们进一步简化，将具有相同下标的术语分组如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/a76cb20580f3a148f69a70b96203b0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WSKX-aykImxQCDvC4z2pfw.png"/></div></div></figure><p id="3946" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">并把它代入表达式中得到</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/4d7feebe722013a3f9da609100500816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4avxTnJ1DuK4LU6tFn6c6w.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">感知器delta函数</figcaption></figure><p id="44d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">框中的表达式是<strong class="kt ir"> <em class="ln">感知器增量函数</em> </strong> — <em class="ln">一个量化当前权重w_ij(k)需要改变多少以获得更新的权重w_ij(k+1)的函数。</em></p><blockquote class="nz oa ob"><p id="0a7f" class="kr ks ln kt b ku kv jr kw kx ky ju kz oc lb lc ld od lf lg lh oe lj lk ll lm ij bi translated"><strong class="kt ir"><em class="iq"/><em class="iq">感知器增量函数</em> <em class="iq">量化当前权重w_ij(k)需要改变多少，以便获得更新的权重w_ij(k+1)，这将有助于进一步减小误差。</em> </strong></p></blockquote><p id="e6a7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">反复重复这个过程，直到误差最小化，这就是我们所说的训练感知器的过程。</p><h2 id="2e72" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">3.多元案例</h2><p id="882c" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">上面的计算是针对单个感知器j进行的，该感知器使用单个权重w_ij对输出y_j做出贡献。如果我们有m个感知器贡献于某个输出y_j(例如，在神经网络的输出层中有m个感知器),那么误差函数的公式如下</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/0e08259bd32a984cf33b0991b152d98d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEN-Cm_WBZveJnajXhmKHA.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">定义误差函数的多元版本</figcaption></figure><p id="6ad7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，如果我们想用将所有n个输入与每个感知器连接起来的n个权重来计算所有n个输入，那么对于上述公式中的每个感知器j，我们需要使用感知器delta函数n次来计算n个更新的权重，从而计算E_j的n个偏导数，这些偏导数是E_j的梯度向量的分量。因此，您可以看到，一旦我们开始计算更多的权重和更多的感知器，这将变得非常复杂，这证明了神经网络的计算复杂性。</p><h2 id="25bf" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated"><strong class="ak"> <em class="op"> 4。概括所有的数学难题</em> </strong></h2><ol class=""><li id="33ce" class="nk nl iq kt b ku mz kx na la oq le or li os lm np nq nr ns bi translated"><strong class="kt ir"> <em class="ln">训练一个感知器</em> </strong>是一个优化问题，它涉及以最小化误差函数的方式迭代更新权重。</li><li id="dfb0" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">我们导出了<strong class="kt ir"> <em class="ln">误差函数</em> </strong>，并且定义了<strong class="kt ir"> <em class="ln">更新的权重</em> </strong>应该基于当前权重和在当前迭代中计算的误差。我们使用一个单一权重和一个单一感知器的例子来完成这一切。</li><li id="be9c" class="nk nl iq kt b ku nt kx nu la nv le nw li nx lm np nq nr ns bi translated">然后，我们推导出<strong class="kt ir"> <em class="ln">感知器增量函数</em> </strong>，该函数量化需要添加到当前权重或从当前权重中减去的变化，以达到进一步减小误差的更新后的权重。</li></ol><p id="5f7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我的下一篇文章中，我将基于这里导出的数学公式，对<strong class="kt ir"> <em class="ln">前馈反馈比例算法</em> </strong>进行一次演练，将其应用于一个简单的多层感知器(MLP)的例子。___________________________________________________________________</p><h2 id="9f2a" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">奖金——为什么使用梯度下降，而不是设置导数为零，以找到最小值？</h2><p id="7170" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">出现了一个问题，为什么不简单地通过将其导数设置为零来最小化误差函数。如果权重的数量变大，那么误差函数很快就会变得非常复杂。假设下图是构成曲面的某个三维(三个权重)误差函数的切片或横截面视图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/ee6d54f4b09e01d2c4d140a7ce70453b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKSF055FCpTMlWHHluEvCQ.png"/></div></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk translated">单个砝码误差函数的简化图。当然，在现实情况下，我们会处理更多的权重。每一个额外的重量都会给这个图增加一个维度</figcaption></figure><p id="d9bc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如你所见，误差函数非常复杂！这种复杂函数的问题是:</p><p id="d3bc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">1.我们有许多最小值</p><p id="ade0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.这些函数太复杂了，无法用一个简洁的公式进行数学表达</p><p id="6a41" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">3.如果没有一个简洁的数学公式，对如此复杂的函数求导可能是不可行的</p><p id="19ed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">4.找到对应于全局最小值的自变量(最优权重)是不现实的。</p><p id="d5db" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">通过将函数的导数设置为零来最小化函数是解决优化问题的一种解析方法，但是解析解并不总是对我们可用的。因此，我们可以使用另一种计算方法——这种分析方法的数值近似法。这就是梯度下降-一种通过随机初始化一些权重来查找函数最小值的迭代方法，我们可以从这些权重沿着表面以最陡下降的方向向前或向后移动，直到我们到达对应于表面最小值的权重。</p></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><ul class=""><li id="621a" class="nk nl iq kt b ku kv kx ky la nm le nn li no lm pb nq nr ns bi translated">此内容摘自<a class="ae ne" href="http://page.mi.fu-berlin.de/rojas/neural/index.html.html" rel="noopener ugc nofollow" target="_blank"> <em class="ln"> Rojas，Raul (1996):神经网络:系统介绍。柏林:施普林格出版社。ch 4.1–4 . 2 . 5</em></a><em class="ln">摘自约翰霍普金斯大学教授M. Fleischer博士的课堂笔记《神经网络导论研究生课程》。</em></li></ul></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><div class="kg kh ki kj gt lr"><a href="https://skilled.dev" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">编写面试问题</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">一个完整的平台，在这里我会教你找到下一份工作所需的一切，以及…</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">技术开发</p></div></div><div class="ma l"><div class="pc l mc md me ma mf kp lr"/></div></div></a></div></div></div>    
</body>
</html>