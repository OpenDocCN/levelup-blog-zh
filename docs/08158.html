<html>
<head>
<title>Lessons Learnt from Scaling Memcached in Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在生产中扩展Memcached的经验教训</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/lessons-learnt-from-scaling-memcached-in-production-86778ab616c7?source=collection_archive---------5-----------------------#2021-04-06">https://levelup.gitconnected.com/lessons-learnt-from-scaling-memcached-in-production-86778ab616c7?source=collection_archive---------5-----------------------#2021-04-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="915f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为业务用例构建高可用性缓存解决方案的主要考虑事项和策略</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/861a20b08cb9720d0b81dfec0648264c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dGyqtON3ENJdqoXK"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">Elena Mozhvilo 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="d8ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> M </span> emcached是一个众所周知的简单的内存缓存解决方案，被脸书、Twitter和Pinterest等几家大公司使用。Memcached的主要用例是后备缓存，以减少数据库的负载。与Redis不同，以简单著称的Memcached不提供任何内置的高可用性特性。</p><h1 id="6fc4" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">问题是</h1><p id="99f6" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">随着缓存集群规模的扩大，高可用性(HA)成为一个关键问题。在缓存服务器暂时甚至永久崩溃的情况下，我们如何快速响应？我们如何防止数据库服务器的请求过载？</p><p id="f074" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然有一些开源的Memcached HA解决方案(最流行的是脸书的Mcrouter)，但这些解决方案可能不完全适合个人的业务用例。例如，Mcrouter确保尽最大努力实现最终一致性(即陈旧数据仍可能出现，尤其是在存在复制的情况下)，而一些特定的使用情形可能需要更高的数据一致性。对于不同的业务用例，可能还需要更多地控制可用性、一致性、性能和成本效益之间的权衡。</p><p id="c230" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，在撰写本文时，Mcrouter使用了一个分支版本的Memcached，该版本使用租约来确保最终的一致性[1]。在最近版本的开源Memcached中，租约是不可用的，这使得Mcrouter很难适应一般的Memcached基础设施。</p><blockquote class="my mz na"><p id="790e" class="kw kx nb ky b kz la jr lb lc ld ju le nc lg lh li nd lk ll lm ne lo lp lq lr ij bi translated">本文的目的不是描述一个固定的扩展Memcached的解决方案。</p></blockquote><p id="1893" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在过去的4个月里，我一直致力于扩展Memcached，我的目标是整合关键策略和考虑事项，以<strong class="ky ir">构建高度可用的缓存解决方案，同时满足业务用例的一致性需求。</strong>这些策略不是特定于Memcached的，可以应用于类似的后备缓存解决方案。</p><h1 id="9643" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">高可用性缓存解决方案需要什么</h1><p id="ceee" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">那么，高可用性缓存解决方案需要什么呢？我们确定了高可用性解决方案中三个最重要的特性:</p><ol class=""><li id="53fb" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated"><strong class="ky ir">缓存复制</strong></li><li id="bf69" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated"><strong class="ky ir">冷缓存预热</strong>:如果发生崩溃故障，有没有热备份缓存来缓冲数据库负载的增加？</li><li id="f0d6" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated"><strong class="ky ir">自动快速故障转移</strong>:我们能够足够快地检测并纠正崩溃故障吗？</li></ol><p id="fa83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然缓存复制背后的动机类似于在节点故障时进行热缓存备份，但复制可能更强大，因为它还有助于增加Memcached集群每秒可以处理的总查询数。例如，如果我们采用将读取流量定向到任一副本的策略，单个Memcached的负载可以减少副本数量的一倍，因此在整个副本中，我们可以支持更高的每秒查询数(QPS)。</p><p id="e3f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，通常为了换取更高的可用性，会牺牲一致性。例如，对于两个副本Memcached，我们不仅要关心Memcached和DB之间的一致性，还要关心两个副本Memcached之间的一致性。</p><p id="967b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Amazon也报告了这一点，根据他们的经验，在ACID (C代表一致性)属性和可用性之间通常存在一种折衷。我们将在后面的部分讨论平衡这种权衡的策略。</p><h1 id="fb5e" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">缓存的主要业务用例</h1><p id="92e4" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">为了理解如何平衡一致性和可用性之间的平衡，我们需要确定业务用例及其需求。缓存通常有两种主要的使用情形:</p><ol class=""><li id="2857" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">后备缓存(数据库是事实的权威来源)</li><li id="93f7" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">缓存作为权威存储(缓存现在是事实的权威来源)</li></ol><p id="a010" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然Memcached的主要用途通常是作为后备缓存，但一些业务用例可能会将缓存用作权威存储，在这种情况下，一致性可能变得更加重要。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/c780b6cf26985ca7beb08213ba005f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTMiS7_-RUIdefcD2SOpJQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图1:远程标记机制使用Memcached作为权威数据源来存储标记。该机制用于最小化读取副本数据库中陈旧数据的可能性。</figcaption></figure><p id="cdf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在脸书的Scaling Memcached论文中，描述了缓存作为权威存储的用例:对于需要高度一致性的用例，使用<em class="nb">远程标记</em>机制来最小化读取副本数据库中陈旧数据的概率。本文中描述的问题源于这样一个事实，即副本数据库可能落后于主数据库(DB)，有时这种复制滞后是不可忽略的(例如，当主数据库和副本数据库位于不同的地理区域时)。</p><p id="b77a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如图1所示，当新数据写入master DB时，客户机也将向Memcached中写入一个标记。通常标记的到期时间非常短。随后，在客户端从数据库中读取数据之前，它将检查缓存中是否存在远程标记。如果标记存在，则意味着数据最近被写入或更新，客户端将从主数据库读取，否则，它将从副本数据库读取。</p><h2 id="f4cb" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">选择正确的一致性保证</h2><p id="b8e3" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在确定我们的业务用例之后，我们需要选择正确的一致性保证。例如，在作为权威存储用例的缓存中，我们可能需要Memcached副本之间的高度一致性，因为数据只存储在缓存中，而缓存是真实数据的权威来源。在其他业务情况下，最终的一致性可能就足够了，我们可以将策略集中在维护更高的可用性或优化性能上。</p><p id="303b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们需要考虑两个主要的一致性关系:</p><ol class=""><li id="f1bd" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">Memcached副本之间的一致性(如果使用复制)</li><li id="bbbd" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">数据库和Memcached之间的一致性</li></ol><p id="e016" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们的重点是扩展Memcached基础设施，所以我们不会关心主数据库和副本数据库之间的一致性。</p><p id="574b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是业务级别通常需要的几个一致性级别。请记住，高一致性通常是可用性、性能(低延迟、高吞吐量)或/和成本的折衷。</p><ol class=""><li id="c892" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated"><strong class="ky ir">强一致性</strong></li></ol><p id="14d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Memcached副本之间的强一致性保证了Memcached副本具有相同的数据，并且对副本的不同读取请求将返回相同的结果。当缓存被用作权威存储时，或者当不一致的数据可能会对业务产生重大影响时，可能需要Memcached副本之间具有如此强的一致性。例如，在远程标记机制(如上所述)的情况下，高速缓存未命中可能导致客户端从可能包含陈旧数据的副本DB中读取数据。</p><p id="d9d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.<strong class="ky ir">最终一致性</strong></p><p id="c0f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最终一致性保证了如果给定的数据项没有新的更新，<strong class="ky ir">最终</strong>对该项目的所有get请求都将返回最后更新的值。大多数(如果不是全部)缓存使用案例至少需要最终的一致性。</p><p id="34da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.<strong class="ky ir">允许陈旧数据(在有限的时间内)以换取更低的延迟</strong></p><p id="d285" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过确定返回稍微过时的数据是可以接受的情况，我们可以采用允许在有限的时间内返回过时数据的策略，以减少延迟。</p><p id="c373" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.<strong class="ky ir">顺序一致性</strong></p><p id="fe45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据兰波特的定义:</p><blockquote class="my mz na"><p id="f692" class="kw kx nb ky b kz la jr lb lc ld ju le nc lg lh li nd lk ll lm ne lo lp lq lr ij bi translated">顺序一致性意味着操作似乎是以某种总的顺序发生的，并且这种顺序与每个单独过程中的操作顺序是一致的。</p></blockquote><p id="bafa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在分布式缓存的上下文中，顺序一致性保证了Memcached服务器接收的操作顺序与每个客户机发送的部分操作顺序一致。也就是说，每个客户端看到它们的操作是按顺序执行的(即使它们的操作可能与其他客户端发送的操作交错)。</p><h1 id="0f8c" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">扩展分布式缓存的策略</h1><p id="3c3d" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在分析了我们的业务案例及其所需的一致性级别后，我们现在准备讨论扩展我们的分布式缓存解决方案的策略。所讨论的每一种策略都源于生产中在扩展Memcached基础设施时所面临的不同问题。</p><h2 id="69f3" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">1.在数据更新时执行缓存失效</h2><p id="e787" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">Memcached基础设施中出现的一个问题是并发写入的竞争条件，这会导致缓存中出现无限陈旧的数据。这对业务逻辑是有害的，因为甚至最终的一致性也不能保证。</p><p id="9fe9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，考虑Memcached的单个实例，其中来自客户端的并发写入有时可能被重新排序，也就是说，如果我们采用简单的“先写入数据库，再写入缓存”策略，写入数据库的顺序可能与写入Memcached的顺序不同，这将导致数据无限期地过时。主要问题是因为写不是等幂的，也不是可交换的。</p><blockquote class="my mz na"><p id="e5e1" class="kw kx nb ky b kz la jr lb lc ld ju le nc lg lh li nd lk ll lm ne lo lp lq lr ij bi translated">“我们选择删除缓存的数据而不是更新它，因为删除是等幂的。Memcache不是数据的权威来源，因此被允许驱逐缓存的数据"[1]。</p></blockquote><p id="c7f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">避免这个问题的常见策略是在更新数据库时使用缓存失效，因为删除是等幂的。例如，在脸书论文[1]的扩展Memcached中，作者提出，在对数据项x进行DB写入时，运行守护进程<em class="nb">MC quiller</em>的无效流水线将读取DB日志，然后向Memcached发出对相同数据项x的无效(即删除命令)。然后，当客户端收到缓存未命中时，它们将直接从数据库中获取数据项，并将最新的值写入Memcached。</p><p id="a01d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了准备意外的情况，比如短暂的网络故障，我们需要确保失效守护进程继续以相同的顺序重试删除命令，直到成功为止，这样当Memcached实例断开连接时，失效请求不会丢失。为了在节点故障期间减少无效流水线上的负载，可以以指数补偿的方式实现重试。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/bb1e63ef95b112d0b539bfe2d922c571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*SqG1AvU2iHOFEFl0koY6Ww.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">改编自[1]。</figcaption></figure><p id="3aa6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法最大限度地降低了并发写入被重新排序的风险，因为删除是等幂的，如果多个客户端并发地更新同一个数据项，数据库将负责排序更新并从Memcached中删除数据项。</p><p id="6c2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，使用这种策略仍然存在以陈旧数据告终的小风险。考虑给定的竞争条件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="7904" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，脸书在Memcached服务器端使用了一种类似CAS(检查和设置)的方法，称为租约。然而，在撰写本文时，在最近版本的开源Memcached中还没有租约。</p><h2 id="df2c" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">2.客户端与服务器端方法</h2><p id="26cd" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在扩展缓存基础设施时，将系统的复杂性嵌入到无状态客户端或独立代理中通常是一个好主意。这极大地简化了Memcached，并使人们能够专注于使它对特定用例具有高性能。为了扩展Memcached基础设施，我们发现有两种通用方法可以采用:</p><p id="26e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a)可以嵌入到应用程序中的库(客户端方法)</p><p id="bd04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">b)独立代理(可以是客户端代理进程，如Mcrouter或服务器端代理)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/6d2ebca02f5f2fecc9601dc1eb7778ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FMSjgrBFTGCSnXvYZfJlWA.png"/></div></div></figure><p id="20e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">独立客户端代理的一个例子是Mcrouter [1]，它通常被部署为客户端机器的附属设备，这意味着它独立于客户端API库[5]。服务器端代理的一个例子是部署一个LVS负载平衡器，在同一个一致散列槽中的不同Memcached副本之间分割流量。使用独立代理解决方案的主要优点是客户端的代码修改很少或没有修改。</p><p id="ba69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与客户端代理相比，部署服务器端代理还减少了对代码添加和更改的需求，从而降低了错误的风险，并使现有团队更容易转换到新的解决方案。但是，服务器端代理可能需要额外的成本(以另一台物理机/专用机架的形式)。在复制策略一节中，我们将研究如何使用这两种策略来实现高可用性。</p><h2 id="ef6f" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">3.复制策略</h2><p id="d34f" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">我们在一致性一节中已经看到，不同的业务需求可能需要非常不同的一致性或可用性保证。有时，我们甚至需要在同一个缓存基础架构中满足多个完全不同的用例。为了满足这些业务目标，我们必须采用特定的策略来平衡这些权衡。我们将在这一部分讨论其中的一些复制策略。请注意，我们检查的规模是一个特定的复制群集(即一致性哈希算法的一个片段)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/3923c97a9c99abcd0fef395835fc0c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MQNdOEakwr0aT4J_5E7eiA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">我们的策略将集中在一个特定的Memcached一致散列槽上。</figcaption></figure><ol class=""><li id="b0b9" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">自动故障转移到冷备份的主Memcached节点</li><li id="4e19" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">写入任何节点；从任意节点获取。</li><li id="d8c0" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">写入所有节点；从任何节点获取</li><li id="bc90" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">写入所有节点；仅从主Memcached节点获取</li></ol><p id="bb41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">自动故障转移到冷备份的主Memcached节点</strong></p><p id="fa6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此策略不支持复制或热缓存备份；它主要支持Memcached节点失败时的自动故障转移。如果Memcached出现故障，将流量路由到冷缓存将导致缓存未命中，从而增加数据库负载。但是，如果DB能够承受几个Memcached节点的负载，那么这个解决方案可能适合作为临时解决方案。</p><p id="880d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种策略的一种可能实现是通过使用服务器端策略:我们可以在客户机和Memcached服务器之间添加一层虚拟路由器冗余协议(VRRP)。VRRP执行自动故障检测和故障转移，因此如果活动的物理Memcached主服务器出现故障，将选择另一台物理机器来自动替换它。</p><p id="2d7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">写入任意节点；从任意节点获取。</strong></p><p id="f0bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，脸书使用客户端代理Mcrouter实现了这一策略。这种策略也可以以服务器端代理的形式实现，使用负载均衡器(如LVS)来分割Memcached副本之间的流量。</p><p id="affa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">优点</em>:副本在它们之间分担流量负载，因此，总体上可以支持更多的QPS。由于流量的分割是随机的，我们可以期望密钥在副本之间均匀分布。因此，在部分副本出现故障的情况下，我们可以保证有热备份。</p><p id="44fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">缺点</em>:无法确保副本之间的可重复读取，因为不能保证写入会在所有副本中结束。对于需要高度一致性的使用情形，例如将缓存用作权威存储，此解决方案可能不够。</p><p id="e733" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">写入所有节点；从任意节点获取</strong></p><p id="9022" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此策略旨在支持所有副本中的完整复制，即写入将传播到所有副本(同步)。</p><p id="d45c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">优点</em>:如果实现得当，可以支持不同Memcached副本之间的高度一致性。由于请求被拆分到不同的副本中，一个一致哈希槽中支持的总体QPS也会随着副本数量的增加而增加。</p><p id="675f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">缺点</em>:保证所有Memcached副本彼此一致并不容易，特别是对于客户端方法。这是因为我们必须管理由于临时网络延迟而导致Memcached写入失败的情况。</p><p id="ddaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">尝试写入其他节点；仅从主Memcached节点获取</strong></p><p id="4745" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该策略放宽了先前策略的条件:即尝试实现完全复制。在缓存未命中时，Memcached将从DB获取新数据，并以同步方式写入主Memcached节点，然后以异步方式写入辅助节点。Get查询将只定向到主Memcached。</p><p id="1eab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">优点</em>:能够维护热Memcached副本备份，假设大多数异步写入将会成功。因为Get查询只由主Memcached节点处理，所以在大多数正常情况下，确保主节点和备份之间的一致性并不重要。</p><p id="ccae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nb">缺点</em>:同样，保证所有副本彼此一致也是很重要的。如果主Memcached节点出现故障，提升到主节点的备份可能包含一些陈旧的数据。</p><p id="df6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，由于只有一个主节点被用于处理所有查询流量，所以在一个一致散列槽中可以支持的总QPS保持不变。</p><h2 id="8050" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">4.实现故障转移</h2><p id="4afd" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">故障转移指的是在主要机器出现故障时回退到次要服务/机器的行为。故障转移是任何高可用性解决方案的一个重要方面，包括两个主要组件:故障检测和到另一个Memcached副本或备份的逐步故障转移。理想情况下，我们希望实现快速故障转移，有时是自动故障转移。</p><p id="04c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">检测节点故障的一种常见方法是通过使用守护程序脚本向服务器发送定期心跳来执行健康检查。回复心跳的服务器被认为是健康的，我们可以在像ETCD/Zookeeper这样的中央配置中心跟踪这个健康的服务器列表，客户端进程可以访问它。支持渐进式故障转移的一种可能方式是通过服务器端策略，如支持这种高可用性功能的VRRP。</p></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><p id="12d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，随着Memcached规模的增加，人们必须记住一致性、可用性和性能之间的权衡，这些因素之间的复杂平衡取决于Memcached支持的业务用例。</p><p id="afb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读！请点击此处查看我之前关于如何测试Memcached性能的帖子:</p><div class="oq or gp gr os ot"><a href="https://medium.com/swlh/the-complete-guide-to-benchmark-the-performance-of-memcached-on-ubuntu-16-04-71edeaf6e740" rel="noopener follow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd ir gy z fp oy fr fs oz fu fw ip bi translated">在Ubuntu 16.04上测试Memcached性能的完整指南</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">如何识别瓶颈并为memcached服务器建立安全的流量级别。</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">medium.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph kp ot"/></div></div></a></div><h2 id="6aab" class="nu mc iq bd md nv nw dn mh nx ny dp ml lf nz oa mn lj ob oc mp ln od oe mr of bi translated">参考</h2><p id="3e9a" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">[1]在脸书扩展Memcached<a class="ae kv" href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" rel="noopener ugc nofollow" target="_blank">https://www . usenix . org/system/files/conference/nsdi 13/nsdi 13-final 170 _ update . pdf</a></p><p id="9216" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]迪纳摩:亚马逊的高可用键值存储<a class="ae kv" href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" rel="noopener ugc nofollow" target="_blank">https://www . usenix . org/system/files/conference/nsdi 13/nsdi 13-final 170 _ update . pdf</a></p><p id="0ed4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]Memcached<a class="ae kv" href="https://memcached.org/" rel="noopener ugc nofollow" target="_blank">https://memcached.org/</a></p><p id="77af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4]关于在https://pdos.csail.mit.edu/6.824/notes/l-memcached.txt脸书<a class="ae kv" href="https://pdos.csail.mit.edu/6.824/notes/l-memcached.txt" rel="noopener ugc nofollow" target="_blank">缩放Memcached的说明</a></p><p id="2b99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5]在Pinterest扩展缓存基础设施<a class="ae kv" href="https://medium.com/pinterest-engineering/scaling-cache-infrastructure-at-pinterest-422d6d294ece" rel="noopener">https://medium . com/Pinterest-engineering/Scaling-Cache-infra structure-at-Pinterest-422 d6d 294 ECE</a></p></div></div>    
</body>
</html>