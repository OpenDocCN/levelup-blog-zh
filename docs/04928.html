<html>
<head>
<title>Generating Captions for Images using Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用神经网络为图像生成字幕</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/generating-captions-for-images-using-neural-networks-2b0ecf657335?source=collection_archive---------3-----------------------#2020-07-24">https://levelup.gitconnected.com/generating-captions-for-images-using-neural-networks-2b0ecf657335?source=collection_archive---------3-----------------------#2020-07-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="19d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们都知道，在执行某些任务时，神经网络可以在复制人脑方面做很多事情。神经网络在计算机视觉和自然语言生成方面的应用确实令人瞩目。</p><p id="6ecf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文将向读者介绍神经网络的一个这样的应用，并让读者了解我们如何使用CNN和RNNs (LSTM)的混合网络来实际生成图像的标题(描述)。我们在这个任务中使用的数据集是流行的<em class="ko"> flickr 8k图像数据集</em>，它是这个任务的基准数据，可以通过下面的链接<em class="ko">访问。</em></p><p id="d172" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">https://www.kaggle.com/adityajn105/flickr8k</p><blockquote class="kq kr ks"><p id="3f94" class="jq jr ko js b jt ju jv jw jx jy jz ka kt kc kd ke ku kg kh ki kv kk kl km kn im bi translated">注意:我们将把数据集分成7k用于训练，1k用于测试。</p></blockquote><p id="bc11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将首先讨论混合神经网络中的不同组件(层)及其功能。除此之外，我们还将看看使用Tensorflow、Keras和Python开发混合神经网络的实际实现。</p><h1 id="c199" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">神经网络的整体架构</strong></h1><p id="2bca" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">让我们看看我们将用于生成字幕的神经网络的整体架构。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/9edd8acb86296050d4e7759af25253d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D3JoyOelmtyowMuoSIkadg.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">神经网络架构(来源:谷歌图片)</figcaption></figure><p id="5de0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">简而言之，上述神经网络有3个主要组件(子网络)，每个组件都分配有一个特定的任务，即卷积网络(用于从图像中提取特征)、RNN (LSTM)(用于文本生成)和解码器(用于组合两个网络)。</p><p id="af2e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们详细讨论每个组件并了解它们的工作原理。</p><h1 id="0bd2" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">图像特征提取器</strong></h1><p id="a9c3" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">为了从图像中生成特征，我们将使用卷积神经网络，只需稍加修改。让我们看一个用于图像识别的ConvNet。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mp"><img src="../Images/5235372cbe3f3db0a83d8d3263c8edb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXP94kNxfDlyqCaTQg9pEg.jpeg"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">CNN架构(来源:Bing图片)</figcaption></figure><p id="5dfd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，我们的CNN有两个子网络—</p><ol class=""><li id="cdbc" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated"><strong class="js iu">特征学习网络</strong> —负责从图像生成特征图的网络(多重卷积&amp;汇集层的网络)。</li><li id="8d26" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">分类网络</strong> —负责图像分类的全连接深度神经网络(多个密集层和单个输出层的网络)。</li></ol><p id="dbc0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为我们只对从图像中提取特征感兴趣，而不是对它们的分类感兴趣，所以我们只对CNN的特征学习部分感兴趣，这就是我们如何从图像中提取特征。</p><p id="013e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码可用于从任何一组图像中提取特征-</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">设计自己的图像特征提取器</figcaption></figure><p id="bc3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是的，任何人都可以使用上面的代码构建自己的图像特征提取器，但是有一个问题…</p><p id="8917" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的模型太简单了，无法从我们的图像集中提取每个重要的细节，因此会影响我们整体模型的性能。此外，由于高性能GPU和系统的不可用性，使模型过于复杂(具有大量神经元的多个密集层)也具有挑战性。T3】</p><p id="0ed0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了解决这个问题，我们有非常流行的预训练CNN模型(VGG-16，ResNet50等。由来自不同大学和组织的科学家开发)在Tensorflow中可用，并可用于从图像中提取特征。<strong class="js iu">在使用输出图层进行特征提取之前，请记住将其从模型中移除。</strong></p><p id="4432" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码将让您了解如何在Tensorflow中使用这些预训练的模型从图像中提取特征。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">利用ResNet50模型进行图像特征提取</figcaption></figure><p id="45a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您在下面看到的，如果您执行上面的代码，您将会看到我们的图像特征只不过是shape的numpy数组— (18432，)</p><pre class="ma mb mc md gt ng nh ni nj aw nk bi"><span id="8a49" class="nl kx it nh b gy nm nn l no np">image_feature_dictionary[list(image_feature_dictionary. Keys())[0]].shape</span><span id="d55e" class="nl kx it nh b gy nq nn l no np">(18432,)</span></pre><p id="23f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们将开发我们的LSTM网络(RNN)为图像生成字幕。</p><h1 id="7d5f" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">用于生成字幕的LSTM</h1><p id="66a4" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">文本生成是LSTM网络最流行的应用之一。LSTM单元(LSTM网络的基本构件)具有基于先前层的输出生成输出的能力，即它保留先前层的输出(存储器)并使用该存储器来生成(预测)序列中的下一个输出。</p><p id="ed6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们的数据集，每个图像有5个标题，即总共40k个标题。</p><p id="5377" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看我们的数据集-</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/610629256b4637b3a19ea9fbabeb08a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*LO2YGullmHu-iFUtVWL_EA.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">来自Flickr8k数据集的图像</figcaption></figure><p id="5bb0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图像标题</strong></p><ol class=""><li id="aca4" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated">一个穿着粉色连衣裙的孩子正在入口处爬上一组楼梯。T11】</li><li id="06dc" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu"> <em class="ko">一个女孩走进一栋木屋。</em>T15】</strong></li><li id="d9ca" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu"> <em class="ko">一个小女孩爬进一个木制玩具屋。</em>T19】</strong></li><li id="2a80" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu"> <em class="ko">一个小女孩爬楼梯去她的玩具屋。</em> </strong></li><li id="0e9c" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated">一个穿着粉红色连衣裙的小女孩走进一间木屋。 </li></ol><p id="80e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如所见，所有的标题都很好地描述了这幅图像。我们现在的任务是设计一个RNN，它可以对任何类似的图像集重复这项任务。</p><p id="27dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">回到最初的任务，我们首先要看看LSTM网络是如何生成文本的。对于LSTM网络来说，字幕不过是一长串单独的单词(编码为数字)放在一起。利用这些信息，它试图根据前面的单词(记忆)来预测序列中的下一个单词。</p><p id="caa6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的例子中，由于标题可以有不同的长度，我们首先需要指定每个标题的开始和结束。让我们看看这到底意味着什么-</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ns"><img src="../Images/73708079bd19ff70da437769df485d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccAxD4C8u86gE4Z_-shFPw.jpeg"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">准备训练数据集</figcaption></figure><p id="f06f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们将为数据集中的每个标题添加<start>和<end>。之后，在创建最终词汇之前，我们将对训练数据集中的每个标题进行标记。为了训练我们的模型，我们将从我们的词汇表中删除频率小于或等于10的tokes(单词)。添加这一步是为了提高我们模型的一般性能，并防止它过度适应训练数据集。</end></start></p><p id="fd0e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码可用于实现这一点-</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">加载标题的代码</figcaption></figure><p id="b922" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上述代码将生成以下输出—</p><pre class="ma mb mc md gt ng nh ni nj aw nk bi"><span id="812d" class="nl kx it nh b gy nm nn l no np">train_image_captions[list(train_image_captions. Keys())[150]]<br/></span><span id="5a0d" class="nl kx it nh b gy nq nn l no np">['&lt;start&gt; A brown dog chases a tattered ball around the yard . &lt;end&gt;',<br/> '&lt;start&gt; A brown dog is chasing a tattered soccer ball across a low cut field . &lt;end&gt;',<br/> '&lt;start&gt; Large brown dog playing with a white soccer ball in the grass . &lt;end&gt;',<br/> '&lt;start&gt; Tan dog chasing a ball . &lt;end&gt;',<br/> '&lt;start&gt; The tan dog is chasing a ball . &lt;end&gt;']</span></pre><p id="a40f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦我们加载了标题，我们将首先使用spacy和Tokenizer(来自<em class="ko">tensor flow . preprocessing . text</em>类)对所有内容进行标记。</p><p id="c7d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">记号化就是把一个句子分解成不同的单词，同时去掉特殊字符，所有的都小写。结果是，我们在句子中有了一个有意义的单词(标记)的语料库，在将它用作我们的模型的输入之前，我们可以进一步对其进行编码。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">用于标记字幕的代码</figcaption></figure><p id="5ab6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的代码将生成一个字典，其中每个标记都被编码为一个整数，反之亦然。示例输出如下所示—</p><pre class="ma mb mc md gt ng nh ni nj aw nk bi"><span id="2c53" class="nl kx it nh b gy nm nn l no np">tokenizer.word_index </span><span id="1c6a" class="nl kx it nh b gy nq nn l no np">{'a': 1,<br/> 'end': 2,<br/> 'start': 3,<br/> 'in': 4,<br/> 'the': 5,<br/> 'on': 6,<br/> 'is': 7,<br/> 'and': 8,<br/> 'dog': 9,<br/> 'with': 10,<br/> 'man': 11,<br/> 'of': 12,<br/> 'two': 13,<br/> 'black': 14,<br/> 'white': 15,<br/> 'boy': 16,<br/> 'woman': 17,<br/> 'girl': 18,<br/> 'wearing': 19,<br/> 'are': 20,<br/> 'brown': 21.....}</span></pre><p id="38de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这之后，我们需要找到我们的词汇的<strong class="js iu">长度和最长字幕的长度。让我们来看看这两个度量在创建我们的模型中的重要性。</strong></p><ol class=""><li id="86e2" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated"><strong class="js iu">词汇长度</strong> →词汇长度基本上就是我们语料库中唯一词的计数。此外，我们输出层中的神经元将等于<strong class="js iu">词汇长度+ 1 </strong> <em class="ko"> (+ 1是由于填充序列而产生的额外空白)</em>因为在每次迭代中，我们需要我们的模型从我们的单词语料库中生成一个新单词。</li><li id="9959" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">最大字幕长度</strong> →因为在我们的数据集中，即使是同一张图像，我们也有不同长度的字幕。让我们试着更详细地理解这一点</li></ol><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nt"><img src="../Images/3c1a18fc002f4e68f1a2f1b67707112b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i19g_Cl5k03OT-iKMwZmxA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">字幕序列长度</figcaption></figure><p id="169d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，每个标题都有不同的长度，因此我们不能将它们作为LSTM模型的输入。为了解决这个问题，我们将每个标题填充到最大标题长度。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/2843ed99ca4b2350b4dd8bec048fbd60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*Lv4dkrjtVMw-jXsRBfTdnQ.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">填充序列</figcaption></figure><p id="579f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，每个序列都有一组额外的0，以将其长度增加到最大序列长度。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">查找词汇和最大字幕长度</figcaption></figure><p id="6cf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们需要为我们的模型创建训练数据集，指定输入和输出。对于我们的问题，我们有2个输入和1个输出。让我们看得更详细一点，以便理解-</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nv"><img src="../Images/00b0e1af9bf4d759f25cf00a939c0ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MhI3macM9r6x6xKlbosppQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">训练数据集</figcaption></figure><p id="eb93" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们拥有的每一幅图像-</p><ol class=""><li id="cc33" class="mq mr it js b jt ju jx jy kb ms kf mt kj mu kn mv mw mx my bi translated"><strong class="js iu">输入图像特征(X1) </strong> →使用ResNet50模型提取的Numpy形状数组(18432，)</li><li id="c1f8" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">输入序列(X2) </strong> →这需要更多的解释。每个标题只是一个序列列表，我们的模型试图预测序列中的下一个最佳元素。因此，对于每个标题，我们将首先从序列中的第一个元素开始，该元素的相应输出将是下一个元素。在下一次迭代中，前一次迭代的输出将与前一次迭代的输入(内存)一起成为新的输入，这一直持续到我们到达序列的末尾。</li><li id="9a89" class="mq mr it js b jt mz jx na kb nb kf nc kj nd kn mv mw mx my bi translated"><strong class="js iu">输出(y) </strong> →序列中的下一个单词。</li></ol><p id="9075" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码可用于实现上述创建训练数据集的逻辑-</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">用于创建训练数据集的代码</figcaption></figure><h1 id="2e2e" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">合并两个子网络</strong></h1><p id="2d60" class="pw-post-body-paragraph jq jr it js b jt lu jv jw jx lv jz ka kb lw kd ke kf lx kh ki kj ly kl km kn im bi translated">现在我们已经开发了两个子网络(图像特征提取器和用于生成字幕的LSTM)，让我们结合这两个来创建我们的最终模型。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nw"><img src="../Images/3d6b31ea9d2715e65f296a0f082ebc25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9t0uK6vJ28m9LYL4DyqGkQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">最终模型架构</figcaption></figure><p id="f2a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于任何新的图像(必须与训练中使用的图像相似)，我们的模型将根据它在训练相似的图像和标题集时获得的知识来生成标题。</p><blockquote class="kq kr ks"><p id="1341" class="jq jr ko js b jt ju jv jw jx jy jz ka kt kc kd ke ku kg kh ki kv kk kl km kn im bi translated">注意:为了获得良好的结果，测试图像应该与培训期间使用的图像相似。</p></blockquote><p id="d2e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面的代码创建了我们的最终模型</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="0cd4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在编译模型之前，我们需要给我们的嵌入层添加权重。这是通过为我们的语料库(词汇表)中存在的每个标记创建单词嵌入(标记在高维向量空间中的表示)来完成的。有一些非常流行的单词嵌入模型可用于此目的(GloVe、Gensim单词嵌入模型等。).</p><p id="7ab1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用Spacy内置的“en_core_web_lg”模型来创建令牌的向量表示(即，每个令牌将表示为一个(300，)numpy数组)。</p><p id="9adc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码可用于创建单词嵌入，并将其添加到我们的模型嵌入层。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">创建单词嵌入并添加到嵌入层</figcaption></figure><p id="d16e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们已经创建了所有的东西，我们只需要编译和训练我们的模型。</p><blockquote class="kq kr ks"><p id="f3e6" class="jq jr ko js b jt ju jv jw jx jy jz ka kt kc kd ke ku kg kh ki kv kk kl km kn im bi translated"><strong class="js iu">注意:由于我们任务的复杂性</strong>，这个网络的训练时间将会非常长(具有大量的历元)</p></blockquote><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">培训模式</figcaption></figure><p id="79ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了生成新的标题，我们首先需要将图像转换为与训练数据集(18432)的图像具有相同维数的numpy数组，并使用<start>作为模型的输入。</start></p><p id="e740" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在序列生成过程中，我们会在输出中一遇到<end>就终止进程。</end></p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ne nf l"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk translated">用于生成字幕的方法</figcaption></figure><p id="990e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们检查模型的输出</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f0d12d906f5e68300ab40dd8ab9bd9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*ulg85KwidtQb8WSp8BLmuA.png"/></div></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1f95ca7e1dc1e90aa017e6b0f0f6b3a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*OoLsEIIWzXJmH7qEsOGgNg.png"/></div></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1433bbf079d2ded34a23b60d857ac1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*9KUnZcGwlbv2_X7YvbiNkA.png"/></div></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/bf4d02ceb0d041f74b008dcfdb99e830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*tpaX1wqUO0BxnidQwnAZrQ.png"/></div></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1c910a388b30cc23b9eb678d49969700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*jSahQnd1oWWO6toKcEvYtw.png"/></div></figure><p id="2910" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，我们的模型为一些图片生成了足够好的标题，但是对于一些图片来说，这些标题并不具有解释性。</p><p id="5bde" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这可以通过增加纪元、训练数据、向我们的最终模型添加层来改善，但所有这些都需要高端机器(GPU)来处理。</p><p id="33b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是我们如何使用自己的深度学习模型为图像生成标题。</p></div></div>    
</body>
</html>