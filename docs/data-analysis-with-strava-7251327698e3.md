# ä½¿ç”¨ Strava è¿›è¡Œæ•°æ®åˆ†æ

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/data-analysis-with-strava-7251327698e3>

## å¦‚ä½•åˆ©ç”¨æ•°æ®å’Œæœºå™¨å­¦ä¹ æé«˜è·‘æ­¥æˆç»©ï¼Ÿ

![](img/e34504dc848c8cd6d53729b9d8961d26.png)

æˆ‘ä¸€ç›´éå¸¸å–œæ¬¢è·‘æ­¥ï¼Œä»å¾ˆå°çš„æ—¶å€™æˆ‘å°±å‚åŠ æ¯”èµ›ï¼Œç›®çš„æ˜¯æé«˜æˆ‘çš„é€Ÿåº¦å’Œè·ç¦»ï¼Œä½†æ˜¯æœ‰å‡ ä¸ªå› ç´ å½±å“ç€è·‘æ­¥ï¼Œä»å¿ƒç†å› ç´ åˆ°å¤–éƒ¨å› ç´ ã€‚ç„¶è€Œï¼Œéšç€å°å·¥å…·ã€å¯ç©¿æˆ´è®¾å¤‡å’Œåº”ç”¨ç¨‹åº(å¦‚ [Strava](https://strava.com/) )çš„ä½¿ç”¨ï¼Œå·²ç»æœ‰å¯èƒ½æ•æ‰æŒ‡æ ‡å¹¶æ‰§è¡Œæœ‰åŠ©äºæ€§èƒ½æå‡çš„åˆ†æã€‚

# æ‘˜è¦

*   è®¿é—®æ•°æ®ï¼›
*   æ•°æ®æ¸…æ´—ï¼›
*   è§è§£ï¼›
*   ç‰¹å¾é€‰æ‹©ï¼›
*   æœºå™¨å­¦ä¹ ï¼›
*   ç»“è®ºï¼›
*   å‚è€ƒæ–‡çŒ®ã€‚

# è®¿é—®æ•°æ®

ä½œä¸ºä¸€ä¸ªæ•°æ®æºï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Stravaï¼Œå®ƒæ˜¯ä¸€ä¸ª Fremium åº”ç”¨ç¨‹åºï¼Œæœ‰ä¸€ä¸ª APIï¼Œå…è®¸è½»æ¾æ•è·æ•°æ®ã€‚

è¿™é‡Œæåˆ°çš„åœ¨ API ä¸­æ’å…¥çš„æ­¥éª¤ä¹Ÿå¯ä»¥ä»å®˜æ–¹æ–‡æ¡£ä¸­è·å¾—ï¼Œä½†æ˜¯å¦‚æœæ‚¨æƒ³å®¢è§‚ä¸€äº›ï¼Œæœ¬æ–‡å°†æè¿°ä¸»è¦æ­¥éª¤ã€‚

[](https://developers.strava.com/docs/getting-started/) [## Strava å¼€å‘å•†

### æ¬¢è¿æ¥åˆ° Strava APIï¼è¿™æ˜¯å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„ API çš„ç®€è¦æ¦‚è¿°ã€‚ä»»ä½•æµæ±—çš„äººéƒ½æ˜¯è¿åŠ¨å‘˜ï¼Œæ‰€ä»¥â€¦

developers.strava.com](https://developers.strava.com/docs/getting-started/) 

è®¿é—®æ•°æ®çš„ç¬¬ä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ª Strava å¸æˆ·ï¼Œç™»å½•ç„¶ååˆ›å»ºä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œå¯ä»¥ä½¿ç”¨[è¿™ä¸ªé“¾æ¥](https://www.strava.com/settings/api)æ¥å®Œæˆã€‚

![](img/442bef3f9614120147284191ac67a5a4.png)

Strava API ä»ªè¡¨æ¿ï¼Œå®¢æˆ·ç«¯ id å­—æ®µä»¥ç»¿è‰²çªå‡ºæ˜¾ç¤ºï¼Œå®¢æˆ·ç«¯å¯†ç å­—æ®µä»¥è“è‰²çªå‡ºæ˜¾ç¤ºã€‚

åˆ›å»ºåº”ç”¨ç¨‹åºåï¼Œæˆ‘ä»¬å°†ä¸»è¦ä½¿ç”¨**å®¢æˆ·ç«¯ ID** (ä»¥ç»¿è‰²çªå‡ºæ˜¾ç¤º)å’Œ**å®¢æˆ·ç«¯ç§˜å¯†**(ä»¥è“è‰²çªå‡ºæ˜¾ç¤º)ã€‚å®ƒå°†è¢«æ”¾åœ¨é¡¹ç›®å°†è¢«æ‰§è¡Œçš„å­˜å‚¨åº“æˆ–æ–‡ä»¶å¤¹çš„ä¸€ä¸ª`.env`æ–‡ä»¶ä¸­ã€‚

ç„¶åï¼Œæ‚¨éœ€è¦è®¿é—®ä»¥ä¸‹é“¾æ¥ï¼Œå°†[CLIENT_ID]å­—æ®µæ›´æ”¹ä¸ºæ‚¨çš„åº”ç”¨ç¨‹åºä¸­å¯ç”¨çš„å€¼ï¼Œåœ¨ä¸Šå›¾ä¸­ä»¥ç»¿è‰²æ˜¾ç¤ºã€‚

> [http://www.strava.com/oauth/authorize?CLIENT _ ID =[CLIENT _ ID]&response _ type = code&redirect _ uri = http://localhost/exchange _ token&approval _ prompt = force&scope = profile:read _ allï¼Œactivity:read_all](http://www.strava.com/oauth/authorize?client_id=[CLIENT_ID]&response_type=code&redirect_uri=http://localhost/exchange_token&approval_prompt=force&scope=profile:read_all,activity:read_all)

è®¿é—®æ­¤é“¾æ¥æ—¶ï¼Œé€‰æ‹©æ‚¨å¸Œæœ›åº”ç”¨ç¨‹åºæœ‰æƒè®¿é—®çš„æ•°æ®(å¦‚ä¸‹å›¾æ‰€ç¤º)ï¼Œç„¶åå•å‡»æˆæƒã€‚

![](img/02c8bd5819710b3481911ee741caeba5.png)

Strava åº”ç”¨ç¨‹åºæˆæƒä»ªè¡¨æ¿ã€‚

è¯¥æ“ä½œå°†ç”Ÿæˆä¸€ä¸ªä¸åŒçš„ URIï¼Œéœ€è¦ä»**ä»£ç **å‚æ•°ä¸­å¤åˆ¶ä»£ç å¹¶ç²˜è´´åˆ°å‰è¿°çš„`.env`ä¸­ã€‚ä¸‹é¢æ˜¯ URI æˆæƒåï¼Œä»¥åŠã€‚env æ–‡ä»¶åº”è¯¥æ˜¯è¿™æ ·çš„ã€‚

> [http://æœ¬åœ°ä¸»æœº/exchange_tokenï¼Ÿstate =&code = 2e 9 Fuhe F9 F2 JD 293 jqd 0g 8 erqt 84 r 802 jqd 0137 q&scope = readï¼Œactivity:read_allï¼Œprofile:read_all](http://localhost/exchange_token?state=&code=2e9fuhef9f2jd293jqd0g8erqt84r802jqd0137q&scope=read,activity:read_all,profile:read_all)

```
client_id=36431
client_secret=fasfjsfajfjie8293u2jf2j92jf232ije0jje92j
strava_code=2e9fuhef9f2jd293jqd0g8erqt84r802jqd0137q
```

æ‰§è¡Œå®Œè¿™äº›æ­¥éª¤åï¼Œæœ‰å¿…è¦åœ¨ä¸`.env`æ–‡ä»¶ç›¸åŒçš„ç¯å¢ƒä¸­è¿è¡Œä¸‹é¢çš„ Python è„šæœ¬ã€‚è¿™ä¸ªè„šæœ¬å°†æ›´æ–°æ•è·æ•°æ®æ‰€éœ€çš„ä»¤ç‰Œï¼Œå¹¶å°†ä½¿ç”¨è¯·æ±‚è¿”å›çš„æ•°æ®ç”Ÿæˆä¸€ä¸ª JSON æ–‡ä»¶ã€‚æˆ‘æŠŠè¿™ä¸ªè„šæœ¬å‘½åä¸º`create_token.py`ã€‚

```
import os
import json
import requests
from dotenv import load_dotenv

load_dotenv()

response = requests.post(
    url='https://www.strava.com/oauth/token',
    data={
        'client_id': int(os.environ.get('client_id')),
        'client_secret': os.environ.get('client_secret'),
        'code': os.environ.get('strava_code'),
        'grant_type': 'authorization_code'
    }
)
strava_tokens = response.json()
with open('strava_tokens.json', 'w', encoding='utf-8') as outfile:
    json.dump(strava_tokens, outfile)
print(strava_tokens)
```

æ›´æ–°äº†ä»¤ç‰Œå’Œç¯å¢ƒå˜é‡åï¼Œåªéœ€è¿è¡Œä»£ç ä» API ä¸­æ•è·æ•°æ®ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚è¿™é‡Œå¯èƒ½ä¼šæ³¨æ„åˆ°æ•è·æ˜¯æŒ‰é¡µè¿›è¡Œçš„ï¼Œæ‰€ä»¥ä¼šæ‰§è¡Œä¸€ä¸ªå¾ªç¯ï¼Œç›´åˆ°å“åº”ä¸ºç©ºæˆ–å‡ºç°é”™è¯¯ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œæˆ‘åœ¨åŒä¸€ä¸ªå·¥ä½œåŒºåˆ›å»ºäº†ä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼Œåˆ†åˆ«åä¸º**æ•°æ®**å’Œ**ç»“æœ**æ¥å­˜å‚¨æ•è·çš„ CSVï¼Œä¸‹é¢çš„è„šæœ¬å‘½åä¸º`get_activities.py`ã€‚

```
import os
import json
import glob
import time
import requests
import pandas as pd
from dotenv import load_dotenv

load_dotenv()

def main():
    url = "https://www.strava.com/api/v3/activities"
    access_token = get_credentials()
    page = 1
    print('Getting data from Strava')
    while True:
        response = get_data(url, access_token, 200, page)
        if 'message' in response.columns:
            raise Exception('Authorization Error')
        if response.empty:
            break
        save_csv(response, f'data/strava_activities_page_{page}.csv')
        page += 1
    merge_files('data/', 'result/strava_all_activities.csv')
    print('Done Successfully')
def get_credentials():
    with open('strava_tokens.json', encoding='utf-8') as json_file:
        strava_tokens = json.load(json_file)
    if 'expires_at' not in strava_tokens.keys() or strava_tokens['expires_at'] < time.time():
        strava_tokens = refresh_credentials(strava_tokens)
    return strava_tokens['access_token']
def refresh_credentials(strava_tokens):
    response = requests.post(
        url='https://www.strava.com/oauth/token',
        data={
            'client_id': int(os.environ.get('client_id')),
            'client_secret': os.environ.get('client_secret'),
            'grant_type': 'refresh_token',
            'refresh_token': strava_tokens['refresh_token']
        }
    )
    strava_tokens = response.json()
    with open('strava_tokens.json', 'w', encoding='utf-8') as outfile:
        json.dump(strava_tokens, outfile)
    with open('strava_tokens.json', encoding='utf-8') as check:
        data = json.load(check)
    return data
def get_data(url, access_token, numb_item_page, page):
    print(f'Getting data from page {page}')
    response = requests.get(
        f'{url}?access_token={access_token}&per_page={numb_item_page}&page={page}'
    )
    response = response.json()
    dataframe = pd.json_normalize(response)
    return dataframe
def save_csv(dataframe, filename):
    print(f'Saving {filename}')
    dataframe.to_csv(filename)
def merge_files(path, filename):
    print('Merging files')
    csv_files = [pd.read_csv(_file)
                 for _file in glob.glob(os.path.join(path, "*.csv"))]
    final_df = csv_files.pop(len(csv_files)-1)
    final_df = final_df.append(csv_files)
    save_csv(final_df, filename)
if __name__ == '__main__':
    main()
```

æœ‰äº†æ•°æ®ï¼Œè®©æˆ‘ä»¬å¼€å§‹åˆ†æï¼Œä¸ºäº†å®Œæˆè¿™ä¸€å£®ä¸¾ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Jupyter ç¬”è®°æœ¬ã€‚

# æ•°æ®æ¸…ç†

ç¬¬ä¸€æ­¥æ˜¯å¯¼å…¥å°†ç”¨äºæ‰§è¡Œæ•°æ®åˆ†æçš„åº“ï¼Œè¿™äº›åº“å¯ä»¥åˆ†ä¸ºç”¨äºæ”¯æŒè„šæœ¬çš„é€šç”¨åº“ã€ç”¨äºåˆ†æå’Œç»˜åˆ¶æ•°æ®å¸§çš„åº“ï¼Œä»¥åŠæœ€åç”¨äºæ‰§è¡Œæœºå™¨å­¦ä¹ æŠ€æœ¯çš„åº“ã€‚

```
# general
import subprocess
import calendar
from geopy.geocoders import Nominatim

# df and plotting
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# machine learning
from sklearn import preprocessing
from sklearn import metrics
from sklearn.cluster import KMeans
from sklearn.feature_selection import chi2
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('result/strava_all_activities.csv')
print('Dataframe Shape:', df.shape)
df.head()
```

![](img/394616bc0888014d98e8929bf0d9063a.png)

æ•°æ®é›†å½¢çŠ¶å’ŒåŒ…å«æ•°æ®é›†æ•°æ®çš„è¡¨ã€‚

ç¬¬ä¸€æ¬¡æ¥è§¦åï¼Œé˜…è¯»äº§ç”Ÿçš„ CSV æ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ•°æ®æ¡†æ¶æœ‰å¤§çº¦ 58 åˆ—å’Œä¸€äº›è¡Œï¼Œå¯ä»¥æ ¹æ®æ¯ä¸ªè¿åŠ¨å‘˜çš„è®°å½•å˜åŒ–ã€‚ä½†æ˜¯å½“æˆ‘ä»¬æŸ¥çœ‹æ•°æ®è´¨é‡æ—¶ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°è®¸å¤šæ•°æ®æ˜¯ç©ºçš„æˆ–è€…å¯¹åˆ†ææ²¡æœ‰è´¡çŒ®ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åªé€‰æ‹©ç ”ç©¶æ„Ÿå…´è¶£çš„åˆ—ã€‚

```
null_df = [[col, df[col].isnull().sum()] for col in df.columns]
print('Null Data:', df.isnull().sum().sum())
list(filter(lambda x: x[1]>0, null_df))
```

![](img/71694b2889506c22b3a81837bfbd94b1.png)

ç©ºæ•°æ®çš„æ€»é‡å’ŒæŒ‰æ•°æ®é›†åˆ—ã€‚

```
selected_columns = ['distance', 'moving_time', 'elapsed_time',
                    'total_elevation_gain', 'type','sport_type', 'id', 'start_date',
                    'start_date_local','location_country', 'achievement_count', 'kudos_count',
                    'comment_count','athlete_count', 'start_latlng',
                    'end_latlng', 'average_speed', 'max_speed', 'average_cadence',
                    'average_heartrate', 'max_heartrate', 'elev_high','elev_low',
                    'upload_id', 'external_id', 'pr_count', 'map.summary_polyline']
df = df[selected_columns]
```

é¦–å…ˆï¼Œæˆ‘å†³å®šæå–æ•°æ®é›†æä¾›çš„æœ€å¤§å€¼ï¼Œå¹¶å°è¯•åˆ é™¤å°½å¯èƒ½å°‘çš„æ•°æ®ï¼Œå› æ­¤æˆ‘æ ¹æ®æ—¥æœŸç”Ÿæˆäº†ä¸€äº›æ•°æ®ï¼Œç”¨é›¶å€¼ã€æœªçŸ¥æ ‡ç­¾æˆ–å¹³å‡å€¼å¡«å†™äº†ä¸€äº›ç©ºå­—æ®µï¼Œæœ€åï¼Œæˆ‘ç”Ÿæˆäº†ä¸€äº›æ•°æ®ï¼Œæ ‡å‡†åŒ–äº†ä»¥å…¬é‡Œä¸ºå•ä½çš„è·ç¦»å’Œä»¥åˆ†é’Ÿä¸ºå•ä½çš„æ—¶é—´ã€‚

```
df['start_date_local'] = pd.to_datetime(df['start_date_local'], errors='coerce')
df = df.sort_values(by='start_date_local')

df['weekday'] = df['start_date_local'].map(lambda x: x.weekday)
df['start_time'] = df['start_date_local'].dt.time
df['start_time'] = df['start_time'].astype(str)
df['start_date'] = df['start_date_local'].dt.date

df = df.drop('start_date_local', 1)
df.head()
```

![](img/aaff238bb460e3f717bc9fcd3662311f.png)

è½¬æ¢äº§ç”Ÿçš„æ•°æ®é›†ã€‚

```
df = df.drop(df[(df.distance < 1) & (df.type == 'Run')].index)
df = df.drop(df[(df.distance < 1) & (df.type == 'Ride')].index)
df = df.drop(df[df.average_speed > 30].index)
df = df.reset_index(drop=True)

df['elev_high'] = df['elev_high'].fillna(value=0)
df['elev_low'] = df['elev_low'].fillna(value=0)
df['upload_id'] = df['upload_id'].fillna(value='unknown')
df['external_id'] = df['external_id'].fillna(value='unknown')
df['map.summary_polyline'] = df['map.summary_polyline'].fillna(value='unknown')
df['average_cadence'] = df['average_cadence'].fillna(value=df['average_cadence'].mean())
df['average_heartrate'] = df['average_heartrate'].fillna(value=df['average_heartrate'].mean())
df['max_heartrate'] = df['max_heartrate'].fillna(value=df['max_heartrate'].mean())

df['moving_time_minutes'] = round(df['moving_time']/60, 2)
df['distance_km'] = round(df['distance'] / 1000, 2)
df['pace'] = df['moving_time_minutes'] / df['distance_km']
df['avg_speed_kmh'] = round(60/df['pace'], 2)
df['max_speed_kmh'] = round(df['max_speed']*3.6, 2)

df['elev'] = df['elev_high'] - df['elev_low']
df['year']= df['start_date'].map(lambda x: x.year)
```

éœ€è¦å¼ºè°ƒçš„ä¸€ä¸ªä¾‹å­æ˜¯ï¼Œæˆ‘æƒ³è¦å®ŒæˆåŸå¸‚å’Œå·å­—æ®µï¼Œå› ä¸ºåœ¨æœ€åˆçš„è®­ç»ƒä¸­ï¼Œåˆ—ä¸­è¿˜æœ‰çº¬åº¦å’Œç»åº¦å­—æ®µã€‚æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½¿ç”¨äº† [geopy](https://geopy.readthedocs.io/en/stable/) åº“ã€‚

```
def get_city_state_from_value(value):
    value = value.replace('[','').replace(']','').split(',')
    if value != ['']:
        location = geolocator.reverse(', '.join(value))
        result = f'{location[0].split(",")[1]}, {location[0].split(",")[4]}'
    else:
        result = 'unknown'
    return result
```

```
geolocator = Nominatim(user_agent="strava_exploration_data")
df['location'] = df['start_latlng'].map(get_city_state_from_value)
```

æœ€åï¼Œåˆ›å»ºäº†ä¸€ä¸ªåŸºäºä½äº 5 åˆ†é’Ÿ/å…¬é‡Œçš„é…é€Ÿçš„è¿‡æ»¤å™¨ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåˆ›å»ºäº†ä¸€ä¸ªæ˜¾ç¤ºæ‰€æœ‰å¹³å‡é€Ÿåº¦ä¸º 12 å…¬é‡Œ/å°æ—¶çš„æ¯”èµ›çš„åˆ—ï¼Œå¹¶å¯ä»¥åœ¨æœªæ¥çš„åˆ†æä¸­ä½¿ç”¨è¯¥åˆ—ä½œä¸ºå“åº”å˜é‡ã€‚

```
df['pace_sub_5'] = np.where(df['pace']<=5, True, False)
df.head()
```

![](img/b01b698fa28d7d7c10b93facbb030af6.png)

åˆ— pace_sub_5 ä½äºæœ€åä¸€ä¸ªä½ç½®çš„æ•°æ®é›†ã€‚

å½“æˆ‘ä»¬è¿è¡Œ`df.info()`å’Œ`df.describe().transpose()`æ—¶ï¼Œå¯ä»¥è·å¾—ä»¥ä¸‹æ•°æ®:

![](img/0848c3ffb0cb600675ec88842fec7d52.png)

å…³äºæ•°æ®é›†çš„ä¿¡æ¯ã€‚

![](img/85854b4f24d3d138e1550e2bec53b6f9.png)

æ•°æ®é›†æè¿°ã€‚

# æ´å¯ŸåŠ›

ç°åœ¨ï¼Œæœ‰äº†å¹²å‡€å’Œå……åˆ†çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€ç³»åˆ—çš„åˆ†æï¼Œè¯•å›¾å›ç­”è¿™æ ·çš„é—®é¢˜:æ¯å¹´æ³¨å†Œçš„æ•°é‡æ˜¯å¤šå°‘ï¼Ÿæ ¹æ®ä¸‹é¢çš„æ–¹æ¡†ï¼Œæœ‰å¯èƒ½å›ç­”è¿™ä¸ªé—®é¢˜ã€‚

```
fig = sns.catplot(x='year', hue='type', data=df, kind='count')
fig.fig.suptitle('Exercices by Years')
fig.set_xlabels('Year')
fig.set_ylabels('Effortments')
fig
```

![](img/a8d15aa82e8d1b0a446d60e7e79ac928.png)

æ¯å¹´ç»ƒä¹ é‡çš„æŸ±çŠ¶å›¾ã€‚

è®°ä½ï¼ŒStrava è®°å½•ä¸åŒç±»å‹çš„æ´»åŠ¨ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†**ä»…å¼ºè°ƒè·‘æ­¥**ï¼Œå› æ­¤åœ¨å½±å“è·‘æ­¥è¡¨ç°çš„å˜é‡(æœ¬è´¨ä¸Š)ä¸­ï¼Œæˆ‘å¼ºè°ƒæµ·æ‹”ã€å¿ƒç‡å’Œä¸é€Ÿåº¦ç›¸å…³çš„å› ç´ ï¼Œæ‰€ä»¥æˆ‘æƒ³å°†å®ƒä»¬ä¸å…¶ä»–é¢†åŸŸè”ç³»èµ·æ¥ã€‚

ç¬¬ä¸€é¡¹åˆ†ææ˜¯å°†æ´»åŠ¨æ—¶é—´ä¸é“è·¯çš„æµ·æ‹”é«˜åº¦ç›¸å…³è”ï¼Œå…¶ä¸­å¯ä»¥å¾—å‡ºç»“è®ºï¼Œæµ·æ‹”é«˜åº¦å¾€å¾€ä¼šæ ¹æ®æ´»åŠ¨æ—¶é—´ç”šè‡³æ ¹æ®è·ç¦»è€Œä¸Šå‡ã€‚

```
runs = df.loc[df['type'] == 'Run']
sns.regplot(x='moving_time_minutes', y = 'elev', data=runs).set_title("Exercice Time vs Elevation")
```

![](img/004ffbfb1163f8afb070c4d1ff10d5ab.png)

è¿åŠ¨æ—¶é—´ä¸æµ·æ‹”é«˜åº¦çš„å›å½’åˆ†å¸ƒå›¾ã€‚

```
sns.regplot(x='distance', y = 'elev', data=runs).set_title("Distance vs Elevation")
```

![](img/7209b82262b8557d7b17258f37f949d9.png)

è·ç¦»å’Œæµ·æ‹”ä¹‹é—´çš„å›å½’åˆ†å¸ƒå›¾ã€‚

ä½†è¿™ä¸åº”è¢«è§†ä¸ºä¸€ç§è§„åˆ™ï¼Œå› ä¸ºåœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œæ— è®ºæ´»åŠ¨æ—¶é—´æˆ–è·ç¦»å¦‚ä½•ï¼Œéƒ½ä¼šå‡ºç°ä½æµ·æ‹”ï¼Œè¿™åœ¨èµ›é“ä¸Šè¿›è¡Œè®­ç»ƒæ—¶éå¸¸å¸¸è§ã€‚

![](img/848506faceaf6aa4c18d02a1838542d2.png)

å›¾å½¢é«˜äº®æ˜¾ç¤ºä»¥ä½æµ·æ‹”è¿è¡Œã€‚

å…³äºè¿åŠ¨æ—¶é—´å’Œè·ç¦»çš„å¦ä¸€ä¸ªè§‚å¯Ÿï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼Œæœ€é•¿å’Œæœ€è€—æ—¶çš„è®­ç»ƒæ—¥é€šå¸¸å‘ç”Ÿåœ¨å‘¨æ—¥ï¼Œå› ä¸ºè®­ç»ƒçš„æ—¶é—´æ›´é•¿ã€‚

```
runs.groupby('weekday').mean()['moving_time_minutes'].plot.bar()
```

![](img/147b9d64ba0e9024c65afce870f5c69c.png)

æ˜¾ç¤ºä¸€å‘¨ä¸­æ¯å¤©é”»ç‚¼æ—¶é—´çš„å›¾è¡¨ã€‚

```
runs.groupby('weekday').mean()['distance'].plot.bar()
```

![](img/631c616f628a55e26f3f2e6dbfe949a5.png)

æŒ‰ä¸€å‘¨ä¸­çš„æ¯ä¸€å¤©æ˜¾ç¤ºè·ç¦»çš„å›¾è¡¨ã€‚

å…³äºå¹³å‡é€Ÿåº¦(km/h)ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°æ´»åŠ¨æ—¶é—´è¶Šé•¿ï¼Œå¹³å‡é€Ÿåº¦è¶Šä½ï¼Œå› ä¸ºç–²åŠ³ç­‰å› ç´ å¼€å§‹å½±å“è¡¨ç°ï¼Œä½†å½“æˆ‘ä»¬è§‚å¯Ÿå¹³å‡é€Ÿåº¦ä¸è·ç¦»çš„å…³ç³»æ—¶ï¼Œå¯ä»¥è¯´è¿™ç§è¶‹åŠ¿æœ‰æ‰€å¢é•¿ï¼Œå³ä½¿è§„æ¨¡å¾ˆå°ã€‚

```
sns.regplot(x='moving_time_minutes', y = 'avg_speed_kmh', data=runs).set_title("Average Speed vs Moving Time")
```

![](img/07bf293b18528159d8d6750fef03806a.png)

å¹³å‡é€Ÿåº¦å’Œé”»ç‚¼æ—¶é—´ä¹‹é—´çš„å›å½’åˆ†å¸ƒå›¾ã€‚

```
sns.regplot(x='distance', y = 'avg_speed_kmh', data=runs).set_title("Average Speed vs Distance")
```

![](img/58dcd3dab2525ee45d3a99985d1ba692.png)

å¹³å‡é€Ÿåº¦å’Œè·ç¦»ä¹‹é—´çš„å›å½’åˆ†å¸ƒå›¾ã€‚

æœ€åï¼Œåœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼Œå¹³å‡é€Ÿåº¦éšç€æ—¶é—´çš„æ¨ç§»è€Œå¢åŠ ï¼Œè¿™æ˜¯è®­ç»ƒå’Œæ‰€æœ‰è‡´åŠ›äºè¿™é¡¹è¿åŠ¨çš„åŠªåŠ›çš„ç»“æœï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

```
fig = plt.figure()
ax1 = fig.add_subplot(111)

x = np.asarray(runs.start_date)
y = np.asarray(runs.average_speed)

ax1.plot_date(x, y)
ax1.set_title('Average Speed over Time')

x2 = mdates.date2num(x)
z=np.polyfit(x2,y,1)
p=np.poly1d(z)
plt.plot(x,p(x2),'r--')
fig.autofmt_xdate(rotation=45)
fig.tight_layout()
fig.show()
```

![](img/cd9742a5b13862bfb139bd7561534f45.png)

å¤šå¹´å¹³å‡é€Ÿåº¦ä¹‹é—´çš„å›å½’åˆ†å¸ƒå›¾ã€‚

# ç‰¹å¾é€‰æ‹©

è‡³äºç‰¹å¾é€‰æ‹©ï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™æ˜¯åé¢æœºå™¨å­¦ä¹ æ¨¡å‹åº”ç”¨çš„é‡è¦ä¸€æ­¥ã€‚ç»Ÿè®¡æ–¹æ³•å¯ç”¨äºé€‰æ‹©ï¼Œè¿™å°†æ­ç¤ºå¯¹äºæ¨¡å‹çš„è‰¯å¥½æ€§èƒ½æ¥è¯´å“ªäº›æ˜¯æœ€é‡è¦çš„ç‰¹å¾(æˆ–ç‰¹æ€§)ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬ä¹Ÿå°†èƒ½å¤Ÿç¡®è®¤ç»éªŒå¼•ç”¨çš„ç‰¹å¾æ˜¯å¦çœŸçš„å¥½ã€‚

äº†è§£æ›´å¤šå…³äºç‰¹å¾åŠå…¶å¦‚ä½•ä¸å“åº”å˜é‡äº¤äº’çš„ç¬¬ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡ç›¸å…³çŸ©é˜µï¼Œåœ¨ pandas ä¸­ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯ä»¥è½»æ¾è®¿é—®ç›¸å…³çŸ©é˜µã€‚

```
corr = runs.corr()
plt.figure(figsize = (12,8))
sns.heatmap(corr, fmt=".2f");
plt.title('Correlation between dataset variables')
plt.show()
```

![](img/5234ab07bef8ae62f4fb90cc8b09bd30.png)

è¿è¡Œæ•°æ®é›†å˜é‡ä¹‹é—´çš„ç›¸å…³çŸ©é˜µã€‚

æ ¹æ®è¯¥çŸ©é˜µï¼Œå¯ä»¥å®šä¹‰æœ€æ¥è¿‘+1 çš„å€¼å…·æœ‰æ­£ç›¸å…³æ€§ï¼Œæœ€æ¥è¿‘-1 çš„å€¼å…·æœ‰è´Ÿç›¸å…³æ€§ã€‚

ä¸ºäº†ç»§ç»­åˆ†æï¼Œè¿è¡Œçš„æ•°æ®å¸§å°†è¢«æ‰“ä¹±ï¼Œä»è€Œé˜²æ­¢ä¸åå·®å’Œæ•°æ®å¸§åºåˆ—å­¦ä¹ ç›¸å…³çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œåˆ†ç±»ç‰¹å¾ä»¥åŠè¿è¡Œçš„`id`å°†ä»åˆ†æä¸­ç§»é™¤ï¼Œå› ä¸ºè¿™äº›å­—æ®µå¯¹äºæ¨¡å‹è®­ç»ƒæ— æ•ˆï¼Œå¹¶ä¸”è¿™äº›å­—æ®µä¸ä¼šå¯¹é¢„æµ‹æœ‰æ‰€è´¡çŒ®ï¼Œå› ä¸ºå®ƒä»¬æ˜¯åœ¨è¿è¡Œç»“æŸåå½¢æˆçš„ã€‚

```
runs = runs.sample(frac=1).reset_index(drop=True)

categorical_cols = [col for col in runs.columns if runs[col].dtypes == 'O']

useless_vars = ['id', 'achievement_count', 'kudos_count', 'comment_count', 'pr_count']
tweak_runs = runs.drop(categorical_cols+useless_vars, axis=1)
tweak_runs
```

æ­¤æ—¶ï¼Œå“åº”å˜é‡å’Œé‚£äº›å°†ç”¨äºè®­ç»ƒçš„å˜é‡å°†è¢«åˆ†ç¦»ï¼Œå› æ­¤åœ¨æ­¤æ“ä½œä¹‹åï¼Œå¯ä»¥åº”ç”¨ä½¿ç”¨`chi2`(æˆ–å…¶ä»–å•å˜é‡ç»Ÿè®¡æµ‹è¯•)çš„`SelectKBest`æ–¹æ³•æ¥é€‰æ‹©æœ€é‡è¦çš„ K ç‰¹å¾ï¼Œä»¥è·å¾—è‰¯å¥½çš„æ¨¡å‹æ€§èƒ½ã€‚

```
y = tweak_runs['pace']
X = tweak_runs.drop('pace',1)

best_features = SelectKBest(chi2, k=7).fit_transform(X, y.astype(int))
best_features
```

![](img/160ecc5fe9f9ca4dbcc0135889f7c739.png)

ç”± SelectKBest é€‰æ‹©çš„ç‰¹æ€§å€¼ã€‚

ç‰¹å¾é€‰æ‹©çš„å¦ä¸€ç§é€‰æ‹©æ˜¯é€’å½’ç‰¹å¾æ¶ˆé™¤(RFE)çš„åº”ç”¨ï¼Œå®ƒè®­ç»ƒæ‰€é€‰æ‹©çš„æ¨¡å‹ï¼Œå¹¶æ ¹æ®ç‰¹å¾é‡è¦æ€§çš„ç¼ºä¹é€’å½’åœ°æ¶ˆé™¤ç‰¹å¾ã€‚ä½†æ˜¯å¦‚ä¸Šæ‰€è¿°ï¼Œæ­¤æ—¶å¿…é¡»å·²ç»ä¸ºæœ¬æ¬¡è¿è¡Œé€‰æ‹©äº†æ¨¡å‹ï¼Œå› æ­¤æˆ‘ä»¬å°†è¿è¡Œä¸€ä¸ªæ¨¡å‹æ¥æ‰§è¡Œçº¿æ€§å›å½’ï¼Œå¦ä¸€ä¸ªæ¨¡å‹æ¥æ‰§è¡Œéšæœºæ¢¯åº¦ä¸‹é™(SGD ),å› æ­¤è¿™ä¸¤ä¸ªæ¨¡å‹çš„å“åº”å˜é‡æ˜¯ä¸åŒçš„ã€‚

å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒRFE å¯¹äºé«˜ç»´æ•°æ®é›†æ¥è¯´æ˜¯ä¸€ä¸ªæ²‰é‡çš„æ–¹æ³•ï¼Œæ‰€ä»¥ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆæ˜¯ä½¿ç”¨ [SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html) ã€‚ä¸‹é¢æ˜¯æ‰§è¡Œ RFE çš„å‡½æ•°çš„å®šä¹‰ï¼Œä»¥åŠå®ƒåˆ†åˆ«ç”¨äºçº¿æ€§å›å½’å’Œ SGD çš„æƒ…å†µã€‚

```
def get_best_rfe_features(X,y, model):
    rfe = RFE(model, step=0.05).fit(X, y)
    selected_features = [i for i, j in zip(X.columns, rfe.support_) if j]
    return selected_features
```

```
y = tweak_runs['pace']
X = tweak_runs.drop('pace',1)

encoded_y = preprocessing.LabelEncoder().fit_transform(y)
model = LinearRegression()
linear_feats = get_best_rfe_features(X, encoded_y, model)
```

![](img/022f38ed154ae9c726ab2af25e301cd7.png)

ä¸ºå›å½’é€‰æ‹©çš„æœ€ä½³å˜é‡ã€‚

```
y = tweak_runs['pace_sub_5']
X = tweak_runs.drop('pace_sub_5',1)

model = SGDClassifier(loss="hinge", penalty="l2", max_iter=5)
class_feats = get_best_rfe_features(X, y, model)
```

![](img/2df9cd825f41384ad1853439bf8608ef.png)

ä¸ºåˆ†ç±»é€‰æ‹©çš„æœ€ä½³å˜é‡ã€‚

å¯ä»¥åº”ç”¨çš„å…¶ä»–æ–¹æ³•å’Œç»„åˆï¼Œä¾‹å¦‚ï¼Œæ”¹å˜ SGD æ¨¡å‹çš„`loss`æˆ–è€…ç”šè‡³æ”¹å˜ RFE ä¸­çš„`steps`çš„æ•°é‡ï¼Œä½†æ˜¯ç”±äºæœ¬æ–‡çš„ç›®çš„ä¸æ˜¯è¦æ·±å…¥ç ”ç©¶è¿™ç§æ–¹å¼ï¼Œæ‰€ä»¥è¿™äº›æ–¹æ³•çš„ä»‹ç»è¶³ä»¥ä¸ºæˆ‘ä»¬å¸¦æ¥å¥½çš„ç»“æœ

# æœºå™¨å­¦ä¹ 

åœ¨æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨ä¸‰ç§ï¼Œç”¨äºèšç±»ã€å›å½’å’Œåˆ†ç±»ã€‚

## ä½¿èšé›†

åœ¨å¯ä»¥å®ç°çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬æåˆ°ä¸€ç§ç”¨äºæ‰§è¡Œèšç±»çš„æ— ç›‘ç£å­¦ä¹ é¢†åŸŸï¼Œç§°ä¸º K-meansã€‚å› æ­¤ï¼Œåœ¨å®è·µä¸­ï¼Œè¿™ç§æŠ€æœ¯ä¼šå°†ç›¸ä¼¼çš„æ¯”èµ›è®°å½•åˆ†ç»„ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™ç§æ–¹æ³•æ˜¯éšæœºçš„ï¼Œæ‰€ä»¥æ¯æ¬¡æ‰§è¡Œå¯èƒ½ä¼šäº§ç”Ÿä¸åŒçš„ç»“æœã€‚

è¦è¿è¡Œ K-meansï¼Œåªéœ€å°†å“åº”å˜é‡ä¸å…¶ä»–å˜é‡åˆ†å¼€ï¼Œå…¶ä¸­æˆ‘ä»¬å°†ä½¿ç”¨ç†ŠçŒ«å‡½æ•°`get_dummies`æ¥åˆ©ç”¨åˆ†ç±»å˜é‡ï¼Œåˆ†ç±»å˜é‡å°†è¢«è½¬æ¢ä¸ºå…¶ä»–è™šæ‹Ÿå˜é‡ã€‚åˆ†ç¦»å˜é‡åï¼Œåªéœ€é€‰æ‹©èšç±»çš„æ•°é‡ï¼Œç„¶åç»§ç»­è¿›è¡Œ K-means ç±»ï¼Œä»¥åŠç‰¹å¾æ•°æ®é›†ä¸­çš„æ‹Ÿåˆã€‚ä¸ºäº†æ‰¾å‡ºæ¯ä¸ªæ ·æœ¬å±äºå“ªä¸ªåˆ†ç±»ï¼Œæˆ‘ä»¬å°†å¤åˆ¶åŸå§‹è¿è¡Œæ•°æ®é›†ï¼Œå¹¶å‘è®°å½•ä¸­æ·»åŠ ä¸€ä¸ªåˆ†ç±»æ ‡è¯†ç¬¦ã€‚

```
X = runs.drop('pace',1)
X = pd.get_dummies(X)

model = KMeans(n_clusters=4).fit(X)
clusterin_runs = runs.copy()
clusterin_runs['Cluster'] = model.labels_
```

å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æ¯ä¸ªåˆ†ç±»ä¸­çš„è®°å½•æ•°ã€å¹³å‡å€¼ã€æ ‡å‡†åå·®ã€è®°å½•æ•°ç­‰æŒ‡æ ‡ï¼Œå¦‚ä¸‹ä¾‹æ‰€ç¤ºã€‚

```
clustering_runs['Cluster'].value_counts()
```

![](img/690300c81494344ffee114a3f8887a7a.png)

é›†ç¾¤çš„åˆ’åˆ†åŠå…¶å„è‡ªçš„æ•°é‡ã€‚

```
clustering_runs.groupby('Cluster').mean()
```

![](img/a527b1a8e2e25943c4bbe89155d98db3.png)

æ¯ä¸ªèšç±»ä¸­çš„å¹³å‡å€¼ã€‚

```
clustering_runs.groupby('Cluster').std()
```

![](img/d7d80466fcfc696307dd1b2eb116a7a0.png)

æ¯ä¸ªèšç±»ä¸­çš„æ ‡å‡†å·®ã€‚

```
clustering_runs[clustering_runs['Cluster'] == 2]
```

![](img/8ddea21bc4de3d8ff0fc53a1411aa77a.png)

åˆ†ç±» 2 ä¸­çš„è®°å½•ã€‚

## å›å½’

åœ¨è¿›è¡Œå›å½’æ—¶ï¼Œæ¨¡å‹ä¼šåœ¨ç»™å®šä¸€ç»„è¦ç´  x çš„æƒ…å†µä¸‹é¢„æµ‹å€¼ yï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹ä¼šäº†è§£å“ªäº›å€¼æ„æˆäº†çº¿çš„æ–¹ç¨‹ï¼Œä»è€Œè°ƒæ•´è¦ç´ å›¾ä¸­çš„å‡ æ¡çº¿å¹¶è¿”å›ä¸¤ç‚¹ä¹‹é—´è¯¯å·®æœ€å°çš„çº¿ã€‚

å¯¹äºçº¿æ€§å›å½’çš„åº”ç”¨ï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨åœ¨å…ˆå‰é€‰æ‹©ä¸­è·å¾—å¹¶å­˜å‚¨åœ¨`linear_feats`å˜é‡ä¸­çš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸º 80%ç”¨äºè®­ç»ƒé˜¶æ®µï¼Œ20%ç”¨äºæµ‹è¯•é˜¶æ®µï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒé˜¶æ®µä¹‹åæµ‹é‡ç®—æ³•çš„æ€§èƒ½ã€‚

```
y = runs['pace']
X = runs[linear_feats]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

ä¸€æ—¦åˆ’åˆ†å®Œæˆï¼Œåªéœ€å°†è®­ç»ƒæ•°æ®é›†æäº¤ç»™çº¿æ€§å›å½’æ‹Ÿåˆå‡½æ•°ï¼Œå¹¶æ‰§è¡Œä¸æµ‹è¯•åŸºç¡€ç›¸å…³çš„é¢„æµ‹ã€‚

```
model = LinearRegression()
model.fit(X_train,y_train)
y_pred = model.predict(X_test)
```

æœ‰äº†é¢„æµ‹å€¼å’Œå®é™…å€¼ï¼Œå°±å¯ä»¥è®¡ç®—å‡æ–¹è¯¯å·®(MSEï¼Œæˆ–å‡æ–¹è¯¯å·®)æ¥è¯æ˜æ¨¡å‹æœ‰å¤šå¤§çš„è¯¯å·®ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä¸‹é¢çš„ä»£ç ä»¥å›¾å½¢æ–¹å¼æŸ¥çœ‹é¢„æµ‹å€¼ä¸å®é™…å€¼çš„å…³ç³»ã€‚å‡æ–¹è¯¯å·®ä¸º 0.271ã€‚

```
print('MSE:', metrics.mean_squared_error(y_test, y_pred))

plt.figure(figsize=(10,10))
plt.scatter(y_test, y_pred, c='crimson')
plt.yscale('log')
plt.xscale('log')

p1 = max(max(y_pred), max(y_test))
p2 = min(min(y_pred), min(y_test))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()
```

![](img/ffd62357a84f5d68a814ad181cd3daf2.png)

MSE å€¼ä»¥åŠé¢„æµ‹å€¼å’Œå®é™…å€¼åˆ†å¸ƒå›¾ã€‚

ä¸¾ä¾‹æ¥è¯´ï¼Œå‡è®¾æˆ‘åœ¨ 2022 å¹´ä»¥ 1488 ç§’(24.8 åˆ†é’Ÿ)è·‘å®Œ 5 å…¬é‡Œï¼Œå¹³å‡é€Ÿåº¦ä¸º 4 ç±³/ç§’(14.4 å…¬é‡Œ/å°æ—¶)ï¼Œæœ€å¤§é€Ÿåº¦ä¸º 5.6 ç±³/ç§’(20.16 å…¬é‡Œ/å°æ—¶)ï¼ŒèŠ‚å¥ä¸º 84ï¼Œé…é€Ÿä½äº 5ï¼Œæˆ‘çš„é…é€Ÿé¢„è®¡ç­‰äº **4.1752 åˆ†é’Ÿ/å…¬é‡Œ**ã€‚

```
model.predict(
    pd.DataFrame(data={
        'moving_time': 1488,
        'average_speed': 4.0,
        'max_speed': 5.6,
        'average_cadence': 84.0,
        'moving_time_minutes': 24.8,
        'distance_km': 5.0,
        'avg_speed_kmh': 14.4,
        'max_speed_kmh': 20.16 ,
        'year': 2022,
        'pace_sub_5': True},
    index=[0]
    )
)
```

## åˆ†ç±»

åè¿‡æ¥ï¼Œåˆ†ç±»ç”¨äºåŒºåˆ†ç±»åˆ«ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå“åº”å˜é‡å…·æœ‰æ ‡è®°æ ·æœ¬çš„ç‰¹å¾ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æ ¹æ®å…¶ç‰¹å¾æ¥é¢„æµ‹ç»™å®šæ ·æœ¬å°†æ¥å—å“ªä¸ªæ ‡è®°ã€‚

ä¸ºäº†æ‰§è¡Œæ­¤æ“ä½œï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä¸å›å½’é˜¶æ®µç±»ä¼¼çš„æ“ä½œï¼Œå°†åŸºç¡€åˆ†ä¸º 80%ç”¨äºè®­ç»ƒï¼Œ20%ç”¨äºæµ‹è¯•ï¼Œä»¥åŠå…·æœ‰æ¨èç‰¹å¾å’Œå“åº”å˜é‡çš„æ ·æœ¬åˆ’åˆ†ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå“åº”å˜é‡å°†æ˜¯äºŒå…ƒçš„ï¼Œè¡¨ç¤ºæ¯”èµ›é€Ÿåº¦æ˜¯å¦ä½äº 5ã€‚

```
y = runs['pace_sub_5']
X = runs[class_feats]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

åœ¨è¿›è¡Œäº†åŸºåº•çš„åˆ’åˆ†ä¹‹åï¼Œæˆ‘ä»¬å°†æ‹Ÿåˆæ¥è‡ª SKLearn åº“çš„`SGDClassifier`åˆ†ç±»å™¨ï¼Œè¯¥åˆ†ç±»å™¨ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä»¥è¿­ä»£æ–¹å¼è¿›è¡Œå‚æ•°ä¼˜åŒ–æ¥å®ç°çº¿æ€§æ¨¡å‹çš„æ­£åˆ™åŒ–ï¼Œæ—¨åœ¨æœ€å°åŒ–æ„Ÿå…´è¶£çš„å‡½æ•°ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œé¢„æµ‹ä¹Ÿæ˜¯é’ˆå¯¹æµ‹è¯•æ•°æ®é›†æ‰§è¡Œçš„ã€‚

```
model = SGDClassifier()
model.fit(X_train,y_train)
y_pred = model.predict(X_test)
```

ä¸å›å½’ä¸åŒï¼Œå¯¹äºåˆ†ç±»ç³»ç»Ÿï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…¶ä»–æŒ‡æ ‡ï¼Œå¦‚ç²¾åº¦ï¼Œè¿™æ˜¯æ­£ç¡®ç²¾åº¦ä¸æ‰§è¡Œçš„æ€»ç²¾åº¦ä¹‹é—´çš„æ¯”ç‡ï¼Œåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹æ˜¯ 95.12%ã€‚è¦äº†è§£çœŸé˜³æ€§(å®é™…å€¼ä¸ºæ­£ï¼Œé¢„æµ‹ä¸ºæ­£)ã€çœŸé˜´æ€§(å®é™…å€¼ä¸ºè´Ÿï¼Œé¢„æµ‹ä¸ºè´Ÿ)ã€å‡é˜³æ€§(å®é™…å€¼ä¸ºè´Ÿï¼Œé¢„æµ‹ä¸ºæ­£)å’Œå‡é˜´æ€§(å®é™…å€¼ä¸ºæ­£ï¼Œé¢„æµ‹ä¸ºè´Ÿ)ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å‘ä¸€ä¸ªæ··æ·†çŸ©é˜µï¼Œå¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºã€‚

```
print('Accuracy:', accuracy_score(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)

disp.plot()
plt.show()
```

![](img/b13a81723ae75bdd70abbeada9bdb005.png)

ç²¾åº¦å€¼å’Œæ··æ·†çŸ©é˜µã€‚

å› æ­¤ï¼Œä¸ºäº†ä¸¾ä¾‹è¯´æ˜å®é™…æƒ…å†µï¼Œå‡è®¾æˆ‘è·‘ 5000 ç±³ï¼Œæ€»æ´»åŠ¨æ—¶é—´ç­‰äº 1488 ç§’(24.8 åˆ†é’Ÿ)ï¼Œè¿åŠ¨æ—¶é—´ä¸º 1440 ç§’ï¼Œé«˜åº¦å¢ç›Šä¸º 25 ç±³ï¼Œé«˜åº¦å·®ä¸º 10 ç±³(æœ€å¤§é«˜åº¦ä¸º 547 ç±³ï¼Œæœ€å°é«˜åº¦ä¸º 237 ç±³)ï¼Œæœ€å¤§é€Ÿåº¦ä¸º 25 å…¬é‡Œ/å°æ—¶ï¼Œæœ€å¤§é€Ÿåº¦ä¸º 210 bpmï¼Œ**æˆ‘å¯ä»¥ä»¥ä½äº 5 åˆ†é’Ÿ/å…¬é‡Œçš„å¹³å‡é…é€Ÿè¿›è¡Œæ¯”èµ›ã€‚**

```
model.predict(
    pd.DataFrame(data={
        'distance': 5000 ,
        'moving_time': 1440,
        'elapsed_time': 1488,
        'total_elevation_gain': 25,
        'max_heartrate': 210,
        'elev_high': 547,
        'elev_low': 537,
        'moving_time_minutes': 24.8,
        'max_speed_kmh': 25,
        'elev': 10
    },
        index=[0]
    )
)
```

# ç»“è®º

å½“æ•°æ®å­˜åœ¨æ—¶ï¼Œæ¢ç´¢æ•°æ®å’Œåº”ç”¨ä¸åŒç±»å‹çš„æ¨¡å‹çš„å¯èƒ½æ€§æ˜¯æ— æ•°çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæœ‰å¯èƒ½å¯¹å…¶ä¸­ä¸€äº›è¿›è¡Œæµ‹è¯•ï¼Œå¹¶è·å¾—ä¸æ¯”èµ›çš„è§è§£å’Œé¢„æµ‹ç›¸å…³çš„å‡ºè‰²ç»“æœï¼Œéœ€è¦è€ƒè™‘çš„ä¸€ç‚¹æ˜¯ï¼Œæ•°æ®åŸºäºå•ä¸ªè¿åŠ¨å‘˜ï¼Œå³ï¼Œä¸ºäº†ä½¿ç»“è®ºæ›´å…·ä¸€èˆ¬æ€§ï¼Œéœ€è¦ä¸ç»„æˆæ•°æ®é›†çš„è¿åŠ¨å‘˜ç›¸å…³çš„æ›´å¤§çš„å¤šæ ·æ€§ï¼Œä½†æ˜¯ï¼Œå¦‚æœéµå¾ªåˆå§‹æ­¥éª¤ï¼Œæ¯ä¸ªè¿åŠ¨å‘˜éƒ½å¯èƒ½æœ‰ä¸ä»–ä»¬è‡ªå·±çš„æ•°æ®ç›¸å…³çš„é¢„æµ‹å’Œæƒ³æ³•ã€‚

å¦‚æœæ‚¨æƒ³è¦æ£€æŸ¥æ‰€ä½¿ç”¨çš„æµ‹è¯•å’Œä»£ç ï¼Œè¯·éšæ„è®¿é—®ä¸‹é¢çš„å­˜å‚¨åº“:

[](https://github.com/Lucs1590/strava-analysis) [## GitHub-lucs 1590/strava-analysis:ä½¿ç”¨ strava è¿›è¡Œä¸ªäººåˆ†æå¹¶ç»ƒä¹ æ•°æ®â€¦

### ä½¿ç”¨ strava è¿›è¡Œä¸ªäººåˆ†æå¹¶ç»ƒä¹ æ•°æ®ç§‘å­¦å®¶æŠ€èƒ½ã€‚æ›´æ–°ç¯å¢ƒä¸Šçš„ strava ä»£ç ã€‚è¿è¡Œâ€¦

github.com](https://github.com/Lucs1590/strava-analysis) 

# å‚è€ƒ

[1]æ‹‰é©¬ä¸ï¼ŒS. [çº¿æ€§å›å½’ç ”ç©¶:æ¦‚å¿µä¸åº”ç”¨](https://medium.com/@lamartine_sl/regress%C3%A3o-linear-com-sklearn-modelo-de-previs%C3%A3o-de-custos-com-plano-de-sa%C3%BAde-5e963e590f4c) (2020)ã€‚ä¸­ç­‰ã€‚

[2] Stojiljkoviï¼ŒM. [ç”¨ Python å’Œ NumPy å®ç°çš„éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•](https://realpython.com/gradient-descent-algorithm-python/) (2020)ï¼ŒReal Pythonã€‚

[3] Vasconcellosï¼Œp .[Como sele cionar as melhores features para seu modelo de Machine Learning](https://paulovasconcellos.com.br/como-selecionar-as-melhores-features-para-seu-modelo-de-machine-learning-2e9df83d062a)(2019)ï¼ŒPaulo Vasconcellos-Cientista de Dados Brasileiroï¼Œ

# åˆ†çº§ç¼–ç 

æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:

*   ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰
*   ğŸ“°æŸ¥çœ‹[å‡çº§ç¼–ç å‡ºç‰ˆç‰©](https://levelup.gitconnected.com/?utm_source=pub&utm_medium=post)ä¸­çš„æ›´å¤šå†…å®¹
*   ğŸ””å…³æ³¨æˆ‘ä»¬:[Twitter](https://twitter.com/gitconnected)|[LinkedIn](https://www.linkedin.com/company/gitconnected)|[æ—¶äº‹é€šè®¯](https://newsletter.levelup.dev)

ğŸš€ğŸ‘‰ [**åŠ å…¥å‡çº§äººæ‰é›†ä½“ï¼Œæ‰¾åˆ°ä¸€ä»½ç¥å¥‡çš„å·¥ä½œ**](https://jobs.levelup.dev/talent/welcome?referral=true)