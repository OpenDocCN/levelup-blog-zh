# 一致散列法

> 原文：<https://levelup.gitconnected.com/consistent-hashing-27636286a8a9>

一致散列是一种散列技术，当在分布式系统频繁伸缩的动态环境中运行时，它表现得非常好。一致性散列的核心概念在论文[Consistent Hashing and random trees:Distributed Caching Protocols for relief the Hot spot on the World Wide Web](https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)中介绍，但它在著名的论文 DynamoDB — [Dynamo: Amazon 的高度可用的键值存储](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)之后变得流行起来。

从那以后，一致散列法获得了发展，并在有效设计和扩展分布式系统中找到了大量的用例。彻底使用这种技术的两个著名例子是 Bit Torrent，用于他们的对等网络，以及 Akamai，用于他们的 web 缓存。在这篇文章中，我们深入探讨了一致性散列的需求，它的内部机制，更重要的是使用数组和二分搜索法来实现它。

# 哈希函数

在我们进入核心一致散列技术之前，我们首先需要弄清楚一些事情，其中之一是散列函数。散列函数是将值从任意大小的域映射到另一个固定大小的域(通常称为散列空间)的任何函数。例如，将 URL 映射到 32 位整数，或者将网页的 HTML 内容映射到 256 字节的字符串。作为这些散列函数的输出而生成的值通常被用作密钥，以实现对原始实体的高效查找。

简单散列函数的一个例子是将 32 位整数映射到 8 位整数散列空间的函数。该函数可以使用算术运算符`modulo`来实现，我们可以通过取一个`modulo 256`来实现，它产生在`[0, 255]`范围内的数，用 8 位来表示。将关键字映射到这种整数域的散列函数通常会应用`modulo N`，以便将值或散列空间限制到一个范围`[0, N-1]`。

一个好的哈希函数具有以下属性

*   该函数计算效率高，生成的值易于查找
*   对于大多数一般用例，该函数的行为类似于一个伪随机生成器，它将数据均匀地展开，没有任何明显的相关性

现在我们已经了解了什么是散列函数，我们来看看如何使用它们来构建一个可伸缩的分布式系统。

# 构建分布式存储系统

假设我们正在构建一个分布式存储系统，用户可以上传文件并按需访问。该服务向用户公开以下 API

*   `upload`上传文件
*   `fetch`获取文件并返回其内容

在后台，系统有存储节点，在这些节点上存储和访问文件。这些节点公开了函数`put_file`和`fetch_file`，它们将文件内容放入磁盘或从磁盘获取文件内容，并将响应发送给主 API 服务器，主 API 服务器再将响应发送回用户。

为了维持初始负载，系统有 5 个存储节点，以分布式方式存储上传的文件。拥有多个节点可以确保系统作为一个整体不会不堪重负，并且存储几乎均匀地分布在。

当用户使用文件的路径调用`upload`函数时，系统首先需要识别将负责保存文件的存储节点，我们通过对路径应用散列函数来实现这一点，进而获得存储节点索引。一旦我们获得了存储节点，我们就读取文件的内容，并通过调用节点的`put_file`函数将该文件放在节点上。

![](img/3e8069e5abe5d08f1544ef541a96ac67.png)

这里使用的哈希函数只是简单地将字节相加，并通过`5`取模(因为系统中有 5 个存储节点)，从而在哈希空间中生成输出`[0, 4]`。该输出值现在表示将负责保存文件的存储引擎的索引。

假设我们有 5 个文件‘f1 . txt’，‘F2 . txt’，‘F3 . txt’，‘F4 . txt’，‘F5 . txt’，如果我们对这些文件应用哈希函数，我们会发现它们分别存储在存储节点 E、A、B、C 和 D 上。

当系统获得一些牵引力，需要扩展到 7 个节点时，事情就变得有趣了，这意味着现在散列函数应该做`mod 7`而不是`mod 5`。更改哈希函数意味着更改文件与存储节点的映射和关联。我们首先需要管理新的关联，并查看哪些文件需要从一个节点移动到另一个节点。

使用新的哈希函数，相同的 5 个文件“f1.txt”、“f2.txt”、“f3.txt”、“f4.txt”、“f5.txt”现在将与存储节点 D、E、F、G、a 相关联。在这里我们可以看到，更改哈希函数需要我们将 5 个文件中的每一个文件都移动到不同的节点。

![](img/43786755c659cd15a21e5dc2064531e7.png)

如果我们每次扩大或缩小规模时都必须更改哈希函数，并且如果这要求我们移动的不是所有数据，而是一半的数据，那么该过程将变得非常昂贵，并且从长远来看是不可行的。因此，我们需要一种方法来最大限度地减少纵向扩展或横向扩展过程中所需的数据移动，这就是一致性哈希的用武之地，它可以最大限度地减少所需的数据传输。

# 一致散列法

上述系统的主要痛点是，它容易发生像扩大规模和缩小规模这样的事件，因为它需要大量的关联变更。这些关联完全由底层哈希函数驱动，因此，如果我们能够以某种方式使哈希函数独立于系统中的存储节点数量，我们就可以解决这个缺陷。

一致哈希通过保持哈希空间巨大且恒定来解决这种情况，大约在`[0, 2^128 - 1]`的位置，存储节点和对象都映射到这个巨大哈希空间中的一个槽。在传统系统中，文件与存储节点在它被散列到的索引处相关联，与此不同，在此系统中，文件与存储节点之间发生冲突的可能性极小，因此我们需要一种不同的方式来定义这种关联。

我们没有使用基于冲突的方法，而是将关联定义为—文件将与其哈希位置右侧的存储节点相关联。这样定义关联有助于我们

*   保持哈希函数独立于存储节点的数量
*   保持关联的相对性，不受绝对冲突的驱动

![](img/521b31dc30314413a09f7da5513fee58.png)

> *在规模扩大和缩小期间，平均而言，一致性散列只需要迁移 k/n 个数据单元；其中 k 是键的总数，n 是系统中节点的数量。*

实现这一点的一个非常简单的方法是分配一个大小等于哈希空间的数组，并将文件和存储节点放在数组中的哈希位置。为了获得关联，我们从该项的散列位置向右迭代，找到第一个存储节点。如果我们到达数组的末尾，但没有找到任何存储节点，我们将返回到索引 0 并继续搜索。这种方法很容易实现，但是受到以下限制

*   需要巨大的内存来容纳如此大的数组
*   每次向右迭代寻找关联是`O(hash_space)`

更好的实现方式是使用两个数组:一个保存存储节点，称为`nodes`，另一个保存存储节点在哈希空间中的位置，称为`keys`。这两个数组之间是一一对应的——存储节点`nodes[i]`位于哈希空间中的位置`keys[i]`。两个数组都按照`keys`数组排序。

# 一致性哈希中的哈希函数

我们将`total_slots`定义为整个哈希空间的大小，通常为`2^256`的数量级，哈希函数可以通过采用 [SHA-256](https://en.wikipedia.org/wiki/SHA-2) 后跟`mod total_slots`来实现。由于`total_slots`很大，并且是一个常数，因此下面的哈希函数实现与系统中存在的存储节点的实际数量无关，因此不受规模扩大和缩小等事件的影响。

![](img/ac626c8d65d310c92bd5f81a675cd7d8.png)

# 在系统中添加新节点

当需要纵向扩展并在系统中添加新节点(在我们的示例中是新的存储节点)时，我们

*   找到节点在散列空间中的位置
*   用它应该服务的数据填充新节点
*   在散列空间中添加节点

当新节点被添加到系统中时，它只影响在新节点将适合的位置的左边的位置散列的并且与右边的节点相关联的文件。所有其他文件和关联不受影响，从而最大限度地减少了要迁移的数据量和需要更改的映射。

![](img/ae58f4a439058f5420d96ea608e44fee.png)

从上面的图示中，我们可以看到，当在节点 B 和 E 之间添加新的节点 K 时，我们改变了段 B-K 中存在的文件的关联，并将它们分配给节点 K。属于段 B-K 的数据可以在它们先前关联的节点 E 上找到。因此，唯一受影响且需要迁移的文件在段 B-K 中；并且它们的关联从节点 E 到节点 k 变化

为了使用`nodes`和`keys`数组在底层实现这一点，我们首先使用哈希函数获得新节点在哈希空间中的位置。然后，我们使用二分搜索法找到比排序后的`keys`数组中的位置大的最小键的索引。该索引将是键和新存储节点分别被放置在`keys`和`nodes`数组中的位置。

![](img/25d7b9ea60de86c7a67954a259e46bf0.png)

# 从系统中删除新节点

当需要缩小规模并从系统中删除现有节点时，我们

*   找到要从哈希空间中移除的节点的位置
*   用与要删除的节点相关联的数据填充右侧的节点
*   从哈希空间中删除节点

当从系统中删除一个节点时，它只影响与该节点本身相关联的文件。所有其他文件和关联不受影响，从而最大限度地减少了要迁移的数据量和需要更改的映射。

![](img/4aa7a182f15da65115d244888ae22b2b.png)

从上图中我们可以看到，当从系统中删除节点 K 时，我们将与节点 K 关联的文件的关联更改为位于其右侧的节点，即节点 e。因此，只有与节点 K 关联的文件才会受到影响并需要迁移

为了使用`nodes`和`keys`数组在底层实现这一点，我们使用二分搜索法得到节点 K 在`keys`数组中的位置索引。一旦有了索引，我们就从该索引上的`keys`阵列中删除键，从`nodes`阵列中删除存储节点。

![](img/e82a477524c262af349c0fb4ca10175f.png)

# 将项目与节点相关联

现在，我们已经看到了一致散列如何有助于在规模扩大和缩小期间将数据迁移保持在最低限度；是时候看看如何高效地找到给定项目的“右侧节点”了。寻找关联的操作必须超级快速和高效，因为它将被系统上发生的每一次读取和写入调用。

为了在底层实现这一点，我们再次利用二分搜索法并在`O(log(n))`中执行该操作。我们首先将该项传递给散列函数，并获取该项在散列空间中被散列的位置。然后在`keys`数组中对该位置进行二进制搜索，以获得大于该位置的第一个键的索引(从哈希函数中获得)。如果在`keys`数组中没有大于位置的键，我们返回第 0 个索引。由此获得的索引将是与该项目相关联的`nodes`数组中的存储节点的索引。

![](img/e76d54714cb23ac09e9e13e9f0b9bea2.png)

用 Python 实现一致散列的源代码可以在[github.com/arpitbbhayani/consistent-hashing](https://github.com/arpitbbhayani/consistent-hashing/blob/master/consistent-hashing.ipynb)找到。

# 结论

一致散列是帮助我们横向扩展和管理任何分布式系统的最重要的算法之一。该算法不仅适用于分片系统，还可应用于负载平衡、数据分区、管理基于服务器的粘性会话、路由算法等等。许多数据库的规模、性能和处理海量负载的能力都归功于一致性散列。

# 参考

*   [哈希函数—维基百科](https://en.wikipedia.org/wiki/Hash_function)
*   [一致散列法——维基百科](https://en.wikipedia.org/wiki/Consistent_hashing)
*   [一致散列法—斯坦福](https://web.stanford.edu/class/cs168/l/l1.pdf)
*   [一致散列和随机树](https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)
*   [迪纳摩:亚马逊的高可用性键值存储](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)

# 你可能喜欢的其他文章

*   [Python 缓存整数](https://arpitbhayani.me/blogs/python-caches-integers)
*   [分数级联—加速二进制搜索](https://arpitbhayani.me/blogs/fractional-cascading)
*   [写时复制语义](https://arpitbhayani.me/blogs/copy-on-write)
*   [什么使得 MySQL LRU 缓存能够抵抗扫描](https://arpitbhayani.me/blogs/mysql-cache)
*   [用 Python 协程构建有限状态机](https://arpitbhayani.me/blogs/fsm)

*如果你喜欢你所读到的，传播一个关于这份简讯的消息，给我大声喊出来*[*@ arpit _ bhayani*](https://twitter.com/arpit_bhayani)*。*