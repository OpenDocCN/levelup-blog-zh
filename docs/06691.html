<html>
<head>
<title>Tweet Analysis for COVID-19 Fake News Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微博分析在新冠肺炎假新闻检测中的应用</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/tweet-analysis-for-covid-19-fake-news-detection-bf7cbea5c12d?source=collection_archive---------5-----------------------#2020-12-20">https://levelup.gitconnected.com/tweet-analysis-for-covid-19-fake-news-detection-bf7cbea5c12d?source=collection_archive---------5-----------------------#2020-12-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="aa3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假新闻绝不是一个陌生的概念；自从人类学会交流以来，它就一直存在。但互联网和社交媒体的发明给它增加了另一个维度，使它比以往任何时候都更加突出和有影响力。其影响力的一个例子可以在新冠肺炎疫情事件之后爆发的假新闻以及由此发生的事件中找到。世界停止了，几代人以来，人们第一次在家里，互联网成为他们的主要信息来源，这是一个它还没有准备好的责任。互联网上充斥着关于封锁、潜在治疗和医院床位的错误信息。这些帖子弊大于利，并试图在全球范围内制造集体恐慌。</p><p id="a63a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Twitter是一个广泛使用的社交媒体平台，因此在假新闻爆发中发挥了重要作用。下面这篇文章比较了在新冠肺炎疫情期间Twitter上区分“假”新闻和真新闻的各种分类技术。</p><h1 id="b70a" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">推文分析和预处理</strong></h1><p id="cd57" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">数据集包括6，420条带有标注标签的训练数据和2，140条测试数据。数据集在两个班级中几乎平分秋色，没有观察到班级不平衡。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/3dfcb6ff74ba6a43c341dbc9142e2eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*EpTs24TcYMxyty3Xu4zlBw.png"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">针对训练数据集的类标签绘制计数图</figcaption></figure><p id="ac17" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对数据集中的词频进行了分析，观察到“真”和“假”标签有一组特定的词，而几个词在两个类别之间是共享的。得出的结论是，这些常用词对分类结果没有意义。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ma"><img src="../Images/ab9c909b7e9ec1d30ea0645446883f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ovOozML4-qYRhbdv3Emdw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">集合数据和“真”与“假”标签的词云</figcaption></figure><p id="c0e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">据观察，像“冠状病毒”、“covid”、“covid19”、“新”、“人”、“死亡”、“国家”和“一个”这样的词在两个标签中都很常见，因此它们与停用词、生僻词、标点符号和超链接一起从数据集中删除。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mf"><img src="../Images/2abf973093db680cf5870d4500a31349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ah9HNIj9pqb7iJL8fnhGoQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">预处理步骤</figcaption></figure><h1 id="a83d" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">基线模型性能</h1><p id="16d1" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">从数据集中清理出来的推文被标记化，并在计数矢量化后输入基线分类模型。据观察，被动-主动分类器的性能优于任何其他分类模型，SVM紧随其后。</p><p id="418c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基线分类的结果如下:<br/> 1 .被动-攻击性量词- 94.39% <br/> 2。SVM- 94.31% <br/> 3。Logistic回归- 92.24% <br/> 4。天真巴爷的- 91.92% <br/> 5。决策树- 85.03% <br/> 6。KNN- 69.26%</p><p id="a665" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">观察到最大准确度为94.39%，并且可以得出结论，当使用像被动-主动分类器这样的健壮分类器时，计数矢量化本身对于自然语言处理来说是非常重要的。</p><h1 id="6e94" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">深度学习模型:RNN和伯特</h1><p id="f0b7" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">与基线机器学习模型一起，为推文分类构建了三个深度学习。这三种架构包括具有手套嵌入的RNN模型、具有可训练嵌入层的LSTM RNN模型以及微调预训练的伯特模型。</p><p id="e91a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具有手套嵌入的RNN使用大小为50的嵌入向量，并将每个tweet转换成一组手套向量。这些向量然后被输入到RNN模型中，该模型被训练20个时期以避免过度拟合。该模型显示了88.27%的准确率，并且比决策树和KNN等分类器表现得更好，但是与其他基线模型相比失败了。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/ce2c58ba5e262e632da85ef1a817a487.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*rEFxY05w57z7pOwudTydUQ.jpeg"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">带手套RNN的精确v/s历元</figcaption></figure><p id="dfe4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具有可训练嵌入的RNN模型有一个额外的嵌入层，将单词转换成大小为64的向量。该模型的其余架构与嵌入手套的架构相似。它由两个双向LSTM层和两个密集层组成，其中一个作为最终层的输出维度。具有可训练嵌入的RNN显示出91.88%的准确度，并且优于手套模型3.61%，这无疑是一个改进，但是仍然低于基线。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mh"><img src="../Images/bc38af8743ceabcbacaf1741fa0e0e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W3N14hvxH2LSi6ekSYlCdw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">使用可训练嵌入来训练和测试RNN性能</figcaption></figure><p id="7d5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">BERT是一个预先训练的强大的NLP模型，可以通过在现有模型上添加分类架构来针对文本分类进行微调。在预训练的BERT模型上添加了一个两层分类架构，该模型可通过拥抱人脸库进行推文分类。正如预期的那样，BERT模型以97.39%的准确率优于所有基线模型。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mi"><img src="../Images/e31ba46de4e58033b777de0f78816b4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sSuzfcJkhrI-5bHb9ITgiw.jpeg"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk translated">BERT验证精度v/s历元</figcaption></figure><h1 id="54bd" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结论</h1><p id="0ab6" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">使用六个基线机器学习模型和三个深度学习模型，将推文数据分类为“真实”和“虚假”新闻。据观察，一些稳健的基线模型，如被动-积极分类器，SVM和逻辑回归优于这两个RNN模型。另一个重要的观察结果是，具有可训练嵌入的RNN优于具有手套嵌入的，这表明使嵌入适合手头的问题在NLP分类中确实起着重要的作用。<br/>另一方面，像BERT这样的预训练模型，经过微调以适应特定的数据集，表现优于所有其他模型。因此，可以得出结论，BERT是迄今为止新冠肺炎假新闻检测的最佳模型，准确率为97.39%。</p></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="17b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该项目由<a class="ae mq" href="https://www.linkedin.com/in/srishtisahni/" rel="noopener ugc nofollow" target="_blank"> Srishti Sahni </a>、<a class="ae mq" href="https://www.linkedin.com/in/atul-rawat-iiitd" rel="noopener ugc nofollow" target="_blank"> Atul Rawat </a>和<a class="ae mq" href="https://www.linkedin.com/in/vijayponnganti" rel="noopener ugc nofollow" target="_blank"> Vijay Ponnaganti </a>在我们的教授<a class="ae mq" href="https://www.linkedin.com/in/tanmoy-chakraborty-89553324/" rel="noopener ugc nofollow" target="_blank"> Tanmoy Chakraborty </a> <br/> 1的指导下共同完成。Srishti Sahni和Atul Rawat进行了探索性数据分析并对数据进行了预处理。<br/> 2。Vijay Ponnaganti、Atul Rawat和Srishti Sahni构建了用于分类的基线机器学习模型。<br/> 3。Vijay Ponnaganti创造了嵌入手套的RNN模型<br/> 4。Srishti Sahni创建了具有可训练嵌入的RNN模型，以及<br/> 5。阿图尔·拉瓦特对伯特模型进行了微调</p></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="bbb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该项目是提交给<a class="ae mq" href="https://constraint-shared-task-2021.github.io" rel="noopener ugc nofollow" target="_blank">CONSTRAINT’21</a>workshop shared challenge的。数据集的链接可在<a class="ae mq" href="https://competitions.codalab.org/competitions/26655" rel="noopener ugc nofollow" target="_blank"> CodaLab </a>的竞赛页面上找到。</p></div></div>    
</body>
</html>