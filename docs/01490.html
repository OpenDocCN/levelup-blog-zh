<html>
<head>
<title>Machine Learning — Nearest Neighbours Algorithm with Code Walkthrough</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习——带代码遍历的最近邻算法</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/machine-learning-nearest-neighbours-algorithm-with-code-walkthrough-d7fc05cdd698?source=collection_archive---------1-----------------------#2020-01-07">https://levelup.gitconnected.com/machine-learning-nearest-neighbours-algorithm-with-code-walkthrough-d7fc05cdd698?source=collection_archive---------1-----------------------#2020-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/654432a94e4dc8d59862a30198ae85b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OuUNfLrEnK0tPiJW"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">机器学习中的一些关键概念</figcaption></figure><p id="705d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">“最近邻”算法是数学上最容易理解的机器学习算法之一。尽管它很简单，但算法相当精确，基于它的模型通常会产生最佳结果。</p><p id="ccc9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">通过使用该算法来执行数据分类，可以更好地理解该算法。在给定我们需要确定预测标签(类别)的数据点的情况下，使用这种基本的机器学习算法，我们将找到与所讨论的数据点最接近的数据点，并假设我们的数据点的标签与其最接近的数据点的标签相匹配。</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ld"><img src="../Images/0b61f309769b956fb231b1138a0cf993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wjJp96mFjdYBB_7_"/></div></div></figure><p id="e3d0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">考虑旁边图表中的例子。我们得到一组红色或蓝色的点。这些都是根据一些参数绘制在图上的。现在，我们得到一个新点(用绿色标出)，并被要求预测它应该是红色还是蓝色。在最近邻(NN)算法中，我们首先基于我们用于绘制早期点的相同参数在图上绘制绿点，然后我们搜索与所讨论的点最近的点。在这种情况下，坐标为(2，2)的红点最接近绿点。因为最近的点是红色的，我们预测这个新点也将是红色的。</p><p id="da9b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这样一个简单的图表上，距离公式可以用来计算距离，以找到最近的点，即“最近的邻居”。</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi li"><img src="../Images/e0e7d5d41fed9aeea83ce9ca907ab48f.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*RDQsp7_ZqzWi0TlR8kqHrg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk translated">距离公式的数学表示(二维)</figcaption></figure><p id="f2f8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当我们实际编码时，我们使用numpy.linalg.norm()函数(在Python中)来计算数据点之间的距离，它使用欧几里得距离，这是任意两点之间“直线距离”的度量。在这种情况下，测量任何数据点和我们图上的问题点之间的垂直距离。</p><p id="2745" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">理解了最近邻算法之后，现在让我们检查它在数据分类中的应用</p><h1 id="d48c" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">伪代码:</strong></h1><p id="8dfb" class="pw-post-body-paragraph kf kg it kh b ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky ml la lb lc im bi translated">对于测试数据中的每个点:</p><p id="ffc0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第一步:<em class="mm">计算所有其他点的距离。</em></p><p id="c82c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第二步:<em class="mm">找到距离最小的数据点</em></p><p id="7b8f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第三步:<em class="mm">找到这个最近点的正确标签，用相同的标签</em>对有问题的点进行分类。</p><h1 id="0c01" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">代码</strong></h1><p id="a4ce" class="pw-post-body-paragraph kf kg it kh b ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky ml la lb lc im bi translated">出于本教程的目的，我选择使用MNIST数据集来执行图像分类:一组手写数字的图像。</p><p id="1cff" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了构建这个分类模型，我们必须做的第一件事是导入必要的库，即:</p><ol class=""><li id="9c9c" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm"> numpy </em>:处理向量、数组和矩阵</li><li id="5163" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> matplotlib.pyplot </em>:绘制图形，查看图像等。</li><li id="737a" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated">keras库包含许多数据集，我们将从这个库中导入MNIST数据集，用作我们的训练数据。</li></ol><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/390145d825fd3976b68ae576a77990b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/0*qQMnlNc4ws2PwizN"/></div></figure><p id="5f4d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们必须从互联网上下载MNIST数据集。这个数据集已经被分成两部分——60，000个训练图像和另外10，000个测试图像。我们现在必须存储训练和测试图像以及它们各自的标签。</p><p id="cce9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们使用以下四个numpy数组来存储数据:</p><ol class=""><li id="3286" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm"> x_train </em>:存储训练图像</li><li id="a8ca" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> y_train </em>:存储训练图像的标签</li><li id="1316" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> x_test </em>:存储测试图像</li><li id="f097" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> y_test </em>:存储测试数据的正确标签</li></ol><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/adf5cdd4ac2609e9b4ff0ed6dccd2f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DcNhjlgksbuZOS_q"/></div></div></figure><p id="7b92" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这些图像目前是rgb格式，但是对于识别所画的数字来说，数字的颜色并不重要。因此，为了使计算更容易，我们将把图像中当前处于0到255 [0，255]范围内的颜色转换为0到1 [0，1]范围内的颜色。这是通过将像素值除以255来实现的。</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/1b4397040116e20f4246e8d687343f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zEO2NAsSXx3hW-st"/></div></div></figure><p id="316a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上面的代码中可以看到的另一个步骤是将out标签从整数格式转换成一种称为“<strong class="kh iu"> one-hot vectors </strong>”的格式。当我们的标签是0和1的二进制形式时，计算速度会更快，而不是像0，1，2，…，8，9这样的整数标签。因此，我们创建了一个零向量，它在正确标签的索引处有一个“一”(1)。例如，如果我们有三个类(0、1和2)，我们想把“1”变成一个热向量，我们会有[0，1，0]。如果我们想把“0”变成一个热向量，我们会有[1，0，0]。如果我们有10个标签为0–9的类(MNIST数据集就是这种情况)，并且我们想将“9”转换为一个热向量，我们将得到[0，0，0，0，0，0，0，0，1]。</p><p id="6996" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来我们要做的是定义一个函数，它将向我们显示一个图像及其相应的标签。这对于实际的机器学习算法来说并不重要，但它将帮助我们可视化我们的图像。</p><p id="2177" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们定义了一个名为“<em class="mm"> imshow </em>”的函数。该功能的目的是接收图像，然后:</p><ol class=""><li id="8c99" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm">可视化图像</em>:这将通过使用matplotlib库创建一个图来完成</li><li id="d030" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm">重塑我们的矢量</em>回到28x28图像的形式:在我们的数据集中，所有的图像都已经是28x28像素的格式，但是我们已经重塑了它们，以便应用颜色转换。因此，我们必须将它们改回28x28的格式。在其他数据集中，由于所有影像的尺寸可能不同，因此最好将所有影像的尺寸调整为一致的尺寸，以确保影像尺寸的差异不会以任何方式影响分类。</li></ol><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/4ae994bfd93de464800c1ff5192b96fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nvZUnl7WOhE-RqPk"/></div></div></figure><p id="5bae" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，我们将编写几行代码，从我们的训练集中为一幅图像选择一个随机索引，并将对它使用我们的"<em class="mm"> imshow" </em>函数，以查看我们的显示函数是否工作正常。然后，我们将打印出正确的标签，这样我们就知道图像中画的是哪个数字。</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ne"><img src="../Images/420533c4a96de34379e9f96c648e70ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GSSi0ok6jX-O793E"/></div></div></figure><p id="3815" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们将定义一个函数"<em class="mm">getnearestneighborhood</em>"来返回训练集中最近点的索引以及testInstance与该点之间的距离。</p><p id="2aff" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该函数的参数是:</p><ol class=""><li id="afff" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm"> trainingSet: </em>这是一个n x d (n乘d)的数组，其中n是图像的数量，d = 784 (28x28=784)。</li><li id="ed05" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm">测试实例</em>:这是我们的一张图片(以784维向量的形式)</li></ol><p id="1207" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了使我们的功能能够使用上述参数执行上述任务，我们必须遵循以下步骤:</p><ol class=""><li id="45d0" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm">形成我们的图像和每个其他训练图像之间的距离的数组:</em>我们将使用预定义的函数‘linalg . norm’来计算这个距离。当我们调用' linalg.norm '函数时，我们将指定axis = 1。这是为了让函数分别考虑我们的每个图像</li><li id="aef9" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm">找到离我们最近的点的索引:</em>函数‘arg min’将用于返回“距离”中最小值的索引。</li><li id="8187" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm">获取离我们最近的点与我们的点之间的距离以及这个最近点的索引</em>。这很容易，因为所有的距离都存储在“距离”中，我们将最近点的索引存储在变量“nn_index”中。</li></ol><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/134da426afa68f382ed7216aa926b8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vGrAQ-S-eRk67gGh"/></div></div></figure><p id="cacf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最近邻方法是最简单的机器学习模型之一，因此需要非常少量的代码。我们现在要做的就是决定用于训练和测试我们的模型的图像数量，从而评估它的准确性。</p><ol class=""><li id="3f0f" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm"> num_train </em>:存储我们在训练模型时想要使用的图像数量(在我们的训练数据集中)</li><li id="e46c" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> num_test </em>:存储我们想要测试我们的模型的图像的数量(在我们的测试数据集中)(我们想要测试我们的模型的多少图像来检查它的准确性)</li></ol><p id="14cc" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我还编写了一些代码来计算模型的准确性。该代码片段中的主要变量是:</p><ol class=""><li id="03d2" class="mn mo it kh b ki kj km kn kq mp ku mq ky mr lc ms mt mu mv bi translated"><em class="mm"> correct_count </em>:当我们预测测试数据集中图像的标签时，这个变量存储了正确预测的数量。</li><li id="5a39" class="mn mo it kh b ki mw km mx kq my ku mz ky na lc ms mt mu mv bi translated"><em class="mm"> ind </em>:用于从我们的测试数据集中挑选一个随机图像，然后可视化它。我们还将可视化我们的模型识别为该图像的“最近邻居”的图像。</li></ol><figure class="le lf lg lh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/a496d80c2c0532f64f46d1883086546d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kzrqJvmiT_OjjmGy"/></div></div></figure><p id="eafb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">因此，尽管事实上“最近邻”是一个如此简单和基本的机器学习算法，但当用于分类手写数字时，它具有合理的准确度。同样值得注意的是，在给定的超参数设置下，精确度达到了87.3%。您可以随时查看我的Colab文档(本文末尾的链接),使用这些代码调整这些值并进一步提高精确度(在这种情况下，仅有的超参数是测试数据和训练数据中的图像数量，因此可以进行的更改非常有限，但在更高级的算法中，有更多突出的超参数是算法本身的直接部分， 而在这些情况下，寻找超参数值的最优集合，虽然繁琐耗时，但对模型的精度和整体性能有很大的影响)。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="3a0c" class="lj lk it bd ll lm no lo lp lq np ls lt lu nq lw lx ly nr ma mb mc ns me mf mg bi translated"><strong class="ak"> KNN (K个最近邻居)</strong></h1><p id="7583" class="pw-post-body-paragraph kf kg it kh b ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky ml la lb lc im bi translated">k-最近邻，通常称为KNN，是最近邻算法的一种变体，在大多数情况下有助于提高准确性。它基于与“最近的邻居”相同的原理，除了它寻找K个最近的邻居，而不仅仅是最近的点(它寻找最近的K个点，而不仅仅是最近的点)。因此，由于减少了数据中异常值和不确定边界的影响，准确性得到了提高。</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/eb311a048a7c45b618fab3676a593fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/0*17czwnifxKacTRpC"/></div></figure><p id="0cac" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上图中，假设蓝色和红色点在训练数据中，现在，我们必须将绿色点分类为红色或蓝色。如果我们使用K-最近邻的概念，K=2，那么离绿色最近的两个点都是蓝色的，这表明我们的预测应该是这个新点是蓝色的。</p><p id="ea35" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">还可能存在这样的情况，其中两个最接近的点是这样的，一个是红色的，一个是蓝色的。在这种情况下，我喜欢做的是寻找下一个最接近的点作为“决胜局”。如果下一个最接近的点是红色的，那么我们将绿点归类为红色，如果下一个最接近的点是蓝色的，那么我们将绿点归类为蓝色。下图展示了一个相同的示例:</p><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/334e0e72e62cc70f919b39ad9ae839a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/0*TEj6JX-hvrwokt-g"/></div></figure><p id="5e4e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里，最接近的两个点是(2，2)处的红点和(1，1)处的蓝点。由于这是一个相等的数字，我们取下一个最接近的点，也就是(2.2，2.2)处的红点。因此，我们将这个绿点归类为红色。</p><p id="c9df" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了避免这种“平局决胜问题”,我通常喜欢为K保留一个奇数值。在这种情况下(K有一个奇数值),我们就按照它进行预测。</p><p id="aaab" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">KNN算法的代码与我之前解释的最近邻的代码非常相似，因此尝试修改该代码以使其适用于“K个最近点”将是一个很好的练习。</p><p id="c049" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">要查看最近邻居模型的可执行教程，您可以在其中与代码进行交互并修改代码，请查看我网站上的colab笔记本:</p><div class="nv nw gp gr nx ny"><a href="https://colab.research.google.com/drive/1Z-ae-manV0-c0uai_SBmgURfYALof4lB" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">Karan Kashyap的最近邻居教程:谷歌合作实验室</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">这是一个Colab笔记本，上面有我在上面的文章中解释过的所有代码。您可以到笔记本上编辑代码，以便更好地理解它是如何工作的。可以尝试的几件事是:1)更改超参数的值以提高模型精度，2)编辑代码以将其从神经网络模型转换为KNN模型。</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">colab.research.google.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om jz ny"/></div></div></a></div></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="7c0f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你也可以在这里查看我的其他文章:</p><div class="nv nw gp gr nx ny"><a href="https://medium.com/analytics-vidhya/machine-learning-decision-trees-and-random-forest-classifiers-81422887a544" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">机器学习-决策树和随机森林分类器</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">分类是识别物体、动物等属于哪个组的能力。可能属于给定的一些…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="on l oj ok ol oh om jz ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://medium.com/@karankashyap_7430/machine-learning-google-colab-why-when-and-how-to-use-it-9624e34abd6d" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">机器学习:Google Colab——为什么、何时以及如何使用它</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">机器学习(ML)是计算机科学领域的最新趋势，任何对数据有兴趣的人…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="oo l oj ok ol oh om jz ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://medium.com/@karankashyap_7430/programming-in-the-21st-century-which-languages-should-you-learn-d4055e5871f4" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">21世纪的编程:应该学习哪些语言？</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">深入了解初学者如何根据自己的兴趣和爱好选择学习哪种编程语言</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="op l oj ok ol oh om jz ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://medium.com/@karankashyap_7430/calculating-the-value-of-pi-using-random-numbers-a-monte-carlo-simulation-d4b80dc12bdf" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">使用随机数计算圆周率的值:蒙特卡罗模拟</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">深入了解如何使用随机数相当准确地计算像“圆周率”这样具体的数字…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="oq l oj ok ol oh om jz ny"/></div></div></a></div></div></div>    
</body>
</html>