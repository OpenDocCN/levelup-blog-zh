<html>
<head>
<title>De-Blurring images using Convolutional Neural Networks along with code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络和编码去模糊图像</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/de-blurring-images-using-convolutional-neural-networks-with-code-51d3f8d7b1d7?source=collection_archive---------2-----------------------#2020-06-19">https://levelup.gitconnected.com/de-blurring-images-using-convolutional-neural-networks-with-code-51d3f8d7b1d7?source=collection_archive---------2-----------------------#2020-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="1c94" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN可以用来从图像中提取一些隐藏的特征，并对它们进行“去模糊”。</p><blockquote class="ko kp kq"><p id="f5a9" class="jq jr kr js b jt ju jv jw jx jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kn im bi translated">注意，本文假设读者熟悉CNN的工作和功能。</p></blockquote><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/0878da5b290ed9a6aec55ca2e8d4a157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EbyXPnL2wqiUlq82WJWKwg.jpeg"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">机器学习算法可以用来将模糊的图像(左)转换为质量更好的图像(右)。这张照片是由<a class="ae ll" href="https://unsplash.com/@nathsegato" rel="noopener ugc nofollow" target="_blank">娜塔莉亚·塞加托</a>在<a class="ae ll" href="https://unsplash.com/photos/c168jRbeIEM" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/c168jRbeIEM</a>拍摄的。</figcaption></figure></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="a8b7" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">理论</h1><p id="65ba" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated"><strong class="js iu">卷积神经网络</strong>是一种用于图像的特殊类型的神经网络。这些网络倾向于从图像中提取一些隐藏的特征，这些特征对于人眼可能是可见的，也可能是不可见的。因此，它们被广泛用于许多计算机视觉应用中，如对象检测、对象识别、对象跟踪、对象定位等等。</p><p id="d76b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在了解了CNN的使用方式和位置后，了解它们在图像去模糊的应用中有多有用是很重要的。<em class="kr">自动编码器</em>有效地使用这些CNN来解决这个问题。关于他们的更多信息即将发布。</p><p id="f3b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">自动编码器</strong>用于拍摄输入图像，然后将该图像的细节存储为不同的格式，其大小小于图像的大小。这些存储的细节随后可用于<em class="kr">基于输入图像重建</em>相同的图像或不同的图像。自动编码器是图像重建以及生成新图像背后的基本概念，因此也用于许多一般的敌对网络中。</p><p id="0740" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个自动编码器，整体上有<em class="kr"> 3个</em>部分，一个<strong class="js iu">编码器</strong>，一个<strong class="js iu">隐藏层，</strong>和一个<strong class="js iu">解码器</strong>。<em class="kr">编码器</em>接收输入，处理输入，提取特征，然后将数据存储在<em class="kr">隐藏层</em>中。一个<em class="kr">解码器</em>做与编码器相反的事情。它从隐藏层获取数据，然后<em class="kr">使用相同的数据重建</em>图像。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/d23e14268f45e456077f33014a0a410e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*cgqgUdE3lszYbngqNX_r8Q.jpeg"/></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">自动编码器的基本轮廓</figcaption></figure><p id="d0cb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于本文，<strong class="js iu">编码器</strong>仅由不同数量的滤波器的各种卷积层组成。这些层从输入图像(模糊图像)中提取特征，然后将这些特征转移到隐藏层。</p><p id="9917" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，在这种情况下，<strong class="js iu">隐藏层</strong>由卷积层组成，该层的输入是编码器的特征图或输出。</p><p id="b9c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">来自隐藏层的数据被传递到<strong class="js iu">解码器</strong>。由于编码器涉及卷积层，所以对<em class="kr">解卷积</em>以得到与输入图像相似的图像是有意义的。在这种情况下，它是去模糊的图像。在图像的去卷积中，你采用一个具有权重的核，类似于卷积层，并将其乘以来自特征图的单个像素的强度。这个新矩阵取代了特征图中的像素。在训练整个模型的过程中学习每一层的核的权重。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mx"><img src="../Images/a60c1ef6017190724ad357306621a9e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*b5gA7W5speHgR1znEB9gdw.gif"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">这张GIF对反卷积的工作原理做了一个简单的解释。特征图被去卷积以获得上面所示的矩阵。</figcaption></figure><p id="6a7d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，至少在这种情况下，解码器仅涉及<strong class="js iu">反卷积层</strong>或者有时甚至被称为<strong class="js iu">卷积转置层</strong>。解码器中的去卷积层与为编码器选择的去卷积层具有相似的参数和属性。</p><p id="10b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们已经准备好了自动编码器的架构。但是为了训练模型，我们也需要选择一个损失函数。有相当多的损失函数可用于实现目标。但是，我们将专注于<strong class="js iu">均方误差</strong>和<strong class="js iu">二元交叉熵</strong>损失函数。</p><p id="2897" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">均方误差</strong>是预测图像和地面真实值之间的像素差异的平方的<em class="kr">平均值。它的代表是:</em></p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi my"><img src="../Images/be9da159edcd233067bf8faef055f8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/0*vkaioliK4N3LxFk4.png"/></div></figure><p id="83ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">二值交叉熵</strong>损失是<em class="kr">预测图像和地面真实之间的像素交叉熵</em>的总和。它的代表是:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/18f1f9d1ac60e32be7efa19f8ae7e70c.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/0*0ltdPWDfl7R5Ki-F.png"/></div></figure><p id="b36e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这两个损失函数给我们一个粗略的概念，地面真实情况与预测的图像有所不同。最小化这两种损失将有助于解决以前设计的CNN中使用的<em class="kr">权重</em>和<em class="kr">偏差</em>的调整。</p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="5fe1" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">密码</h1><p id="130c" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">现在，在人们能够理解理论之后，我们可以深入前述概念的<em class="kr">实现</em>，以最终实现深度学习模型，从而对图像进行<em class="kr">去模糊</em>。代码使用Python中可用的<strong class="js iu"> Keras </strong>包实现。你可以在这个链接查阅完整的代码:<a class="ae ll" href="https://github.com/done-n-dusted/deblur-fashionmnist" rel="noopener ugc nofollow" target="_blank">https://github.com/done-n-dusted/deblur-fashionmnist</a>。</p><p id="a6de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们需要加载数据集。我已经使用了<strong class="js iu">时尚-MNIST </strong>数据集，可以很容易地从Keras包中获取。</p><pre class="kw kx ky kz gt na nb nc nd aw ne bi"><span id="b82e" class="nf lu it nb b gy ng nh l ni nj">#loading the dataset<br/>(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()<br/>X_train, X_test = X_train/255, X_test/255</span></pre><p id="284f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于数据集中没有模糊的图像，我们需要通过模糊现有图像来创建一个新的数据集。为了模糊它们，我们可以使用<em class="kr"> OpenCV </em>包中的<em class="kr"> GaussianBlur </em>函数。选择的内核大小为3 x 3。</p><pre class="kw kx ky kz gt na nb nc nd aw ne bi"><span id="dba9" class="nf lu it nb b gy ng nh l ni nj">def add_noise(X):<br/>    result = []<br/>    for img in X:<br/>        noisy = cv2.GaussianBlur(img, (3, 3), 0)<br/>        noisy = np.clip(noisy, 0, 1)<br/>        result.append(noisy)<br/>    return np.array(result)</span><span id="ee21" class="nf lu it nb b gy nk nh l ni nj">noise_train = add_noise(X_train)<br/>noise_test = add_noise(X_test)</span></pre><p id="de71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在是时候建立我们的架构了。我构建的架构如下所示:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nl"><img src="../Images/2acbb74583ae0fca6bc1679d56ccc3e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DZ5ymvB5zxZI9SEKz04dMg.jpeg"/></div></div></figure><p id="7918" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第一个<strong class="js iu"> conv2d_1、conv2d_2、conv2d_3 </strong>代表<em class="kr">编码器</em>，<strong class="js iu"> conv2d_4 </strong>代表<em class="kr">隐藏层</em>，所有其他<strong class="js iu"> Conv2DTranspose </strong>层代表<em class="kr">解码器</em>。请记住，在这种情况下，输出维度必须与输入维度相同。因此，仔细选择内核大小。该架构可以编码如下:</p><pre class="kw kx ky kz gt na nb nc nd aw ne bi"><span id="5140" class="nf lu it nb b gy ng nh l ni nj">from keras import models, layers<br/>model = models.Sequential()</span><span id="6693" class="nf lu it nb b gy nk nh l ni nj">#encode</span><span id="f49e" class="nf lu it nb b gy nk nh l ni nj">model.add(layers.Conv2D(64, (2, 2), strides = 1, padding = 'same', input_shape = (28, 28, 1)))<br/>model.add(layers.Conv2D(32, (2, 2), strides = 1, padding = 'same'))<br/>model.add(layers.Conv2D(16, (2, 2), strides = 1, padding = 'same'))</span><span id="1cb4" class="nf lu it nb b gy nk nh l ni nj">#latent</span><span id="8025" class="nf lu it nb b gy nk nh l ni nj">model.add(layers.Conv2D(8, (2, 2), strides = 1, padding = 'same'))</span><span id="1c44" class="nf lu it nb b gy nk nh l ni nj">#decode<br/>model.add(layers.Conv2DTranspose(16, (2, 2), strides = 1, padding = 'same'))<br/>model.add(layers.Conv2DTranspose(32, (2, 2), strides = 1, padding = 'same'))<br/>model.add(layers.Conv2DTranspose(64, (2, 2), strides = 1, padding = 'same'))<br/>model.add(layers.Conv2DTranspose(1, (1, 1), strides = 1, activation = 'sigmoid', padding = 'same'))</span></pre><p id="492a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如上所述，可以采用任何损失函数。对于这个数据集，我个人发现使用<strong class="js iu">均方差</strong> <strong class="js iu">误差</strong>的结果更好。请随意选择你想要的。现在，我们需要编译这个模型，然后拟合数据。</p><pre class="kw kx ky kz gt na nb nc nd aw ne bi"><span id="f941" class="nf lu it nb b gy ng nh l ni nj">model.compile(loss = 'mse', optimizer = 'adam')</span><span id="64fa" class="nf lu it nb b gy nk nh l ni nj">model.fit(noise_train.reshape(-1, 28, 28, 1), <br/>          X_train.reshape(-1, 28, 28, 1), <br/>          epochs = 100, <br/>          batch_size = 2000, <br/>          validation_data = (noise_test.reshape(-1, 28, 28, 1),                                                                                               X_test.reshape(-1, 28, 28, 1)))</span></pre><p id="e3f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在模型适合输入数据之后，现在是预测<em class="kr">去模糊</em>图像的时候了。</p><pre class="kw kx ky kz gt na nb nc nd aw ne bi"><span id="efb3" class="nf lu it nb b gy ng nh l ni nj">#utility function to pick samples to be tested</span><span id="d9c6" class="nf lu it nb b gy nk nh l ni nj">def get_samples(arr, n):<br/>    temp = random.sample(range(len(arr)), n)<br/>    result = arr[temp]<br/>    return result, temp</span><span id="89c0" class="nf lu it nb b gy nk nh l ni nj">num = 15<br/>org, temp = get_samples(X_test, num)<br/>blur = noise_test[temp]<br/>preds = model.predict(blur.reshape(-1, 28, 28, 1))<br/>preds = preds.reshape(-1, 28, 28)</span><span id="40f3" class="nf lu it nb b gy nk nh l ni nj">#plotting results</span><span id="7791" class="nf lu it nb b gy nk nh l ni nj">plt.figure(figsize = (15, 15))<br/>print('Original Images')<br/>for i in range(num):<br/>    plt.subplot(1, num, i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(org[i], cmap=plt.cm.binary)<br/>plt.show()</span><span id="6e67" class="nf lu it nb b gy nk nh l ni nj">plt.figure(figsize = (15, 15))<br/>print('Blurred Images')<br/>for i in range(num):<br/>    plt.subplot(1, num, i + 1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(blur[i], cmap=plt.cm.binary)<br/>plt.show()</span><span id="b751" class="nf lu it nb b gy nk nh l ni nj">plt.figure(figsize = (15, 15))<br/>print('Predicted Images')<br/>for i in range(num):<br/>    plt.subplot(1, num, i + 1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(preds[i], cmap=plt.cm.binary)<br/>plt.show()</span></pre><p id="79ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面显示的代码输出如下图所示。可以观察到预测图像非常接近原始图像。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nm"><img src="../Images/6c4888e4f2cdbf4d0117adf67ccf1d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u5WItogDX1eAq2sxraeNOA.png"/></div></div><figcaption class="lh li gj gh gi lj lk bd b be z dk translated">模型的预测被训练来“去模糊”图像。</figcaption></figure><p id="b64f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你想自己实现它，我建议你调整一些代码，使用<em class="kr">不同的数据集，优化器</em>用于模型编译，<em class="kr">架构</em>，<em class="kr">激活函数</em>等等。你可能会得到比我更好的结果。<strong class="js iu"> <em class="kr">万事如意！</em> </strong></p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="caf8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">T35】谢谢T37】。希望您喜欢阅读这篇文章，并且至少对自动编码器、解卷积等有了部分了解。工作。祝您愉快！:)</strong></p><h2 id="02dd" class="nf lu it bd lv nn no dn lz np nq dp md kb nr ns mh kf nt nu ml kj nv nw mp nx bi translated">参考</h2><div class="ny nz gp gr oa ob"><a href="https://medium.com/@jannik.zuern/but-what-is-an-autoencoder-26ec3386a2af" rel="noopener follow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">但是什么是自动编码器呢？</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">在今天的帖子中，我想给你一个快速和肮脏的神经网络架构类型的介绍，称为…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">medium.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op lf ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a href="https://www.coursera.org/projects/autoencoders-image-denoising" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">Keras和Python中使用自动编码器的图像去噪</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">由Coursera项目网提供。在这个1小时的基于项目的课程中，您将能够:-理解…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">www.coursera.org</p></div></div><div class="ok l"><div class="oq l om on oo ok op lf ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a href="https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8" rel="noopener follow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">转置卷积用… MS Excel解释！</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">你已经成功地在1D回旋，2D回旋和三维回旋中导航。你已经征服了…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">medium.com</p></div></div><div class="ok l"><div class="or l om on oo ok op lf ob"/></div></div></a></div></div></div>    
</body>
</html>