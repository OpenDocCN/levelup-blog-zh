<html>
<head>
<title>BERT for Patents by Google, vs. DeepPatent and PatentBERT, Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌专利与DeepPatent和Patent简化版</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/bert-for-patents-by-google-vs-deeppatent-and-patentbert-simplified-2ccea99201bd?source=collection_archive---------7-----------------------#2022-08-14">https://levelup.gitconnected.com/bert-for-patents-by-google-vs-deeppatent-and-patentbert-simplified-2ccea99201bd?source=collection_archive---------7-----------------------#2022-08-14</a></blockquote><div><div class="fc hw hx hy hz ia"/><div class="ib ic id ie if"><div class=""/><p id="acb6" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">除了描述它的方法和用例，我还阐明了它与PatentBERT和DeepPatent的区别</p><figure class="ke kf kg kh gg ki fu fv paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="fu fv kd"><img src="../Images/ad6291b79499792ec6649f0f82d20890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQyYt-pG3PncYKi_QKkrPQ.jpeg"/></div></div><figcaption class="kp kq fw fu fv kr ks bd b be z dk translated">来自Pexels的马克西姆·冈查伦诺克</figcaption></figure><p id="0601" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">如果你想在市场上为他人识别竞争专利，你不应该有一个大概的数字。我正在研究一项专利，需要验证它，以便提交我的专利进行审查。在浏览多个网站、资料来源和法律服务时，我遇到了Google[2]开发的一项功能来帮助完成这些任务。另一个伯特模型。此外，我偶然发现了另外两种方法，DeepPatent和PatentBERT。一旦我明白了什么是什么，并为我的任务激活了一个，我就承担起了澄清它们的责任。</p><h1 id="e132" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">这都是关于专利的</strong></h1><p id="1626" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">专利是知识产权的一种形式，它赋予其所有者在规定的公开期限内禁止他人制造、使用、销售或进口发明的合法权利。因此，存在时间限制——这是一个复杂的领域，涉及时间在实践中与原则上的应用；这里就不赘述了。)进一步说，发明者基本上是带着法律文件离开的，这些文件授予他们制造、使用和销售发明的专有法律权利。作为一种保护形式，专利保护发明不被他人在未经发明人许可的情况下制造、使用或出售。</p><p id="5a13" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">全球活跃专利和申请超过2000万件；每个专利包含大约10，000个。</p><figure class="ke kf kg kh gg ki fu fv paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="fu fv lx"><img src="../Images/b32c0091ef75b1cdfac92558ebe3fdf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D5Glwl-6iur2jwVyLArNhg.jpeg"/></div></div><figcaption class="kp kq fw fu fv kr ks bd b be z dk translated">由来自Pexels的<a class="ae kt" href="https://www.pexels.com/@karolina-grabowska/" rel="noopener ugc nofollow" target="_blank">卡罗琳娜·格拉博斯卡</a></figcaption></figure><h1 id="5b9d" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">模型的基本原理</strong></h1><p id="9c60" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">首先需要明确两个区别:(1)这是一个由谷歌创建的模型，使用1亿多份专利出版物进行训练，这些不仅仅是覆盖美国的专利；(2)这是一个伯特模型。</p><p id="3626" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">当谷歌在2018年发布BERT模型[2]时，研究人员蜂拥至实证结果，以验证其性能指标。意识到它在自然语言处理(NLP)基准测试中的表现优于许多其他领先的先进模型[5](如GLUE、MultiNLI和SQuAD [2])，我们中的许多人首先在无数的NLP实现管道中应用了BERT。</p><p id="713d" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">但是，请注意，与BERT相比，它的最大输入长度为512个令牌。此外，它还增加了8000个单词(相对于标准的BERT词汇)[3]。</p><p id="f4c4" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">在结果中看到澄清的一种方式是通过查看“上下文”标记指示符，该指示符使用以下标签来分解:(1)摘要；(二)债权；(3)总结；和(4)发明[3]。这种分类表示会使文本与专利信息交叉。</p><figure class="ke kf kg kh gg ki fu fv paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="fu fv ly"><img src="../Images/56716b37b4d28935fa710740009951d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYlYmJ1VWUuGdM10-pJmtg.jpeg"/></div></div><figcaption class="kp kq fw fu fv kr ks bd b be z dk translated">通过像素的<a class="ae kt" href="https://www.pexels.com/@gratisography/" rel="noopener ugc nofollow" target="_blank">地形图</a></figcaption></figure><h1 id="9dcf" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">其方法</strong></h1><p id="81f7" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">在识别关于专利的信息的上下文中的布尔搜索是一种需要使用特定术语的搜索。然后，布尔搜索的挑战变成了如何识别进行搜索所需的内容。搜索专利时会出现困难，因为专利中使用的术语在设计上是显而易见的。</p><p id="9e4e" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">美国专利和贸易办公室(USPTO)提供了大约9，000个示例来帮助进行布尔搜索(此处[6]作为示例)，以应用于跨合作专利分类(CPC)代码搜索。</p><p id="537d" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">为了告知专利中使用的特定术语，谷歌创建了一个定制的标记器，它就像一本字典，专门用于专利术语，以帮助提高预测任务的准确性。他们确实注意到所看到的改进是. 5% [9]，最终是希望允许更好的解释，尤其是当涉及到“同义词生成”时[9]。</p><figure class="ke kf kg kh gg ki fu fv paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="fu fv lz"><img src="../Images/7f2eeca993eaa94ded3af3428bf7ec53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fksx_HRQzkJhw53IRLfTjw.jpeg"/></div></div><figcaption class="kp kq fw fu fv kr ks bd b be z dk translated">来自Pexels的娜塔莉亚·瓦特凯维奇</figcaption></figure><h1 id="0208" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">还有patent Bert——有什么区别？</strong></h1><p id="c4bf" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">这里概述[7]，不要混淆这两者。在Jieh Hisang等人的领导下，他们阐述了如何使用不同的训练数据集(与谷歌的专利BERT模型无关)应用BERT-Base预训练模型(无案例和1.1亿个参数[7])的具体研究。</p><h1 id="46ca" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">现在，还有DeepPatent？</strong></h1><p id="3e43" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">另一个用例:DeepPatent展示了从设计专利中分析和检索技术图纸的任务。有趣的是，PatentBERT利用DeepPatent的F1分数作为基准进行基准测试[7]。此外，PatentBERT通过其F1分数证明了他们优于[7] DeepPatent。</p><figure class="ke kf kg kh gg ki fu fv paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="fu fv ma"><img src="../Images/3b950bfef4e6b3034bd2d959125b506a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6QeVd0D3wZQXt2n-OBKpA.jpeg"/></div></div><figcaption class="kp kq fw fu fv kr ks bd b be z dk translated">来自Pexels的Nataliya Vaitkevich</figcaption></figure><h1 id="e34c" class="ku kv ii bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">离别的思念</strong></h1><p id="96d2" class="pw-post-body-paragraph jf jg ii jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc ib bi translated">除了阐述这种新方法的方法论和基本原理，我还简单地阐明了它与PatentBERT和DeepPatent的区别。如果你对这篇文章的编辑有任何建议，或者对进一步扩展这个主题领域有什么建议，请和我分享你的想法。</p><p id="7e3c" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated">这是我的时事通讯；我希望你能考虑订阅:</p><div class="mb mc gc ge md me"><a href="https://pventures.substack.com" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab hd"><div class="mg ab mh cl cj mi"><h2 class="bd ij gm z mj mk ml mm mn mo mp ih bi translated">产品。风险时事通讯</h2><div class="mq l"><h3 class="bd b gm z mj mk ml mm mn mo mp dk translated">产品和人工智能交汇处的想法。点击阅读产品。投资时事通讯，作者安尼尔…</h3></div><div class="mr l"><p class="bd b dl z mj mk ml mm mn mo mp dk translated">pventures.substack.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx kn me"/></div></div></a></div><p id="7da4" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><strong class="jh ij">我写了以下帖子(作为BERT家族的一员)，你可能会感兴趣:</strong></p><div class="mb mc gc ge md me"><a rel="noopener  ugc nofollow" target="_blank" href="/scibert-wins-5-improvements-over-bert-simply-explained-a965b71d9a96"><div class="mf ab hd"><div class="mg ab mh cl cj mi"><h2 class="bd ij gm z mj mk ml mm mn mo mp ih bi translated">SciBERT胜出:比BERT提高了5点，简单解释</h2><div class="mq l"><h3 class="bd b gm z mj mk ml mm mn mo mp dk translated">SciBERT与BERT，及其应用程序、最佳实践，以及它如何超越BERT。</h3></div><div class="mr l"><p class="bd b dl z mj mk ml mm mn mo mp dk translated">levelup.gitconnected.com</p></div></div><div class="ms l"><div class="my l mu mv mw ms mx kn me"/></div></div></a></div><p id="c602" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><strong class="jh ij">和，</strong></p><div class="mb mc gc ge md me"><a rel="noopener  ugc nofollow" target="_blank" href="/how-matscibert-is-an-improvement-over-scibert-and-bert-5d39e8c1571b"><div class="mf ab hd"><div class="mg ab mh cl cj mi"><h2 class="bd ij gm z mj mk ml mm mn mo mp ih bi translated">MatSciBERT如何优于SciBERT和BERT</h2><div class="mq l"><h3 class="bd b gm z mj mk ml mm mn mo mp dk translated">我描述MatSciBERT，将其与SciBERT进行比较，并显示与原始BERT模型相比的总体结果</h3></div><div class="mr l"><p class="bd b dl z mj mk ml mm mn mo mp dk translated">levelup.gitconnected.com</p></div></div><div class="ms l"><div class="mz l mu mv mw ms mx kn me"/></div></div></a></div></div><div class="ab cl na nb hm nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="ib ic id ie if"><p id="c581" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh">参考文献:</em></p><p id="f11c" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 1。安费里科/伯特专利拥抱脸。(未注明)。检索到2022年8月11日，来自</em><a class="ae kt" href="https://huggingface.co/anferico/bert-for-patents" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://huggingface.co/anferico/bert-for-patents</em></a></p><p id="308a" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 2。人工智能如何改善专利分析？(未注明)。谷歌云博客。2022年8月11日检索，来自</em><a class="ae kt" href="https://cloud.google.com/blog/products/ai-machine-learning/how-ai-improves-patent-analysis" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://cloud . Google . com/blog/products/ai-machine-learning/how-ai-improves-patent-analysis</em></a></p><p id="cf70" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 3。谷歌。(未注明)。专利-公共数据/BERT for patents . MD at master Google/patents-public-data。GitHub。检索于2022年8月11日，来自</em><a class="ae kt" href="https://github.com/google/patents-public-data/blob/master/models/BERT%20for%20Patents.md" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://github . com/Google/patents-public-data/blob/master/models/BERT % 20 for % 20 patents . MD</em></a></p><p id="35ae" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 4。谷歌，谷歌在BigQuery上的公共数据集专利，(未注明)。</em></p><p id="a2a6" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><a class="ae kt" href="https://console.cloud.google.com/bigquery?p" rel="noopener ugc nofollow" target="_blank"><em class="nh"/></a><em class="nh">=专利-公开-数据。</em></p><p id="146d" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 5。Devlin，j .，Chang，m-w，Lee，k .，&amp;# 38；k . toutanova(2018年10月11日)。BERT:用于语言理解的深度双向转换器的预训练。ArXiv.Org。</em><a class="ae kt" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://arxiv.org/abs/1810.04805</em></a></p><p id="7fa8" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 6。CPC定义。(未注明)。G06F电气数字数据处理(基于特定Compu的计算机系统…2022年8月11日检索，来自</em><a class="ae kt" href="https://www.uspto.gov/web/patents/classification/cpc/html/defG06F.html" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://www . USPTO . gov/web/patents/classification/CPC/html/defg 06 f . html</em></a></p><p id="9a83" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 7。李，j-s，&amp;# 38；Hsiang，J. (2019年5月14日)。PatentBERT:通过微调预先训练的BERT模型进行专利分类。ArXiv.Org。</em><a class="ae kt" href="https://arxiv.org/abs/1906.02124" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://arxiv.org/abs/1906.02124</em></a></p><p id="2dfe" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 8。DeepPatent:大规模专利图识别和检索。(未注明)。IEEE Xplore。检索到2022年8月11日，来自</em><a class="ae kt" href="https://ieeexplore.ieee.org/document/9707064" rel="noopener ugc nofollow" target="_blank"><em class="nh">【https://ieeexplore.ieee.org/document/9707064】</em></a></p><p id="c1a1" class="pw-post-body-paragraph jf jg ii jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc ib bi translated"><em class="nh"> 9。Yonamine等人利用专利的BERT算法与TensorFlow和BigQuery。</em><a class="ae kt" href="https://services.google.com/fh/files/blogs/bert_for_patents_white_paper.pdf" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://services . Google . com/FH/files/blogs/Bert _ for _ patents _ white _ paper . pdf</em>T11】</a></p></div></div>    
</body>
</html>