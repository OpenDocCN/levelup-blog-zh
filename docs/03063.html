<html>
<head>
<title>K-Means Clustering Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-均值聚类算法</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/k-means-clustering-algorithm-4fc5f1d74a23?source=collection_archive---------14-----------------------#2020-04-17">https://levelup.gitconnected.com/k-means-clustering-algorithm-4fc5f1d74a23?source=collection_archive---------14-----------------------#2020-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2fa2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">简介</em> : K-means聚类是一种无监督的学习方法。在这篇文章中，我将介绍无监督学习的概念以及它为什么有用。然后我会谈到K-means聚类:问题的数学公式，python从头实现，以及使用机器学习库。</p><h1 id="fb0f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">无监督学习</h1><p id="a9fe" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">通常，机器学习模型会对数据进行预测，学习以前看不到的模式来做出重要的商业决策。当数据集由标签和数据点组成时，它被称为<a class="ae lp" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir"><em class="kl"/></strong></a><strong class="jp ir"><em class="kl"/></strong>，垃圾邮件检测、语音识别、手写识别是它的一些用例。从没有任何<em class="kl">基本事实</em>或<em class="kl">正确标签</em>的数据点中提取洞察力的学习方法属于<a class="ae lp" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> <em class="kl">无监督学习</em> </strong> </a>的范畴。</p><p id="a2b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">无监督学习</em>是<a class="ae lp" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" rel="noopener ugc nofollow" target="_blank"> <em class="kl">探索性数据分析</em> </a>中使用的基本技术之一，在准备制作复杂的机器学习模型进行推断之前，对数据进行意义分析。由于这不包括人类标记的数据，偏差被最小化。同样，因为没有标签，所以没有正确的答案。从概率的角度来看，<em class="kl">监督</em>和<em class="kl">非监督学习</em>之间的对比如下:监督学习推断<em class="kl">条件概率分布p(x|y) </em>，而非监督学习关注的是<em class="kl">先验概率p(x) </em>。</p><h1 id="ec7c" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">k-均值聚类算法</h1><blockquote class="lq lr ls"><p id="d432" class="jn jo kl jp b jq jr js jt ju jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj kk ij bi translated">聚类方法的目标是将数据点分成单独的聚类(预先确定的)，最大化聚类间距离并最小化聚类内距离(增加相似性)。</p></blockquote><p id="f041" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">K-Means是无监督学习算法中的一种聚类技术。其他一些常用的技术有<a class="ae lp" href="https://en.wikipedia.org/wiki/Fuzzy_clustering" rel="noopener ugc nofollow" target="_blank">模糊聚类</a>(软k均值)、层次聚类、混合模型。<em class="kl">硬聚类</em>或<em class="kl">硬k均值</em>是将每个数据点只分配给一个聚类(例如垃圾邮件或非垃圾邮件)，而不是像<em class="kl">软k均值</em>那样为每个聚类分配非零成员值(垃圾邮件:13%，非垃圾邮件:87%)。在这篇文章中，我将介绍<em class="kl">硬聚类</em>。</p><p id="a94d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl"> K均值算法</em>的工作原理:</p><ol class=""><li id="28d8" class="lw lx iq jp b jq jr ju jv jy ly kc lz kg ma kk mb mc md me bi translated">从<strong class="jp ir"> <em class="kl"> X </em> </strong>中随机选取<strong class="jp ir"> <em class="kl"> k </em> </strong>个质心(不替换)。</li></ol><p id="5727" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.计算每个<strong class="jp ir"><em class="kl"/></strong>到所有<strong class="jp ir"> <em class="kl"> μ </em> </strong>的距离(<em class="kl"> L2 </em>或<em class="kl">欧几里德距离</em></p><p id="9d05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.挑选最近的一个簇作为这个<strong class="jp ir"> <em class="kl"> x </em> </strong>的标签。</p><p id="140c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.通过找到每个<strong class="jp ir"> <em class="kl"> k </em> </strong>簇的算术平均值来更新质心。</p><p id="b9d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.重复步骤<em class="kl">2–4</em>直到质心停止变化。</p><p id="a856" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数学上可以归结为寻找数据集<strong class="jp ir"><em class="kl"/></strong>的一个最优划分<strong class="jp ir"><em class="kl"/></strong>。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/6dcad1afbbe2c7dec7f1b7ab1a022aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IN0bXbGgb-oO1wgaUIOTcg.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">K-均值的数学公式</figcaption></figure></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><h1 id="2ec1" class="km kn iq bd ko kp nc kr ks kt nd kv kw kx ne kz la lb nf ld le lf ng lh li lj bi translated">密码</h1><p id="abf0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">首先，我将用python从头开始编写k-means的基本实现。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="560d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们生成一些数据并应用k-means来看看它是如何工作的。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/f0f6de4cfccbb758ccf4abea67fa210c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*QkdpziVfDd0muH2jc4fjLg.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">合成数据</figcaption></figure><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ed13d0307ce65505435e5bdf9b8c9dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*8BjDi3LU-db2WzklNYc8tA.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">输出:K-意味着从零开始</figcaption></figure><p id="44cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不错吧。用50行代码从头构建一个模型很酷:)</p><p id="f360" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过导入scikit-learn库，只需几行代码就可以完成同样的任务。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/53dc1017b885a946a2e622851f751319.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*GamrTn2I_Q2aymyqbWNC7g.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk translated">输出:K-表示使用sklearn</figcaption></figure><p id="5701" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Sklearn 给出了与我们在这个虚拟数据集上从头构建的模型几乎相同的输出。</p><p id="b8b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你从头开始编写了一个基本的框架结构，并且熟悉了实现的细节。之后，实现<strong class="jp ir"> <em class="kl"> k-means </em> </strong>或者任何其他算法，都是使用专门的库函数在公园里散步。</p></div><div class="ab cl mv mw hu mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ij ik il im in"><h1 id="61d7" class="km kn iq bd ko kp nc kr ks kt nd kv kw kx ne kz la lb nf ld le lf ng lh li lj bi translated">结论</h1><p id="8787" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">K-means是最简单的无监督学习方法之一。在继续构建复杂的架构以做出决策之前，它可以用来为EDA提供见解。这个博客是了解无监督学习、聚类、k-means及其实现的一个很好的起点。</p><p id="ae5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请随意阅读、编码和探索以了解更多信息。在下面留言，分享你的经历。感谢阅读:)</p></div></div>    
</body>
</html>