<html>
<head>
<title>Machine Learning explained with high-school math</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用高中数学解释机器学习</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/machine-learning-explained-with-high-school-math-254f4f0dce02?source=collection_archive---------17-----------------------#2021-03-28">https://levelup.gitconnected.com/machine-learning-explained-with-high-school-math-254f4f0dce02?source=collection_archive---------17-----------------------#2021-03-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/876b072f56331f314fdbff2de54c4ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kh_jOA0MgalOOc5QwjwsbA.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">克里斯·利维拉尼在<a class="ae jd" href="https://unsplash.com/collections/10610004/simple-math?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><div class=""/><div class=""><h2 id="a0da" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">对于这篇文章，你需要知道什么</h2></div><ol class=""><li id="0d56" class="kv kw jg kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">高中数学</li><li id="815e" class="kv kw jg kx b ky ln la lo lc lp le lq lg lr li lj lk ll lm bi translated">Python知识</li><li id="cd01" class="kv kw jg kx b ky ln la lo lc lp le lq lg lr li lj lk ll lm bi translated">均方误差</li><li id="0463" class="kv kw jg kx b ky ln la lo lc lp le lq lg lr li lj lk ll lm bi translated">PyTorch(实际上不多，将在本文中解释代码)</li><li id="5414" class="kv kw jg kx b ky ln la lo lc lp le lq lg lr li lj lk ll lm bi translated">二次函数的行为(即x的系数如何影响函数的凹度)</li></ol><h2 id="40e4" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated">这篇文章是给你的吗？</h2><p id="8c65" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">本文是“落后一步”系列的第二篇。如果你对机器学习有最低限度的先验知识，阅读<a class="ae jd" href="https://medium.com/mlearning-ai/gradient-descent-4fda4e3fbdc0" rel="noopener">的第一篇文章</a>将有助于理解这一点。在这篇文章中，我将讨论机器如何使用高中数学进行学习。如果你对机器学习背后的场景感兴趣，那么这篇文章可能适合你。先前训练ML模型的经验将对理解这篇文章有很大帮助，即使你只是阅读了别人的代码并毫无头绪地运行它。</p><h2 id="839c" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated">为什么学习ML令人生畏，为什么不应该如此</h2><p id="7b2b" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">机器学习领域无疑是有趣的；然而，ML中花哨词汇的数量令人望而生畏。事实上，许多行话实际上只是高中数学隐藏在花哨的词汇后面。</p><p id="1a7a" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">当我刚开始学习ML时，这对我来说是个问题。术语包装的简单概念通常会让我陷入困境，因为我仍然需要搜索并试图理解它们。在我以前学习ML的几种方式中，目前为止最有效的是FAST AI的在线课程。它使用自上而下的方法，但在这样做的时候，他们不会用花哨的词语来吓唬你，因为他们会抽象地告诉你这些结果，而你不必担心落后于课程。</p><h2 id="a25b" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated">本文的内容</h2><p id="05c5" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">在本文中，我们将看到机器如何学习像循环这样简单的概念。</p><h2 id="ac42" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated"><strong class="ak">启动前的提示</strong></h2><p id="c028" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">如果你跟着做，你的学习体验会更好。这里是下面提到的代码的<a class="ae jd" href="https://colab.research.google.com/drive/1fr-hhP2tFpn6ENBBqk8AafyNgBsB86Ub?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>。</p><p id="e42b" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">https://colab . research . Google . com/drive/1fr-HHP 2 tfpn 6 enbbqk 8 aafyngbsb 86 ub？usp =共享</p><p id="112b" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">注意</strong>:运行笔记本的第一个电池需要一段时间。输入为您生成的授权码，将其安装到您的驱动器上。</p><h1 id="3834" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated">我们开始吧</h1><blockquote class="no np nq"><p id="cd5c" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">假设我们安排一些自动方法来测试任何当前权重分配在实际性能方面的有效性，并提供一种机制来改变权重分配以最大化性能。我们不需要研究这样一个过程的细节，就可以看出它是完全自动化的，并且看出这样编程的机器会从它的经验中“学习”。</p><p id="c466" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">亚瑟·塞缪尔</p></blockquote><p id="b8eb" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">上面亚瑟·塞缪尔的引用告诉了我们机器学习的本质。我们今天的目标是理解上面的这句话。</p><figure class="nw nx ny nz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/64ea9e95c71e2c7b3d299e76ec9b3e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_4-vSj8Pc9muBC0Q8W5JnA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">截图来自<a class="ae jd" href="https://course.fast.ai/videos/?lesson=4" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=4</a></figcaption></figure><p id="2c42" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">该图像是报价的图形表示。</p><p id="3600" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">问题</strong>:我们想要找到一个函数，它会给出我们在某个时间点上过山车的速度。</p><p id="d53a" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">给定:</strong>我们得到了一个骑手用速度计捕捉到的数据。</p><figure class="nw nx ny nz gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4793e75f789010261a2ce562b50ae36d.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*TE43fKx9JMo3eHu8oR61dg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自:<a class="ae jd" href="https://course.fast.ai/videos/?lesson=3" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=3</a></figcaption></figure><p id="df72" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">上面是时间与速度的图表，代表了骑手在他的骑行中的几个点上获得的数据。</p><p id="da22" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">样本解读:</strong>2.6秒时，过山车以每秒25米的速度行驶。</p><p id="3793" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">看着它，我们可以推断出它可以用一个二次函数来建模。也就是说，我们想要创建一个与上面的函数非常相似的二次函数。(创建二次函数并不意味着我们画出它，而是获得它的实际数值)</p><h2 id="fb83" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated"><strong class="ak">python中的二次函数</strong></h2><p id="6e55" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">首先我们想用python做一个二次函数。这是回忆高中课程的好时机，尤其是函数。我们知道，一个二次函数看起来是这样构造的:<em class="nr"> f(x) = ax + bx + c. </em>对比一下下面的python函数。</p><blockquote class="no np nq"><p id="15bf" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">def f(t，params): <br/> a，b，c = params <br/>返回a*(t**2) + (b*t) + c</p></blockquote><p id="bfde" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">也许你已经开始看到他们之间的相似之处。是的，它们本质上是一样的。唯一的区别是x被t代替了，这并不重要，因为它们只是变量。我们在这里使用<em class="nr"> t </em>是因为使用<em class="nr"> t </em>来表示时间更符合逻辑。</p><h2 id="19ce" class="ls lt jg bd lu lv lw dn lx ly lz dp ma lc mb mc md le me mf mg lg mh mi mj mk bi translated">知道我们有多正确或多错误</h2><blockquote class="no np nq"><p id="4f1a" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">定义均方误差(预测值、目标值):</p><p id="ae42" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">return((预测-目标)**2)。平均值()。sqrt()</p></blockquote><p id="6488" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">为了确定我们离正确答案有多近，我们将使用<strong class="kx jh">均方误差(MSE) </strong>。上面的函数将接收上面的二次函数的输出，并将其与骑车人从速度计获得的实际值进行比较。</p><h1 id="5439" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated">亚瑟·塞缪尔描述的第一步:初始化</h1><blockquote class="no np nq"><p id="8650" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">params = torch.randn(3)。requires_grad_()</p></blockquote><p id="433a" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">为了更容易理解上面的代码是如何工作的，我将对它进行分解。</p><p id="f4f2" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh"> torch.randn(3) </strong> —返回3个随机数，将成为我们的a，b，c ( <strong class="kx jh">供参考</strong> : <em class="nr"> f(x) = ax + bx + c) </em></p><p id="74a0" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh"> requires_grad() </strong> —将允许PyTorch(我们正在使用的库)计算梯度(稍后您会明白为什么)</p><p id="5fc6" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">好吧，太好了！我们现在完成了第一步。我们现在有一个随机二次函数。这可能不太符合给定的数据，但至少我们已经有所进展。</p><h1 id="b398" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">第二步:预测</strong></h1><blockquote class="no np nq"><p id="ee31" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">preds = f(时间，参数)</p></blockquote><p id="db7a" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr">时间</em>这里是一串数字。</p><p id="009e" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">在二次函数中拟合<em class="nr">时间</em>的值，<em class="nr"> f()的输出就是预测。</em></p><p id="f86c" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">注意</strong> : <em class="nr"> preds </em>这里是秩1张量(一维数组)，里面有几个值。</p><p id="552b" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">至此，您可能开始意识到预测模型与函数非常相似。嗯，实际上它只是一个函数。你给它一个x值，在这种情况下是时间，然后它会给你相应的x的y值。从这个意义上说，建模只是找到正确的参数，使这个函数能够有一个正确的y值/预测。</p><p id="bac8" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">下图显示了我们的功能(红点)的<strong class="kx jh">结果与<strong class="kx jh">实际结果</strong>(蓝点)的对比</strong></p><p id="83ae" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">注</strong>:由于功能是随机启动的，可能会有一些差异。</p><figure class="nw nx ny nz gt is gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/56ba3f4666720e4811b4861763a8250c.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*V9SG7lk89739WhOV68s6Qw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自:<a class="ae jd" href="https://course.fast.ai/videos/?lesson=3" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=3</a></figcaption></figure><h1 id="fe69" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">第三步:计算损失</strong></h1><p id="8fef" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">是的，我们知道我们的预测是错误的，但我们知道它们有多错吗？这是我们之前定义的均方误差。</p><blockquote class="no np nq"><p id="93d4" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">定义均方误差(预测值、目标值):</p><p id="98f6" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">return((预测-目标)**2)。平均值()。sqrt()</p></blockquote><p id="0d6e" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">称之为</p><blockquote class="no np nq"><p id="3b48" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">损失= mse(预测值，速度)</p></blockquote><p id="1f32" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">我们的目标是尽量减少损失。随着我们的函数开始更加符合数据，它们之间的差异也将开始减少，因此随着我们变得更加精确，损耗也将开始减少。</p><h1 id="8a68" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">第四步:计算梯度</strong></h1><p id="fbe6" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">又来了一个高中数学概念。梯度对你来说可能有点抽象，因为你可能只记得:</p><p id="f04b" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr"> f(x) = x </em></p><p id="9798" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr"> f'(x) = 2x </em></p><p id="3107" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">换句话说，梯度就是一个函数的斜率(上升超过下降)。在线性函数中，你可以很容易地得到它，因为斜率总是恒定的，但是在二次函数中，斜率经常是变化的。这就是我们在x的导数/梯度中有变量的原因，随着x值的变化，斜率也随之变化。</p><p id="0606" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">也就是说，下一步是计算参数的梯度。</p><blockquote class="no np nq"><p id="ea2e" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">loss.backward()</p><p id="c5c8" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">帕拉姆斯·格拉德</p></blockquote><p id="43fe" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">参数的梯度是令人困惑的。简单来说，上面这段代码会告诉你参数的变化如何影响损耗的变化。</p><figure class="nw nx ny nz gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/141ab5d0c017a004d19d446b47619651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*fasDwPbozuKU7x5miEuqqA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">截图来自:<a class="ae jd" href="https://course.fast.ai/videos/?lesson=3" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=3</a></figcaption></figure><p id="c0e1" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">有了这个，我们现在知道我们可以从哪个方向改变参数(x轴)以减少损耗(y轴)</p><p id="2c05" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">注:</strong>上图和红点蓝点的不一样。这个代表我们的损失和参数之间的关系，而上面的一个给出了实际数据点和预测数据点之间的比较。</p><h1 id="a6e7" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">第五步:改变权重</strong></h1><p id="955f" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">看看这一节的标题，你可能会开始奇怪为什么“重量”这个词会突然出现。这是告诉你权重是模型的参数的好时机。这些是您放入模型参数中的值。</p><p id="71c7" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">例如:</p><p id="7b6d" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr"> f(x) = ax + bx + c </em></p><p id="2ef3" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr">这里a </em>、<em class="nr"> b </em>、<em class="nr"> c </em>是模型的参数。</p><p id="ecb4" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><em class="nr"> f(x) = 2x + 3x + 4 </em></p><p id="bb1a" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">2、3和4是模型的权重。</p><p id="e137" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">希望澄清权重和参数。</p><p id="09a9" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">下面是更新权重的代码:</strong></p><blockquote class="no np nq"><p id="d0e9" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">lr = 1e-5</p><p id="910f" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">参数数据-= lr *参数数据</p><p id="35b7" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">params.grad =无</p></blockquote><p id="509f" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">让我们一个一个来看。</p><blockquote class="no np nq"><p id="6579" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated"><strong class="kx jh"> lr = 1e-5 </strong></p></blockquote><p id="bc79" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">lr 指的是模型的学习率，在这种情况下，学习率从1提高到-5。从我们之前计算的梯度，我们知道哪个方向，方向有多陡。</p><figure class="nw nx ny nz gt is gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d954a13666f66c7b2611a3899094d3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*sPpkQ1gs9os9CkGaeRixxw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk translated">截图来自:<a class="ae jd" href="https://course.fast.ai/videos/?lesson=3" rel="noopener ugc nofollow" target="_blank">https://course.fast.ai/videos/?lesson=3</a></figcaption></figure><p id="e6b6" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">学习率越大，我们在x轴上的步长就越大，这将使它学习得更快，但它也可能具有相反的效果，因为它将采取太大的步长，这将使它错过具有最小损失值的点。另一方面，小的学习率将使其更准确，因为它将采取更多的步骤，这意味着它错过最小损失值的机会更小；然而，这将需要较长的时间来执行。</p><p id="afe1" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">在了解了整个过程之后，你可以尝试不同的学习速率，但是现在我们只使用1提高到-5。</p><blockquote class="no np nq"><p id="f5c5" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated"><strong class="kx jh">参数数据-= lr *参数分类数据</strong></p></blockquote><p id="df3f" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">有了学习率和梯度，我们就可以开始改变参数值，以更接近我们的目标，即具有更低的损失值。为了在调整参数时不影响我们的渐变，我们添加了<em class="nr"> .data. </em>，因为我们之前声明了。<em class="nr">要求_grad() </em> ]我们希望PyTorch记住对参数所做的操作，以了解梯度，调整这些参数也将包括在操作记录中。我们不想这样，因为我们唯一需要梯度的时候是在预测阶段。</p><blockquote class="no np nq"><p id="37af" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated"><strong class="kx jh"> params.grad = None </strong></p></blockquote><p id="c6c2" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">这一步只是删除梯度，为下一个预测中的下一个梯度留出空间。</p><h1 id="693f" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">让我们回到步骤2:预测和步骤3:计算损失</strong></h1><p id="540e" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">现在我们已经改变了模型的权重，我们可以检查损失是否降低了。</p><p id="7a07" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">再次运行步骤2和3中的代码:</p><p id="e5e3" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">预测</strong></p><blockquote class="no np nq"><p id="0bd0" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">preds = f(时间，参数)</p></blockquote><p id="a2c9" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">查找损失</strong></p><blockquote class="no np nq"><p id="9c55" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">损失= mse(预测值，速度)</p><p id="6c4e" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">失败</p></blockquote><p id="d9b5" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">我的损失从143.6154降到了143.3416</p><p id="aea8" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">让我们编译它们，这样我们可以使用for循环多次运行它们</strong></p><blockquote class="no np nq"><p id="50c3" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">定义学习():</p><p id="c220" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">preds = f(时间，参数)</p><p id="ab19" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">损失= mse(预测值，速度)</p><p id="f9cc" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">loss.backward()</p><p id="9b3e" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">参数数据-= lr *参数数据</p><p id="089a" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">params.grad =无</p><p id="de66" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">print("loss: " + loss[0])</p></blockquote><p id="fc99" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">在for循环中运行它</strong></p><blockquote class="no np nq"><p id="f5fd" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">对于范围(10)内的I:</p><p id="2419" class="ml mm nr kx b ky kz kh mo la lb kk mq ns na ms mt nt nb mv mw nu nc my mz li ij bi translated">学习()</p></blockquote><p id="000c" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated"><strong class="kx jh">下面是我输的结果:</strong></p><pre class="nw nx ny nz gt oe of og oh aw oi bi"><span id="685f" class="ls lt jg of b gy oj ok l ol om">tensor(142.2465, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(141.9728, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(141.6992, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(141.4256, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(141.1520, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(140.8785, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(140.6050, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(140.3315, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(140.0581, grad_fn=&lt;SqrtBackward&gt;)<br/>tensor(139.7847, grad_fn=&lt;SqrtBackward&gt;)</span></pre><h1 id="20f9" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated">第七步:停止</h1><p id="bbd6" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated"><strong class="kx jh">经过近千个循环:</strong></p><pre class="nw nx ny nz gt oe of og oh aw oi bi"><span id="93bb" class="ls lt jg of b gy oj ok l ol om">tensor(25.1210, grad_fn=&lt;SqrtBackward&gt;)</span></pre><p id="20fb" class="pw-post-body-paragraph ml mm jg kx b ky kz kh mo la lb kk mq lc na ms mt le nb mv mw lg nc my mz li ij bi translated">在大约一千次循环后，我的损失值大约是25。它只是在这个值上维持了一段时间，所以我决定停下来。</p><h1 id="0eb6" class="nd lt jg bd lu ne nf ng lx nh ni nj ma km nk kn md kp nl kq mg ks nm kt mj nn bi translated"><strong class="ak">结论</strong></h1><p id="a0e4" class="pw-post-body-paragraph ml mm jg kx b ky mn kh mo la mp kk mq lc mr ms mt le mu mv mw lg mx my mz li ij bi translated">恭喜你创造了一个机器学习模型！感谢您阅读完本文。</p></div></div>    
</body>
</html>