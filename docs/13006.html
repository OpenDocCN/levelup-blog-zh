<html>
<head>
<title>How LightGBM, a New AI Framework, Outperforms XGBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新的人工智能框架LightGBM如何超越XGBoost</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-lightgbm-a-new-ai-framework-outperforms-xgboost-6044ea7b8281?source=collection_archive---------3-----------------------#2022-07-31">https://levelup.gitconnected.com/how-lightgbm-a-new-ai-framework-outperforms-xgboost-6044ea7b8281?source=collection_archive---------3-----------------------#2022-07-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="5fc3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以速度和准确性为导向:LightGBM已经获得了大量的研究和有希望的实证结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e3c595484638d678f273285b3b681a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QpxAA5Qpg2i5zU3kl7ErDg.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的Pavel Danilyuk</figcaption></figure><p id="bbcb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在搜索一个比XGBoost更快更准确的机器学习优化器时，我偶然发现了LightGBM，Light Gradient Boosting Machine的缩写。我自己用它实现了成功，我想撰写这篇文章来分解我对LightGBM的理解(它是开源的，免费的，最初是由微软开发的(2016年，在MIT许可下[5])。</p><p id="15bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LightGBM [1]是一个使用基于树的学习算法的梯度推进框架。它的设计比传统的梯度推进决策树(GBDT)更有效，可以有效地处理大规模数据集。同样，它支持在多个GPU/CPU上进行并行训练[2]。此外，它还使用了一些高级功能，如GPU加速[3]、自动并行化[4]、大规模树提升支持以及针对其优化过程的高效内存使用[4]。适用于LightGBM环境的理想实现包括预测建模、特性选择或工程任务。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lf"><img src="../Images/5e6a006eb7354ecc7f8aedb4f0868e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*derTBm2MJIC6oUdnCDD8LA.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的马里乌斯·哈克斯塔德(T3)</figcaption></figure><h2 id="95dd" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">与其他机器学习模型相比，使用light GBM的一个优势是它可以训练数据集的速度——在特定的用例中，与XGBoost和AdaBoost相当，甚至可能更快。</h2><p id="542e" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">更重要的是，它能比XGBoost [6]更准确地实现结果。</p><h1 id="fe25" class="me lh it bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated"><strong class="ak">light GBM和XGBoost的4个主要区别</strong></h1><p id="a584" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">1.LightGBM使用基于梯度的单侧采样算法[1]来过滤掉不重要的样本，而XGBoost使用预先排序的算法技巧[7]来选择正确的分割点，这可能会导致与LightGBM相比可能更慢的速度。</p><p id="1bb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.LightGBM垂直生长树[8]，而XGBoost水平生长树[9]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/7b96d0d107b433f2028b9f8740868b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zD9eTsC3OBdXY3W82G5D0Q.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@drscythe" rel="noopener ugc nofollow" target="_blank">张秀坤大镰刀</a>从Unsplash</figcaption></figure><p id="60c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.LightGBM使用贪婪算法预测特定的实现管道[1]，而XGboost使用分数函数[10](例如，借助基于牛顿的方法或牛顿推进[11])。</p><p id="6e79" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.学习率度量:LightGBM具有更高的学习率[12]和良好的泛化能力，而XGBoost的学习任务更加保守[13]。</p><h1 id="45b1" class="me lh it bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated"><strong class="ak">light GBM的实际工作原理</strong></h1><p id="fd69" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">LightGBM是一种机器学习算法，通常用于分类和回归任务。它属于被称为梯度推进机器(GBMs)的算法家族。GBM是强大的机器学习模型，已被证明在各种任务中优于许多其他类型的模型，包括深度神经网络。</p><p id="3ae7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LightGBM使用一种称为基于直方图的宁滨[1]的新技术，使其能够比传统的GBM更有效地从数据中学习。此外，LightGBM可以处理高维的大型数据集，具有相对的可扩展性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mw"><img src="../Images/c0869ecb2a4879f36fb451736dd6d621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XKLsap4oKnsVIrS_v7GAZw.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的Taiki Ishikawa</figcaption></figure><p id="bfe2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要理解LightGBM的工作原理，首先理解GBM的一般工作原理是有帮助的。GBM是组合多个弱学习者模型的预测以产生强预测的集成模型。GBM通常由一系列决策树组成，其中每棵树都根据数据子集进行训练，并做出预测，然后将这些预测与集成中其他树的预测相结合。</p><p id="4011" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要进一步打开上面斜体部分的内容:</p><h2 id="62ca" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">Bagging (Bootstrap Aggregation)和Boosting的概念可以在本文中进一步阐述。也就是说，当我们谈论Boosting时，有必要澄清(如<a class="my mz ep" href="https://medium.com/u/912391a02ce3?source=post_page-----6044ea7b8281--------------------------------" rel="noopener" target="_blank">托马斯·米凯莱纳·桑多斯</a>所述)在每次训练迭代中，新树都是根据前一棵树的残差进行训练的，随着训练过程的发展，可能会提高其得分。</h2><p id="ba27" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">GBM中弱学习者模型的理想组合取决于手头的数据和任务的属性。一般来说，当有大量训练数据可用并且特征具有高预测能力时，GBM表现良好。它们在捕捉特征和目标变量之间的非线性关系方面也是有效的。</p><p id="4508" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LightGBM使用一种新颖的方法来构建基于直方图的决策树。直方图是数据的一种表示，它显示了条柱中值的分布。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/2e9d07596c569118537205d65bee3dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_pofbwbh63xGO9VFmiFa0A.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的丹尼尔·张</figcaption></figure><h2 id="e3f8" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">LightGBM通过逐层垂直生长决策树来构建决策树，而不是像上面提到的那样，像大多数其他基于树的模型一样，逐分支水平生长。</h2><p id="ffc8" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">在每个级别上，LightGBM通过搜索该箱中的梯度和与所有其他箱中的梯度和之间的最大差异来计算最佳分割点。</p><h2 id="6d5f" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">这种方法的优点是，它可以更有效地识别特征和目标变量之间的单调[14]关系，如线性关系。</h2><p id="c3d4" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">此外，因为在每一级只考虑一个特征，所以与在每一级考虑多个特征的传统GBM相比，训练时间减少了。</p><p id="e78d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与任何机器学习算法[16]一样，使用LightGBM也要权衡利弊。一个潜在的问题是过度拟合，因为它的灵活性很高。如果调整不当，LightGBM很容易使训练数据过拟合。类似地，与其他GBM一样，LightGBMs对异常值很敏感，当数据集很大时，训练速度会很慢。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nb"><img src="../Images/8e93a63b0916e3c44bf34240de0adc5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVqrPxtE1rxR3rzyUBVg-g.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的Lyman Hansel Gerona</figcaption></figure><h1 id="3280" class="me lh it bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated"><strong class="ak">light GBM优于XGBoost的4个理由</strong></h1><p id="28be" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">1.运行时:LightGBM可以比XGBoost训练得更快，因为它使用了一种称为基于直方图的优化的新技术，减少了构建每棵树所需的数据量。在某些情况下，这可能导致训练时间比XGBoost快很多倍。</p><p id="cd7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.可伸缩性:LightGBM可以很好地扩展到大型数据集，并且可以轻松处理数百万个示例，即使是在没有针对复杂任务进行优化的机器上。这种类型的可伸缩性是由于使用了有效利用存储器资源的梯度提升的高效实现而实现的[4]。</p><h2 id="6f36" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">此外，在训练LightGMB模型时利用了多核CPU架构，这导致了比XGBoost更进一步的加速。</h2><p id="f140" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">最后，并行学习(跨多台机器)对LightBGM来说不太重要，因为在训练过程中构建的树可以很容易地分布在一个集群中，而没有节点之间的通信开销[15]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nc"><img src="../Images/d01e0bd779d7f5464a60b7073f0d428c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ckmv7jFwUxIUIzERhW4bug.jpeg"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk translated">来自Unsplash的<a class="ae le" href="https://unsplash.com/@centelm" rel="noopener ugc nofollow" target="_blank">克莱门特·法利泽</a></figcaption></figure><p id="238a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.预测分析性能:LightGBM在数据集的运行时间和预测精度方面优于XGBoost这是可以观察到的，因为LightGBM以贪婪的方式构建树(即，它贪婪地分割节点，这将导致准确性的最大提高[1])，这可能导致与XGBoost的更随机的方法相比更好的模型。</p><p id="a82f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.易用性:LightBGM具有易于使用的API，与scikit-learn等其他流行的机器学习库保持一致。</p><h2 id="0cda" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">使用几行代码就可以构建具有多个参数的复杂模型，用户可以访问可用的函数来评估模型性能并对新数据进行预测。</h2><p id="84b3" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">此外，预先训练的模型可以轻松地从磁盘上保存/加载，从而方便与其他人共享模型或将其部署到生产应用程序中，而无需每次从头开始重新训练模型。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="2088" class="me lh it bd li mf nk mh ll mi nl mk lo ml nm mn lr mo nn mq lu mr no mt lx mu bi translated">如果您有任何编辑/修改建议或关于进一步扩展此主题的建议，请考虑与我分享您的想法。</h1><h1 id="ec91" class="me lh it bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated">另外，请考虑订阅我的每周简讯:</h1><div class="np nq gp gr nr ns"><a href="https://pventures.substack.com/" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">周日报告#1</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">人工智能和产品:帖子和聚光灯，截至2022年7月24日</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">pventures.substack.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og ky ns"/></div></div></a></div><p id="8f6f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我写了以下与这篇文章相关的内容:他们可能与你有相似的兴趣:</p><h1 id="d431" class="me lh it bd li mf mg mh ll mi mj mk lo ml mm mn lr mo mp mq lu mr ms mt lx mu bi translated"><strong class="ak"> XGBoost:它现在的能力和机器学习的用例</strong></h1><div class="np nq gp gr nr ns"><a href="https://pub.towardsai.net/xgboost-its-present-day-powers-and-use-cases-b4cac3d6e1d5" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">XGBoost:它在机器学习方面的当前能力和用例</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">XGBoost基于当前实现的深入研究</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">pub.towardsai.net</p></div></div><div class="ob l"><div class="oh l od oe of ob og ky ns"/></div></div></a></div><p id="5d77" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mx">参考文献。</em></p><p id="0ac2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 1。</em>刘天元(未标明)。LightGBM:一种高效的梯度推进决策树。神经信息处理系统进展，30。<a class="ae le" href="https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://proceedings . neur IPS . cc/paper/2017/file/6449 f 44 a 102 FDE 848669 BDD 9 EB 6b 76 fa-paper . pdf</em></a></strong></p><p id="3792" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">②<em class="mx">。</em> </strong> <em class="mx">柯、、王泰丰、、祁伟业、、。一种通信高效的决策树并行算法。《神经信息处理系统进展》，第1271-1279页，2016年。</em></p><p id="e121" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 3。</em> </strong> <em class="mx">张、h、斯、&amp;# 38；谢长廷(2017年6月26日)。大规模树提升的GPU加速。ArXiv.Org。</em><a class="ae le" href="https://arxiv.org/abs/1706.08359" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://arxiv.org/abs/1706.08359</em></a></p><p id="102d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 4。</em> </strong> <em class="mx">(未注明)。ACM数字图书馆。检索2022年7月24日，转自</em><a class="ae le" href="https://dl.acm.org/doi/abs/10.1145/3357254.3357290" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://dl.acm.org/doi/abs/10.1145/3357254.3357290</em></a></p><p id="6cf9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 5。</em> </strong> <em class="mx">欢迎tLightGBM的stLightGBM的文档！— LightGBM 3.3.2文档。(未注明)。检索2022年7月24日，转自</em><a class="ae le" href="https://lightgbm.readthedocs.io/en/v3.3.2/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://lightgbm.readthedocs.io/en/v3.3.2/</em></a></p><p id="0b17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">6<em class="mx">。</em> </strong> <em class="mx"> Daoud，E. A .(未注明)。使用家庭信用数据集比较XGBoost、LightGBM和CatBoost。国际计算机与信息工程杂志，13(1)，6–10。</em></p><p id="7441" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">T59】7。 </strong> <em class="mx">(未注明)。ACM数字图书馆。检索到2022年7月24日，来自</em><a class="ae le" href="https://dl.acm.org/doi/abs/10.1145/3436286.3436293" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://dl.acm.org/doi/abs/10.1145/3436286.3436293</em></a></p><p id="1d5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 8。</em> </strong> <em class="mx">【内梅特】，博金，&amp;# 38；米哈尔诺克。(2019年1月1日)。预测能源发展的机器学习方法xgboost和lightgbm的比较。斯普林格国际出版公司。</em><a class="ae le" href="https://link.springer.com/chapter/10.1007/978-3-030-31362-3_21" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://link . springer . com/chapter/10.1007/978-3-030-31362-3 _ 21</em></a></p><p id="77be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 9。</em> </strong> <em class="mx">【孙，】刘，&amp;# 38；司马，Z. (2020)。基于LightGBM的加密货币价格趋势预测模型。金融研究快报，32，101084。</em><a class="ae le" href="https://doi.org/10.1016/j.frl.2018.12.032" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://doi.org/10.1016/j.frl.2018.12.032</em></a></p><p id="dcb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 10。</em> </strong> <em class="mx">不平衡-XGBoost:利用加权和焦点损失进行二元标签-不平衡分类。(未注明)。模式识别字母，136，190–197。</em><a class="ae le" href="https://doi.org/10.1016/j.patrec.2020.05.035" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://doi.org/10.1016/j.patrec.2020.05.035</em></a></p><p id="f396" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 11。</em> </strong> <em class="mx">尼尔森博士(n.d .)。用xgboost提升树。</em><a class="ae le" href="https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2433761/16128_FULLTEXT.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://ntnuopen . ntnu . no/ntnu-XM lui/bitstream/handle/11250/2433761/16128 _ full text . pdf</em></a></p><p id="6787" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">12<em class="mx">。</em> </strong> <em class="mx"> LightGBM:金融行业预测客户忠诚度的有效决策树梯度推进方法。(未注明)。IEEE Xplore。检索2022年7月24日，转自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/8845529" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://ieeexplore.ieee.org/abstract/document/8845529</em></a></p><p id="fbac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">13<em class="mx">。</em> </strong> <em class="mx">伊斯兰教，S. F. N .，Sholahuddin，a .，&amp;# 38；阿卜杜拉(2021)。极端梯度推进法在美元兑印尼盾汇率预测中的应用与分析。物理学杂志:会议系列，1722(1)。</em><a class="ae le" href="https://doi.org/10.1088/1742-6596/1722/1/012016" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://doi.org/10.1088/1742-6596/1722/1/012016</em></a></p><p id="9358" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 14。</em></strong>【科克尔】【h】【奥多姆】【p】【杨】【s】【38号】；纳塔拉詹(2020年)。知识密集型梯度推进的统一框架:利用人类专家处理噪声稀疏领域。AAAI人工智能会议论文集，34(04)，4460–4468。<a class="ae le" href="https://doi.org/10.1609/aaai.v34i04.5873" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://doi.org/10.1609/aaai.v34i04.5873</em></a></p><p id="96c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 15。</em> </strong> <em class="mx"> SecureGBM:安全多方梯度提升。(未注明)。IEEE Xplore。检索2022年7月24日，来自</em><a class="ae le" href="https://ieeexplore.ieee.org/abstract/document/9006000" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://ieeexplore.ieee.org/abstract/document/9006000</em></a></p><p id="4b1a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="mx"> 16。</em> </strong> <em class="mx"> k-Means聚类— Michael Fuchs Python。</em><a class="ae le" href="https://michael-fuchs-python.netlify.app/2020/05/19/k-means-clustering/" rel="noopener ugc nofollow" target="_blank"><em class="mx">https://Michael-fuchs-python . netlify . app/2020/05/19/k-means-clustering/</em></a></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="c4df" class="me lh it bd li mf nk mh ll mi nl mk lo ml nm mn lr mo nn mq lu mr no mt lx mu bi translated">分级编码</h1><p id="09ed" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">感谢您成为我们社区的一员！在你离开之前:</p><ul class=""><li id="28a3" class="oi oj it js b jt ju jx jy kb ok kf ol kj om kn on oo op oq bi translated">👏为故事鼓掌，跟着作者走👉</li><li id="b72f" class="oi oj it js b jt or jx os kb ot kf ou kj ov kn on oo op oq bi translated">📰查看<a class="ae le" href="https://levelup.gitconnected.com/?utm_source=pub&amp;utm_medium=post" rel="noopener ugc nofollow" target="_blank">升级编码出版物</a>中的更多内容</li><li id="38b1" class="oi oj it js b jt or jx os kb ot kf ou kj ov kn on oo op oq bi translated">🔔关注我们:<a class="ae le" href="https://twitter.com/gitconnected" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae le" href="https://www.linkedin.com/company/gitconnected" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae le" href="https://newsletter.levelup.dev" rel="noopener ugc nofollow" target="_blank">时事通讯</a></li></ul><p id="a8d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🚀👉<a class="ae le" href="https://jobs.levelup.dev/talent/welcome?referral=true" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">加入升级达人集体，找到一份惊艳的工作</strong> </a></p></div></div>    
</body>
</html>