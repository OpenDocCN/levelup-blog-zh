<html>
<head>
<title>Performance Analysis of Text-Summary Generation Models Using ROUGE Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于ROUGE评分的文本摘要生成模型的性能分析</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/performance-analysis-of-text-summary-generation-models-using-rouge-score-72e4a8418df6?source=collection_archive---------6-----------------------#2022-02-18">https://levelup.gitconnected.com/performance-analysis-of-text-summary-generation-models-using-rouge-score-72e4a8418df6?source=collection_archive---------6-----------------------#2022-02-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="004a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何评价文本摘要模型的性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6ab19c5350ec86cfde34e42ea99c8b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*er17QSr7SQeen54ypE_ydQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">封面艺术:寻找给定文本的最佳摘要。(来源:图片由作者提供)</figcaption></figure><p id="6aa5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于大多数自然语言处理任务，我们使用最广泛和标准的度量标准，如准确性或f1分数。然而，对于文本摘要和文本翻译任务，这些度量在描述模型的性能方面不是很有帮助，因为这些度量不能直接用于文本序列来评估生成的摘要或机器翻译系统的输出的质量。因此，我们需要一个可以用来评估这些算法生成的摘要的指标。有几个性能指标来评估这种用例的性能，例如双语评估替角(蓝色)和面向回忆的替角(红色)。在这篇文章中，我们将只涉及胭脂分数。</p><h1 id="12b5" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">什么是胭脂度量？</h1><p id="c914" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">ROUGE是一组用于评估文本自动摘要和机器翻译的指标[1]。ROUGE度量标准有几种变体；然而，它们背后的基本思想是给一个摘要分配一个单一的数字分数，告诉我们它与一个或多个参考摘要相比有多好[2]。</p><p id="cf68" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，在图1所示的例子中，我们有一个电影“蝙蝠侠”的电影评论和一个模型生成的摘要。如果我们将生成的摘要与参考人类摘要进行比较，我们可以看到该模型表现良好，只有几个字的差异。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mo"><img src="../Images/b1662c1b5bb85bb00631f60babde4da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DKGWDRuW2dXJaYCRW17ezQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图一。机器生成的摘要和相应参考摘要的示例。(来源:图片由作者提供)</figcaption></figure><h1 id="8546" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">衡量生成的摘要的质量</h1><p id="cc3b" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">ROUGE将生成的摘要的n元语法与引用的n元语法进行比较。有几种类型的胭脂度量，如胭脂-1、胭脂-2、胭脂-1等。</p><p id="00ed" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了理解摘要是如何生成的，让我们看一下图2中的例句。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/751bc82d525ccf5c973a2a68eebc28ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kk8a_kFh6w82JOf0rRDdJw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图二。文本的机器生成和人工参考摘要。(来源:图片由作者提供)</figcaption></figure><h2 id="92fe" class="mq ls iq bd lt mr ms dn lx mt mu dp mb le mv mw md li mx my mf lm mz na mh nb bi translated">胭脂-1</h2><p id="dbc2" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">它比较机器生成的摘要和人类参考摘要之间的单字。对于ROUGE-1指标，我们有单独的召回率和精确度。</p><p id="6c91" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROUGE-1 recall是匹配的单词数(在机器生成的摘要和人类参考摘要中)与参考中的单词数的比率。因此，对于图2中的例子，ROUGE-1召回是5/5 = 1。现在出现了一个问题，只用胭脂-1召回就够了吗？答案是否定的！！！</p><p id="9a91" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果机器生成的总结如下:<br/> <em class="nc">我真的真的真的真的很喜欢看《蝙蝠侠》</em></p><p id="6a74" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，我们也将得到ROUGE-1召回为1。它有一个完美的回忆，但总结很糟糕。因此，我们也需要精确。</p><p id="ebcd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROUGE-1 precision是匹配的字数与摘要中的字数之比。因此，对于图2中的示例，ROUGE-1精度为5/6 = 0.83。</p><p id="e330" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们计算两者的调和平均值，也称为f1分数。<em class="nc">f1-得分= (2 x精确x召回)/(精确+召回)</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/013c2434af75b81da983070098031a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*11fxei_9bIf83-6SeDbZjg.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图3。每台机器生成的二元图和人工参考摘要。(来源:图片由作者提供)</figcaption></figure><h2 id="7ba8" class="mq ls iq bd lt mr ms dn lx mt mu dp mb le mv mw md li mx my mf lm mz na mh nb bi translated">胭脂-2</h2><p id="4b23" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">对于ROUGE-2，我们使用二元语法来代替一元语法。这里，我们也计算精度和召回率。考虑图2中提到的类似例子。首先，如图3所示，我们创建了二元语法，并使用与ROUGE-1相同的公式来计算精度和召回率。</p><p id="b396" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROUGE-2 recall是匹配的二元语法的数量与引用中的二元语法的数量之比。因此，对于图2中的例子，ROUGE-2的召回率是3/4 = 0.75。类似地，ROUGE-2精度是匹配的二元语法的数量与生成的摘要中的二元语法的数量之比。因此，对于图2中的示例，ROUGE-2精度为3/5 = 0.60。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/6ec26c997f4c47b95ac21cec71ef4701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ECMlQ1R3r2hwTNMBTh8RA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图4。机器生成和人类参考摘要之间的最长公共子序列(LCS)。(来源:图片由作者提供)</figcaption></figure><h2 id="213c" class="mq ls iq bd lt mr ms dn lx mt mu dp mb le mv mw md li mx my mf lm mz na mh nb bi translated"><strong class="ak">胭脂-L </strong></h2><p id="5855" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">ROUGE-L不比较n-grams；而是将每个摘要视为一个单词序列，然后寻找最长的公共子序列(LCS)。图4显示了机器生成的参考摘要和人工参考摘要之间的LCS。</p><p id="914f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROUGE-2召回率是LCS长度与参考摘要字数的比值。因此，对于图2中的例子，ROUGE-L召回是5/5 = 1。类似地，ROUGE-L精度是LCS的长度与生成的摘要中的字数之比。因此，对于图2中的示例，ROUGE-L精度为5/6 = 0.83。</p><p id="2762" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与ROUGE-1和ROUGE-2相比，使用ROUGE-L的优势在于它不依赖于连续的n元语法匹配，并且它倾向于更准确地捕捉句子结构。</p><h1 id="84bd" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论</h1><p id="3589" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这篇文章提到需要ROUGE度量来评估文本摘要模型的性能。此外，还举例讨论了三种不同类型的ROUGE度量。</p></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><h1 id="40f2" class="lr ls iq bd lt lu nm lw lx ly nn ma mb jw no jx md jz np ka mf kc nq kd mh mi bi translated">参考</h1><ol class=""><li id="5573" class="nr ns iq kx b ky mj lb mk le nt li nu lm nv lq nw nx ny nz bi translated">赛。林。" Rouge:一个自动评估摘要的包."在<em class="nc">文本摘要分支</em>，第74–81页。2004.</li><li id="52c0" class="nr ns iq kx b ky oa lb ob le oc li od lm oe lq nw nx ny nz bi translated">页（page的缩写）Singh，P. Chhikara和J. Singh，“一种用于摘录文本摘要的集成方法”，2020年信息技术和工程新兴趋势国际会议(ic-ETITE)，2020年，第1–7页。</li></ol></div></div>    
</body>
</html>