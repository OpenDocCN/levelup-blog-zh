# é›¶é•œå¤´åˆ†ç±»ç®€å†åˆ†æï¼Œnltk ç‰¹å¾æå–ï¼Œæ€ªç™–

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/r%C3%A9sum%C3%A9-analysis-with-zero-shot-classification-nltk-feature-extraction-the-quirks-d789425a2d59>

CV è§£ææ˜¯ä¸€ä¸ªé—®é¢˜é™ˆè¿°ï¼Œè¿«åˆ‡éœ€è¦èƒ½å¤Ÿçµæ´»å¤„ç†æ¨¡ç³Šå¤æ‚æ€§æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆã€‚CV æ ¼å¼ä»¤äººè®¨åŒçš„æ¨¡ç³Šæ€§åŠ å‰§äº†è¿™ç§æƒ…å†µï¼Œå¯¼è‡´æ–‡æœ¬æ··ä¹±ï¼Œä»è€Œé˜»ç¢äº†ä¸€è‡´è§£æ
ä»¥è¯†åˆ«ç‰¹å®šæ•°æ®å…ƒç´ çš„å°è¯•ã€‚

å› æ­¤ï¼Œè¿™ç¯‡æ–‡ç« è¯•å›¾ç ”ç©¶ä¸€äº›ç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥å¯èƒ½ä¼šæä¾›è®¿é—®è·¯å¾„ï¼Œä¸ºè§£æç»ƒä¹ çš„éšæœºæ€§å¸¦æ¥ä¸€äº›æ–¹æ³•ä¸Šçš„ç›¸ä¼¼æ€§ã€‚åœ¨å’Œä¸€äº› NLP åº“è°ƒæƒ…çš„æ—¶å€™ã€‚

å¤§å¤šæ•°ç®€å†è§£ææ–‡ç« æå‡ºä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥ç­›é€‰å‡ç»“çš„å¤§é‡å•è¯(åœ¨ PDF/DOC åˆ°æ–‡æœ¬è½¬æ¢ä¹‹å)ä»¥è·å¾—ç”µå­é‚®ä»¶ã€æ•°å­—ã€æŠ€èƒ½ç­‰ã€‚æœ¬æ–‡ä¸­çš„æ–¹æ³•æ—¨åœ¨åˆ†ç¦»ç®€å†ä¸­çš„å¥å­ï¼Œç„¶ååˆ†ææ¯ä¸ªå¥å­ä»¥ç¡®å®šä¸Šä¸‹æ–‡ï¼Œå®ƒæ˜¯å¦åŒ…å«å·¥ä½œç»å†ç®€ä»‹/å…¬å¸åç§°ã€æŠ€èƒ½ç»„åˆã€é›‡ä½£æœŸæˆ–åªæ˜¯é¡¹ç›®/è´£ä»»çš„ä»»æ„æ–‡æœ¬æè¿°ç­‰ã€‚

è¿™ä¸ºæœºå™¨å­¦ä¹ éå¸¸æ“…é•¿å¤„ç†çš„æ–‡æœ¬åˆ†ç±»ç»ƒä¹ å¥ å®šäº†åŸºç¡€ã€‚è¯·æ³¨æ„ï¼Œè¿™ç¯‡æ–‡ç« çš„ç›®çš„ä»…ä»…æ˜¯ä»‹ç»ç”¨ ML è§£å†³è¿™ä¸ªé—®é¢˜çš„æ›¿ä»£æ–¹æ³•â€”â€”æ„å»ºä¸€ä¸ªå®Œæ•´çš„äº§å“çº§è§£æå™¨çš„æœ€ç»ˆé€‰æ‹©å°†éœ€è¦å¤§é‡çš„å¾®è°ƒï¼Œå¹¶ä¸”å¯èƒ½æ¶‰åŠå„ç§æ–¹æ³•çš„ç»„åˆã€‚

æ‰€ä»¥è®©æˆ‘ä»¬æŠŠä¸€ä¸ªæ ‡å‡†çš„ç®€å†åˆ‡æˆå‡ è¡Œï¼Œæ¯ä¸€è¡Œéƒ½è¦è¿›è¡Œåˆ†ç±»ã€‚

é¦–å…ˆï¼Œæˆ‘å€¾å‘äºä½¿ç”¨é›¶é•œå¤´åˆ†ç±»è¿›è¡Œç¬¬ä¸€æ¬¡å°è¯•ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ NLP åˆ†ç±»ï¼Œå¾ˆå°‘æˆ–æ²¡æœ‰ä»»ä½•æ•°æ®é›†çš„è®­ç»ƒã€‚è¿™æ˜¯ä¸ºäº†é¿å…ç¹ççš„ä»»åŠ¡ï¼Œå³å¿…é¡»åˆ›å»ºå¸¦æœ‰æ‰‹åŠ¨æ³¨é‡Šçš„è®­ç»ƒæ•°æ®æˆ–ä½¿é¢„è§£æçš„æ ·æœ¬ä¸ç±»åˆ«åŒ¹é…ã€‚

åœ¨å¿«ç…§ä¸­ï¼Œé›¶é•œå¤´å­¦ä¹ æ˜¯æŒ‡åº”ç”¨é¢„å…ˆè®­ç»ƒçš„åˆ†ç±»å™¨æ¨¡å‹åœ¨å®ƒä»æœªè§è¿‡çš„æ–‡æœ¬åºåˆ—ä¸Šè¿è¡Œã€‚é›¶è·ç¦»åˆ†ç±»å™¨æ˜¯åŸºäº NLI(è‡ªç„¶è¯­è¨€æ¨ç†)çš„åŸåˆ™ï¼Œåœ¨ä¸€ä¸ªå¥å­ä¸­ï¼Œè¿™æ„å‘³ç€è§£é‡Šä¸€ä¸ªåºåˆ—æ¥é™å®š(éµå¾ª)æˆ–å¦å®šä¸€ä¸ªå‡è®¾(æŒ‡çš„æ˜¯ä¸€ä¸ªç±»åˆ«)ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥é€šè¿‡é›¶å‘½ä¸­ç‡åˆ†ç±»å™¨è¿è¡Œä»»ä½•æ–‡æœ¬æ ·æœ¬ï¼ŒåŒæ—¶ä¸ºå…¶æä¾›ä¸€äº›é¢„å®šä¹‰çš„ç±»å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œå¦‚ BART æˆ– Robertaï¼Œä»¥æŸ¥çœ‹åˆ†ç±»å™¨é¢„æµ‹çš„å¥å­ç±»å‹ã€‚

ä½†æ˜¯è®©æˆ‘ä»¬å…ˆå†™ä»£ç ï¼Œç„¶åå†è°ˆâ€¦çœ‹çœ‹å‡ è¡Œ zero shot æ˜¯å¦‚ä½•å¯¹ CV å¥å­è¿›è¡Œå¿«é€Ÿåˆ†ç±»çš„ã€‚

Requirements.txt æ¥å®‰è£…å¿…è¦çš„åº“â€¦å‰æå‡è®¾æ˜¯ç†Ÿæ‚‰ python å’Œ regexã€‚

```
numpy
pdfminer.six
transformers[torch]
nltk
```

ä½¿ç”¨çš„åº“æ˜¯ HuggingFace Transformersï¼Œä¸ºäº† CPU å‹å¥½ï¼Œç”¨ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ä»£æ›¿ã€‚

```
import re
import numpy as np
from pdfminer.high_level import extract_text
from transformers import pipelinelabels = ["date range or time period", "name of organization or company", "job title or designation", "programming languages", "software libraries", "educational institutes", "academic qualifications",  "project description"]
classifier = pipeline("zero-shot-classification",  model='cross-encoder/nli-distilroberta-base')def zero_shot_test(cv):
    cvtext = extract_text(cv)
    for text in cvtext.split("\n"):
        text = text.strip()
        text = re.sub("^[^A-Za-z0-9]","",text) 
        token_arr = re.split("(\t+|\s{4}|\|+|:)\s*", text) # a crude hack to split lines that have employment dates and company names in the same line
        for token in token_arr:
            token = token.strip()
            token = re.sub("^[^A-Za-z0-9]","",token)
            if len(token) > 0:
                res = classifier(token, labels)
                res_label = res["labels"][np.argmax(res["scores"])]
                print(f'text {token} is categorized as { res["labels"][np.argmax(res["scores"])] }')zero_shot_test("SomeCV.pdf")
```

ä¸‹é¢æ˜¯ä¸€äº›è¾“å‡ºç¤ºä¾‹-

-è®¾è®¡ã€å¼€å‘ã€ä¿®æ”¹ã€ç»´æŠ¤å’Œæ”¹è¿›ç½‘ç»œåº”ç”¨ç¨‹åºå’Œç§»åŠ¨åº”ç”¨ç¨‹åºã€‚è¢«å½’ç±»ä¸º*é¡¹ç›®æè¿°*
â€”â€”React-Nativeã€ReactJSã€NodeJSã€Android studioã€Xcode æ¡†æ¶ç­‰æŠ€æœ¯ã€‚è¢«å½’ç±»ä¸º*ç¼–ç¨‹è¯­è¨€*
â€”â€”HTMLã€CSSã€C++ã€JAVAã€jQueryã€Bootstrapã€Gitã€‚è¢«å½’ç±»ä¸º*ç¼–ç¨‹è¯­è¨€*
â€”â€”Oracleã€MySQLã€MongoDBã€‚è¢«å½’ç±»ä¸º*è½¯ä»¶åº“*
-å¯è§†åŒ–ä»£ç ã€Android studioã€XCodeã€Chrome è°ƒè¯•ã€Postman è¢«å½’ç±»ä¸º*ç¼–ç¨‹è¯­è¨€*
-2018 å¹´ 5 æœˆ-å·¥ä½œè¢«å½’ç±»ä¸º*æ—¥æœŸèŒƒå›´æˆ–æ—¶é—´æ®µ*
-6 æœˆ-9 æœˆ 18 æ—¥è¢«å½’ç±»ä¸º*æ—¥æœŸèŒƒå›´æˆ–æ—¶é—´æ®µ*
-å›½é™…ç§‘å­¦å¥¥æ—åŒ¹å…‹é“¶ç‰Œã€‚è¢«å½’ç±»ä¸º*å­¦å†*
-B . sc . 2018 å¹´ä»¥ 74.01%çš„æˆç»©ä»{ç¼–æ ¡}ä¿¡æ¯æŠ€æœ¯å­¦é™¢æ¯•ä¸šã€‚è¢«å½’ç±»ä¸º*æ•™è‚²æœºæ„*
-03/2019-ç›®å‰è¢«å½’ç±»ä¸º*æ—¥æœŸèŒƒå›´æˆ–æ—¶é—´æ®µ*
- JavaScriptã€Pythonã€C++ã€HTMLã€CSS è¢«å½’ç±»ä¸º*ç¼–ç¨‹è¯­è¨€*
-è®¡ç®—æœºç§‘å­¦ B.Tech è¢«å½’ç±»ä¸º*å­¦å†*

æˆ‘è§‰å¾—è¿™æ˜¯ä¸ªä¸é”™çš„å¼€ç«¯ã€‚è¿›ä¸€æ­¥çš„æ­¥éª¤å¯ä»¥å°†è¿™äº›åˆ†ç±»çš„è¡Œæä¾›ç»™ç†Ÿç»ƒçš„æ­£åˆ™è¡¨è¾¾å¼è§£æå™¨ï¼Œä»¥æå–æˆ‘ä»¬éœ€è¦çš„ç²¾ç¡® CV æ•°æ®å…ƒç´ ã€‚
ä½†è¿™é‡Œæœ‰å‡ ä¸ªå¤±è¯¯â€”â€”
ä¸ç°æœ‰å®¢æˆ·å’Œæ–°å®¢æˆ·å¯†åˆ‡åˆä½œï¼Œäº†è§£è¢«å½’ç±»ä¸º*ç»„ç»‡æˆ–å…¬å¸çš„åç§°*ã€‚ï¼ï¼

ç°åœ¨ï¼Œäººä»¬æ€»æ˜¯å¯ä»¥é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„å˜å‹å™¨æ¨¡å‹æ¥é‡‡å–å¦ä¸€ç§åˆ†ç±»æ–¹æ³•ï¼Œä½†å¦‚æœéœ€è¦è¿›ä¸€æ­¥è¿½æ±‚é›¶å‘½ä¸­ç‡ï¼Œåˆ™å¯ä»¥é€šè¿‡å¯¹æˆ‘ä»¬æä¾›ç»™åˆ†ç±»å™¨çš„æ ‡ç­¾è¿›è¡Œæ–‡æœ¬è°ƒæ•´æ¥æé«˜å‘½ä¸­ç‡ï¼Œä½¿å®ƒä»¬æ›´å¥½åœ°ä¸æ ·æœ¬å¥å­çš„æ›´æ˜æ˜¾æ€»ç»“ä¿æŒä¸€è‡´ã€‚

ä½†æ˜¯ç°åœ¨æˆ‘ä»¬å°†æŠŠè¿™ä¸ªä¸»é¢˜ç•™åœ¨è¿™é‡Œï¼Œå› ä¸ºæˆ‘ä»¬å°†æ”¹å˜è¯é¢˜ï¼Œå°è¯•å¦ä¸€ç§æ–¹æ³•ï¼Œè¿™ç§æ–¹æ³•å°†ä½¿æˆ‘ä»¬å¯¹åˆ†ç±»ç»ƒä¹ æœ‰æ›´å¤šçš„æ§åˆ¶ã€‚

æˆ‘ä»¬å°†å°è¯•é€šè¿‡ç‰¹å¾æå–è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼Œå›åˆ°æ¯” HuggingFace æ›´ç®€å•çš„åº“ï¼Œä»¥åŠåœ¨ç‰¹å¾å®šä¹‰åè¿›è¡Œåˆ†ç±»è®­ç»ƒçš„æ›´åŸºæœ¬çš„æ–¹æ³•ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬ç”¨ NLP å­¦è€…çš„å® å„¿ nltk æµ‹è¯•äº†(ç›¸å¯¹è¾ƒæµ…çš„)æ°´åŸŸã€‚è€å®è¯´ï¼Œè¿™ä¸æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œä½†ç›®æ ‡æ˜¯å°è¯•æ“ä½œå°†å†³å®šåˆ†ç±»ç»ƒä¹ çš„ç‰¹å¾ã€‚

åŒæ ·ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œå®ƒå°†ä¸€ä¸ªæ ·æœ¬è¡Œä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸ºè¯¥æ ·æœ¬æ„å»ºæœ‰èµ„æ ¼ä½œä¸ºâ€œç‰¹å¾â€çš„å†…å®¹ã€‚å…³äºç‰¹å¾æ„å»ºçš„å¿«é€Ÿè„šæ³¨:
å¦‚ä¸‹é¢çš„å‡½æ•°æ‰€ç¤ºï¼Œå®ƒå®šä¹‰äº†å“ªäº›ç‰¹å¾ä¸ç¡®å®šå¥å­çš„ç±»åˆ«ç›¸å…³ï¼Œä»¥åŠå¦‚ä½•å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œç¼–ç â€”â€”åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰ç®€å•å…³é”®å­—çš„ç‰¹å¾å­—å…¸ï¼Œè¿™äº›å…³é”®å­—ç¡®å®šå¥å­æ ·æœ¬çš„ä¸Šä¸‹æ–‡ã€‚è¿™å¯¼è‡´åˆ†ç±»å™¨ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ä¸€ä¸ªç›¸å¯¹å¹¼ç¨šçš„æœ´ç´ è´å¶æ–¯ï¼Œæ¥ç¡®å®šå¥å­çš„ç±»åˆ«ã€‚

```
def cv_features(sentence):
    features = dict()
    edu_pattern=r'([A-Z][a-z]+\s*(University|School|College))|((University|School|College)\s*[A-Z][a-z]+)'
    date_grammar = r"""
    DT: {<IN|JJ|NN|NNP><CD><.*>?<NN|NNP><CD>}
        {<CD><CD><.*>?<CD><CD>}
    """
    tokens = nltk.word_tokenize(sentence)
    tokens = [x for x in tokens if x not in stop_words ]
    if re.search('([A-Za-z0-9]+\s*,\s*){2,}',sentence):
        tokens = [ x for x in tokens if x != ',' ]
    tags = nltk.pos_tag(tokens)
    # chunking of POS tags to identify noun chunks and consequent NER's i.e. ORGANIZATION or DATE etc..
    ne_list =  [ (x[0][1], x.label())  for x in nltk.chunk.ne_chunk(tags) if hasattr(x, "label") ]
    if any (True for x in tokens if x.lower() in skills_set):
        features["technologies"] = True
        return features if any (True for (pos, label) in ne_list if label == 'ORGANIZATION' and pos == 'NNP'):
        features["organization"] = True
    if re.search(edu_pattern, sentence, re.IGNORECASE):
        features["educational institute"] = True
    if any (True for (pos, label) in ne_list if label == 'DATE' ):
        features["date"] = True
    if (not features):
        # RegExpParser works on groups of POS tags to match
        cp = nltk.RegexpParser(date_grammar)
        tree = cp.parse(nltk.pos_tag(nltk.word_tokenize(re.sub(r'[^A-Za-z0-9]',' ', sentence))))
        for subtree in tree.subtrees():
            if hasattr(subtree, "label") and subtree.label() == "DT":
                features["date"] = True
    if (not features):
        features["description"] = Truereturn features
```

è¿™äº›æ˜¯åŸºæœ¬çš„å‡½æ•°å’Œç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºæ£€æŸ¥å¥å­æ˜¯å¦åŒ…å«æ—¥æœŸï¼Ÿæ­£å¦‚ RegExpParser çš„åˆ†å—ç»ƒä¹ æ‰€å®šä¹‰çš„é‚£æ ·ã€‚è€å®è¯´ï¼Œè™½ç„¶åˆ†å—ä½¿ç”¨ POS æ ‡ç­¾æ¥åŒ¹é…æˆ‘ä»¬æƒ³è¦çš„ï¼Œä½†æˆ‘æ›´å–œæ¬¢ä½¿ç”¨æ™®é€šçš„æ­£åˆ™è¡¨è¾¾å¼æ¥æ£€æµ‹æ—¥æœŸï¼Œå› ä¸ºå®ƒæ›´å®¹æ˜“é¢„æµ‹ã€‚
nltk POS å¹¶ä¸æ€»æ˜¯å¯é çš„ï¼Œå› ä¸ºæœˆä»½åç§°å¯ä»¥è¢«è§£é‡Šä¸º NNã€NNP ç”šè‡³ JJ(åè¯æˆ–å½¢å®¹è¯)ã€‚ä¸å¤ªå¯é ï¼Œä½†è¿™é‡Œçš„ç›®çš„è¿˜æ˜¯æ¼”ç¤ºç‰¹æ€§æ„å»ºã€‚
â€”â€”ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬ä½¿ç”¨æ™®é€šçš„æ­£åˆ™è¡¨è¾¾å¼æˆ–å¸¦æœ‰ nltk çš„ NER æ ‡ç­¾æ¥çª¥æ¢æ•™è‚²æœºæ„å’Œå…¬å¸åç§°â€”â€”ç®€å•çš„ä¸œè¥¿ã€‚
-æŠ€æœ¯åç§°å¯ä»¥ä½¿ç”¨ä¸€ç»„æŠ€æœ¯æ ·æœ¬è¿›è¡ŒåŒ¹é…ï¼Œå¦‚

`skills_set = set([â€˜javaâ€™,â€™c++â€™,â€™câ€™,â€™pythonâ€™,â€™javascriptâ€™,â€™cassandraâ€™,â€™juliaâ€™, â€˜oracleâ€™,â€™mongodbâ€™,â€™.netâ€™â€¦â€¦â€¦â€¦â€¦..])`

å®Œæˆç‰¹å¾å®šä¹‰åï¼Œè®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ ·æœ¬è¯­æ–™åº“-

```
def train_corpus():
    global classifier
    train_arr=[]
    fp = open('cv_train_data.csv', 'r')
    for x in fp:
        rec = x.split(",")
        train_arr.append(( ",".join(rec[0:-1]), rec[-1:][0].strip() ))
    featuresets = [(cv_features(txt), category) for (txt, category) in train_arr]
    classifier = nltk.NaiveBayesClassifier.train(featuresets)
```

è®­ç»ƒç”¨çš„æ˜¯å¹³åŸã€‚CSV æ–‡ä»¶ï¼Œå¸¦æœ‰ CV çº¿æ ·æœ¬å’Œå®ƒçš„ç±»åˆ«ï¼Œç®€å•å¦‚-
`Jan 2019-Feb 2022,dates
C, Python, Java, .net, technologies
won 3rd prize in chess competition, description
IBM Corp.,organization ........`

åŒæ ·ï¼Œè¿™åªæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„åˆ—è¡¨ï¼Œæ‚¨å¯ä»¥å°†å…¶æ‰©å±•ä¸ºä¸€ä¸ªåŒ…å«æ›´å¤šç±»åˆ«çš„å®Œæ•´åˆ—è¡¨ï¼Œä½†æ˜¯ç‰¹å¾æå–å°†éœ€è¦ç­›é€‰æ–‡æœ¬ä¸­åæ˜ è¿™äº›é™„åŠ ç±»åˆ«çš„å…ƒç´ ã€‚

ç°åœ¨è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªæ ·æœ¬ CV è¿è¡Œè¿™ä¸ªï¼Œä½¿ç”¨ä¸é›¶é•œå¤´å®Œå…¨ç›¸åŒçš„å—â€”â€”åªæ˜¯æ›¿æ¢é›¶é•œå¤´åˆ†ç±»çš„ 2 è¡Œ

```
 res = classifier(token, labels)
    res_label = res["labels"][np.argmax(res["scores"])]
    print(f'text {token} is categorized as { res["labels"][np.argmax(res["scores"])] }')
```

éšç€

```
 res = classifier.classify(cv_features(token))
    print(f'text {token} is categorized as { res }')
```

ç„¶åçœ‹ä¸€äº›ç»“æœè¾“å‡ºï¼Œå¦‚æœæˆ‘ä»¬æ³¨æ„åˆ°çš„è¯ï¼Œå®ƒæ¯”é›¶ç‚®è¿è¡Œè¦å¿«å¾—å¤š

React-Nativeï¼ŒReactJSï¼ŒNodeJSï¼ŒJavaScriptï¼ŒClojurescriptï¼ŒSQLï¼ŒNOSQLã€‚C è¢«å½’ç±»ä¸º*æŠ€æœ¯*
HTMLï¼ŒCSSï¼ŒC++ï¼ŒJAVAï¼ŒjQueryï¼ŒBootstrapï¼ŒGitã€‚è¢«å½’ç±»ä¸º*æŠ€æœ¯*
2014 å¹´ 6 æœˆ-2018 å¹´ 6 æœˆè¢«å½’ç±»ä¸º*æ—¥æœŸ*
2016 å¹´ 9 æœˆâ€”2017 å¹´ 10 æœˆè¢«å½’ç±»ä¸º*æ—¥æœŸ*
B.Sc.IT äº 2018 å¹´ä»¥ 74.01%çš„æˆç»©ä»{ Redacted }ä¿¡æ¯æŠ€æœ¯å­¦é™¢æ¯•ä¸šã€‚è¢«å½’ç±»ä¸º*æ•™è‚²å­¦é™¢*
æ—¶é—´ç›‘æ§åº”ç”¨ç¨‹åºå°±åƒä¸€ä¸ªç”Ÿç‰©è¯†åˆ«åº”ç”¨ç¨‹åºï¼Œé›‡ä¸»æ¯å¤©è¿›å‡ºè¢«å½’ç±»ä¸º*æè¿°*

ç°åœ¨ä¸€äº›çœŸæ­£çš„å¤§å¤±è¯¯â€”â€”
Reactâ€”â€”Nativeã€ReactJSã€NodeJSã€Android studioã€Xcode æ¡†æ¶ç­‰æŠ€æœ¯ã€‚è¢«å½’ç±»ä¸º*ç»„ç»‡*
åœ¨æ•´ä¸ªè½¯ä»¶è¿‡ç¨‹ä¸­ç§¯æåè°ƒ UI å›¢é˜Ÿã€æµ‹è¯•å›¢é˜Ÿã€ç»ç†ã€åŒäº‹æˆå‘˜è¢«å½’ç±»ä¸º*ç»„ç»‡*

è¿™æ˜¯å› ä¸º nltk çš„ NER åˆ†ç±»å°†è®¸å¤šæŠ€æœ¯åç§°è¯†åˆ«ä¸º ORG çš„ã€‚äººä»¬ä¼šæ³¨æ„åˆ°è¿™é‡Œé¢æœ‰è®¸å¤šä¸ç€è¾¹é™…çš„é¢„æµ‹ï¼Œå› ä¸º NER åœ¨ nltk ä¸­å¯ä»¥æŠ›å‡ºè’è°¬çš„ä¸œè¥¿ï¼Œå°±åƒä»–ä»¬ä¹‹å‰å¯¹æœˆä»½åç§°æ‰€åšçš„é‚£æ ·ã€‚

æˆ‘ä»¬çœ‹åˆ°é›¶é•œå¤´åœ¨ä¸»è¦ç±»åˆ«ä¸­å·¥ä½œå¾—æ›´å¥½ï¼Œä½†æ˜¯ nltk åˆ†ç±»åœ¨è¿™é‡Œä»…ä»…æ˜¯ä¸ºäº†æ˜¾ç¤ºç‰¹å¾æå–çš„ç®€æ˜“æ€§ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨ nltk çš„åˆ†ç±»ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨æ‚¨è‡ªå·±çš„ç‰¹å¾æå–å—ï¼Œä½¿ç”¨æ¯”è¿™é‡Œä»‹ç»çš„æ›´å¤æ‚çš„æ–¹æ³•æå–ç‰¹å¾å­—å…¸å…ƒç´ ã€‚
ç±»ä¼¼åœ°ï¼Œå»ºè®®ä½¿ç”¨å¦ä¸€ä¸ª NER è§£æå™¨ï¼ŒPOS taggerï¼Œç›´è§‚è„šæœ¬æ¥ç¡®å®šå’Œå¡«å……ç‰¹å¾å­—å…¸ï¼Œè€Œä¸æ˜¯ nltk çš„åè¯åˆ†å—ï¼Œå› ä¸ºåè€…ä¸å‡†ç¡®ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬è°ˆåˆ°äº†ä¸¤ç§ CV æ›²çº¿åˆ†ææ–¹æ³•ï¼Œå®ƒä»¬ä»æ–¹æ³•å’ŒåŠªåŠ›çš„è§’åº¦æ¥çœ‹éƒ½éå¸¸ä¸åŒã€‚å¦‚æœæˆ‘å¿…é¡»å»ºè®®ä¸€ä¸ªäº§å“çº§çš„è§£æï¼Œæˆ‘ä¼šå¼ºçƒˆæ¨è Spacyï¼Œè¿™æ˜¯æˆ‘ä¸ªäººæœ€å–œæ¬¢çš„è‡ªç„¶è¯­è¨€ã€‚

ä½†è¿™ä¸€ç‚¹å°†ç•™å¾…ä¸‹æ¬¡è®¨è®ºï¼

# åˆ†çº§ç¼–ç 

æ„Ÿè°¢æ‚¨æˆä¸ºæˆ‘ä»¬ç¤¾åŒºçš„ä¸€å‘˜ï¼åœ¨ä½ ç¦»å¼€ä¹‹å‰:

*   ğŸ‘ä¸ºæ•…äº‹é¼“æŒï¼Œè·Ÿç€ä½œè€…èµ°ğŸ‘‰
*   ğŸ“°æŸ¥çœ‹[å‡çº§ç¼–ç å‡ºç‰ˆç‰©](https://levelup.gitconnected.com/?utm_source=pub&utm_medium=post)ä¸­çš„æ›´å¤šå†…å®¹
*   ğŸ””å…³æ³¨æˆ‘ä»¬:[Twitter](https://twitter.com/gitconnected)|[LinkedIn](https://www.linkedin.com/company/gitconnected)|[æ—¶äº‹é€šè®¯](https://newsletter.levelup.dev)

ğŸš€ğŸ‘‰ [**åŠ å…¥å‡çº§äººæ‰é›†ä½“ï¼Œæ‰¾åˆ°ä¸€ä»½ç¥å¥‡çš„å·¥ä½œ**](https://jobs.levelup.dev/talent/welcome?referral=true)