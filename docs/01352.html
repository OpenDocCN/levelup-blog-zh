<html>
<head>
<title>AWS Tricks: RAID0 with EBS volumes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS技巧:带EBS卷的RAID0</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/aws-tricks-raid0-with-ebs-volumes-aff5ccac88bf?source=collection_archive---------7-----------------------#2019-12-16">https://levelup.gitconnected.com/aws-tricks-raid0-with-ebs-volumes-aff5ccac88bf?source=collection_archive---------7-----------------------#2019-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a8125a6881d9cefed4496e015d0be34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pxDLTCZZt9-YAZOg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">帕特里克·林登伯格(Patrick Lindenberg)在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片——固态硬盘的照片看起来就没那么酷了。</figcaption></figure><p id="53c7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(更新2021:这项技术不再相关。如果您需要额外的IOPS或吞吐量，您更适合使用gp3。)</p><p id="4961" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">今年早些时候，我帮助在EC2实例上对gunicorn应用程序进行了负载测试。这是运行现代Linux发行版的第五代EC2实例，gunicorn在单个<a class="ae kc" href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ebs-volume-types.html" rel="noopener ugc nofollow" target="_blank"> EBS gp2 </a>卷上写日志文件。令我们惊讶的是，我们注意到在记录到磁盘上的文件时，它是I/O绑定的。</p><p id="217d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">甚至</em>更令人惊讶的是，将EC2实例更改为在两个EBS卷上使用RAID0配置<em class="lb">效果非常好</em>，我们能够将该EC2实例上的gunicorn工作线程数量增加一倍，直到它达到下一个限制因素。</p><h2 id="786b" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">Python中的日志记录是同步的</h2><p id="d129" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在Python 2和Python 3中，默认的日志处理程序是同步的和I/O阻塞的。记住这一点很重要。此外，StreamHandler还将<a class="ae kc" href="https://github.com/python/cpython/blob/master/Lib/logging/__init__.py#L1058-L1067" rel="noopener ugc nofollow" target="_blank">获取一个锁</a>，用于阻塞写入的持续时间。这对于延迟和并发性来说是个坏消息，尤其是如果您有一个多线程应用程序，它通过一个共享的<a class="ae kc" href="https://github.com/python/cpython/blob/master/Lib/logging/__init__.py#L1121" rel="noopener ugc nofollow" target="_blank"> FileHandler </a>写入磁盘上的一个日志文件。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="c29a" class="lc ld iq mf b gy mj mk l ml mm">def flush(self):<br/>    """<br/>    Flushes the stream.<br/>    """<br/>    self.acquire()<br/>    try:<br/>        if self.stream and hasattr(self.stream, "flush"):<br/>            self.stream.flush()<br/>    finally:<br/>        self.release()</span></pre><p id="94f1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有几种方法可以将应用程序迁移到异步日志，比如使用Python 3中内置的<a class="ae kc" href="https://docs.python.org/3.2/library/logging.handlers.html#queuelistener" rel="noopener ugc nofollow" target="_blank"> QueueHandler </a>、<a class="ae kc" href="https://github.com/B2W-BIT/aiologger" rel="noopener ugc nofollow" target="_blank"> aiologger </a>、logbook的<a class="ae kc" href="https://logbook.readthedocs.io/en/stable/api/queues.html#logbook.queues.ThreadedWrapperHandler" rel="noopener ugc nofollow" target="_blank"> ThreadedWrapperHandler、</a>一些更激烈的方法，比如<a class="ae kc" href="https://logbook.readthedocs.io/en/stable/api/queues.html#zeromq" rel="noopener ugc nofollow" target="_blank"> ZeroMQHandler </a>。尽管如此，其中一些需要对调用点进行重大更改，而QueueHandler只在Python 3.2中可用。不是所有人都那么幸运。</p><h2 id="9398" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">gevent不在磁盘I/O上切换</h2><p id="5750" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我意识到，当我第一次了解gevent时，我只是简单地记住了“gevent在遇到阻塞I/O时会切换greenlets”。我还愚蠢地假设阻塞I/O包括磁盘I/O(很明显)，但从未真正测试过我的理解。</p><p id="467c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我花了一段时间才注意到gevent文档中的所有例子都使用了网络套接字<em class="lb">例如</em>查询DNS，或者写入TCP套接字。</p><figure class="ma mb mc md gt jr"><div class="bz fp l di"><div class="mn mo l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">写入磁盘I/O不会切换greenlets。</figcaption></figure><p id="e08b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原来gevent在写入磁盘时并不切换greenlets。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="bdee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当gunicorn与gevent workers一起使用时，这意味着同一进程中的所有greenlets是:</p><ul class=""><li id="819b" class="mw mx iq kf b kg kh kk kl ko my ks mz kw na la nb nc nd ne bi translated">使用共享FileHandler追加到同一个日志文件中，</li><li id="e18a" class="mw mx iq kf b kg nf kk ng ko nh ks ni kw nj la nb nc nd ne bi translated">在写入磁盘之前获取互斥体，</li><li id="f0a5" class="mw mx iq kf b kg nf kk ng ko nh ks ni kw nj la nb nc nd ne bi translated">在等待冲洗完成的同时保持锁定，以及</li><li id="56c6" class="mw mx iq kf b kg nf kk ng ko nh ks ni kw nj la nb nc nd ne bi translated">在通过EBS网络发送字节时暂停。</li></ul><p id="270d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每次调用<code class="fe nk nl nm mf b">logger.info</code>时都会发生这种情况，而另一端的客户端正在等待HTTP响应。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/b1c8d2f86e296691f0e50e535e72052c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HNexNqpnK15bOyzM"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk translated">Christian Fregnan 在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h2 id="8538" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">资源视角:解读CloudWatch</h2><p id="b519" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在尝试优化日志记录器之前，我们希望在CloudWatch上明确证明我们在单个EBS卷上达到了资源限制。这种努力是徒劳的。<code class="fe nk nl nm mf b">VolumeQueueLength</code>、<code class="fe nk nl nm mf b">VolumeWriteBytes</code>和<code class="fe nk nl nm mf b">VolumeWriteOps</code>指标有损耗(可能是抽样的？)，并且经常无法捕获我们正在寻找的短暂I/O峰值。此外，我们在图表中找不到任何天花板或平台，这表明我们达到了一些EBS上限。我们也没有动用我们的<code class="fe nk nl nm mf b">BurstBalance</code>。</p><p id="4abf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们后来了解到，EC2和EBS都有多层限制，这使研究变得混乱。</p><ul class=""><li id="bf56" class="mw mx iq kf b kg kh kk kl ko my ks mz kw na la nb nc nd ne bi translated">每个<a class="ae kc" href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ebs-volume-types.html" rel="noopener ugc nofollow" target="_blank"> EBS卷都受到IOPs(每GiB 3 IOPS)和吞吐量(250 MiB/s)的限制</a>，这取决于I/O大小和卷大小。</li><li id="cfcf" class="mw mx iq kf b kg nf kk ng ko nh ks ni kw nj la nb nc nd ne bi translated">每个<a class="ae kc" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-optimized.html" rel="noopener ugc nofollow" target="_blank"> EC2实例都受到IOPs和吞吐量的限制</a>，这些也取决于I/O大小和实例大小。</li></ul><p id="c27b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于小于<code class="fe nk nl nm mf b">4xlarge</code>的EC2实例，吞吐量限制有以下警告:</p><blockquote class="no np nq"><p id="8bc5" class="kd ke lb kf b kg kh ki kj kk kl km kn nr kp kq kr ns kt ku kv nt kx ky kz la ij bi translated">这些实例类型每24小时至少可以支持30分钟的最高性能。如果您的工作负荷需要持续30分钟以上的最高性能，请根据下表所示的基准性能选择一个实例类型。</p></blockquote><p id="7a6a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，我们发现随着负载测试的增加，平均写入延迟(毫秒/操作)增加，这是EBS上资源争用的迹象。也有足够的线索可以推断，在一些HTTP请求中，gunicorn向磁盘发出了足够多的写入，达到了单个EBS卷的吞吐量限制(但不是IOPs限制)。这些峰值通常持续不到1秒，但足以导致受影响请求的响应时间下降。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="eb91" class="lc ld iq mf b gy mj mk l ml mm">Avg Write Latency = <!-- -->(Sum(VolumeTotalWriteTime) / Sum(VolumeWriteOps)) * 1000</span></pre><h2 id="f1ba" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">工作负载视角:分析主机</h2><p id="344b" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在EC2实例上，我们运行了经典工具(iostat、dstat、iotop ),并努力隔离问题。我们已经知道<code class="fe nk nl nm mf b">%iowait</code>很高；具体来说，我们希望确定使用磁盘I/O的进程，以及我们需要的写吞吐量，以便我们可以适当地调整EBS卷的大小。</p><p id="d6b3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些工具提供了进一步的证据来支持我们的假设，即gunicorn的磁盘写入量短暂超过EBS限制，并且还帮助我们识别和减少浪费，例如来自辅助进程的磁盘写入(<em class="lb">例如</em> sendmail)，以及重复日志记录(<em class="lb">例如</em> supervisord日志记录、docker日志记录)。</p><p id="c699" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我也尝试使用<a class="ae kc" href="http://www.brendangregg.com/Perf/bpf_book_tools.png" rel="noopener ugc nofollow" target="_blank">新的bpf工具，</a>但是对bpf的理解不足以解释和使用结果。</p><h2 id="c336" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">RAID0来救援</h2><p id="1592" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">针对EBS吞吐量限制的建议解决方法是<a class="ae kc" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/raid-config.html" rel="noopener ugc nofollow" target="_blank">将RAID0 </a>与mdadm配合使用，以便在多个EBS卷之间进行条带化写入。每个EBS卷的大小都应该能够提供最大250 MiB/s的吞吐量。条带化使应用程序可用的总写入吞吐量翻倍，但也增加了系统故障的可能性，因为当任何一个条带化的EBS卷出现故障时，整个装载都会失败。</p><p id="6ee2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个合理的替代方案是使用ZFS进行条带化，而不是mdadm/ext4。事实上，通过在ZFS <em class="lb">启用压缩，即</em>在将数据块发送到EBS之前对其进行压缩，ZFS可以进一步降低所需的写入吞吐量。这需要CPU，非常适合受I/O限制且未充分利用主机上可用CPU资源的应用程序。</p><h2 id="feae" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">参考</h2><ul class=""><li id="32bd" class="mw mx iq kf b kg lv kk lw ko nu ks nv kw nw la nb nc nd ne bi translated"><a class="ae kc" href="https://www.rhythmictech.com/blog/aws/understanding-gp2-volume-performance/" rel="noopener ugc nofollow" target="_blank">https://www . rhytrifice tech . com/blog/AWS/understanding-GP2-volume-performance/</a></li></ul></div></div>    
</body>
</html>