<html>
<head>
<title>Creating an iOS AR app using the AR Quick Look API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AR快速查看API创建iOS AR应用程序</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/creating-an-ios-ar-app-using-the-ar-quick-look-api-fe31aede5267?source=collection_archive---------6-----------------------#2021-12-27">https://levelup.gitconnected.com/creating-an-ios-ar-app-using-the-ar-quick-look-api-fe31aede5267?source=collection_archive---------6-----------------------#2021-12-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2e709f11820bf401304f4440d400985e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQHQHzDbloEw0qrQezX7LA.jpeg"/></div></div></figure><p id="4f5c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用iOS/iPadOS AR Quick Look API，你可以用很少几行Swift代码创建一个iOS/iPadOS的AR应用。</p><p id="287c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我将带您了解为AR准备3D数据、创建动画和交互式AR场景以及使用AR Quick Look API开发AR应用程序的过程。</p><ol class=""><li id="658f" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka ir"> 3D数据准备</strong>:使用计算机视觉处理(摄影测量)从真实物体的照片生成3D数据。</li><li id="1c5d" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir"> AR场景创建</strong>:放置虚拟物体，通过GUI直观地创建具有动画和交互性的AR场景。</li><li id="1516" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir"> AR应用创建</strong>:使用Swift代码创建一个AR应用，该代码使用AR Quick Look API。</li></ol><h1 id="5584" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">AR快速查看的基础</h1><p id="9c31" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">在解释开发过程之前，我们先来回顾一下AR Quick Look (ARQL)。<br/> ARQL是快速查看功能的AR版本，在WWDC18上宣布用于iOS 12和更高版本。它允许你从Safari、邮件、消息、文件等在AR中显示3D虚拟模型。此外，ARQL特性以API的形式提供，因此您可以在自己的应用程序中使用它们。</p><p id="8dfb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ARQL的主要特点是</p><ol class=""><li id="c47b" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">虚拟3D模型可以放置在水平面、垂直面、面部或图像上，手势可用于改变位置、大小、旋转和高度(双指滑动)。</li><li id="d508" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">支持USDZ和REALITY文件。如果它们包含动画或交互数据，它将被执行。WWDC18上展示的ARQL 3D数据指南:100k多边形，一组2048 x 2048 PBR纹理，10秒动画。</li><li id="b071" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">基于物理的渲染(PBR ),用于反映虚拟对象表面材质的真实渲染。<br/>支持的纹理类型:反照率、金属、粗糙、正常、环境遮挡、发射<br/>纹理数据根据执行设备的能力自动缩减采样。</li><li id="ce95" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">相机图像和虚拟对象以看起来自然的方式被组合和显示。<br/>从一开始，环境纹理和接触阴影就被用来创建一个真实的场景。在WWDC19上推出的RealityKit中添加了光线跟踪阴影、相机噪声、人物遮挡、景深和运动模糊，以使显示器更熟悉相机图像和真实场景。</li></ol><p id="f098" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ARQL提供的高级AR显示功能取决于设备的功能。例如，对象遮挡仅在激光雷达设备上有效，光线跟踪阴影仅在A12+ SoC设备上可用。这种设备能力的确定是自动的，并且显示是针对该设备优化的。使用ARQL API时也是如此。您根本不需要检查设备功能，您可以将一切交给ARQL API。</p><p id="038f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将支持ARQL的文件放在网页链接中并在Safari或Web View组件中显示它，或者在支持ARQL的标准应用程序中打开它是非常容易的。另一方面，如果您不想直接显示3d数据文件，或者如果AR只是应用程序功能的一部分，而主要功能在其他地方，您可以创建一个应用程序，并将数据文件存储在其内部包或本地文件中以保护它们。可以使用ARQL API用更少的代码创建AR app。</p><h1 id="f6a3" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">1 -准备3D数据</h1><p id="d069" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">第一步是准备3D数据。通常，3D数据是使用用于3DCG的DCC(数字内容创建)工具创建的。另一种方法是拍摄真实对象的照片，并通过计算机视觉处理(摄影测量)生成3D数据。苹果为iPhone/iPad提供了一个样本应用程序来拍照，并为Mac提供了一个样本命令行工具来运行摄影测量。</p><p id="f53b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然更常见的是使用DCC工具来准备3D数据，但摄影测量允许您从手头的真实对象生成逼真的3D数据，因此它是一种即使您没有3D建模技能也可以采用的方法。使用摄影测量的方法并不容易，因为它需要大量的时间和精力来拍照和处理数据，但在重复几次过程后，你会逐渐掌握它的窍门，并能够轻松地做到这一点。</p><p id="f9a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从现在开始，我们将使用Apple提供的摄影测量工具来准备3D数据。</p><h1 id="0b51" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">1 - 1拍摄实物照片</h1><p id="b9dc" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">我们拍摄了大约20到200张真实物体的照片，并将其转换成3D数据。这些照片将由计算机视觉处理，以生成3D数据。使用苹果公司提供的iPhone/iPad示例应用程序拍照很方便。</p><ul class=""><li id="000e" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">苹果示例代码:<a class="ae mo" href="https://developer.apple.com/documentation/realitykit/taking_pictures_for_3d_object_capture" rel="noopener ugc nofollow" target="_blank">为3D物体捕捉拍照</a></li><li id="8164" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv mn lc ld le bi translated">Xcode 13.0+，iOS/iPadOS 15.0+，带双后置摄像头的设备</li></ul><p id="9ea0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">获取示例代码(一组Xcode项目)并用Xcode构建它以创建CaptureSample应用程序。在兼容的iPhone/iPad上运行该应用程序，并连续拍摄真实物体各个方向的许多照片。使用CaptureSample应用程序的功能定期拍摄一系列照片非常方便。包含深度信息和相关文件的多个HEIC文件存储在CaptureSample应用程序的Document文件夹中。深度信息可用于生成再现实际物体的大小(尺寸)的数据。将照片存储在文件夹中的操作有点混乱，但如果您通过按文件夹屏幕上的“+”按钮创建一个新会话，您已经拍摄的照片集将会保存在文件夹中。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/549ba7df1da6a8d004382320be70db97.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*HE1RvHNKd0PaufYAWdGFHw.png"/></div></div></figure><p id="7493" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">WWDC21上介绍了一些如何拍摄真实物体的技巧。(CaptureSample app的帮助画面里也有说明。)</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/1e72f1823ad81e1421699271e815ea32.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*ZDkyuw1YL5SPs11mGR2_FQ.png"/></div></div></figure><ol class=""><li id="b3a6" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">使用简单的背景。设置照明，使真实物体上没有阴影。</li><li id="2966" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">真实的物体应该是不透明的，几乎没有表面反射。</li><li id="c85f" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">当改变其方向时，注意不要改变真实对象的形状。</li><li id="6d4f" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">从各个角度拍摄大约20到200张照片，重叠部分超过70%。</li></ol><p id="4096" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">建议拍100张以上，效果更好。更多信息，请参考这篇文章。</p><ul class=""><li id="675f" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">苹果文章:<a class="ae mo" href="https://developer.apple.com/documentation/realitykit/capturing_photographs_for_realitykit_object_capture" rel="noopener ugc nofollow" target="_blank">为RealityKit对象捕捉捕捉照片</a></li></ul><p id="0087" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于摄影测量过程是在Mac上执行的，请使用“文件”应用程序通过隔空投送或iCloud将存储的文件夹拷贝到Mac上。</p><h1 id="c9e6" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">1 - 2利用摄影测量生成3D数据</h1><p id="d2a3" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">摄影测量是从2D图像生成3D数据的计算机视觉过程。虽然有专门用于这个目的的软件，但RealityKit - Object Capture API从macOS 12开始就有了，苹果也提供了样本代码，所以你可以很容易地在你的Mac上运行它。</p><ul class=""><li id="5c2e" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">苹果示例代码:<a class="ae mo" href="https://developer.apple.com/documentation/realitykit/creating_a_photogrammetry_command-line_app" rel="noopener ugc nofollow" target="_blank">创建摄影测量命令行应用</a></li><li id="19bd" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv mn lc ld le bi translated">macOS 12.0+，Xcode 13.0+，全Apple Silicon Mac或AMD GPU(4MB)和16MB RAM Intel Mac</li></ul><p id="bc1c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你得到样本代码(一组Xcode项目)并用Xcode构建，你会有一个命令行工具叫做HelloPhotogrammetry。将它复制到您的工作文件夹中，使用起来很简单。在工作文件夹中，放入您拍摄的照片所在的文件夹。当您运行命令行工具时，它将以USDZ格式输出3D数据。</p><p id="edd8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在运行时，指定以下参数:<br/>(照片文件夹)、输出文件名(要输出的USDZ文件的名称)、细节(细节级别)、样本排序(照片在空间上是否连续)和特征敏感度(目标的特征敏感度)。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="53d0" class="mz ll iq mv b gy na nb l nc nd">% ./<strong class="mv ir">HelloPhotogrammetry</strong> -h<br/>OVERVIEW: Reconstructs 3D USDZ model from a folder of images. </span><span id="644e" class="mz ll iq mv b gy ne nb l nc nd">USAGE: hello-photogrammetry &lt;input-folder&gt; &lt;output-filename&gt; [--detail &lt;detail&gt;] [--sample-ordering &lt;sample-ordering&gt;] [--feature-sensitivity &lt;feature-sensitivity&gt;]  </span><span id="5298" class="mz ll iq mv b gy ne nb l nc nd">ARGUMENTS:<br/>   &lt;input-folder&gt;          The local input file folder of images.<br/>   &lt;output-filename&gt;       Full path to the USDZ output file.  </span><span id="87ff" class="mz ll iq mv b gy ne nb l nc nd">OPTIONS:<br/>   -d, --detail &lt;detail&gt;<br/>       detail {preview, reduced, medium, full, raw}  Detail of<br/>       output model in terms of mesh size and texture size . <br/>       (default: nil)<br/>   -o, --sample-ordering &lt;sample-ordering&gt;<br/>       sampleOrdering {unordered, sequential} Setting to sequential<br/>       may speed up computation if images are captured in a<br/>       spatially sequential pattern.<br/>   -f, --feature-sensitivity &lt;feature-sensitivity&gt;<br/>       featureSensitivity {normal, high}  Set to high if the scanned<br/>       object does not contain a lot of discernible structures,<br/>       edges or textures.<br/>   -h, --help              Show help information.</span></pre><p id="974b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">detail参数指定要生成的3D模型数据的详细程度。详细程度越高，再现性越好，但数据量也越大。完整和原始参数用于需要高质量数据(五种纹理或原始数据)的专业工作流程。对于ARQL，使用简化或中等。几何网格和纹理(漫射、法线、环境遮挡- AO)以USDZ格式输出，大小适合移动应用程序。Reduced被认为是web分发的最佳选择，因为它的数据量较小。中等被认为是复杂对象和应用程序的最佳选择。</p><p id="726d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果拍摄的照片在空间上是连续的，添加“-o sequential”将会加快这个过程。如果工具运行结束后没有输出USDZ文件，添加或删除`-o sequential '可能会成功。</p><p id="aed9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">生成的USDZ文件可以在macOS上的Quick Look中轻松查看。如果质量不够好，例如形状(网格)断裂或纹理不连续，可能会通过增加照片数量或重叠区域来改善。</p><p id="11cf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用CaptureSample应用程序(166张照片)拍摄了一个圣诞老人装饰品(11 x 7 x 7 cm ),并使用HelloPhotogrammetry工具进行了处理，结果预览版的USDZ文件大小为2MB，缩小版为9.4MB，中版为28MB。</p><p id="ef11" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">中等水平的执行示例:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="f0eb" class="mz ll iq mv b gy na nb l nc nd">% ./HelloPhotogrammetry SantaImages santa_m.usdz -d medium<br/> -o sequential</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/544f195a350075f385942d6dceadf9fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*MVKVsqlyUMDvSDqXV4Y5iA.png"/></div></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a4375bb11c3beacff0ae955e70ee4ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*lJudAbBe0gl1V3EABFnIJw.png"/></div></figure><p id="a345" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由medium生成的USDZ纹理(漫射、正常、AO)的分辨率均为4096 x 4096 [px]。Reduced的分辨率为2048 x 2048 [px]，符合ARQL准则。</p><p id="dfa2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用DCC tool - Blender 3.0检查网格数，介质的网格为顶点:约25，000，面:约50，000。简化的网格是顶点:大约12，000，面:大约24，000。</p><p id="fc68" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然我们已经使用摄影测量学准备了3D数据，我们将使用medium生成的USDZ文件来创建AR场景。</p><h1 id="8189" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">2 -创建一个AR场景</h1><p id="c566" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">虽然您可以简单地使用ARQL API在AR中显示USDZ文件，但您可以使用Reality Composer来合成具有多个USDZ文件的场景，并指定虚拟对象相对于现实世界的排列方式(平面、垂直等)。).Reality Composer是在WWDC19上与RealityKit一起推出的开发工具，可用于macOS和iPadOS。常见的是先在Mac上创建一个场景，然后在iPad上检查和修改AR显示。</p><p id="8546" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Reality Composer将AR场景输出为Reality或rcproject文件。ARQL可以打开现实文件进行AR展示，所以可以像USDZ一样作为交换格式。reality文件针对RealityKit进行了优化，因此文件较小，性能优于USDZ。在WWDC20上，随着从Reality Composer导出USDZ文件的功能的发布，还可以将Reality Composer中创建的内容返回到DCC工具，以调整工作流程中的3D数据。将在Reality Composer中创建的AR场景引入Xcode时，使用标准的Reality Composer rcproject文件格式会更有效。</p><p id="4614" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在使用ARQL API的AR应用程序中，应用程序将简单地播放和执行在Reality Composer中创建的AR场景。没有其他编程控制。换句话说，AR应用程序显示的AR场景和交互性都是在Reality Composer中创建的，并作为文件嵌入到应用程序中。正因为如此，AR app程序会非常简单，独立于AR场景。</p><p id="9553" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Reality Composer功能丰富，足以创建具有复杂行为的AR场景，但使用起来也足够直观。使用拖放放置虚拟对象，使用GUI设计动画和交互等行为。有关如何使用它的详细信息，请查看WWDC19上的Reality Composer介绍视频。</p><ul class=""><li id="fffc" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">WWDC19视频:<a class="ae mo" href="https://developer.apple.com/videos/play/wwdc2019/609/" rel="noopener ugc nofollow" target="_blank">使用Reality Composer构建AR体验</a></li></ul><p id="9c51" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将使用之前准备的圣诞老人的USDZ文件创建一个AR场景。从Xcode中的菜单“打开开发者工具&gt; Reality Composer”启动Reality Composer。(添加到Dock，下次启动会更方便。)在“选择锚点”对话框中，选择您希望虚拟对象与现实世界中的哪个位置相关联。按照这个规范，ARQL会显示AR。在这种情况下，我们选择“垂直”将圣诞老人放置在垂直表面上，如墙壁。</p><p id="77cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，将我们之前准备好的圣诞老人的USDZ文件(中等大小的文件)拖放到屏幕中央。这将把USDZ加载到Reality Composer中。旋转圣诞老人来调整他的脸的方向。圣诞老人是一个小的扫描雕像，因此要使它比AR显示的默认大小稍大一点，请选择圣诞老人，按属性按钮，并将变换-缩放属性设置为600 %以将其放大6倍。使用箭头移动圣诞老人，使他与原点对齐。</p><p id="2701" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一步是给圣诞老人添加交互性，当他被点击时，它会以一个简单的动画来响应。单击顶部的行为按钮，打开行为编辑区域。按“+”按钮添加点击和翻转行为。这将设定轻按对象时的行为。(还有各种其他行为可用，如声音播放、定时调整等。)选择触发器面板，点击Santa，按Done，将Santa设置为Tap触发器的目标。接下来，选择动作序列面板，单击Santa，然后按Done将Santa设置为动作序列的目标。可以在面板中设置运动模式和时间。在本例中，我们将运动类型更改为眨眼。按下面板右上角的播放按钮，观看动作。如果您按下屏幕顶部的播放按钮，您可以看到从轻敲到动作的动作。点击圣诞老人确认闪烁动画正在播放。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/426e28185ea69c256e5dd47e3edb276c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*76YKPBW6ZghMXSDAoKOTpA.png"/></div></figure><p id="a0fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你也可以将在Mac上创建的场景发送到iPad上，以查看AR显示。在iPad上安装并启动Reality Composer，然后在Mac上按Reality Composer顶部的“发送到…”按钮，将场景数据发送到iPad上的Reality Composer。按下iPad上Reality Composer上的AR按钮，查看AR显示。iPad上Reality Composer中的AR显示在某些方面可能与ARQL显示不匹配，例如对象遮挡不起作用，但它对于检查场景构图很有用。</p><p id="7aef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">AR场景完成后，从Reality Composer的“文件”&gt;“保存”…“菜单中将其保存为santaScene.rcproject。您也可以将场景导出为USDZ或Reality文件格式，但我们将使用标准的rcproject格式将其导入Xcode。</p><p id="078b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们已经使用圣诞老人的USDZ数据创建了一个简单的AR场景作为示例，但Reality Composer的直观GUI使其易于理解。你可以创建复杂的动画和交互性，所以我认为看苹果的视频并一点一点习惯它是一个好主意。</p><h1 id="1b2c" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">3 -创建AR应用程序</h1><p id="29e9" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">我们将创建一个使用ARQL API来显示AR的应用程序。它加载并显示与应用程序捆绑在一起的Reality或USDZ文件。在现实文件中，AR场景根据放置(水平面、垂直面等)进行显示和回放。)和行为设置。没有放置规范的USDZ文件被视为水平面放置，如果USDZ文件有动画，它将被播放。</p><p id="9ee1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ARQL API用于显示AR场景，并封装了ARKit / RealityKit的最新功能，使其易于使用。设备优化功能无需对运行设备的功能进行任何检查(人物遮挡、对象遮挡、光线跟踪阴影等)。).甚至不需要在Info.plist中添加密钥来访问摄像机。</p><p id="26f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一方面，没有办法在外部配置功能或以编程方式控制行为，AR场景回放完全交给ARQL API。因此，作为AR应用程序的AR体验的丰富性取决于您使用Reality Composer创建的AR场景。如果要做复杂的编程控制，可以使用ARKit/reality kit API而不是ARQL APIs完全自己控制，当然这需要复杂的Swift代码。</p><p id="7b71" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要创建使用ARQL API的AR应用程序，首先使用iOS - App模板创建一个Xcode项目。ARQL API基于UIKit，所以项目接口可以是UIKit或者SwiftUI。用于配置ARQL行为的ARQuickLookPreviewItem类与iOS / iPadOS 13.0+兼容。我们将在这里使用iOS 14目标。</p><ul class=""><li id="d981" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">Xcode 13.2.1</li><li id="1441" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv mn lc ld le bi translated">iOS部署目标:14.0</li></ul><p id="12b4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，通过将我们之前在Reality Composer中创建的rcproject文件拖放到项目中来添加它，并选中“如果需要，复制项目”来复制它。rcproject文件将在构建时转换为现实文件，并捆绑到应用程序中，因此Swift代码会将其视为同名的现实文件。</p><p id="cdc7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来就是写Swift代码了，非常简单。这个代码不依赖于AR场景文件，所以一旦你创建了它，你就可以在你的AR应用中使用它来实现各种AR场景。ARQLViewController类是符合QLPreviewControllerDataSource协议的UIViewController。为了清楚起见，可变部分总结在前四个let语句中。</p><ol class=""><li id="ed2a" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka ir"> assetName </strong> : rcproject，USDZ，文件的真实名称</li><li id="4b89" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir">资产类型</strong> : usdz或reality(文件的类型)(rcproject也应该是reality)</li><li id="9980" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir">allowscontscaling</strong>:如果设置为false，手势缩放被禁用。</li><li id="61cc" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated"><strong class="ka ir"> canonicalWebPageURL </strong>:指定Share Sheet要共享的网址。nil表示AR场景文件将被共享。</li></ol><p id="79e8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ARQL有一个内置的共享特性。点击分享按钮，就可以把AR场景文件(USDZ或者现实文件)给对方了。如果将canonicalWebPageURL设置为Web URL，将会共享该URL，而不是AR场景文件。如果不想分享AR场景文件，可以设置相关网址。如果要共享AR场景文件，就设置为nil。</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="a946" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要从SwiftUI中使用它，请用UIViewControllerRepsentable包装它，使它成为SwiftUI视图。</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/69b3f119fe6049c271239c792853c9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*Dbgff8doiZmJiUAUEUtTDQ.png"/></div></div></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/450f21824118939031d955e2e60ec6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*L5NWRlMFYbHbN_MhnC8v_w.png"/></div></div></figure><p id="fbf6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在Simulator和SwiftUI preview中，您可以构建和运行应用程序，但它显示“不支持的文件格式”,并且不显示3D场景。应该在真实设备上检查3D场景。</p><p id="727c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当在真实设备上运行时，由于物体遮挡，圣诞老人将贴在墙上并透过门偷看(在配备激光雷达的设备的情况下)。当点击圣诞老人时，该行为会播放一个幽默的动画。</p><h1 id="9a00" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">结论</h1><p id="df53" class="pw-post-body-paragraph jy jz iq ka b kb mi kd ke kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv ij bi translated">最初，3D数据创建是一个高度专业化的领域，需要专用的DCC工具。在WWDC21上发布的对象捕获API (macOS)使使用摄影测量创建3D数据变得更加容易，当与Reality Composer结合使用时，您可以使用GUI直观地创建3D场景，然后使用使用ARQL API的简单AR应用程序分发和播放AR场景。app代码很简单，但是AR表现力是自动配置的，可以通过最新的ARKit / RealityKit最大限度地发挥设备的能力。</p><p id="7fe2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在WWDC21的一个会议上，介绍了使用对象捕捉、Reality Composer和AR Quick Look API的组合来开发AR应用程序的框架。如果你喜欢，可以看看WWDC的视频。</p><ul class=""><li id="9055" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">WWDC21视频:<a class="ae mo" href="https://developer.apple.com/videos/play/wwdc2021/10078/" rel="noopener ugc nofollow" target="_blank"> AR快看，遇见物体捕捉</a></li></ul><p id="0515" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文描述的Swift代码和rcproject可以在GitHub上获得。</p><ul class=""><li id="eb4d" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv mn lc ld le bi translated">GitHub: <a class="ae mo" href="https://github.com/ynagatomo/ARQLSanta" rel="noopener ugc nofollow" target="_blank"> ARQL圣诞老人</a></li></ul><p id="d3c6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，这里是本文中描述的生产流程图。文章中没有提到Reality Converter，但它是苹果公司的一个转换3D文件的工具。它的测试版可以从苹果开发者网站获得。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/a459e3b15c7dca2d6ee28120faab1888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*VA2XyEArNxuv4X4E5zVd0w.png"/></div></figure><p id="f921" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">参考:</p><ol class=""><li id="8e43" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">苹果文章:<a class="ae mo" href="https://developer.apple.com/documentation/arkit/previewing_a_model_with_ar_quick_look" rel="noopener ugc nofollow" target="_blank">用AR Quick Look预览模型</a></li><li id="ff97" class="kw kx iq ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">苹果文章:<a class="ae mo" href="https://developer.apple.com/documentation/arkit/adding_visual_effects_in_ar_quick_look_and_realitykit" rel="noopener ugc nofollow" target="_blank">在AR Quick Look和RealityKit中添加视觉效果</a></li></ol></div></div>    
</body>
</html>