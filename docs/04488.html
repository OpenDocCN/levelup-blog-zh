<html>
<head>
<title>Natural Language Processing and Sentiment Analysis using Tensorflow.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流的自然语言处理和情感分析。</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/natural-language-processing-and-sentiment-analysis-using-tensorflow-c2948f2623f?source=collection_archive---------14-----------------------#2020-06-29">https://levelup.gitconnected.com/natural-language-processing-and-sentiment-analysis-using-tensorflow-c2948f2623f?source=collection_archive---------14-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b4a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">自然语言处理(NLP)是人工智能和深度学习的一个领域，它赋予机器阅读、理解和从人类语言中获取意义的能力，并专注于数据科学和人类语言之间的交互。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/55f03c6d41a9f797814b7f877c21145d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2ewvhSSTrSIOcIUeLdqfA.png"/></div></div></figure><p id="a1e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这次尝试是先睹为快，主要集中在使用Tensorflow和Keras执行基本的情感分析。一种常用的方法是使用卷积神经网络(CNN)来进行情感分析。然而，Keras有<strong class="js iu"> Embedding() </strong>层、<strong class="js iu">globaveragepooling1d()</strong>和<strong class="js iu"> LSTM </strong>层，可以用来建立一个更加精确的机器学习模型。</p><p id="d36a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Keras的顺序API很容易使用，也很常用于创建层的线性堆栈。它提供了<strong class="js iu">输入</strong> <em class="la">层</em>用于取输入，<strong class="js iu">密集</strong> <em class="la"> </em>层用于创建单层神经网络，内置<strong class="js iu"> <em class="la"> tf.losses </em> </strong>用于选择一系列损失函数使用，内置<em class="la"/><strong class="js iu"><em class="la">TF . optimizer</em></strong>，内置<strong class="js iu"><em class="la">TF . activation</em></strong>我们可以创建自定义层、损失函数等。</p><p id="82e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从导入Tensorflow和其他必需的库和包开始。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi lb"><img src="../Images/46f4af822da7078d52837eb1f86aaa01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*7sA1WEYOoxtwI1jCcdeo8Q.png"/></div></div></figure><h1 id="b57f" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">数据准备和清理。</h1><p id="450a" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">导入数据集或CSV文件，并检查包含所有类的列的value_counts()。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mf"><img src="../Images/bac6eaaac1acaf534825cbec11f526ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2AYBomP234KqJiNwOmZSw.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mg"><img src="../Images/62ca6d8a35ebb7109386d6f080489ef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZT6lMYIfxdvbs8QqR0cPBQ.jpeg"/></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk translated">数据帧的前十行。</figcaption></figure><p id="59e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该数据集没有情感分类栏，这就是为什么我们将使用df[“评级”]栏来创建熊猫数据框架中可能的情感栏。一种可能的方法是创建一个函数，对于较低的评级返回“负”，对于相对较高的评级返回“正”。目的是创建一个新的数据帧，我们稍后将使用它进行编码。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/4ff3da0ae0b3abc0d5db5152f38d91a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*qtGtop_IT7X4-mIOuvFavA.png"/></div></figure><p id="29d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为数据执行可视化。WordCloud 总是一个不错的选择，因为WordCloud旨在根据单词出现的频率，根据它们的大小来突出它们。</p><p id="c075" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用Python生成单词云，需要的模块有——matplotlib、pandas和word cloud。要安装这些软件包，请运行以下命令:</p><pre class="kp kq kr ks gt mn mo mp mq aw mr bi"><span id="88fe" class="ms ld it mo b gy mt mu l mv mw">pip install matplotlib<br/>pip install pandas<br/>pip install wordcloud</span></pre><p id="ac9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在这里 查看WordCloud的文档:<a class="ae mm" href="https://amueller.github.io/word_cloud/" rel="noopener ugc nofollow" target="_blank"> <em class="la"/></a></p><p id="0f1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一步是预处理和删除停用词。文本清理程序取决于任务。例如，如果您的任务是文本分类或情感分析，那么您应该删除停用词，因为它们不会为建模提供任何信息，但是如果您的任务是语言翻译，那么停用词是有用的。我们将使用NLTK(自然语言工具包)来下载这些停用词。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/a16933ed3928bae24b5302e62f3551f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*ye1uRSKInSq5FrhAkPVJ1g.png"/></div></figure><h1 id="562b" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">列车测试分离</h1><p id="aca8" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">机器学习就是一般化，这样你的推论对看不见的数据是正确的。如果你不分割它，你将会在所有可用的数据上进行训练。尽管你现在可能已经根据这些数据做出了正确的推论。但是你不能确定，你的推论在看不见的数据上有多好。因此，验证和测试集是分开的，这样您就可以了解模型如何处理看不见的数据。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi my"><img src="../Images/21786f5e8afaff95a066abc202d826c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r7C9NSBtYk3bRtS6yKpVA.png"/></div></div></figure><h1 id="d481" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">使用记号赋予器和创建填充序列。</h1><p id="8bae" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">Tokenizer允许对文本语料库进行矢量化，方法是根据字数将每个文本转换为整数序列(每个整数是字典中某个标记的索引)或向量，其中每个标记的系数可以是二进制的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mz"><img src="../Images/a427855f862ba89a53c620ac7433ab17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Kg6v6DXb2OKKpQ3MlT-9w.png"/></div></div></figure><p id="4308" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我已经使用<strong class="js iu">TF . keras . preprocessing . sequence . pad _ sequences</strong>为句子创建填充序列。这个函数将序列列表(长度为<code class="fe na nb nc mo b">num_samples</code>)转换成形状为<code class="fe na nb nc mo b">(num_samples, num_timesteps)</code>的2D Numpy数组。<code class="fe na nb nc mo b">num_timesteps</code>或者是<code class="fe na nb nc mo b">maxlen</code>参数(如果提供的话)，或者是列表中最长序列的长度。</p><p id="8797" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这之后，我们还必须对标签进行标记，并为测试数据创建pad_sequences。因为我们将使用它作为模型训练的验证集。</p><h1 id="342c" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">使用Keras构建模型</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nd"><img src="../Images/fcf512b97144647aca1e28039bcedc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xnqJ10VpCAaQ7YLBdOnBNw.png"/></div></div></figure><p id="c9bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在检查了模型和所有可训练参数的概要之后，我们所要做的就是在相当数量的时期内根据训练数据来训练我们的模型。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mf"><img src="../Images/0b8af943c4e32ca26d78a9812747fb40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHVhq7staJ5_awDEPEkzUw.png"/></div></div></figure><p id="b1cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在完成训练后，我得到了0.9032的训练精度和0.8742的验证精度，这很好。此外，差异较小，这表明这不是一个过度拟合的情况。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ne"><img src="../Images/9b9e12afd6a5ad1a159074ee4ca46381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S5tNI_DXp9CrpcKilwwdGg.jpeg"/></div></div></figure><h1 id="611a" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">绘制精确度和损耗图。</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nf"><img src="../Images/f77ef05efe8130f13a0d92ccfe0fae25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7OHrsWKLmQoEghXvQ9uMXA.png"/></div></div></figure><p id="8004" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是这些图表的样子。</p><div class="kp kq kr ks gt ab cb"><figure class="ng kt nh ni nj nk nl paragraph-image"><img src="../Images/5a352677bb8a81b1a4c72f950a31363b.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*y15JOMjcW_-e-UMOxsrohg.png"/></figure><figure class="ng kt nm ni nj nk nl paragraph-image"><img src="../Images/7fddf829c1a232734ab993e5ebd47411.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*-ECrhic2APZ6SrWibxqhMA.png"/></figure></div><h1 id="de46" class="lc ld it bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">用我们的模型做预测。</h1><p id="f16e" class="pw-post-body-paragraph jq jr it js b jt ma jv jw jx mb jz ka kb mc kd ke kf md kh ki kj me kl km kn im bi translated">我们要做的第一件事是标记我们的类，因为我们将使用这些标记作为类列表的索引。显然，第二步是创建一个包含所有这些情感的课程列表。</p><p id="6836" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第三步是使用<strong class="js iu"> model.predict() </strong>进行预测，这将返回一个数组。为了获得我们预测的令牌或索引，我们将使用<strong class="js iu"> np.argmax() </strong>，因为它将以最高的概率返回令牌(这是softmax函数发挥作用的地方)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/799585483b3f9f98a489db306870c3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*GohKmEr6VlvwEC5ArlZ2pw.png"/></div></figure><p id="e604" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个代码块将允许我们从用户的输入(审查)，并把word_index序列。预测将在填充的句子上进行，该句子稍后返回样本文本的预测类别。</p><p id="1a3a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是如何根据看不见的数据做出预测。</p><p id="800c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还可以使用LSTM和RNNs来提高模型的准确性。长短期记忆(LSTM)网络是一种能够在序列预测问题中学习顺序依赖性的递归神经网络。</p></div></div>    
</body>
</html>