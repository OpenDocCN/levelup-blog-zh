<html>
<head>
<title>Create a Demand Sales Forecast Model and Minimize the Error</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建需求销售预测模型并最小化误差</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/create-a-demand-sales-forecast-model-and-crush-the-error-9fe1653d9abf?source=collection_archive---------6-----------------------#2020-10-08">https://levelup.gitconnected.com/create-a-demand-sales-forecast-model-and-crush-the-error-9fe1653d9abf?source=collection_archive---------6-----------------------#2020-10-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="872c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Python的循序渐进教程。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/e6b17b75b910d121999fdde7ddc766ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*pqf0gKSiBCE9_yOM.jpeg"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">最小化成本函数</figcaption></figure><p id="9d1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">销售或需求预测是<strong class="jp ir"> </strong>大量公司(从初创公司到跨国公司)数据科学/分析部门的优先事项</strong>。退一步说，这个领域的专家在T4供应不足。即使减少很小的误差，也能在收入或节约上产生巨大的差异。</p><p id="233e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将用真实数据做一个简单的销售<strong class="jp ir">预测模型</strong>，然后通过使用Python寻找相关特性来改进它。</p><h1 id="0891" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">我们要做什么</h1><ul class=""><li id="2ce7" class="lv lw iq jp b jq lx ju ly jy lz kc ma kg mb kk mc md me mf bi translated">第一步:定义并理解<strong class="jp ir">数据</strong>和<strong class="jp ir">目标</strong></li><li id="2b04" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">第二步:制作一个<strong class="jp ir">简单预测模型</strong></li><li id="1677" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">第三步:增加<strong class="jp ir">新的财务指标</strong>进行改进</li><li id="0e6a" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated">步骤4:分析<strong class="jp ir">结果</strong></li></ul><h1 id="646c" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">第一步。定义并理解数据和目标</h1><p id="2887" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在本文中，我们将使用沃尔玛提供的真实的每周销售数据。</p><p id="b69b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">沃尔玛发布了包含每家<strong class="jp ir">实体店</strong>99个<strong class="jp ir">部门</strong>(服装、电子产品、食品……)的<strong class="jp ir">周销售额</strong>以及一些其他附加功能的数据。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/984c0441075d862ed7f599aab970a0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OkXbOmsA9p3OCoeB.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk translated">沃尔玛数据集截图</figcaption></figure><p id="a65b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为此，我们将<strong class="jp ir">创建一个以“<em class="mt"> Weekly_Sales”为目标的ML模型</em></strong>，，用前70%的观察值进行训练，并对后30%进行测试。</p><p id="f872" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目标是<strong class="jp ir">最小化未来周销售额的预测误差</strong>。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mu"><img src="../Images/c962c38f7315ff0309c25be9cfd9d167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IlgHr82Ugo0cngj5.png"/></div></div></figure><p id="be7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将<strong class="jp ir">添加影响销售或与销售有关系的外部变量</strong>，如<strong class="jp ir">美元</strong>指数、<strong class="jp ir">石油</strong>价格和关于沃尔玛的<strong class="jp ir">新闻</strong>。</p><h1 id="c375" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">第二步。制作一个简单的预测模型</h1><p id="9e61" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">首先，您需要安装Python 3和以下库:</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="a119" class="na ky iq mw b gy nb nc l nd ne">$ pip install pandas OpenBlender scikit-learn</span></pre><p id="8be4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，打开一个Python脚本(最好是Jupyter notebook)，让我们导入所需的库。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="d8d3" class="na ky iq mw b gy nb nc l nd ne">from sklearn.ensemble import RandomForestRegressor<br/>import pandas as pd<br/>import OpenBlender<br/>import json</span></pre><p id="92f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们定义用于所有实验的方法和模型。</p><p id="876d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">首先是</strong>，数据的<em class="mt">日期范围</em>是从2010年1月到2012年12月<strong class="jp ir">。</strong>让我们定义用于<strong class="jp ir">训练</strong>的数据的第一个<strong class="jp ir"> 70% </strong>和用于<strong class="jp ir">测试</strong>的后一个<strong class="jp ir"> 30% </strong>(因为我们不希望我们的预测出现数据泄漏)。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nf"><img src="../Images/70fa1a7ec20e4df32c14413a563fa4cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIwIUgu8v5t6N2pYiVGX6A.png"/></div></div></figure><p id="437a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">接下来</strong>，让我们将<strong class="jp ir">标准模型</strong>定义为具有50个估计量的<em class="mt"> RandomForestRegressor </em>，这是一个相当好的选择。</p><p id="0bbf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，为了使事情尽可能简单，让我们将误差定义为误差的绝对和。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/dceef16d4b0360c8d97a8871baa4d472.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/0*JJYFNYiOz5GomYpT.png"/></div></figure><p id="e340" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们把它放到一个Python类中。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="f7ce" class="na ky iq mw b gy nb nc l nd ne">class <strong class="mw ir">StandardModel</strong>:<br/>    <br/>    model = RandomForestRegressor(n_estimators=50, criterion='mse')<br/>    <br/>    def <strong class="mw ir">train</strong>(self, df, target):        <br/>        # Drop non numerics<br/>        df = df.dropna(axis=1).select_dtypes(['number'])   <br/>        <br/>        # Create train/test sets<br/>        X = df.loc[:, df.columns != target].values<br/>        y = df.loc[:,[target]].values        <br/>        <br/>        # We take the first bit of the data as test and the <br/>        # last as train because the data is ordered desc.<br/>        div = int(round(len(X) * 0.29))        <br/>        X_train = X[div:]<br/>        y_train = y[div:]        <br/>        print('Train Shape:')<br/>        print(X_train.shape)<br/>        print(y_train.shape)        <br/>        #Random forest model specification<br/>        self.model = RandomForestRegressor(n_estimators=50)        <br/>        # Train on data<br/>        self.model.fit(X_train, y_train.ravel())<br/>        <br/>        <br/>    def <strong class="mw ir">getMetrics</strong>(self, df, target):<br/>        <br/>        # Function to get the error sum from the trained model        <br/>        # Drop non numerics<br/>        df = df.dropna(axis=1).select_dtypes(['number'])      <br/>        <br/>        # Create train/test sets<br/>        X = df.loc[:, df.columns != target].values<br/>        y = df.loc[:,[target]].values        <br/>        div = int(round(len(X) * 0.29))        <br/>        X_test = X[:div]<br/>        y_test = y[:div]        <br/>        print('Test Shape:')<br/>        print(X_test.shape)<br/>        print(y_test.shape)<br/>        <br/>        # Predict on test<br/>        y_pred_random = self.model.predict(X_test)  <br/>        <br/>        # Gather absolute error<br/>        error_sum = sum(abs(y_test.ravel() - y_pred_random))        <br/>        return error_sum</span></pre><p id="4a24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面我们有一个包含3个元素的对象:</p><ul class=""><li id="da91" class="lv lw iq jp b jq jr ju jv jy nh kc ni kg nj kk mc md me mf bi translated"><strong class="jp ir">模型</strong> (RandomForestRegressor)</li><li id="9a09" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir">训练:</strong>用数据帧和目标训练模型功能</li><li id="592a" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir"> getMetrics: </strong>用测试数据对训练好的模型进行测试并检索错误的函数</li></ul><p id="ec57" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将在所有实验中使用这种配置，尽管您可以根据需要修改它来测试不同的模型、优化参数、特征工程或其他任何东西。附加值将保持不变，并有可能提高。</p><p id="2c7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们得到沃尔玛的数据。你可以在这里下载‘walmartdata . CSV’<a class="ae nk" href="https://github.com/federico2001/walmart_data" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="8644" class="na ky iq mw b gy nb nc l nd ne">df_walmart = pd.read_csv('walmartData.csv')<br/>print(df_walmart.shape)<br/>df_walmart.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nl"><img src="../Images/4977f3459bce2768489d64b5813d5d9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ECARcsaTRLbhFBr6.png"/></div></div></figure><p id="3d1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有421，570个观察值。如前所述，观察值是每个部门每个商店的每周销售额的记录。</p><p id="ff8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们将数据插入到模型中，而不要篡改它。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="d206" class="na ky iq mw b gy nb nc l nd ne">our_model = StandardModel()<br/>our_model.train(df_walmart, 'Weekly_Sales')<br/>total_error_sum = our_model.getMetrics(df_walmart, 'Weekly_Sales')<br/>print("Error sum: " + str(total_error_sum))</span><span id="aa58" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir"><em class="mt">&gt; Error sum: 967705992.5034052</em></strong></span></pre><p id="e34a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">整个模型的所有误差总和为<strong class="jp ir"> $ 967，705，992.5美元</strong>。</p><p id="7fdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这本身没有太大的意义，唯一的参考就是那段时间所有销售额的总和<strong class="jp ir">6，737，218，987.11美元</strong>。</p><p id="c2f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于有大量的数据，在本教程中，我们将<strong class="jp ir">仅关注商店#1 </strong>，但该方法绝对可用于所有商店。</p><p id="3d63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再来看看<strong class="jp ir">存储1 </strong>单独产生的<strong class="jp ir">错误</strong>。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="a6d8" class="na ky iq mw b gy nb nc l nd ne"># Select store 1<br/>df_walmart_st1 = df_walmart[df_walmart['Store'] == 1]</span><span id="d057" class="na ky iq mw b gy nm nc l nd ne"># Error of store 1<br/>error_sum_st1 = our_model.getMetrics(df_walmart_st1, 'Weekly_Sales')<br/>print("Error sum: " + str(error_sum_st1))</span><span id="be62" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir"># &gt; Error sum: 24009404.060399983</strong></span></pre><p id="0698" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，商店1应对<strong class="jp ir">24，009，404.06美元</strong>误差负责，而<strong class="jp ir">这个</strong> <strong class="jp ir">将是我们进行比较的阈值。</strong></p><p id="2051" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们按部门分解错误，以便稍后有更多的可见性。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="4c50" class="na ky iq mw b gy nb nc l nd ne">error_summary = []<br/>for i in range(1,100):<br/>    try:<br/>        df_dept = df_walmart_st1[df_walmart_st1['Dept'] == i]<br/>        error_sum = our_model.getMetrics(df_dept, 'Weekly_Sales')<br/>        print("Error dept : " + str(i) + ' is: ' + str(error_sum))<br/>        error_summary.append({'dept' : i, 'error_sum_normal_model' : error_sum})<br/>    except: <br/>        error_sum = 0<br/>        print('No obs for Dept: ' + str(i))</span><span id="6fed" class="na ky iq mw b gy nm nc l nd ne">error_summary_df = pd.DataFrame(error_summary)<br/>error_summary_df.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/1787e75c976a4d247350acac492cb6c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/0*1UizcQ5RgM3CfibJ.png"/></div></figure><p id="db0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们有了一个数据框架，其中包含了与阈值模型中商店1的每个部门相对应的错误。</p><p id="dd1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们<strong class="jp ir">提高</strong>这些数字。</p><h1 id="e505" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">第三步。通过添加新闻和财务指标进行改进</h1><p id="5ec9" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">让我们选择部门1作为一个简单的例子。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="2c10" class="na ky iq mw b gy nb nc l nd ne">df_st1dept1 = df_walmart_st1[df_walmart_st1['Dept'] == 1]</span></pre><p id="864e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们搜索相交的数据集。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="6759" class="na ky iq mw b gy nb nc l nd ne"># First we need to add the <strong class="mw ir">UNIX timestamp</strong> which is the number <br/># of seconds since 1970 on UTC, it is a very convenient <br/># format because it is the same in every time zone in the world!</span><span id="f802" class="na ky iq mw b gy nm nc l nd ne">df_st1dept1['timestamp'] = OpenBlender.dateToUnix(df_st1dept1['Date'], <br/>                       date_format = '%Y-%m-%d', <br/>                       timezone = 'GMT')</span><span id="49f6" class="na ky iq mw b gy nm nc l nd ne">df_st1dept1 = df_st1dept1.sort_values('timestamp').reset_index(drop = True)</span></pre><p id="31dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们在OpenBlender中搜索关于“商业”或“沃尔玛”的时间交叉(重叠)数据集。</p><p id="23ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:</strong>要获得您<em class="mt">需要的令牌</em>必须在<a class="ae nk" href="https://www.openblender.io/#/welcome/or/42" rel="noopener ugc nofollow" target="_blank"> openblender.io </a>上创建一个帐户(免费)，您可以在您个人资料图标的“帐户”选项卡中找到它。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5ae067841f53ddbba55e20393640c115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/0*wJ0LJWBuGUAAYHiq.png"/></div></figure><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="4199" class="na ky iq mw b gy nb nc l nd ne">token = '<strong class="mw ir">YOUR_TOKEN_HERE</strong>'</span><span id="4f18" class="na ky iq mw b gy nm nc l nd ne">print('From : ' + OpenBlender.unixToDate(min(df_st1dept1.timestamp)))<br/>print('Until: ' + OpenBlender.unixToDate(max(df_st1dept1.timestamp)))</span><span id="81df" class="na ky iq mw b gy nm nc l nd ne"># Now, let's search on OpenBlender<br/>search_keyword = 'business walmart'</span><span id="99c2" class="na ky iq mw b gy nm nc l nd ne"># We need to pass our timestamp column and <br/># search keywords as parameters.<br/>OpenBlender.searchTimeBlends(token,<br/>                             df_st1dept1.timestamp,<br/>                             search_keyword)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi np"><img src="../Images/a089ae8d48c0f0e1636fbf7c09c9b38f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7VGI9eprNtS8ZM7Ax5S2Ag.png"/></div></div></figure><p id="1874" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">搜索找到了几个数据集。我们可以看到名称、描述、url、特征，最重要的是，我们的时间交互，因此我们可以将它们混合到我们的数据集。</p><p id="4719" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从混合这个<a class="ae nk" href="https://www.openblender.io/#/dataset/explore/5e1deeda9516290a00c5f8f6/or/42" rel="noopener ugc nofollow" target="_blank">沃尔玛推文</a>数据集开始，寻找宣传片。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nq"><img src="../Images/3918f090e09dfdedb91b040f7f0d260c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDu1EejMpYKV91QOEKCbBw.png"/></div></div></figure><ul class=""><li id="521c" class="lv lw iq jp b jq jr ju jv jy nh kc ni kg nj kk mc md me mf bi translated"><em class="mt">注:</em>我挑了这个，因为它有道理，但是你可以搜索几百个其他的。</li></ul><p id="e263" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以<strong class="jp ir">通过搜索按时间聚合的文本或新闻术语，将新列混合到我们的数据集</strong>。例如，我们可以创建一个“推广”功能，其提及次数将与我们自制的ngrams相匹配:</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="9fc7" class="na ky iq mw b gy nb nc l nd ne"><strong class="mw ir">text_filter</strong> = {'name' : 'promo', <br/>               'match_ngrams': ['promo', 'dicount', 'cut', 'markdown','deduction']}</span><span id="893d" class="na ky iq mw b gy nm nc l nd ne"># <strong class="mw ir">blend_source</strong> needs the id_dataset and the name of the feature.</span><span id="93dd" class="na ky iq mw b gy nm nc l nd ne">blend_source = {<br/>                'id_dataset':'<strong class="mw ir">5e1deeda9516290a00c5f8f6</strong>',<br/>                'feature' : '<strong class="mw ir">text</strong>',<br/>                'filter_text' : <strong class="mw ir">text_filter</strong><br/>            }</span><span id="5dca" class="na ky iq mw b gy nm nc l nd ne">df_blend = OpenBlender.timeBlend( token = token,<br/>                                  anchor_ts = df_st1dept1.timestamp,<br/>                                  blend_source = blend_source,<br/>                                  blend_type = 'agg_in_intervals',<br/>                                  interval_size = 60 * 60 * 24 * 7,<br/>                                  direction = 'time_prior',<br/>                                  interval_output = 'list')</span><span id="5af3" class="na ky iq mw b gy nm nc l nd ne">df_anchor = pd.concat([df_st1dept1, df_blend.loc[:, df_blend.columns != 'timestamp']], axis = 1)</span></pre><p id="2525" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">timeBlend功能的参数(你可以在这里找到文档<a class="ae nk" href="https://www.openblender.io/#/api_documentation" rel="noopener ugc nofollow" target="_blank">):</a></p><ul class=""><li id="311b" class="lv lw iq jp b jq jr ju jv jy nh kc ni kg nj kk mc md me mf bi translated"><strong class="jp ir"> anchor_ts </strong>:我们只需要发送我们的时间戳列，这样它就可以作为一个锚来混合外部数据。</li><li id="380c" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir"> blend_source </strong>:关于我们想要的特性的信息。</li><li id="2c4d" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir">blend _ type</strong>:‘agg _ in _ intervals’因为我们希望对我们的每个观察进行1周时间间隔的聚合。</li><li id="bc98" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir"> inverval_size </strong>:间隔的大小，以秒为单位(本例中为24 * 7小时)。</li><li id="b6c1" class="lv lw iq jp b jq mg ju mh jy mi kc mj kg mk kk mc md me mf bi translated"><strong class="jp ir">方向</strong>:‘time _ prior’因为我们希望间隔收集前7天的观察值，而不是转发以避免数据泄漏。</li></ul><p id="0ace" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在有了原始数据集，但增加了两个新列，即“推广”功能的“计数”和一个实际文本列表，以防有人想要遍历每个文本。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="55f7" class="na ky iq mw b gy nb nc l nd ne">df_anchor.tail()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nr"><img src="../Images/3a6c8911256497d006de5e6c55b791c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bRY1280qnYzu24ei_j5t9Q.png"/></div></div></figure><p id="8a3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了一个数字特征，关于我们的ngrams被提及的次数。如果我们知道哪个商店或部门对应于“1”，我们可能会做得更好。</p><p id="53f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们应用标准模型，并将误差与原始值进行比较。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="f5bc" class="na ky iq mw b gy nb nc l nd ne">our_model.train(df_anchor, 'Weekly_Sales')<br/>error_sum = our_model.getMetrics(df_anchor, 'Weekly_Sales')<br/>error_sum</span><span id="eaa0" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir">#&gt; 253875.30</strong></span></pre><p id="d497" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前的模型有253，975美元的误差，而以前的模型有290，037美元的误差。这是一个12%的进步。</p><p id="3a5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是这个<strong class="jp ir">并不能证明什么</strong>，可能是随机森林运气好。毕竟，原始模型是用超过299K的观测值训练的。目前一只<strong class="jp ir">训练用102！！</strong></p><p id="4ee3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们也可以混合数字特征。让我们试着混合<a class="ae nk" href="https://www.openblender.io/#/dataset/explore/5e91029d9516297827b8f08c" rel="noopener ugc nofollow" target="_blank">美元指数</a>、<a class="ae nk" href="http://5e91045a9516297827b8f5b1" rel="noopener ugc nofollow" target="_blank">油价</a>和<a class="ae nk" href="https://www.openblender.io/#/dataset/explore/5e979cf195162963e9c9853f" rel="noopener ugc nofollow" target="_blank">月度消费者情绪</a></p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="3ccf" class="na ky iq mw b gy nb nc l nd ne"><strong class="mw ir"># OIL PRICE</strong></span><span id="0bef" class="na ky iq mw b gy nm nc l nd ne">blend_source = {<br/>                'id_dataset':'5e91045a9516297827b8f5b1',<br/>                'feature' : 'price'<br/>            }</span><span id="f50a" class="na ky iq mw b gy nm nc l nd ne">df_blend = OpenBlender.timeBlend( token = token,<br/>                                  anchor_ts = df_anchor.timestamp,<br/>                                  blend_source = blend_source,<br/>                                  blend_type = 'agg_in_intervals',<br/>                                  interval_size = 60 * 60 * 24 * 7,<br/>                                  direction = 'time_prior',<br/>                                  interval_output = 'avg')</span><span id="723d" class="na ky iq mw b gy nm nc l nd ne">df_anchor = pd.concat([df_anchor, df_blend.loc[:, df_blend.columns != 'timestamp']], axis = 1)</span><span id="78ba" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir"># DOLLAR INDEX</strong></span><span id="3167" class="na ky iq mw b gy nm nc l nd ne">blend_source = {<br/>                'id_dataset':'5e91029d9516297827b8f08c',<br/>                'feature' : 'price'<br/>            }</span><span id="8915" class="na ky iq mw b gy nm nc l nd ne">df_blend = OpenBlender.timeBlend( token = token,<br/>                                  anchor_ts = df_anchor.timestamp,<br/>                                  blend_source = blend_source,<br/>                                  blend_type = 'agg_in_intervals',<br/>                                  interval_size = 60 * 60 * 24 * 7,<br/>                                  direction = 'time_prior',<br/>                                  interval_output = 'avg')</span><span id="f4b4" class="na ky iq mw b gy nm nc l nd ne">df_anchor = pd.concat([df_anchor, df_blend.loc[:, df_blend.columns != 'timestamp']], axis = 1)</span><span id="b4e7" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir"># CONSUMER SENTIMENT</strong></span><span id="c372" class="na ky iq mw b gy nm nc l nd ne">blend_source = {<br/>                'id_dataset':'5e979cf195162963e9c9853f',<br/>                'feature' : 'umcsent'<br/>            }</span><span id="24be" class="na ky iq mw b gy nm nc l nd ne">df_blend = OpenBlender.timeBlend( token = token,<br/>                                  anchor_ts = df_anchor.timestamp,<br/>                                  blend_source = blend_source,<br/>                                  blend_type = 'agg_in_intervals',<br/>                                  interval_size = 60 * 60 * 24 * 7,<br/>                                  direction = 'time_prior',<br/>                                  interval_output = 'avg')</span><span id="e693" class="na ky iq mw b gy nm nc l nd ne">df_anchor = pd.concat([df_anchor, df_blend.loc[:, df_blend.columns != 'timestamp']], axis = 1)</span><span id="06c0" class="na ky iq mw b gy nm nc l nd ne">df_anchor</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ns"><img src="../Images/cd9066837fc949fa487309ac6c97c8f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ipoAwsczX22agPTnp68pbg.png"/></div></div></figure><p id="dcb8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们又有了<strong class="jp ir"> 6个特征</strong>，石油指数、美元指数和消费者情绪在7天间隔内的平均值，以及它们各自的计数(这在本例中是不相关的)。</p><p id="5389" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们再运行一次那个模型。</p><pre class="km kn ko kp gt mv mw mx my aw mz bi"><span id="6d18" class="na ky iq mw b gy nb nc l nd ne">our_model.train(df_anchor, 'Weekly_Sales')<br/>error_sum = our_model.getMetrics(df_anchor, 'Weekly_Sales')<br/>error_sum</span><span id="e865" class="na ky iq mw b gy nm nc l nd ne"><strong class="mw ir">&gt;223831.9414</strong></span></pre><p id="7ba8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们减少到223，831美元的错误。相对于最初的290，037美元，提高了24.1%！！</p><h1 id="1885" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">第四步。分析结果</h1><p id="e99c" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">为了查看结果是否一致，对每个商店的前10个部门运行了上面的测试(我没有添加代码，因为它是一个太大的脚本)。但实际上，这是在每个商店的每个部门(前10个)进行的。</p><p id="120b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我根据每个添加的特性来分离实验，以测量每个特性的误差减少量:</p><p id="9b66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">0:原始错误</p><p id="9b7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1:沃尔玛促销</p><p id="2ed7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2:石油价格</p><p id="bbe8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3:美元指数</p><p id="627d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4:消费者情绪</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nt"><img src="../Images/35d1e5f7c33eea683e74d6fd3be5b287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qLh3ciH5BbjqHyjy.png"/></div></div></figure><p id="dc73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第4和第6部门比其他部门更高级。让我们把它们拿掉，仔细看看剩下的部分。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nu"><img src="../Images/3caebcaa5dda0410ce840edef90d6bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4QvIROeWqf2mC2bb.png"/></div></div></figure><p id="e9ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，随着我们<strong class="jp ir">增加新功能</strong>，几乎所有部门的错误都降低了。我们还可以看到，石油指数(第三个特征)对某些部门不仅没有帮助，甚至是有害的。</p><p id="a86b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在销售预测中，减少百分之几的误差就意味着巨大的收入。需要改进的3个主要驱动因素是:<strong class="jp ir">特征工程</strong>，模型和<strong class="jp ir">参数优化</strong>和<strong class="jp ir">融合有用特征</strong>。</p></div></div>    
</body>
</html>