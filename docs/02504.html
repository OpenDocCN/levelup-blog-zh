<html>
<head>
<title>Building a high performance — Linux Based Traffic generator with DPDK</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用DPDK构建高性能的基于Linux的流量生成器</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/building-a-high-performance-linux-based-traffic-generator-with-dpdk-93bb9904416c?source=collection_archive---------1-----------------------#2020-03-18">https://levelup.gitconnected.com/building-a-high-performance-linux-based-traffic-generator-with-dpdk-93bb9904416c?source=collection_archive---------1-----------------------#2020-03-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="d078" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir"> <em class="iq">本文原载于我的个人博客</em></strong><a class="ae kp" href="https://toonk.io/" rel="noopener ugc nofollow" target="_blank"><strong class="jt ir"><em class="iq">toonk . io</em></strong></a></p></blockquote><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/c9a163ac737fca1a53bb7e1179e99860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*m_orpnWbrodIIjlJ"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk translated">照片由<a class="ae kp" href="https://unsplash.com/@rockthechaos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kolleen Gladden </a>在<a class="ae kp" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="fb08" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">在我20年的网络生涯中，我经常需要做一些网络性能测试。使用案例多种多样，从排除客户问题到测试新的网络硬件，现在越来越多的虚拟网络功能和基于软件的“线路中的颠簸”。</p><p id="60ab" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我一直喜欢玩基于硬件的流量生成器。我第一次体验IXIA硬件测试可以追溯到2003年，在阿姆斯特丹互联网交易所，我们测试了全新的Foundry 10G卡。这些基于硬件的测试器非常强大，是验证新设备(如路由器线路卡、防火墙和IPsec设备)的绝佳工具。然而，我们并不总是能够获得这些基于硬件的流量生成器，因为它们往往非常昂贵或者只能在实验室中获得。在这篇博客中，我们将看看一个任何人都可以使用的基于软件的流量生成器——基于DPDK。当你在读这个的时候，请记住脚本和其他信息可以在<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/" rel="noopener ugc nofollow" target="_blank">我的GitHub页面上找到。</a></p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi lq"><img src="../Images/819a4fb554e58dff561970613de372da.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*L3shetNxtIGOhKt-_0xv5A.png"/></div></div></figure><p id="160c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">DPDK，即数据平面开发工具包，是一个开源软件项目，由Intel发起，现在由Linux基金会管理。它提供了一组运行在用户空间中的数据平面库和网络接口控制器轮询模式驱动程序。好，让我们考虑一下，这是什么意思？用户空间网络是你可能越来越多地听到和读到的东西。用户空间网络(又名内核旁路)背后的主要驱动因素与Linux构建其网络堆栈的方式有关；它是作为通用、多用途、多用户操作系统的一部分而构建的。Linux中的联网功能强大且功能丰富，但这只是Linux众多功能中的一个，所以；因此，网络堆栈需要公平竞争，并与其余的内核和用户程序共享资源。最终的结果是，通过Linux网络栈每秒获得几百万(1到3百万)个包，差不多就是在一个标准系统上所能做到的。这不足以填满64字节数据包的10G链路，这相当于每秒14M数据包(pps)。这就是Linux中传统的中断驱动(IRQs)联网方式开始限制需求的地方，这就是DPDK的用武之地。对于DPDK和userland网络程序，我们从内核中取出NIC，并将其交给userland DPDK程序。DPDK驱动程序是一个轮询模式驱动程序(PMD)，这意味着通常每个网卡的一个内核总是使用100%的CPU，它处于一个繁忙的循环中，总是轮询数据包。这意味着您将看到该核心以100%的速度运行，而不管该网卡上有多少数据包正在到达或发送。这显然有点浪费，但如今，随着大量内核和对高吞吐量系统的需求，这通常是一个很好的权衡，最重要的是，它允许我们在Linux上达到1400万pps的数字。</p><p id="a8ca" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">好吧，高性能，我们都应该转移到DPDK，对不对？！嗯，只有一个问题……因为我们现在绕过了内核，我们无法从Netfilter等丰富的Linux特性中获益，甚至无法从TCP/IP栈等一些我们现在认为是基本的特性中获益。这意味着你不能仅仅用DPDK运行你的Nginx、Mysql、Bind等基于套接字的应用程序，因为所有这些都依赖于Linux套接字API和内核来工作。因此，尽管DPDK通过绕过内核为我们提供了很高的速度和性能，但您也损失了很多功能。</p><p id="0f48" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">现在有相当多的基于DKDK的应用程序，从基于软件的路由器和交换机等网络转发器，到F-stack等TCP/IP堆栈。</p><p id="185e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">在这篇博客中，我们将关注DPDK-pktgen，一个由DPDK团队维护的基于DPDK的流量生成器。我将逐步完成安装DPDK、设置SR-IOV和运行pktgen以下所有内容都是在<a class="ae kp" href="https://www.packet.com/cloud/servers/x1-small/" rel="noopener ugc nofollow" target="_blank"> x1.small.x86 </a>类型的<a class="ae kp" href="https://www.packet.com/" rel="noopener ugc nofollow" target="_blank">Packet.com</a>服务器上测试的，该服务器具有一个英特尔X710 10G网卡和一个4核E3–1578 l至强CPU。我用的是LTS Ubuntu 18 . 04 . 4。</p><h1 id="a3d1" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">安装DPDK和Pktgen</h1><p id="329a" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">首先，我们需要安装DPKD库、工具和驱动程序。安装DPDK和pktgen的方法有很多种；我选择编译源代码。有几件事你需要做；为了使它更容易，你可以下载我用来帮助你安装的<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/install-dpdk-pktgen.sh" rel="noopener ugc nofollow" target="_blank">相同的bash脚本</a>。</p><h1 id="d235" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">解决单网卡问题</h1><p id="816a" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">DPDK面临的挑战之一是它将完全控制nic。要使用DPDK，您需要从内核中释放nic并将其交给DPDK。假设我们只有一个网卡，一旦我们把它给了DKDK，我将失去所有的访问权限(记住，没有简单的方法继续使用SSH，等等。因为它依赖于Linux内核)。通常人们通过一个管理NIC(用于Linux)和一个或多个用于DPDK的NIC来解决这个问题。但是我只有一个网卡，所以我们需要创新:我们将使用SR-IOV来实现同样的目标。SR-IOV允许我们将一个网卡显示为多个PCI插槽，因此在某种程度上，我们正在虚拟化网卡。</p><p id="f143" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">要使用SR-IOV，我们需要在内核中启用iommu(在DPDK安装脚本中完成)。之后，我们可以像这样设置虚函数的数量(新PCI NIC的数量)</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="537d" class="mz ls iq mv b gy na nb l nc nd">echo 1 &gt; /sys/class/net/eno1/device/sriov_numvfs<br/>ip link set eno1 vf 0 spoofchk off<br/>ip link set eno1 vf 0 trust on</span></pre><p id="167d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">dmesg -t将显示如下内容:</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="0266" class="mz ls iq mv b gy na nb l nc nd">[Tue Mar 17 19:44:37 2020] i40e 0000:02:00.0: Allocating 1 VFs.<br/>[Tue Mar 17 19:44:37 2020] iommu: Adding device 0000:03:02.0 to group 1<br/>[Tue Mar 17 19:44:38 2020] iavf 0000:03:02.0: Multiqueue Enabled: Queue pair count = 4<br/>[Tue Mar 17 19:44:38 2020] iavf 0000:03:02.0: MAC address: 1a:b5:ea:3e:28:92<br/>[Tue Mar 17 19:44:38 2020] iavf 0000:03:02.0: GRO is enabled<br/>[Tue Mar 17 19:44:39 2020] iavf 0000:03:02.0 em1_0: renamed from eth0</span></pre><p id="b303" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我们现在可以看到新的PCI设备和nic名称:</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="085f" class="mz ls iq mv b gy na nb l nc nd">root@ewr1-x1:~# lshw -businfo -class network | grep 000:03:02.0<br/>pci@0000:03:02.0 em1_0 network Illegal Vendor ID</span></pre><p id="1f13" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">接下来，我们将解除网卡与内核的绑定，并将其交给DPDK管理:</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="554e" class="mz ls iq mv b gy na nb l nc nd">/opt/dpdk-20.02/usertools/dpdk-devbind.py -b igb_uio 0000:03:02.0</span></pre><p id="eb7c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我们可以这样验证(注意em2未连接且未使用):</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="70fd" class="mz ls iq mv b gy na nb l nc nd">/opt/dpdk-20.02/usertools/dpdk-devbind.py -s</span><span id="64ff" class="mz ls iq mv b gy ne nb l nc nd">Network devices using DPDK-compatible driver<br/>============================================<br/>0000:03:02.0 ‘Ethernet Virtual Function 700 Series 154c’ drv=igb_uio unused=iavf,vfio-pci,uio_pci_generic</span><span id="d292" class="mz ls iq mv b gy ne nb l nc nd">Network devices using kernel driver<br/>===================================<br/>0000:02:00.0 ‘Ethernet Controller X710 for 10GbE backplane 1581’ if=eno1 drv=i40e unused=igb_uio,vfio-pci,uio_pci_generic<br/>0000:02:00.1 ‘Ethernet Controller X710 for 10GbE backplane 1581’ if=em2 drv=i40e unused=igb_uio,vfio-pci,uio_pci_generic</span></pre><h1 id="d996" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">测试设置</h1><p id="d57c" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">既然我们已经准备好开始测试，我应该解释一下我们简单的测试设置。我使用两台x1小型服务器；一个是发送方(运行dpdk-pktgen)，另一个是普通的Ubuntu机器。我们要测试的是接收器内核(有时称为被测设备(DUT))从网卡获取数据包的能力。仅此而已；我们没有处理任何东西，数据包被发送到的IP地址甚至没有在DUT上配置，所以内核在从网卡获取数据包后会尽快丢弃数据包。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nf"><img src="../Images/bb79607b1c8ef7630193e276dec26f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4dnNk4hTHqehbtjSq7c5kQ.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk translated">测试设置</figcaption></figure><h1 id="a393" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">单流交通</h1><p id="4d69" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">好了，该开始测试了！让我们运行pktgen并生成一些包！我的第一个实验是计算在目标机器开始丢弃数据包之前，我可以在单个流中向它发送多少。</p><p id="40ef" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">请注意，您可以在这个博客的<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/" rel="noopener ugc nofollow" target="_blank"> GitHub repo中找到确切的配置。文件</a><a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/pktgen.pkt" rel="noopener ugc nofollow" target="_blank"> pktgen.pkt </a>包含配置测试设置的命令。我配置了mac和IP地址、端口和协议以及发送速率。注意，我测试的是从10.99.204.3到10.99.204.8。这些都在/31网络上，所以我将目的mac地址设置为默认网关的地址。使用<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/pktgen.pkt" rel="noopener ugc nofollow" target="_blank"> pktgen.pkt </a>中定义的配置，我一遍又一遍地发送相同的64字节数据包(5元组，UDP 10 . 99 . 204 . 3:1234&gt;10 . 99 . 204 . 8:81)。</p><p id="ede5" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我使用下面的代码来启动pktgen。</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="8526" class="mz ls iq mv b gy na nb l nc nd">/opt/pktgen-20.02.0/app/x86_64-native-linuxapp-gcc/pktgen — -T -P -m “2.[0]” -f pktgen.pkt</span></pre><p id="0a78" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">在发送器上调整发送速率属性并用<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/monitorpkts.sh" rel="noopener ugc nofollow" target="_blank"> <em class="js">监控后。/monitorpkts.sh </em> </a>在接收器上，我们发现单个流(单队列、单核)将在这个接收器机器上干净地运行，直到大约120k pps。如果我们把发送速率提高到更高，我开始观察到接收端有数据包丢失。这比预期的要低一点，尽管它是一个流，但我可以看到服务于该队列的CPU有足够的空闲时间。一定还有别的事情发生…</p><p id="dd2d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">答案与接收方网卡上的接收缓冲环有关。对于更高的数据包速率来说，它太小了。在我把它从512增加到4096之后。我现在最高能收到1.4Mpps才看到滴，单个流量还不错！</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="2178" class="mz ls iq mv b gy na nb l nc nd">ethtool -G eno1 rx 4096</span></pre><h1 id="de97" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">多流交通</h1><p id="7eb4" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">Pktgen还提供了对范围进行配置的能力。范围的示例包括源和目的IP地址以及源和目的端口。你可以在<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/pktgen-range.pkt" rel="noopener ugc nofollow" target="_blank"> pktgen-range.pkt文件</a>中找到一个例子。对于大多数环境，这是一个更典型的场景，因为您的服务器可能从许多不同的IP地址为许多不同的流提供服务。事实上，Linux系统依赖于许多流的存在来处理这些更大的流量。Linux内核将这些不同的流散列并负载平衡到nic上可用的接收队列。然后，每个队列由一个独立的中断线程服务，允许内核并行处理工作并利用系统上的多个内核。</p><p id="c1c4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">下面你会发现一个我用许多流运行测试时的截图。左边是接收端，右边是发送端。这里要注意的主要事情是，在接收节点上，所有可用的CPU都被使用，请注意<em class="js"> ksoftirqd/X </em>进程。由于我们使用了广泛的源端口和目的端口，我们在所有内核上实现了适当的负载平衡。有了这个，我现在可以实现0%的数据包丢失率，最高可达6Mpps。为了达到14Mpps、10g线速@ 64字节包，我需要更多的CPU。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ng"><img src="../Images/0e78ad97348ce33098288c7bd742fb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4YbY1b8viqfjoHNi6NPjA.png"/></div></div></figure><h1 id="c733" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">IMIX试验</h1><p id="353d" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi translated">最后，我们将使用dpdk-pktgen pcap特性运行一个基本的IMIX测试。互联网混合或IMIX是指典型的互联网流量。当使用IMIX数据包测量设备性能时，性能被假定为类似于“真实世界”条件下的性能。</p><p id="092c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated"><a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/imix.pcap" rel="noopener ugc nofollow" target="_blank"> imix pcap文件</a>包含100个数据包，其大小和比例符合<a class="ae kp" href="https://en.wikipedia.org/wiki/Internet_Mix" rel="noopener ugc nofollow" target="_blank"> IMIX规范</a>。</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="99fe" class="mz ls iq mv b gy na nb l nc nd">tshark -r imix.pcap -V | grep ‘Frame Length’| sort | uniq -c|sort -n<br/>9 Frame Length: 1514 bytes (12112 bits)<br/>33 Frame Length: 590 bytes (4720 bits)<br/>58 Frame Length: 60 bytes (480 bits)</span></pre><p id="6974" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我需要重写源和目标IP和MAC地址，以便它们与我当前的设置相匹配，可以这样做:</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="2f9a" class="mz ls iq mv b gy na nb l nc nd">tcprewrite \<br/> — enet-dmac=44:ec:ce:c1:a8:20 \<br/> — enet-smac=00:52:44:11:22:33 \<br/> — pnat=16.0.0.0/8:10.10.0.0/16,48.0.0.0/8:10.99.204.8/32 \<br/> — infile=imix.pcap \<br/> — outfile=output.pcap</span></pre><blockquote class="jn jo jp"><p id="4f10" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">更多细节也可以看我这里的笔记:<a class="ae kp" href="https://github.com/atoonk/dpdk_pktgen/blob/master/DPDKPktgen.md" rel="noopener ugc nofollow" target="_blank">https://github . com/ATO oonk/dpdk _ pktgen/blob/master/dpdkpktgen . MD</a></p></blockquote><p id="a279" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">然后，我们启动packetgen应用程序，并给它pcap</p><pre class="kr ks kt ku gt mu mv mw mx aw my bi"><span id="c097" class="mz ls iq mv b gy na nb l nc nd">/opt/pktgen-20.02.0/app/x86_64-native-linuxapp-gcc/pktgen — -T -P -m “2.[0]” -s 0:output.pcap</span></pre><p id="ef3d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">我现在可以看到，我正在以10Gbs的速度发送和接收320万pps的数据包，远远低于我们之前看到的最大值。这意味着被测设备(DUT)能够使用IMIX流量模式接收10Gbs的数据包。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nh"><img src="../Images/89a4f19af65556e84c591ee700666c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxb0aQmNeSvhvFfOwTI4nw.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk translated">以PCAP为源的IMIX测试结果。接收者(DUT)在左边，发送者窗口在右边。</figcaption></figure><h1 id="375f" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">结论</h1><p id="8a3f" class="pw-post-body-paragraph jq jr iq jt b ju mp jw jx jy mq ka kb lg mr ke kf lh ms ki kj li mt km kn ko ij bi ni translated"><span class="l nj nk nl bm nm nn no np nq di">在</span>这篇文章中，我们介绍了如何启动和运行DPDK，讨论了什么是DPDK，并使用了它的pktgen流量生成器应用程序。使用DPDK时的一个典型挑战是您失去了网络接口，这意味着内核不能再使用它。在这篇博客中，我们使用SR-IOV解决了这个问题，它允许我们为DPDK创建第二个逻辑接口。使用这个接口，我能够毫无问题地生成14Mpps。</p><p id="e60b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">在这个测试流量的接收端，我们有另一台Linux机器(没有DPDK)，我们测试了它从NIC接收流量的能力(之后内核直接丢弃了它)。我们看到了每秒的数据包数是如何受到rx缓冲区的限制，以及CPU内核拾取数据包的能力(软中断)。我们看到单核能够处理大约1.4兆位/秒的速度。一旦我们开始利用更多的内核，通过创建更多的流，我们开始看到大约每秒600万的丢包。如果我们有更多的CPU，我们可能会做得更多。</p><p id="f27a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">还要注意的是，在这篇博客中，我主要谈论的是每秒的包数，而不是每秒的比特数。原因是Linux接收器(DUT)上的每个新数据包都会产生一个中断。因此，系统可以处理的中断数量是Linux系统每秒可以处理多少位的最关键指标。</p><p id="14b7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">总而言之，pktgen和dpdk需要一点工作来设置，无疑有一点学习曲线。我希望GitHub repo中的脚本和示例将有助于您的测试，并记住:能力越大，责任越大。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi nr"><img src="../Images/6556ce35a88cd71c690772a5a9da35eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*60-YU-v_jMuccCaCqqDw6A.jpeg"/></div></div></figure></div></div>    
</body>
</html>