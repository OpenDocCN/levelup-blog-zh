# ç½‘é¡µæŠ“å– 2.0

> åŸæ–‡ï¼š<https://levelup.gitconnected.com/web-scraping-2-0-6600abca37de>

![](img/b016314bcbeb73cbdcd43006604f2b93.png)

[Marjan Blan | @marjanblan](https://unsplash.com/@marjan_blan?utm_source=medium&utm_medium=referral) åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

## ä½¿ç”¨ Scrapy è¿›è¡Œé¡¶å±‚ç½‘ç»œåˆ®æ“¦

Scrapy æ˜¯ä¸€ä¸ªç”¨äº web æŠ“å–çš„å…¨æ ˆ python æ¡†æ¶ã€‚æ˜¯å¤§è§„æ¨¡ç½‘é¡µæŠ“å–çš„å·¥å…·ã€‚å®ƒæœ‰ä¸€ä¸ªåä¸ºé€‰æ‹©å™¨çš„å†…ç½®æœºåˆ¶ï¼Œç”¨äºä»ç½‘ç»œä¸­æå–æ•°æ®ã€‚å®ƒæ˜¯ä¸€ä¸ªç”¨ python ç¼–å†™çš„å¼€æºå…è´¹ä½¿ç”¨çš„æ¡†æ¶ã€‚å®ƒå¯ä»¥ä½¿ç”¨è‡ªåŠ¨æ²¹é—¨æœºæ„è‡ªåŠ¨æ§åˆ¶çˆ¬è¡Œé€Ÿåº¦ã€‚Scrapy åœ¨èœ˜è››çš„å¸®åŠ©ä¸‹ä»ç½‘ç«™ä¸ŠæŠ“å–æ•°æ®ã€‚å®ƒå¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…ç³»ç»Ÿåœ°çˆ¬éæ•´ä¸ªç½‘ç«™ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒçš„ä¸€äº›ç‰¹æ€§ã€‚

**åŠŸèƒ½:-**

*   CPU å’Œå†…å­˜ä½¿ç”¨ç‡ä½ã€‚
*   æ˜“äºéµå¾ªçš„æ–‡æ¡£ã€‚
*   å¯ä»¥åŒæ—¶æŠ¥åºŸå¤šä¸ªç½‘ç«™ã€‚
*   å¼‚æ­¥çš„
*   ä½¿ç”¨èœ˜è››æŠ“å–ç½‘ç«™ã€‚

å®‰è£…:`pip install scrapy`

# Scrapy çš„å…³é”®ç»„ä»¶:-

## 1.ç²—ç³™çš„å¤–å£³

Scrapy æä¾›äº†ä¸€ä¸ªäº¤äº’å¼ shellï¼Œå¯ä»¥ç”¨æ¥éå¸¸å¿«é€Ÿåœ°è°ƒè¯•å’Œæµ‹è¯•æ‚¨çš„æŠ“å–ä»£ç ï¼Œè€Œæ— éœ€è¿è¡Œèœ˜è››ã€‚èœ˜è››æ˜¯å®šä¹‰ä¸€ä¸ªç«™ç‚¹å¦‚ä½•è¢«åºŸå¼ƒçš„ç±»ã€‚scrapy shell æ˜¯ä¸€ç§ python shellï¼Œè¿™æ„å‘³ç€æ‚¨ä¹Ÿå¯ä»¥åœ¨ shell ä¸­è¿è¡Œå’Œæµ‹è¯•æ‚¨çš„ python è„šæœ¬ã€‚

å®ƒä¸»è¦ç”¨äºæµ‹è¯• Xpath å’Œ CSS è¡¨è¾¾å¼ï¼Œä»¥æ£€æŸ¥å®ƒä»¬æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

å®‰è£… Scrapy åï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è¿™ä¸ª shell

```
scrapy shellORscrapy shell "URL"
```

ä¸€æ—¦å¤–å£³æ‰“å¼€ï¼Œä½ å°±å¯ä»¥ç”¨å®ƒä»ç½‘ä¸ŠæŠ“å–ä»»ä½•æ•°æ®ã€‚ä¸ºäº†å‘ web æœåŠ¡å™¨å‘é€ä¸€ä¸ªçˆ¬è¡Œè¯·æ±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`fetch(URL)`

```
fetch(URL)-----
fetch('[http://books.toscrape.com/index.html](http://books.toscrape.com/index.html)')
```

![](img/498af8984c191f74ceecb6dc6ee58fc8.png)

è¿è¡Œä¸Šè¿° fetch å‘½ä»¤åï¼Œæ‚¨å°†ä¼šçœ‹åˆ°ä¸€æ¡è°ƒè¯•æ¶ˆæ¯ Crawled(200)è¡¨ç¤ºæ‚¨çš„ç½‘ç«™æ­£åœ¨è¿è¡Œï¼Œå¹¶ä¸”è¿æ¥è¯·æ±‚æˆåŠŸã€‚

åœ¨ scrapy ä¸­ï¼Œç½‘ç«™çš„æºä»£ç å­˜å‚¨åœ¨ä¸€ä¸ªå˜é‡`response`ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡ä¼ é€’ä¸€ä¸ªé€‰æ‹©å™¨è¡¨è¾¾å¼æ¥æå–æ•°æ®ã€‚

è®©æˆ‘ä»¬ç”¨ shell æ¥æŠ“å–é¡µé¢çš„æ ‡é¢˜â€”

```
response.css("title")----------------
[<Selector xpath='descendant-or-self::title' data='<title>\n    All products | Books to S...'>]
```

å½“æ‚¨è¿è¡Œè¯¥å‘½ä»¤æ—¶ï¼Œä¼šè¿”å›ä¸€ä¸ªé€‰æ‹©å™¨åˆ—è¡¨ä½œä¸ºè¾“å‡ºï¼Œå…¶ä¸­åŒ…å«æ‚¨æ‰€è¯·æ±‚çš„ç‰¹å®š CSS å…ƒç´ ã€‚

ç°åœ¨æˆ‘ä»¬ä½¿ç”¨`extract()`ä»åˆ—è¡¨ä¸­åˆ é™¤æ ‡ç­¾

```
response.css("title").extract()---------------------------
['<title>\n    All products | Books to Scrape - Sandbox\n</title>'
```

è¿”å›çš„è¾“å‡ºåŒ…å«åˆ—è¡¨ä¸­çš„æ ‡ç­¾ã€‚ä¸ºäº†ä»ä¸­è·å–æ–‡æœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨`::text`ï¼Œå¹¶åœ¨é€‰æ‹©å™¨è¡¨è¾¾å¼çš„æœ«å°¾æŒ‡å®šå®ƒã€‚

```
response.css("title::text").extract()-------------------------
'\n    All products | Books to Scrape - Sandbox\n'
```

ç°åœ¨ï¼Œä¸ºäº†æ›´æ¸…æ¥šåœ°æµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ strip()è¿™æ ·çš„å­—ç¬¦ä¸²å†…ç½®å‡½æ•°æ¥åˆ é™¤ç©ºç™½ï¼Œä½¿ç”¨ replace å‡½æ•°æ¥æ›¿æ¢æŸä¸ªå…³é”®å­—ã€‚

```
response.css('title::text').extract()[0].strip().replace('\n',' ')-----------------
'All products | Books to Scrape - Sandbox'
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å°è¯•ä½¿ç”¨ shell æœ¬èº«æ¥æŠ“å–æ‰€æœ‰çš„ä¹¦åã€‚

![](img/e4d579f6ed379df0bfe339fb466783a8.png)

ç¬¬ä¸€æœ¬ä¹¦æ ‡é¢˜çš„ HTML ç‰‡æ®µ

ç¬¬ä¸€æœ¬ä¹¦çš„æ ‡é¢˜åœ¨ anchor `<a>`æ ‡ç­¾ä¸­ï¼Œè¯¥æ ‡ç­¾æ˜¯ heading 3 `<h3>`æ ‡ç­¾çš„å­æ ‡ç­¾ã€‚ä¸ºäº†æŠ“å–å®ƒï¼Œæˆ‘ä»¬å°†é¦–å…ˆç„å‡†< h3 >æ ‡ç­¾ï¼Œç„¶åç„å‡†< a >æ ‡ç­¾ä»¥ä»ä¸­è·å–æ–‡æœ¬ã€‚é¡µé¢ä¸Šæ‰€æœ‰æ ‡é¢˜çš„ HTML ç»“æ„éƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬æŠ“å–ä¸€ä¸ªï¼Œæ‰€æœ‰æ ‡é¢˜éƒ½ä¼šè‡ªåŠ¨æŠ“å–ã€‚æŠ“å–çš„æ•°æ®å­˜å‚¨åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚

```
response.css("h3 a::text").extract()
```

ä¸Šé¢çš„ä»£ç å°†ä»ç½‘é¡µä¸­æŠ“å–æ‰€æœ‰çš„ä¹¦åã€‚å°è¯•è‡ªå·±ä½¿ç”¨å­—ç¬¦ä¸²å‡½æ•°åˆ é™¤ç©ºç™½å’Œæ¢è¡Œç¬¦ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨è¿™ä¸ª shell æ¥è°ƒè¯•å’Œæµ‹è¯•å¤§å‹æŠ“å–é¡¹ç›®ä¸­çš„ä¸€äº›ä»£ç è¡Œã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»§ç»­åˆ›å»ºä¸€ä¸ªé¡¹ç›®ã€‚

## 2.é¡¹ç›®ç»“æ„

Scrapy æ˜¯ä¸€ä¸ªå®Œæ•´çš„ web æŠ“å–æ¡†æ¶ï¼Œéµå¾ªä¸€ä¸ªç³»ç»Ÿçš„æ–¹æ³•æ¥æŠ“å–æ•°æ®ã€‚scrapy éµå¾ªä¸€ä¸ªé€‚å½“çš„é¡¹ç›®ç»“æ„ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨ scrapy ä¸­å¯åŠ¨ä¸€ä¸ªæ–°é¡¹ç›®ã€‚

```
scrapy startproject PROJECT_NAME------
scrapy startproject bookscraper
```

è¿è¡Œè¯¥å‘½ä»¤åï¼Œæ‚¨çš„é¡¹ç›®ç»“æ„å°†è¢«åˆ›å»ºï¼Œå¦‚ä¸‹æ‰€ç¤º

![](img/a4418823c71b69f442761c48165d3487.png)

é¡¹ç›®ç»“æ„

ç°åœ¨ä½ åªéœ€è¦å…³å¿ƒä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œé‚£å°±æ˜¯`spiders`æ–‡ä»¶å¤¹ï¼Œä½ ä¼šæŠŠæ‰€æœ‰çš„èœ˜è››æ”¾åœ¨é‚£é‡Œï¼Œè¿™æ„å‘³ç€ä»¥åä¼šæŠ“å–ä»£ç ã€‚

## 3.ç¬¬ä¸€åªèœ˜è››

æ‰“å¼€ spiders æ–‡ä»¶å¤¹ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º`book_scraper.py`çš„ python æ–‡ä»¶å¹¶æ‰“å¼€å®ƒã€‚èœ˜è››æ–‡ä»¶å¤¹æ˜¯ä½ æ”¾ç½®æ‰€æœ‰èœ˜è››çš„åœ°æ–¹ã€‚æ‚¨å¯ä»¥åˆ›å»ºå¤šä¸ªæŠ“å–ä¸åŒå†…å®¹çš„èœ˜è››ï¼Œå¹¶å°†å®ƒä»¬è¿æ¥åœ¨ä¸€èµ·ã€‚

è®©æˆ‘ä»¬ä»å®˜æ–¹æ–‡ä»¶ä¸­å€Ÿç”¨ä¸€ä¸ª[çš„ä¾‹å­æ¥æ›´å¥½åœ°ç†è§£ä¸€åˆ‡â€”â€”](https://docs.scrapy.org/en/latest/intro/tutorial.html#:~:text=import%20scrapy%0A%0A%0Aclass,f%27Saved%20file%20%7Bfilename%7D%27))

![](img/6e6fb26912f2f747784f66117edd47a1.png)

è®©æˆ‘ä»¬ä¸€è¡Œä¸€è¡Œåœ°ç†è§£ä¸Šé¢çš„ä»£ç 

**ç¬¬ 1 è¡Œ**:å¯¼å…¥åº“ã€‚
**ç¬¬äºŒè¡Œ**:æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç±»ï¼Œscrapy ä½¿ç”¨å®ƒä» web ä¸­æŠ“å–å†…å®¹ã€‚ä½ å¯ä»¥ç»™å®ƒèµ·ä»»ä½•åå­—ï¼Œä½†é‡è¦çš„æ˜¯å®ƒå°†ç»§æ‰¿ç±» Spiderã€‚
**ç¬¬ä¸‰è¡Œ** : `name`æ˜¯æˆ‘ä»¬èœ˜è››çš„åå­—ã€‚ä½ ä¹Ÿå¯ä»¥ç»™å®ƒå–ä»»ä½•åå­—ï¼Œä½†æ˜¯ä¸è¦åœ¨æ–‡æœ¬ä¹‹é—´æ·»åŠ ä»»ä½•ç©ºæ ¼ï¼Œå› ä¸ºè¿™ä¸ªåå­—å°†ä¼šåœ¨ä½ è¿è¡Œä½ çš„èœ˜è››æ—¶ä½¿ç”¨ã€‚
**ç¬¬ 4 è¡Œ**:æ˜¯æˆ‘ä»¬ç”¨æ¥å®šä¹‰æˆ‘ä»¬èœ˜è››å†…éƒ¨æ‰€æœ‰ URL çš„å‡½æ•°ã€‚
**ç¬¬ 5 è¡Œ** : `URLs`æ˜¯è¦æŠ“å–çš„ URL åˆ—è¡¨ã€‚
**ç¬¬ 8ï¼Œ9 è¡Œ**:ä¸€ä¸ª for å¾ªç¯ï¼Œåœ¨ URL åˆ—è¡¨ä¸Šè¿è¡Œï¼Œé€ä¸ªæå–æ¯ä¸ª URLï¼Œå¹¶ä¼ é€’ç»™ scrapy è¿›è¡Œæ•°æ®æŠ“å–ã€‚
**ç¬¬ 10 è¡Œ** : `parse`æ˜¯ä¸€ä¸ªç±»çš„æ–¹æ³•ï¼Œå®ƒæœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œä¸€ä¸ªæ˜¯`self`ï¼Œå¦ä¸€ä¸ªæ˜¯`response`ï¼Œå®ƒåŒ…å«äº†ä½ æƒ³è¦æŠ“å–çš„ç½‘ç«™çš„æºä»£ç ã€‚ä½ ä¹Ÿå¯ä»¥é‡æ–°å‘½åã€‚
**ç¬¬ 11 è¡Œ**:åœ¨è¿™ä¸€è¡Œä¸­ï¼Œæˆ‘ä»¬è¯•å›¾ä½¿ç”¨ CSS é€‰æ‹©å™¨æŠ“å–ç½‘é¡µçš„æ ‡é¢˜ã€‚
**Line12** :æˆ‘ä»¬åªæ˜¯ç®€å•çš„æ‰“å°æ ‡é¢˜ã€‚

è¦è¿è¡Œä¸Šè¿°ä»£ç ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤â€”

```
scrapy crawl quotes
```

åœ¨å‘½ä»¤ä¸­ï¼Œ`scrapy`æ˜¯åŸºæœ¬åº“ï¼Œ`crawl`æ˜¯æŠ“å–çš„å¯åŠ¨ç¨‹åºï¼Œ`quotes`æ˜¯æ‚¨åœ¨ç¼–å†™ web æŠ“å–ä»£ç æ—¶åˆå§‹åŒ–çš„èœ˜è››çš„åç§°ã€‚å®ƒå°†è¿”å›åˆ—è¡¨ä¸­çš„æ‰€æœ‰æ ‡é¢˜ã€‚

è®©æˆ‘ä»¬åœ¨ä¸‹ä¸€èŠ‚æ›´æ·±å…¥åœ°äº†è§£è¿™äº›é€‰æ‹©å™¨ã€‚

# 4.å…ƒç´ é€‰æ‹©å™¨

ä½¿ç”¨ scrapy æ—¶ï¼Œæœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥é€‰æ‹© web ä¸Šçš„å…ƒç´ â€”â€”CSS å’Œ Xpathã€‚

## 1.CSS é€‰æ‹©å™¨

`css()`ä¸­çš„æ¡ä»¶è¢«ç§°ä¸º CSS é€‰æ‹©å™¨ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€äº›ä¾‹å­ã€‚

æ‰“å¼€ Scrapy Shellï¼Œç¼–å†™ä»¥ä¸‹ä»£ç ï¼Œåœ¨ Shell å’ŒæœåŠ¡å™¨ä¹‹é—´å»ºç«‹è¿æ¥ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ CSS é€‰æ‹©å™¨æŠ“å–ç½‘ç«™ä¸Šæ‰€æœ‰ä¹¦ç±çš„ä¹¦åå’Œä»·æ ¼ã€‚

```
scrapy shell "[http://books.toscrape.com/index.html](http://books.toscrape.com/index.html)"
```

ä»·æ ¼æ˜¯æˆ‘ä»¬é¦–å…ˆæƒ³ä»æ‰€æœ‰ä¹¦ç±ä¸­å‰”é™¤çš„ã€‚æ‰“å¼€ç½‘ç«™ï¼Œå°†é¼ æ ‡æ‚¬åœåœ¨ä¸€ä¸ªä»·æ ¼ä¸Šï¼Œç„¶åå³é”®å•å‡»> inspect æ‰“å¼€è¯¥å…ƒç´ çš„æºä»£ç ã€‚

![](img/190b343b6e4e6f84ecd9135072b0ba1b.png)

ç¬¬ä¸€æœ¬ä¹¦ä»·æ ¼çš„ HTML ç‰‡æ®µ

æˆ‘ä»¬çš„ç¬¬ä¸€æœ¬ä¹¦çš„ä»·æ ¼åœ¨ä¸€ä¸ªæ®µè½æ ‡ç­¾`<p>`ä¸­ï¼Œå®ƒæ˜¯ div æ ‡ç­¾çš„å­æ ‡ç­¾ã€‚è¿™ä¸ª`<p>`æœ‰ä¸€ä¸ª`price-color`ç±»ã€‚ä»·æ ¼çš„æƒŸä¸€æ ‡è¯†ç¬¦å°†æ˜¯ä¸€ä¸ª divï¼Œå®ƒæœ‰ä¸€ä¸ª p æ ‡ç­¾ä½œä¸ºå­æ ‡ç­¾ï¼Œç±»åä¸º`price-color`ï¼Œè®©æˆ‘ä»¬ç”¨å®ƒæ¥æ”¶é›†æ‰€æœ‰çš„ä»·æ ¼ã€‚

```
response.css("div p**.price_color::text**").extract()
```

æˆ‘ä»¬åœ¨`price_color`å‰ç”¨ä¸€ä¸ª`.`æ¥è¡¨ç¤ºå®ƒæ˜¯ä¸€ä¸ªç±»ã€‚å¦‚æœæ˜¯ idï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥ä½¿ç”¨`#price_color`

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å€ŸåŠ©ä¸‹é¢çš„ä»£ç æŠ“å–è¿™æœ¬ä¹¦çš„æ‰€æœ‰æ ‡é¢˜

```
response.css("h3 a::text").extract()
```

## 2.Xpath

Xpath ä¹Ÿæ˜¯åœ¨ XML æ–‡æ¡£ä¸­å®šä½å…ƒç´ çš„ä¸€ç§æ–¹å¼ã€‚HTML æ˜¯ XML çš„å®ç°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨å®ƒæ¥å®šä½ HTML ä¸­çš„å…ƒç´ ã€‚

Xpath çš„åŸºæœ¬è¯­æ³•æ˜¯â€”

```
**Xpath = //tagname[@Attribute='Value']**//       â¡ Select Current Node
tagname  â¡ Tagname like input, div,td,tr
@        â¡ Selects attribute
Attributeâ¡ Attribute name (class,id,name,etc)
value    â¡ value of the attribute
```

è®©æˆ‘ä»¬ä½¿ç”¨ Xpath æå–ä¹¦ç±çš„æ ‡é¢˜å’Œä»·æ ¼ã€‚

```
**## Scraping Titles** titles = response.xpath('//h3/a**/text()**').extract()**## Scraping Prices**
Prices = response.xpath('**//div/p[@class="price_color**"]**/text()**').extract()
```

Xpath ä¸ CSS ç•¥æœ‰ä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨`/text()`ä»æŠ“å–çš„æ–‡æœ¬ä¸­æå–æ–‡æœ¬ã€‚

è®©æˆ‘ä»¬æ¥ç†è§£ä»·æ ¼çš„ Xpathï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬æœ‰`//div`è¡¨ç¤ºé¡¶å±‚æ˜¯ä¸€ä¸ª div æ ‡ç­¾ï¼Œç„¶åæˆ‘ä»¬æœ‰`//div/p`è¡¨ç¤ºåœ¨ä¸€ä¸ª div æ ‡ç­¾ä¸­æˆ‘ä»¬æœ‰ä¸€ä¸ªæ®µè½æ ‡ç­¾ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`//div/p[@class="price_color"]`æ¥å®šä½ä¸€ä¸ªæ®µè½å…ƒç´ ï¼Œè¿™ä¸ªæ®µè½å…ƒç´ æœ‰ä¸€ä¸ª price_color ç±»å’Œä¸€ä¸ª div æ ‡ç­¾çš„å­å…ƒç´ ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä¸¤ç§æ–¹æ³•ä¸­çš„ä»»ä½•ä¸€ç§ä»ç½‘ä¸ŠæŠ“å–æ•°æ®ã€‚è¿è¡Œä»£ç åï¼Œè¿”å›ä¸¤ä¸ªåˆ—è¡¨`Titles, Prices`ä½œä¸ºè¾“å‡ºï¼Œå…¶ä¸­åŒ…å«ç¬¬ä¸€é¡µçš„æ ‡é¢˜å’Œä»·æ ¼ã€‚

ä½†æ˜¯å¦‚æœæˆ‘ä»¬å¸Œæœ›ç½‘ç«™çš„æ¯ä¸€é¡µéƒ½æœ‰æ ‡é¢˜å’Œä»·æ ¼å‘¢ï¼Ÿè¿™é‡Œå‡ºç°äº†å¤šé¡µæŠ“å–çš„æ¦‚å¿µã€‚

# 4.å¤šé¡µåˆ®æ“¦

å¤šé¡µæŠ“å–æ˜¯é€šè¿‡æ“ä½œ URL ä¸€æ¬¡æŠ“å–ç½‘ç«™å¤šä¸ªé¡µé¢çš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬æ­£åœ¨åšçš„ç½‘ç«™æ˜¯ http://books.toscrape.com/index.html çš„ï¼Œ

å¦‚æœä½ æ»šåŠ¨åˆ°åº•éƒ¨ï¼Œä½ ä¼šçœ‹åˆ°ä¸‹ä¸€æ­¥æŒ‰é’®ã€‚

![](img/14aaa83bbdbea0c0c97cf36c5a502107.png)

ç‚¹å‡»å®ƒï¼Œä½ ä¼šè¢«é‡å®šå‘åˆ°ç¬¬ 2 é¡µï¼Œç½‘ç«™çš„ç½‘å€ä¼šå˜æˆ[*http://books.toscrape.com/catalogue/page-2.html*](http://books.toscrape.com/catalogue/page-2.html)

ç°åœ¨å†æ¬¡æ»šåŠ¨åˆ°åº•éƒ¨ï¼Œç‚¹å‡»ä¸‹ä¸€æ­¥å¹¶æ£€æŸ¥ç½‘å€ï¼Œå®ƒä¼šæ›´æ–°åˆ°[*http://books.toscrape.com/catalogue/page-3.html*](http://books.toscrape.com/catalogue/page-3.html)

ç°åœ¨å†åšä¸€æ¬¡ï¼Œæ£€æŸ¥ URLï¼Œè¿™æ¬¡å®ƒæ›´æ–°ä¸º[*http://books.toscrape.com/catalogue/page-4.html*](http://books.toscrape.com/catalogue/page-4.html)

ä½ å¯ä»¥æ³¨æ„åˆ°ï¼Œåœ¨ç¬¬äºŒé¡µä¹‹åï¼Œåªæœ‰ä¸€ä¸ªåœ°æ–¹å‘ç”Ÿäº†å˜åŒ–ï¼Œé‚£å°±æ˜¯ URL ä¸­çš„é¡µç ã€‚æˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥åˆ›å»ºä¸€ä¸ªé€šç”¨çš„ URLï¼Œç”¨ä¸€ä¸ª f-string å˜é‡æ›¿æ¢å®ƒä»¬`page-2`ã€‚

```
for page_number in range(50):
  url=f'http://books.toscrape.com/catalogue/**page-{page_number}**.html'
  print(url)
```

è¿™ä¸ªæ–¹æ³•æ˜¯ä¸€ä¸ªé€šç”¨çš„æ–¹æ³•ï¼Œå³ä½¿ä¸‹ä¸€ä¸ªæ–¹æ³•ä¸èµ·ä½œç”¨ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•ã€‚

å‘ä¸‹æ»šåŠ¨åˆ°æœ€åï¼ŒæŸ¥çœ‹ä¸»é¡µä¸Šçš„`next`æŒ‰é’®ã€‚

![](img/4156c5aa9922caa5bd7774fe02dea6e0.png)

`<a>`æ ‡ç­¾åŒ…å«äº†ç¬¬äºŒä¸ªç½‘é¡µçš„é“¾æ¥ã€‚ç°åœ¨ï¼Œè½¬åˆ°ç¬¬äºŒé¡µï¼Œæ£€æŸ¥â€œnextâ€æŒ‰é’®ï¼Œæ‚¨å°†çœ‹åˆ°è¿™æ¬¡å®ƒæœ‰ç¬¬ 3 é¡µçš„é“¾æ¥ã€‚æˆ‘ä»¬æ‰€éœ€è¦çš„å°±æ˜¯ä»è¿™ä¸ªæ ‡ç­¾ä¸Šåˆ®æ‰é“¾æ¥ï¼Œscrapy ä¼šä¸ºæˆ‘ä»¬åšå…¶ä»–çš„äº‹æƒ…ã€‚

ä¸ºäº†æŠ“å–é“¾æ¥ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä½æŒ‰é’®ï¼Œç„¶åä½¿ç”¨ XPath `//li[@class='next']/a/**@href**`ï¼Œ`@`ä»æ ‡ç­¾ä¸­æå–å±æ€§çš„å€¼ã€‚

è®©æˆ‘ä»¬ç”¨è¿™ä¸ªæ¥åˆ®æ‰€æœ‰çš„ç½‘é¡µã€‚

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œä¸Šè¿°ä»£ç 

```
scrapy crawl books
```

![](img/46e124044dcf1a3f6ee257abf5422b21.png)

ä½œè€…æŠ“å–çš„æ•°æ®è¾“å‡º Gif

æ‚¨å¯ä»¥åœ¨å¼€å§‹æ—¶è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå°†æŠ“å–çš„æ•°æ®ä¿å­˜åœ¨ CSVã€JSON æˆ– XML æ–‡ä»¶ä¸­

```
 scrapy crawl books -o data.csv  
or   
 scrapy crawl books -o data.json  
or   
 scrapy crawl books -o data.xml
```

![](img/8743cea7c7f1cc230a96cd10b1a48253.png)

data.json æ–‡ä»¶æˆªå›¾ä½œè€…

# 5.æœ‰ç”¨çš„æ¦‚å¿µ

## 1.é¡¹ç›®å®¹å™¨

web æŠ“å–çš„ä¸»è¦ç›®æ ‡æ˜¯ä» web ä¸ŠæŠ“å–éç»“æ„åŒ–æ•°æ®ï¼Œå¹¶ä»¥ç»“æ„åŒ–çš„æ–¹å¼å­˜å‚¨ã€‚è¿™äº›é¡¹ç›®å®¹å™¨ç”¨äºå­˜å‚¨æ•°æ®ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒScrapy å°†æ•°æ®ä½œä¸ºé¡¹ç›®è¿”å›ã€‚

items æä¾›äº†ä¸€ä¸ªç±»ä¼¼å­—å…¸çš„ APIï¼Œå¯ç”¨äºå°†éç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ã€‚`items.py`æ–‡ä»¶ç”¨äºå®šä¹‰ä¸€ä¸ª scrapy é¡¹ç›®å†…éƒ¨çš„å®¹å™¨ã€‚

å½“æ‚¨ä½¿ç”¨ scrapy åˆ›å»ºä¸€ä¸ªé¡¹ç›®æ—¶ï¼Œä¼šè‡ªåŠ¨åˆ›å»º`items.py`æ–‡ä»¶ã€‚æ‚¨éœ€è¦å°†å®ƒå¯¼å…¥åˆ°æ‚¨çš„ spider ä¸Šï¼Œä»¥åˆ©ç”¨é¡¹ç›®å®¹å™¨ï¼Œå°±åƒæˆ‘ä»¬åœ¨ä¸Šé¢çš„å›¾ä¹¦æŠ“å–ä»£ç çš„ç¬¬ 2 è¡Œä¸­æ‰€åšçš„é‚£æ ·ã€‚

```
from ..items item BookscraperItem
```

BookscraperItem æ˜¯å¯åŠ¨é¡¹ç›®æ—¶è‡ªåŠ¨åˆ›å»ºçš„ç±»åã€‚è¯¥ç±»çš„åç§°å–å†³äºæ‚¨çš„é¡¹ç›®åç§°ã€‚å®ƒç”¨äºå®šä¹‰æ‚¨çš„é¡¹ç›®å®¹å™¨ã€‚

```
[**items.py**](https://docs.scrapy.org/en/latest/topics/items.html)**class BookscraperItem(scrapy.Item):**
# define the fields for your item here like:
# name = scrapy.Field()
    **link = scrapy.Field()
    price = scrapy.Field()
    title = scrapy.Field()**
```

ä¸€æ—¦å®šä¹‰äº†å®¹å™¨ï¼Œå°±å¯ä»¥ç”¨å®ƒä»¬æ¥å­˜å‚¨æ•°æ®ã€‚è®°ä½ä¸€ä»¶äº‹ï¼Œå®¹å™¨çš„åå­—åº”è¯¥å’Œä½ çš„æ•°æ®å˜é‡çš„åå­—ä¸€æ ·ã€‚

## 2.ä»è¯­æ³•ä¸Šåˆ†æ

`parse`æ˜¯ä¸€ä¸ªè´Ÿè´£å¤„ç†å“åº”å¹¶è¿”å›æŠ“å–çš„æ•°æ®æˆ–æ›´å¤š URL çš„æ–¹æ³•ã€‚å®ƒå°†`response`å˜é‡ä½œä¸ºåŒ…å«æºä»£ç çš„è¾“å…¥ã€‚æ­¤æ–¹æ³•è¿˜ç”¨äºå°†æ•°æ®ä¼ é€’ç»™é¡¹å®¹å™¨è¿›è¡Œä¸´æ—¶å­˜å‚¨ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œä»£ç ä¼šå°†å›è°ƒä¼ é€’ç»™ parse æ–¹æ³•ï¼Œç›´åˆ°æ‚¨æŒ‡å®šå…¶ä»–å†…å®¹ã€‚å°±åƒæˆ‘ä»¬åœ¨å›¾ä¹¦æŠ“å–ä»£ç çš„ç¬¬ 13 è¡Œæ‰€åšçš„é‚£æ ·ã€‚

```
def parse(self,response):
      ...
```

# é¡¹ç›® 1:äºšé©¬é€Šå›¾ä¹¦æŠ“å–

**ä»»åŠ¡**:æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ä»[äºšé©¬é€Š](https://www.amazon.com/s?k=python+programming&page=1&crid=YZEI0VGEO20K&qid=1644079860&sprefix=python+programming&ref=sr_pg_2)æœé›†æ‰€æœ‰å…³äº python ç¼–ç¨‹çš„ä¹¦åã€ä½œè€…åå’Œä»·æ ¼ã€‚

## æ­¥éª¤ 0:åˆ›å»ºé¡¹ç›®

è¿è¡Œ`scrapy startproject amazon`å¯åŠ¨ä¸€ä¸ªæ–°é¡¹ç›®å¹¶ç”Ÿæˆæ–‡ä»¶å¤¹ç»“æ„ã€‚

æ¥ä¸‹æ¥ï¼Œå®šä½åˆ° spiders æ–‡ä»¶å¤¹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ python æ–‡ä»¶`scraper.py`ï¼Œç”¨äºç¼–å†™ web æŠ“å–ä»£ç ã€‚

## æ­¥éª¤ 1:å¯¼å…¥åº“

```
import scrapy
from ..items import AmazonItem  *## class inside items.py*
```

## æ­¥éª¤ 2:åˆ›å»ºç±»å¹¶å‘½åèœ˜è››

```
class Amazonbookscraper(scrapy.Spider):
   name = "amazonbooks"
```

## æ­¥éª¤ 3:å‡†å¤‡èµ·å§‹ URL

```
start_urls = [
"[https://www.amazon.com/s?k=python+programming&page=1&crid=YZEI0VGEO20K&qid=1644079860&sprefix=python+programming&ref=sr_pg_2](https://www.amazon.com/s?k=python+programming&page=1&crid=YZEI0VGEO20K&qid=1644079860&sprefix=python+programming&ref=sr_pg_2)" 
]
```

`start_urls`æ˜¯ä¸€ä¸ªåŒ…å«è¦æŠ“å–çš„ URL åˆ—è¡¨çš„åˆ—è¡¨ã€‚è¿™æ˜¯ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ³•æ¥æŠ“å–ä½ çš„ URLã€‚

## æ­¥éª¤ 4:æ”¶é›†æ•°æ®

1.  æŠ“å–æ ‡é¢˜

![](img/d2470682f781c1a168f7b12701d16e34.png)

æœ‰ä¸‰ä¸ªç±»ä½ å¯ä»¥ä»»æ„ä½¿ç”¨

```
titles = response.css('**.a-size-base-plus**::text').extract()
```

2.å‰Šä»·

![](img/f72dc95c687db2f175a58d803b6f21e3.png)

a-price-whole ç±»åŒ…å«å…³äºä¹¦ç±ä»·æ ¼çš„ä¿¡æ¯

```
prices = response.css('**.a-price-whole:**:text').extract()
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ [**é€‰æ‹©å™¨å°å·¥å…· chrome æ‰©å±•**](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en) æ¥æ”¶é›†ä½œè€…å’Œè¯„çº§ã€‚çœ‹çœ‹è¿™ä¸ª [**youtube è§†é¢‘**](https://www.youtube.com/watch?v=oqNTfWrGdbk) äº†è§£å¦‚ä½•ä½¿ç”¨å®ƒæ¥æŸ¥æ‰¾ç½‘é¡µä¸Šç‰¹å®šå…ƒç´ çš„ CSS æˆ– XPathã€‚

3.æŠ“å–ä½œè€…

```
authors = response.css('.a-color-secondary .a-size-base+ .a-size-base::text').extract()
```

4.åˆ®æ“¦è¯„çº§

```
ratings = response.css('.s-link-style .s-underline-text::text').extract()
```

## æ­¥éª¤ 5:åœ¨é¡¹ç›®å®¹å™¨ä¸­å­˜å‚¨æ•°æ®

```
for i in list(zip(titles,prices,authors,ratings)):
  title,price,author,rating = i
  items['title']=title
  items['price']=price
  items['author']=author
  items['rating']=ratingyield items
```

## ç¬¬å…­æ­¥:æŠ“å–å¤šä¸ªé¡µé¢

```
next_page_url = "https://www.amazon.com"+response.xpath('//*[contains(concat( " ", @class, " " ), concat( " ", "s-pagination-next", " " ))]/@href')[0].extract()if next_page_url is not None:
  yield response.follow(next_page_url, callback=self.parse)
```

## å®Œæ•´ä»£ç 

ä½¿ç”¨å‘½ä»¤`scrapy crawl amazonbooks`è¿è¡Œä»£ç 

ä½ å¯èƒ½ä¼šé™·å…¥äºšé©¬é€Šçš„è¿æ¥é”™è¯¯ã€‚è¿™æ˜¯å› ä¸ºäºšé©¬é€Šé˜»æ­¢äº†ä½ çš„è¿æ¥è¯·æ±‚ã€‚ä¸ºäº†é˜²æ­¢è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç”¨æˆ·ä»£ç†ã€‚æœ‰ä¸€ä¸ªç”± scrapy çˆ±å¥½è€…åˆ›å»ºçš„åº“ï¼ŒåŒ…å«è¶…è¿‡ 2000 ä¸ªç”¨æˆ·ä»£ç†ï¼Œå¹¶ç»å¸¸æ›´æ¢ç”¨æˆ·ä»£ç†ï¼Œä»¥ä¾¿æ‚¨ä¸ä¼šè¢«é˜»æ­¢ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…è¯¥åº“ã€‚

```
pip install scrapy-user-agents
```

ä¸€æ—¦å®‰è£…å®Œæˆï¼Œè¿›å…¥ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸­çš„`settings.py`æ–‡ä»¶ã€‚å°†ä»¥ä¸‹ä»£ç ç²˜è´´åˆ°ä¸‹è½½æ¶æ„è½¯ä»¶æ³¨é‡Šçš„ä¸‹æ–¹ã€‚

```
DOWNLOADER_MIDDLEWARES = {
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
    'scrapy_user_agents.middlewares.RandomUserAgentMiddleware': 400,
}
```

ç°åœ¨ï¼Œå†æ¬¡å°è¯•è¿è¡Œä»£ç ã€‚è¿™ä¸€æ¬¡å®ƒå°†æˆåŠŸè¿è¡Œå¹¶ä» amazon æŠ“å–æ•°æ®ã€‚

![](img/72dac8e6582e3da5793816ffff50d07a.png)

äºšé©¬é€Šå›¾ä¹¦åˆ®åˆ€è¾“å‡º

![](img/94470ce28977a92a6cc0dfcba95344d7.png)

Books _ ç»†èŠ‚. json æ–‡ä»¶

# æ¨èè¯»ç‰©

[](https://medium.com/pythoneers/master-web-scraping-completly-from-zero-to-hero-38051423256b) [## ç½‘ç»œæŠ“å–å¤§å¸ˆä»é›¶åˆ°è‹±é›„ğŸ•¸

### ç”¨ç¾æ±¤å’Œè¯·æ±‚åº“åŒä¸€ä¸ªé¡¹ç›®

medium.com](https://medium.com/pythoneers/master-web-scraping-completly-from-zero-to-hero-38051423256b) [](/master-the-art-of-writing-xpath-for-web-scraping-c14e2f7ee130) [## æŒæ¡ä¸º Web æŠ“å–ç¼–å†™ Xpath çš„è‰ºæœ¯

### ç½‘ç»œæŠ“å–è§„åˆ™çš„ç®€å•ä»‹ç»

levelup.gitconnected.com](/master-the-art-of-writing-xpath-for-web-scraping-c14e2f7ee130) [](https://medium.com/pythoneers/web-scraping-using-selenium-python-6c511258ab50) [## ä½¿ç”¨ Selenium Python è¿›è¡Œ Web æŠ“å–

### ä¸€ä¸ªé¡¹ç›®çš„è¯¦ç»†æ•™ç¨‹

medium.com](https://medium.com/pythoneers/web-scraping-using-selenium-python-6c511258ab50) 

## å‚è€ƒ

[1][https://docs.scrapy.org/en/latest/intro/tutorial.html](https://docs.scrapy.org/en/latest/intro/tutorial.html)

æ„Ÿè°¢ä½ è¯»åˆ°è¿™é‡Œï¼Œå¦‚æœä½ å–œæ¬¢æˆ‘çš„å†…å®¹å¹¶æƒ³æ”¯æŒæˆ‘ï¼Œæœ€å¥½çš„æ–¹å¼æ˜¯â€”

1.  è·Ÿæˆ‘ä¸Š [*ä¸­*](http://abhayparashar31.medium.com/) ã€‚
2.  åœ¨ [*LinkedIn*](https://www.linkedin.com/in/abhay-parashar-328488185/) ä¸Šè”ç³»æˆ‘ã€‚
3.  ä½¿ç”¨ [*æˆ‘çš„æ¨èé“¾æ¥*](https://abhayparashar31.medium.com/membership) æˆä¸ºä¸­ç­‰ä¼šå‘˜ã€‚ä½ ä¼šè´¹çš„ä¸€å°éƒ¨åˆ†ä¼šå½’æˆ‘ã€‚
4.  è®¢é˜… [*æˆ‘çš„é‚®ä»¶åˆ—è¡¨*](https://abhayparashar31.medium.com/subscribe) æ°¸è¿œä¸ä¼šé”™è¿‡æˆ‘çš„ä¸€ç¯‡æ–‡ç« ã€‚