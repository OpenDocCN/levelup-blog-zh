<html>
<head>
<title>A Review of the Math Used in Training a Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于训练神经网络的数学综述</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/a-review-of-the-math-used-in-training-a-neural-network-9b9d5838f272?source=collection_archive---------16-----------------------#2020-06-04">https://levelup.gitconnected.com/a-review-of-the-math-used-in-training-a-neural-network-9b9d5838f272?source=collection_archive---------16-----------------------#2020-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8a3a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人工神经网络(ANN)是一种机器学习建模技术，它使用人脑的概念来构建可以学习解决问题的计算机程序。本文解释了训练神经网络所涉及的计算。</p><h1 id="56ff" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">结节</h1><p id="7ee0" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">人工神经网络由组织成层的互连节点组成。节点就像人脑中的神经元一样，是神经网络的基本构建模块。图1显示了一个节点。节点从输入层的数据或其他节点的输出接收输入，称为激活。节点的每个输入都与权重(w)相关联。权重表示输入对节点的影响的大小。该节点计算输入的加权和，然后应用激活函数(下面解释)来确定该节点的输出。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/ea2489f45a7fdf00e7d3549be6d82127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*sPg-0hha7o3iNPjY4n-vow.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated"><strong class="bd kq">图一。神经网络节点</strong></figcaption></figure><h1 id="5974" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">激活功能</h1><p id="5fc1" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在神经网络中，激活函数是输入值的非线性变换，这是实现复杂任务建模所必需的。如图1所示，输入的加权和</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi md"><img src="../Images/9864628092caebb4607ee7938d036bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*9L9cKprim4OBAsIlML4e6w.png"/></div></figure><p id="a8de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是线性变换。这个线性值z然后通过非线性的激活函数f(z)。在机器学习领域，通常使用几种激活函数，如Sigmoid、TanH、ReLU和Softmax。图2显示了一个sigmoid函数，它将线性值转换为0到1之间的值。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi me"><img src="../Images/8a1de34ce39f5b4a32ef15a037873a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*0wF78fRI0oW5iXXqaALoSQ.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated"><strong class="bd kq">图二。乙状结肠功能</strong></figcaption></figure><h1 id="7023" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">损失函数</h1><p id="146d" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">神经网络中的损失函数测量估计值与实际值的偏差。通过最小化总损失值来获得最佳模型参数(权重)。使用的损失函数取决于模型的目标。如果目标是预测，常用的损失函数是均方误差(MSE)。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/3d9bd559de7872f8f988253a35c5ddb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*RFrmW1UCzfdQ0Tm2_f8XLw.png"/></div></figure><p id="0222" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中y是真实值，ŷ是预测值。</p><p id="e09a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果目标是分类，则二进制交叉熵损失函数用于二进制类别，交叉熵损失函数用于多类别分类。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/4d0f0f312c1b9c5f7cce3ded01448d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*nmZU3QKnClxAuFaBIp5fZA.png"/></div></figure><p id="1fc8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中k是类的数量</p><h1 id="3105" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">神经网络</h1><p id="27a1" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我们将建立一个简单的神经网络，根据两个预测变量(身体质量指数(体重指数)和年龄)对一个人是否患有糖尿病进行分类。因为这里的目的是显示计算，我们将使用一些虚拟数据，如表1所示。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/dd7900a6cf313ec1a2ced11299011358.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*zsyaEjU9_iShWxAqaE9Byw.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated"><strong class="bd kq">表1。输入数据</strong></figcaption></figure><p id="e361" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">简单的神经网络由三层组成:输入层、隐藏层和输出层。图3示出了一个简单的神经网络，其将用于基于表1中的输入数据对一个人是否患有糖尿病进行分类。由于这是一个分类问题，我们将使用sigmoid激活函数和二元交叉熵损失函数。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/07860837fa3310230120a2ab4e4e909f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrBqGXIYZT7wauQN7qUqcw.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk translated"><strong class="bd kq">图三。简单神经网络</strong></figcaption></figure><p id="4ff9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目的:对一个人是否患有糖尿病进行分类</p><p id="75f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">问题类型:分类</p><p id="4bfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">特征数量(d): 2</p><p id="5604" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">观察数量(n): 4</p><p id="3e9a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">隐藏层数:1</p><p id="0f84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">层数:3</p><p id="2311" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">激活功能:乙状结肠</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/f12ec186a9245ff6089214b72c4bb2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*8jAp_wfdnXgzp_E2F9kl7A.png"/></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mo"><img src="../Images/4b1debd2db92bccdab3e8010a053cc62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NZjjzswgar2FkEeS5DoaUQ.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/3805a1e160a2efc4a3247d0f26f22477.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*NYFZIy2ZVthjrc-b9Gjyzg.png"/></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mq"><img src="../Images/754081fc272bf755074f8fbade4408d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tu4mriES6L269W1iXWhJ7A.png"/></div></div></figure><p id="ff1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练神经网络包括以下步骤:</p><p id="1fa7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1.初始化权重</p><p id="108b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.正向传播</p><p id="2fd3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.反向传播</p><ol class=""><li id="3d8e" class="mr ms it js b jt ju jx jy kb mt kf mu kj mv kn mw mx my mz bi translated"><strong class="js iu">初始化权重</strong>:我们先用0到1之间的小随机数初始化权重。</li></ol><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2b6a9507cef50e1f3e25222293f05efe.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*PmINAZ7bYSMFkXM31Euj_A.png"/></div></figure><p id="d1dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.<strong class="js iu">正向传播</strong>:这个过程包括计算隐藏层和输出层中所有节点的输出，从输入层遍历到输出层。每个节点的计算分为两步:</p><p id="f388" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">I .求z = aw。这是激活和权重的线性函数。</p><p id="ebf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">二。对z应用sigmoid激活函数。</p><p id="c40c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">详细情况如下所示:</p><p id="f177" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(矩阵下方括号中的数字表示尺寸。)</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/745612c4b8b00fb168fffec21d45dda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*XBSI5EY1Vj88X1tScuK-ZQ.png"/></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/5715baacdf13266d1ab22fd551ca30ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*QpvV-o_mbobPXPjLTJraXw.png"/></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/5239b921ed6be09c645c2770bfc4b4ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*JPx7qpnXbc1Gn7TR5JS-xw.png"/></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ne"><img src="../Images/feecda39b81573006b657b11ea3c4cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3XmUNbNlf0kmNjFTYiovnA.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nf"><img src="../Images/51874d4438dc538b45030b3f3a2d4246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ZHleKyypcY3R-389PvhWg.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ng"><img src="../Images/1d7480eee25b10f101d1cec7c10fca0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXraNEtGr6VwrGjm0pevkg.png"/></div></div></figure><p id="4386" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Delta(误差)</strong></p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nh"><img src="../Images/b8a9a8b2fe2370eba2e511256813fc59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*997yDpaz6WDx3uZGVPtfuQ.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ni"><img src="../Images/2336368f60952a0d6ff15bce664111c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgiN0TAdgFwPeBjslNgo_Q.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nj"><img src="../Images/54ab4a258091d194664bed1f57303b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iO2XqFMkg5lv0CyRIDklKQ.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nk"><img src="../Images/2b7d282dcf1e4436c6b5f78ed30b5543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DKiz4ysWeXhaW2rODWsc2g.png"/></div></div></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nl"><img src="../Images/6afbbb84e65da21ea55197fccc561f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRsNYtCzg-TjyBL1TVuOAQ.png"/></div></div></figure><p id="a135" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这为我们提供了一组新的权重，然后用于计算预测ŷ和相应的损失值。正向传播、反向传播和权重更新的整个过程是一个迭代过程，一直持续到损失收敛到最小值。当达到最小损失时，相应的权重是最优的。</p><p id="1fd8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在建立神经网络模型的过程中涉及到许多决策。本文的目标是展示训练网络所涉及的计算，以便学习神经网络的人可以更好地理解所涉及的计算。我强烈推荐吴恩达教授的关于机器学习的课程。你也可以看到我的<a class="ae nm" href="https://github.com/dagarwal98/machinelearning" rel="noopener ugc nofollow" target="_blank"> github </a>资源库，里面有关于机器学习的几个主题的完整代码。</p><p id="453b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">参考文献</strong></p><p id="5794" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">安德鲁。“机器学习。”<em class="nn"> Coursera </em>，<a class="ae nm" href="http://www.coursera.org/learn/machine-learning/home/welcome." rel="noopener ugc nofollow" target="_blank">www.coursera.org/learn/machine-learning/home/welcome.</a></p><p id="ca77" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">安德鲁。"深层L层神经网络——深层神经网络."<em class="nn"> Coursera </em>，<a class="ae nm" href="http://www.coursera.org/learn/neural-networks-deep-learning/lecture/7dP6E/deep-l-layer-neural-network." rel="noopener ugc nofollow" target="_blank">www . Coursera . org/learn/neural-networks-deep-learning/lecture/7 dp6e/deep-l-layer-neural-network。</a></p></div></div>    
</body>
</html>