<html>
<head>
<title>An Introduction To PySpark Optimisation, Physical Plan And Caching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark优化、物理规划和缓存简介</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/an-introduction-to-pyspark-optimisation-physical-plan-and-caching-ea98edfaa52a?source=collection_archive---------7-----------------------#2022-05-31">https://levelup.gitconnected.com/an-introduction-to-pyspark-optimisation-physical-plan-and-caching-ea98edfaa52a?source=collection_archive---------7-----------------------#2022-05-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2516" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">不小心缓存会弊大于利！</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d3fec9805b61b6a7c9d35511c82105eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nlnrAzaKSb-NCf_b"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">加里·穆勒曼斯在Unsplash<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">上的照片</a></figcaption></figure><p id="3871" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目的是快速介绍PySpark查询优化和物理规划。通过使用一个简单的示例，我们研究了物理规划，以及缓存或使用检查点对其有何影响。本文不会让您成为专家，但对于不太熟悉Spark中数据处理这一关键方面的读者来说，它可以作为一个起点。如果你已经了解了基本原理，那么在Medium中有许多优秀的文章，如<a class="ae kv" href="https://medium.com/plumbersofdatascience/this-spark-code-is-slower-than-a-snail-lets-optimize-it-dbe6736c784d" rel="noopener">这篇</a>。</p><p id="486e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些示例已经在本地部署的Spark环境(版本3.2.1)上运行。spark会话是用创建的</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="9ee3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分配了2gb(即2吉字节，即2 ⁰字节)的RAM和4个内核。我们还设置了一个保存检查点信息的目录。我们可以在Spark UI中看到(localhost:4040)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/3b2afa5975e5e95df63089090df23313.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wz5oho61D3nQR1aX0s26Gw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图Spark用户界面中的Executors选项卡(localhost:4040)</figcaption></figure><p id="322d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从2gb的内存中，我们可以获得大约900 MiB的操作和存储内存。操作存储器用于数据转换，存储存储器用于数据。默认情况下，操作存储器和存储存储器之间的分割是相等的(这可以通过<code class="fe lv lw lx ly b">spark.memory.storageFraction)</code>改变)。这对于我们的数值实验来说是足够的内存，以确保不会溢出到磁盘。</p><p id="43bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">起始数据集由pandas和numpy生成，有100 000行。创建后，我们将其转换为PySpark数据帧，并复制100次。这给了我们1000万行，足够计算几秒钟。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="6ca4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark数据帧完全缓存在内存中，大约消耗100 MiB</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lz"><img src="../Images/2e1757bcf352bceadf6322214dd0dd67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zz4_NEjkvalKuoqFZw0ODw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk translated">图2:缓存在内存中的起始数据帧</figcaption></figure><p id="99eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着从现在起，所有操作都将起始数据帧存储在内存中，即不会重复任何联合操作。数据框有一个称为group的字符串列和一个称为value的双列，前者包含五个值，后者包含范围在[0.0，10.0]内的均匀随机数。</p><p id="cd56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实验1:查看聚合操作的物理计划</strong></p><p id="850f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一个数值实验使用字符串列进行分组，并计算第二列的平均值</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="0f25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们用<code class="fe lv lw lx ly b">%timeit -r10 sol1(show=False)</code>对执行进行计时，以获得每个循环3.71秒199毫秒(平均标准时间。戴夫。10次运行，每次1个循环)。请注意，数据转换写得很差，是为了戏弄Spark。第二个筛选器适用于分组变量，因此应该在聚合之前指定它。对于基准测试来说，<code class="fe lv lw lx ly b">res.count()</code>函数通常是一个很好的选择，因为与<code class="fe lv lw lx ly b">res.show()</code>函数相比，它执行整个转换，而<code class="fe lv lw lx ly b">res.count()</code>函数可能只是(巧妙地)将转换调整到所需的程度。</p><p id="328c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们用<code class="fe lv lw lx ly b">sol1()</code>再次执行该功能，以查看物理平面图和我们获得的输出</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="b97c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看物理平面图，并以通常的方式自下而上阅读，我们看到Spark非常聪明。这两个过滤器合并在一起，并在汇总前应用。事实上，Spark在交换之前执行了预聚合，通过交换预聚合的分区而不是整个数据集来节省时间。这太棒了，显示了Spark在幕后做了多少工作。</p><p id="3a96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实验2:使用检查点的效果</strong></p><p id="e8cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们在中间挤一个<a class="ae kv" href="https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.checkpoint.html" rel="noopener ugc nofollow" target="_blank">检查点</a>会怎么样？让我们尝试使用</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="b35e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并使用<code class="fe lv lw lx ly b">%timeit -r10 sol2(show=False)</code>计时，以获得每个循环4.91秒127毫秒(平均标准时间。戴夫。10次运行，每次1个循环)。与第一个数值实验相比，执行时间增加了大约30%。产生的数据帧当然是相同的，但是物理平面图(现在是两个)发生了变化</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="9d64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">检查点的作用是将逻辑计划一分为二。现在，第二个过滤发生在交换之后，这导致了更长的执行时间。检查点在迭代算法中很有用，也需要使用，但是需要小心。我们正在试验优化器，我们应该有一个很好的理由这样做。</p><p id="392e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实验3:缓存的效果</strong></p><p id="720b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第三个也是最后一个数值实验中，我们看到了中间数据帧的缓存如何影响执行时间。在这样做之前，我们先看看使用函数<code class="fe lv lw lx ly b">sol1()</code>的修改版本进行缓存和清除缓存需要多少时间</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="b90d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出再次不受影响。物理计划也与第一个数值实验中的相同，因为我们在有机会使用缓存之前清空了它。用<code class="fe lv lw lx ly b">%timeit -r10 sol1_cache_overhead(show=False)</code>获得的执行时间也非常相似，每循环3.86秒138毫秒(平均标准时间。戴夫。10次运行，每次1个循环)。由此我们可以得出结论，这种情况下的缓存成本可以忽略不计，因为缓存发生在聚合之后，这是可以理解的。现在让我们看看当我们真正使用缓存时会发生什么</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="0afa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用<code class="fe lv lw lx ly b">%timeit -r10 sol3(show=False)</code>对执行进行计时，得出每个循环5.77秒279毫秒(平均标准时间。戴夫。10次运行，每次1个循环)，即，与第一个数值实验相比，我们看到执行时间增加。查看物理规划，我们再次看到，两个过滤器没有合并在一起，因为缓存阻止了优化器使用这个选项</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="dc52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">缓存可能比扰乱优化器有更多的不利影响。与再次计算缓存的数据帧相比，这会占用内存资源，最终可能会导致更长的执行时间。当数据框需要多次使用时，缓存会非常有用，在使用REPL进行实验时经常会出现这种情况。第二个用例是当训练机器学习模型时，在这种情况下，需要重复使用训练集。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><p id="c5f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark应用程序的性能调优是一个高级主题。Spark优化了数据处理流程，通常开箱即用。对于大多数用户来说，干预可能是有害的。作为一名数据分析师，我不是很有经验，如果我在查询数据库时需要使用优化器提示，我会像通常一样寻求数据工程师的建议。</p></div></div>    
</body>
</html>