<html>
<head>
<title>How to Understand a Robots.txt File</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何理解Robots.txt文件</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/how-to-understand-a-robots-txt-file-667246d7fa18?source=collection_archive---------5-----------------------#2021-04-27">https://levelup.gitconnected.com/how-to-understand-a-robots-txt-file-667246d7fa18?source=collection_archive---------5-----------------------#2021-04-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9c00" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个网页抓取者的问题在看似吓人但简单的文本文件上得到回答</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3f87ed0ad2c3dc1a07c318fffd3d895f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UtsCdSDMNxbIgsR9"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@waldemarbrandt67w?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">瓦尔德马·布兰德</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="f5f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从电子商务产品信息到体育联盟统计数据，网络上不仅充满了精彩的内容，还有有价值的数据。但是，随着网站和在线资源的数量(以及数据)呈指数级增长，筛选所有这些资源并不总是容易的，无论你是试图聚集数据进行研究或分析，构建一个有用的工具，还是创建一个数据管道。</p><p id="b96a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，网络抓取或网络采集通过使用机器人或程序使收集或使用数据的过程自动化，从而使收集或使用数据变得更加容易。然而，在你着手一个web抓取项目之前，你可能会遇到并且想要熟悉的一个东西是一个<strong class="lb iu"> robots.txt </strong>文件。</p><p id="a910" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乍一看，这似乎有点吓人，但是相信我，一旦你学会了简单的基础知识，就不会了。</p><h1 id="625a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">什么是robots.txt文件？</strong></h1><p id="b76b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">robots.txt文件是一个文本文件，由搜索引擎读取，让它们知道哪些页面可以使用机器人或“蜘蛛”抓取，哪些页面不可以。爬行是一个过程，当他们从一个站点“爬行”到另一个站点时，他们通过跟随链接来发现和索引web。在本文的其余部分，把你想象成一个构建web scraper程序的用户，一个机器人。</p><p id="9a15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Robots.txt存在于一个网站域名的页面上，可以通过在域名后添加<code class="fe ms mt mu mv b">/robots.txt </code>找到，比如<code class="fe ms mt mu mv b">domain.com/robots.txt</code>。不遵守文件中的规则是不被允许的，并且会导致法律上的麻烦。</p><p id="591f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于robots.txt文件，有两个共同的利益相关者:希望控制抓取或优化SEO的网站所有者和希望抓取数据的网络用户。这篇文章将集中在网络用户和他们如何解释这个文件，为什么它是重要的，以及所有其他关于它的使用的常见问题。</p><h1 id="1954" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">如何解释一个robots.txt文件？</strong></h1><p id="dd9f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一个robots.txt文件由一个或多个规则块组成，每个规则块都以一个<code class="fe ms mt mu mv b">user-agent</code>行开始，每个规则都在前面一行。用户代理指的是它所处理的特定机器人或蜘蛛。</p><p id="9cdf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用户代理可以:</p><ul class=""><li id="c44a" class="mw mx it lb b lc ld lf lg li my lm mz lq na lu nb nc nd ne bi translated">对特定的搜索引擎有自己的一套屏蔽指令</li><li id="e9c3" class="mw mx it lb b lc nf lf ng li nh lm ni lq nj lu nb nc nd ne bi translated">使用通配符<code class="fe ms mt mu mv b">*</code>指示符为所有搜索引擎提供一套屏蔽指令</li></ul><p id="857f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看媒体的档案:<a class="ae ky" href="https://medium.com/robots.txt'" rel="noopener">https://medium.com/robots.txt</a></p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="28b1" class="no lw it mv b gy np nq l nr ns">User-Agent: *<br/>Disallow: /m/<br/>Disallow: /me/<br/>Disallow: /@me$<br/>Disallow: /@me/<br/>Disallow: /*/edit$<br/>Disallow: /*/*/edit$<br/>Disallow: /media/<br/>Disallow: /p/*/share<br/>Disallow: /r/<br/>Disallow: /t/<br/>Disallow: /trending<br/>Disallow: /search?q$<br/>Disallow: /search?q=<br/>Allow: /_/<br/>Allow: /_/api/users/*/meta<br/>Allow: /_/api/users/*/profile/stream<br/>Allow: /_/api/posts/*/responses<br/>Allow: /_/api/posts/*/responsesStream<br/>Allow: /_/api/posts/*/related<br/>Sitemap: https://medium.com/sitemap/sitemap.xml</span></pre><p id="1d87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像<code class="fe ms mt mu mv b">Disallow</code>和<code class="fe ms mt mu mv b">Allow</code>这样的规则听起来确实如此。这些行指定了蜘蛛可以或不可以访问网站的哪些相对路径或部分。</p><h2 id="560d" class="no lw it bd lx nt nu dn mb nv nw dp mf li nx ny mh lm nz oa mj lq ob oc ml od bi translated"><strong class="ak">不允许</strong></h2><p id="5385" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有三种方式可以实现此规则:允许完全访问、阻止所有访问或允许部分访问。</p><p id="7d8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">完全访问:</strong><code class="fe ms mt mu mv b">Disallow</code>后面的空值表示没有被禁止。换句话说，没有什么是不允许被抓取的。例如，这个模块允许所有搜索引擎抓取网站的所有部分。</p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="04c6" class="no lw it mv b gy np nq l nr ns">User-agent: *<br/>Disallow:</span></pre><p id="59fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">阻止所有访问:</strong>下面的例子将限制所有用户代理抓取站点的任何部分。</p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="12e7" class="no lw it mv b gy np nq l nr ns">User-agent: *<br/>Disallow: /</span></pre><p id="d7ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">部分访问</strong>:最常见的是，下面的例子将限制所有用户代理抓取站点上的<code class="fe ms mt mu mv b">/trending</code>目录和其中的所有内容(子目录)。</p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="0b9c" class="no lw it mv b gy np nq l nr ns">User-agent: *<br/>Disallow: /trending</span></pre><p id="0e89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，Medium不允许你浏览其网站上任何出版物的趋势页面。</p><h2 id="aa22" class="no lw it bd lx nt nu dn mb nv nw dp mf li nx ny mh lm nz oa mj lq ob oc ml od bi translated">允许</h2><p id="929f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">虽然不允许规则更常见，但是当一些域想要指示允许爬行的特定网页或路径时，它们喜欢包含允许规则。通常，该命令仅适用于用户代理:<code class="fe ms mt mu mv b">Google-bot</code>。</p><p id="87a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，Medium的所有allow规则都引用了其发布API，以便开发人员轻松插入Medium网络。</p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="e282" class="no lw it mv b gy np nq l nr ns">Allow: /_/<br/>Allow: /_/api/users/*/meta<br/>Allow: /_/api/users/*/profile/stream<br/>Allow: /_/api/posts/*/responses<br/>Allow: /_/api/posts/*/responsesStream<br/>Allow: /_/api/posts/*/related</span></pre><p id="9c98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">爬行延迟</strong></p><p id="fb73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">爬行延迟规则限制了允许机器人请求网站页面爬行的频率，要求它们等待指定的时间段。以下示例将在爬网操作之间设置10秒的延迟。</p><pre class="kj kk kl km gt nk mv nl nm aw nn bi"><span id="45d0" class="no lw it mv b gy np nq l nr ns">Crawl-delay: 10</span></pre><h2 id="15f8" class="no lw it bd lx nt nu dn mb nv nw dp mf li nx ny mh lm nz oa mj lq ob oc ml od bi translated">网站地图</h2><p id="2c50" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">站点地图规则为爬虫提供XML站点地图的位置，该位置提供附加信息并允许机器人更有效地爬行站点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8ac7afd0f5b3cde7005fbf364aaa79fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*jZBVn8Wzmr9HQHHpJaw9RQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk translated">媒体网站地图示例(Google Chrome中XML文件的截图)</figcaption></figure><h1 id="1d11" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">robots . txt文件有哪些限制？</strong></h1><p id="5f89" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">尽管Robots.txt受到并且应该受到大多数搜索引擎、程序员和web用户的尊重，但不幸的是，它有其局限性:</p><ol class=""><li id="dead" class="mw mx it lb b lc ld lf lg li my lm mz lq na lu of nc nd ne bi translated">并非所有搜索引擎都支持这些规则，这意味着它们不能强制爬虫行为，而只是提供指导。然而，大多数主要引擎遵守规则。</li><li id="7a63" class="mw mx it lb b lc nf lf ng li nh lm ni lq nj lu of nc nd ne bi translated">不同的爬虫对语法的解释不同，所以最好了解特定爬虫的某些细节。</li></ol><h1 id="5b52" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">robots . txt文件不存在怎么办？</strong></h1><p id="e36d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">万岁——你的第一个倾向可能是，没有robots.txt意味着你可以刮任何东西。这并不完全正确。并非所有网站都会定义robots.txt文件。在这种情况下，你应该检查任何<em class="og">条款条件</em>或网站上的其他法律页面，因为它们通常可能包括关于什么是允许的爬虫和提取数据的细节。最佳实践是检查术语和robots.txt。</p><h1 id="91aa" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">如果我对收集网站数据没有把握，我还能做什么？</strong></h1><p id="3c0e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果查看robots.txt或terms都不能让你完全明白，最好是<em class="og">直接问</em>网站。找到一个合适的电子邮件联系人，处理有关服务条款的法律事务或问题，并列出您的具体问题，解释您是谁以及您从该网站收集潜在数据的目的。</p><h1 id="7334" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="fa8b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">不理解robots.txt或网站的数据提取指南，因为它令人困惑或令人生畏，也不是不服从的有效借口。正如我们所看到的，解释文件及其规则以及获得进一步的澄清是一件相当简单的事情！接下来，你需要做的就是记住阅读并尊重你的数据采集项目的网站规则。刮的开心！</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="1208" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望你喜欢这个简短的介绍性指南。如果您有任何问题或疑虑，请在下方留言或通过LinkedIn<a class="ae ky" href="https://www.linkedin.com/in/bicaj/" rel="noopener ugc nofollow" target="_blank">联系我。如果你喜欢这篇文章，你可能想看看这些关于实际网络抓取项目的帖子:</a></p><div class="oo op gp gr oq or"><a href="https://pub.towardsai.net/tweet-topic-modeling-using-twint-to-scrape-tweets-part-1-a9274e5199d2" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">推文主题建模:使用Twint抓取推文</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">多部分系列展示了如何刮擦，清理，并应用和可视化短文本主题建模的任何集合…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">pub.towardsai.net</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf ks or"/></div></div></a></div><div class="oo op gp gr oq or"><a href="https://towardsdatascience.com/home-field-advantage-does-it-exist-without-fans-a0778c5a6a29" rel="noopener follow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">主场优势:没有粉丝还存在吗？</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">疫情时代之前和期间的数据和统计</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pg l pc pd pe pa pf ks or"/></div></div></a></div><div class="oo op gp gr oq or"><a href="https://pub.towardsai.net/how-to-easily-scrape-podcast-data-using-rss-feeds-e864710cb62" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">如何使用RSS源轻松抓取播客数据</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">通过访问RSS feeds使用R获取播客数据很容易，只需5个简单的步骤</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">pub.towardsai.net</p></div></div><div class="pa l"><div class="ph l pc pd pe pa pf ks or"/></div></div></a></div><h2 id="1e05" class="no lw it bd lx nt nu dn mb nv nw dp mf li nx ny mh lm nz oa mj lq ob oc ml od bi translated">资源</h2><ol class=""><li id="e3af" class="mw mx it lb b lc mn lf mo li pi lm pj lq pk lu of nc nd ne bi translated"><a class="ae ky" href="https://developers.google.com/search/docs/advanced/robots/intro" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/search/docs/advanced/robots/intro</a></li><li id="978d" class="mw mx it lb b lc nf lf ng li nh lm ni lq nj lu of nc nd ne bi translated"><a class="ae ky" href="https://www.cloudflare.com/learning/bots/what-is-robots.txt/" rel="noopener ugc nofollow" target="_blank">https://www . cloud flare . com/learning/bots/what-is-robots . txt/</a></li></ol></div></div>    
</body>
</html>