<html>
<head>
<title>Focal Loss: Focus on What’s Hard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">焦点缺失:专注于困难的事情</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/focal-loss-focus-on-whats-hard-aa603197cc04?source=collection_archive---------7-----------------------#2021-04-07">https://levelup.gitconnected.com/focal-loss-focus-on-whats-hard-aa603197cc04?source=collection_archive---------7-----------------------#2021-04-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f1f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种解决目标检测中类别不平衡的新损失方法</h2></div><p id="11d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">您将了解焦点损失，如何在对象检测中使用它来检测硬负样本，然后对不平衡数据集实施焦点损失。</em>T3】</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/aeb448923e97205b8c1f9db3fcbd0f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o8k4SK51SW9BQrXKBZFE6g.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae lv" href="https://unsplash.com/@elenatrn?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">埃琳娜·塔拉年科</a>在<a class="ae lv" href="https://unsplash.com/s/photos/focus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="e760" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">焦点损失是基于这样的前提，即训练集中在一组稀疏的硬例子上，并且防止大量的易底片在训练期间淹没对象检测器。</p><h2 id="d2bb" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">物体探测器的类型</h2><p id="f042" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><strong class="kk iu">一级检测器是一种简单、高效且优雅的架构；因此它们更快更简单。目标检测网络的输出是每个空间位置的分类概率和盒子偏移。</strong></p><p id="e5ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">例子:YOLO、SSD、RetinaNet、CenterNet、CenterNet等。</strong></p><p id="a946" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">两级探测器的管道更加复杂</strong>。第一阶段使用区域提议网络从整个图像中过滤出具有包含物体的高概率的区域，并且生成候选物体位置的稀疏集合。这些RPN然后被馈送到第二阶段，其中区域卷积网络(R-CNN)获得分类分数和空间偏移。</p><p id="8de6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">示例:R-CNN、快速R-CNN、更快R-CNN、R-FCN和Libra R-CNN </strong></p><p id="3a50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与两级检测器相比，一级对象检测器的准确性受到影响，因为很少图像位置包含对象。<strong class="kk iu">密集检测器的训练遇到极端的前景-背景类别不平衡，导致训练不充分。</strong></p><p id="78bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一级检测器中前景类和背景类之间的类不平衡导致两个问题。</p><ul class=""><li id="d09c" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">培训效率低下，因为大多数地点或班级都是容易被否定的，无助于有用的学习。</li><li id="843c" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">容易否定的课程会淹没训练并导致退化的模型</li></ul><blockquote class="ni nj nk"><p id="7e8c" class="ki kj le kk b kl km ju kn ko kp jx kq nl ks kt ku nm kw kx ky nn la lb lc ld im bi translated"><strong class="kk iu">通过将损失函数从交叉熵损失改为焦点损失，可以提高一级物体检测器的精度。</strong></p></blockquote><p id="36ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">什么是焦损？</em> </strong></p><p id="fa65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">焦点损失通过对分配给分类良好的示例的损失进行向下加权来重塑标准交叉熵损失，从而解决了类别不平衡问题。</p><blockquote class="no"><p id="9f93" class="np nq it bd nr ns nt nu nv nw nx ld dk translated">焦点损失通过降低简单例子的权重，将培训集中在一组稀疏的硬例子上，以防止大多数容易否定的例子淹没培训</p></blockquote><p id="2f45" class="pw-post-body-paragraph ki kj it kk b kl ny ju kn ko nz jx kq kr oa kt ku kv ob kx ky kz oc lb lc ld im bi translated"><strong class="kk iu"> <em class="le">焦点丢失如何解决阶层失衡问题？</em>T3】</strong></p><p id="a598" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">聚焦损失是一种新的损失函数，它在交叉熵损失函数中增加了一个调制因子，聚焦参数γ ≥ 0。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/032a14c6b21f4b049478be273d4325fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:254/format:webp/1*FEn52BL3MHYAYapM9fwx2Q.png"/></div></figure><p id="60be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">聚焦参数</strong> γ <strong class="kk iu">在训练期间自动降低简单示例的权重，同时将模型训练聚焦在困难示例上。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/9d41b8683b64335a9b15b0d88af60fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*1Ll8ydigaxfJRUb5SmVGIw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">焦点损失和交叉熵损失</figcaption></figure><p id="5b16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">焦损失的超参数γ用于调整不同样本的权重。当γ &gt; 0时，它减少了分类良好的例子的相对损失。</p><p id="bb60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着γ的增加，更少的容易分类的样本导致训练损失。当γ达到0时，焦损失与交叉熵损失相同。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/a758f25581164216e53e8eae115b5e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*C3RHolSp82KmOBhlBeBiTg.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated">来源:<a class="ae lv" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">密集物体探测的焦点损失</a></figcaption></figure><p id="04de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上图中，我们观察到焦点损失的两个特性。</p><ol class=""><li id="a47d" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld og na nb nc bi translated">当一个例子被错误分类，并且pt很小时，调制因子接近1，并且损失不受影响。当pt → 1时，调制因子变为0，对于分类良好的示例，损耗被向下加权。</li><li id="4b7d" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld og na nb nc bi translated">聚焦参数γ平滑地调整简单示例向下加权的速率。</li></ol><p id="8f94" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当γ = 0时，FL相当于CE，随着γ的增加，调制因子的效果也增加(我们发现γ = 2在我们的实验中效果最好)。</p><p id="dd6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">焦点损失的α平衡变体</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f2f0c45a67af850006be1ec1812617b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*lkYJfT5jiru2PkDwWyrzpg.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd ly"> α平衡焦损失</strong></figcaption></figure><p id="e5c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中α可用于分别缩放不同的类。</p><p id="aa58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">α平衡的变体比非α平衡的形式产生稍好的精确度。</p><p id="e838" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">α平衡变体</strong>加权焦点损失用于处理前景和背景类别不平衡以及硬阴性样本的梯度显著性。</p><p id="5c7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实验表明，焦点损失使得能够训练高精度一级检测器，该检测器显著优于诸如自举或硬示例挖掘之类的训练的替代技术来处理类别不平衡。</p><p id="7f84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">在这里</strong> 学习其他处理不平衡数据集的技术 <a class="ae lv" href="https://towardsdatascience.com/techniques-for-handling-imbalanced-classification-datasets-5ee58b0b5e7a" rel="noopener" target="_blank"> <strong class="kk iu"/></a></p><p id="84d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在非平衡数据集上为结构化数据实现无焦点。</p><p id="1109" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lv" href="https://www.kaggle.com/mlg-ulb/creditcardfraud/data" rel="noopener ugc nofollow" target="_blank">信用卡欺诈数据集</a></p><p id="2e47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">读取数据集</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="7c32" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">import pandas as pd<br/>import numpy as np<br/>df = pd.read_csv("creditcard.csv")</strong></span></pre><p id="0492" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数据中绘制正常交易和欺诈交易</p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="96bf" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">import matplotlib.pyplot as plt<br/>LABELS = ["Normal","Fraud"]<br/>count_classes = pd.value_counts(df['Class'], sort = True)<br/>count_classes.plot(kind = 'bar', rot=0)<br/>plt.xticks(range(2), LABELS)<br/>plt.title("Frequency by observation number")<br/>plt.xlabel("Class")<br/>plt.ylabel("Number of Observations");</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/9e25ea342502e48bbbfde54dd655ce22.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*o8FY7lJBGPsJEYWuDfjaXQ.png"/></div></figure><p id="85c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有284315笔正常交易，只有492笔欺诈交易</p><p id="8a66" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">实现焦损</strong></p><p id="d8aa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建从<strong class="kk iu"><em class="le">TF . keras . losses . Loss</em>a</strong>继承的类FocalLoss，并基于<strong class="kk iu"> </strong> <a class="ae lv" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">密集对象检测的焦点损失</strong> </a>实现如上所述的FocalLoss</p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="5afc" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">import tensorflow as tf<br/>from keras.callbacks import ModelCheckpoint, TensorBoard<br/>from keras import regularizers<br/>class FocalLoss(tf.keras.losses.Loss):<br/>    def __init__(self, gamma=2., alpha=4.,<br/>                 reduction=tf.keras.losses.Reduction.AUTO, name='focal_loss'):</strong><br/>        """Focal loss for multi-classification<br/>        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)<br/>        Notice: y_pred is probability after softmax<br/>        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper<br/>        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)<br/>        Focal Loss for Dense Object Detection<br/>        <a class="ae lv" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.02002</a></span><span id="9c19" class="lw lx it oj b gy os oo l op oq">Keyword Arguments:<br/>            gamma {float} -- (default: {2.0})<br/>            alpha {float} -- (default: {4.0})<br/>        """<br/>        <strong class="oj iu">super(FocalLoss, self).__init__(reduction=reduction,<br/>                                        name=name)<br/>        self.gamma = float(gamma)<br/>        self.alpha = float(alpha)</strong></span><span id="6378" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">def call(self, y_true, y_pred):</strong><br/>        """<br/>        Arguments:<br/>            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]<br/>            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]</span><span id="c186" class="lw lx it oj b gy os oo l op oq">Returns:<br/>            [tensor] -- loss.<br/>        """<br/>        <strong class="oj iu">epsilon = 1.e-9<br/>        y_true = tf.convert_to_tensor(y_true, tf.float32)<br/>        y_pred = tf.convert_to_tensor(y_pred, tf.float32)</strong></span><span id="2b14" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">model_out = tf.add(y_pred, epsilon)<br/>        ce = tf.multiply(y_true, -tf.math.log(model_out))<br/>        weight = tf.multiply(y_true, tf.pow(<br/>            tf.subtract(1., model_out), self.gamma))<br/>        fl = tf.multiply(self.alpha, tf.multiply(weight, ce))<br/>        reduced_fl = tf.reduce_max(fl, axis=1)<br/>        return tf.reduce_mean(reduced_fl)</strong></span></pre><p id="3278" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建训练和测试数据集</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="cd89" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">from sklearn.model_selection import train_test_split<br/>RANDOM_SEED = 314 <br/>TEST_PCT = 0.4 <br/>batch_size = 128</strong></span><span id="5c67" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">def feature_normalize(dataset):<br/>    mu = np.mean(dataset, axis=0)<br/>    sigma = np.std(dataset, axis=0)<br/>    return (dataset - mu) / sigma</strong></span><span id="021c" class="lw lx it oj b gy os oo l op oq"><br/><strong class="oj iu">X, y = df.iloc[:,:-1], df.iloc[:, -1]<br/>y = tf.keras.utils.to_categorical(y, num_classes=0)<br/>X = feature_normalize(X)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_PCT, random_state=RANDOM_SEED)</strong></span><span id="9058" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">X_train = X_train.values<br/>X_test = X_test.values</strong></span></pre><p id="6b71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建模型</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="080a" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">input_dim = X_train.shape[1]<br/>nb_classes = y_train.shape[1]</strong></span><span id="95f9" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">model_f = tf.keras.Sequential(<br/> [tf.keras.layers.Dense(10, input_dim=input_dim, activation='relu', name='input'),<br/>  tf.keras.layers.Dense(20, activation='relu', name='fc1'),<br/>tf.keras.layers.Dense(10, activation='relu', name='fc2'),<br/>tf.keras.layers.Dense(nb_classes, activation='softmax', name='output')])</strong></span><span id="fd23" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">model_f.summary()</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/3f63c78bb81c025fc677d20ddd82298b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*QSABCkmd9xWT2SgNDgQwyg.png"/></div></figure><p id="3ef0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">编译模型</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="7f18" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">cp_f = tf.keras.callbacks.ModelCheckpoint(filepath=”FL.h5",<br/> mode=’max’, monitor=’val_accuracy’, verbose=2, save_best_only=True)</strong></span><span id="e481" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">model_f.compile(metrics=[‘accuracy’],<br/> loss=FocalLoss(alpha=.25, gamma=4.3),<br/> optimizer=tf.keras.optimizers.Adam(1e-2))</strong></span></pre><p id="4b3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">拟合模型</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="fe35" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">history = model_f.fit(X_train, y_train,<br/>                    epochs=5,<br/>                    batch_size=batch_size,<br/>                    <br/>                    validation_data=(X_test, y_test),<br/>                    verbose=1,<br/>                    callbacks=[cp_f]<br/>                    ).history</strong></span></pre><p id="41c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">评估模型性能</strong></p><pre class="lg lh li lj gt oi oj ok ol aw om bi"><span id="1ed6" class="lw lx it oj b gy on oo l op oq"><strong class="oj iu">from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score<br/>predictions = model_f.predict(X_test)</strong></span><span id="be45" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">act_test=[0 if y_test[i][0] == 1. else 1 for i in range(len(y_test))]<br/>pred_f = [0 if predictions[i][0] &gt; 0.5 else 1 for i in range(len(predictions))]</strong></span><span id="cd87" class="lw lx it oj b gy os oo l op oq"><strong class="oj iu">print(" Accuracy: ",accuracy_score(act_test, pred_f))<br/>print(" Recall: ",recall_score(act_test, pred_f))<br/>print(" Precision: ",precision_score(act_test, pred_f))<br/>print(" F1-Score: ",f1_score(act_test, pred_f))<br/>print(confusion_matrix(act_test, pred_f))</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/af7b508d5b11ea418ed215332ec26014.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*cjyF1d4m4T6v0hxGpYHiPg.png"/></div></figure><p id="e88e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到数据集不平衡，我们有284315个正常交易，只有492个欺诈交易，准确度、精确度、召回率和F1值都很好。</p><h2 id="4223" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">结论:</h2><p id="40c8" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">焦点损失通过降低分配给分类良好的示例的损失的权重来解决类别不平衡。它使用超参数“γ”来调整不同样品的重量。</p><h2 id="48bf" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">参考资料:</h2><p id="00ad" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><a class="ae lv" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">密集物体探测的焦损失</a></p><p id="33ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lv" href="https://arxiv.org/pdf/2011.06283.pdf" rel="noopener ugc nofollow" target="_blank">联邦学习中不平衡数据分类的聚焦损失</a></p></div></div>    
</body>
</html>