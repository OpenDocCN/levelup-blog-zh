<html>
<head>
<title>Rust And Go Web API Performance Testing — Rust Baseline #1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Rust And Go Web API性能测试— Rust基线#1</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/go-vs-rust-web-api-performance-testing-rust-baseline-part-1-f35c5f21e64b?source=collection_archive---------0-----------------------#2022-10-01">https://levelup.gitconnected.com/go-vs-rust-web-api-performance-testing-rust-baseline-part-1-f35c5f21e64b?source=collection_archive---------0-----------------------#2022-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/efa3c309ba133978f49765db12d6f98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0mmQXOwhLxOkBxXtNu1QLQ.jpeg"/></div></div></figure><p id="f3d3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于RUST APIs的语言语义和手动内存管理，人们普遍认为它是性能最好的API。在性能方面，它经常与C++相比较。让我好奇的一个方面也是RUST和Golang相比如何。我能收集一些有助于全面评估的数据吗？因此，我决定为一个用RUST编写的非常简单的API建立一个基线。这篇文章强调了性能的结果。</p><blockquote class="kz la lb"><p id="9bfe" class="kb kc lc kd b ke kf kg kh ki kj kk kl ld kn ko kp le kr ks kt lf kv kw kx ky im bi translated">声明:不要仅仅依靠这篇文章来决定Golang和Rust。这不是一篇A vs B的文章。其目的是提供一些数据点，供人们在评估时使用。这两种语言在现实世界中可能有不同的用例，在选择任何一种之前，必须对用例进行仔细的评估。</p></blockquote><p id="6c43" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我推荐<a class="ae lg" href="https://shanmukhsista.medium.com/golang-vs-rust-for-web-api-development-projects-a-quick-comparison-fcc2ae2d0f6d" rel="noopener">阅读我几天前写的一篇比较Golang和RUST </a>的文章。那篇文章是这篇文章的动机。Golang作为一种高效的系统语言，在性能方面可以与rust相提并论。但是Golang和rust的性能真正的区别是什么。我们能对此进行量化吗？这就是我想亲眼看看的原因。</p><h1 id="5bd7" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">设置</h1><p id="31a7" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">设置分为两个阶段和测试。</p><p id="aa53" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我创建的第一个设置是Rust中的一个新REST API。<a class="ae lg" href="https://shanmukhsista.medium.com/real-world-rest-api-using-rust-axum-framework-with-request-validations-and-error-handling-75d4175cef96" rel="noopener">这是一个简单的API，接受JSON输入，反序列化，验证，然后返回响应</a>。</p><p id="8ce7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第二个设置将包括为每个请求计算一个<strong class="kd iu"> MD5散列。看看这对性能有何影响。我相信这是一个稍微占用CPU资源的操作，会对API性能产生一些影响。我可能错了！</strong></p><p id="74fb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我将这个构建归档，然后通过在GCP上启动一个新的虚拟机来运行性能测试。这将确保我可以标准化一些设置，并在Golang中为相同的API重复一次。</p><h1 id="0f7c" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">Dockerfile文件</h1><p id="6710" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">我的rust应用程序的docker文件很简单</p><pre class="mk ml mm mn gt mo mp mq mr aw ms bi"><span id="96f7" class="mt li it mp b gy mu mv l mw mx"><strong class="mp iu">FROM </strong>rust:1.63.0 <strong class="mp iu">AS <em class="lc">build<br/><br/></em>WORKDIR /</strong>src<strong class="mp iu">/</strong>openab<br/><strong class="mp iu">COPY </strong>. .<br/><strong class="mp iu">RUN </strong>cd management-server <strong class="mp iu">&amp;&amp; </strong>cargo install <strong class="mp iu">--</strong>path .<br/><strong class="mp iu">RUN </strong>ls <strong class="mp iu">-</strong>al <strong class="mp iu">/</strong>usr<strong class="mp iu">/</strong>local<strong class="mp iu">/</strong>cargo<strong class="mp iu">/</strong>bin<br/><br/><strong class="mp iu">FROM </strong>debian:stable-slim<br/><strong class="mp iu">COPY --</strong>from=<strong class="mp iu"><em class="lc">build </em>/</strong>usr<strong class="mp iu">/</strong>local<strong class="mp iu">/</strong>cargo<strong class="mp iu">/</strong>bin<strong class="mp iu">/</strong>management-server <strong class="mp iu">/</strong>bin<br/><strong class="mp iu">CMD </strong>[<strong class="mp iu">"/bin/management-server"</strong>]</span></pre><p id="e248" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">发出所有请求的机器将是一个单独的Docker实例，具有相同的机器配置。我们将使用<code class="fe my mz na mp b">k6</code>来测试我们的负载。下面是运行测试的脚本和命令。</p><h2 id="adb1" class="mt li it bd lj nb nc dn ln nd ne dp lr km nf ng lv kq nh ni lz ku nj nk md nl bi translated">脚本</h2><pre class="mk ml mm mn gt mo mp mq mr aw ms bi"><span id="9e18" class="mt li it mp b gy mu mv l mw mx">import http from 'k6/http';</span><span id="b14f" class="mt li it mp b gy nm mv l mw mx">export default function () {<br/>  const url = '<a class="ae lg" href="http://10.128.0.2:3000/experiments'" rel="noopener ugc nofollow" target="_blank">http://x.x.x.x:3000/experiments'</a>;<br/>  const payload = JSON.stringify(</span><span id="e54a" class="mt li it mp b gy nm mv l mw mx">{<br/>        "name":"new_home_page",<br/>        "variants":[<br/>                {<br/>                        "name":"blue_button",<br/>                        "allocation_percent":50.0<br/>                },<br/>                {<br/>                        "name":"red_button",<br/>                        "allocation_percent":50.0<br/>                }<br/>        ]<br/>}<br/>  );</span><span id="9180" class="mt li it mp b gy nm mv l mw mx">const params = {<br/>    headers: {<br/>      'Content-Type': 'application/json',<br/>    },<br/>  };</span><span id="734b" class="mt li it mp b gy nm mv l mw mx">http.post(url, payload, params);<br/>}</span></pre><h2 id="b57d" class="mt li it bd lj nb nc dn ln nd ne dp lr km nf ng lv kq nh ni lz ku nj nk md nl bi translated">测试命令</h2><pre class="mk ml mm mn gt mo mp mq mr aw ms bi"><span id="573f" class="mt li it mp b gy mu mv l mw mx">k6 run --vus 3000 --iterations 1000000 script.js</span></pre><p id="8790" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该测试使用了一台双核4 GB内存的<code class="fe my mz na mp b">e2-medium </code>机器。我们将对3000个虚拟用户同时访问我们的服务器的100万个请求进行测试。这应该是测试我们性能的一个重要负载。</p><h1 id="2bff" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">结果场景1 —不生成哈希</h1><p id="159d" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">下面是我们第一次测试的结果。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="4dc6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">看着结果，感觉还不错。仅用一个双核4 GB RAM，我们就能够在3000个虚拟用户的情况下<strong class="kd iu">实现9.5K的吞吐量</strong>。<strong class="kd iu">机器的CPU峰值为83%。</strong></p><h1 id="8cf6" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">结果场景#2</h1><p id="5116" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">对于这个场景，我更新了我们的代码库来生成一个MD5散列，用于连接实验名称和unix时间戳。我用散列替换实验名，并将其作为响应返回。</p><pre class="mk ml mm mn gt mo mp mq mr aw ms bi"><span id="47bb" class="mt li it mp b gy mu mv l mw mx"><strong class="mp iu">let </strong>digest = md5::compute(format!(<strong class="mp iu">"{}-{}"</strong>,e.<strong class="mp iu">name </strong>, since_the_epoch.as_secs()));<br/>e.name = format!(<strong class="mp iu">"{:x}"</strong>, digest) ;</span></pre><p id="6154" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我用完全相同的设置运行相同的测试。</p><figure class="mk ml mm mn gt ju"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="a171" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">结果相当有可比性。即使添加了md5散列，结果也有每秒30个请求的下降。对延迟(接收响应时间)的影响非常小，但那是对散列的响应。</p><h1 id="ee2c" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">结论</h1><p id="cdf0" class="pw-post-body-paragraph kb kc it kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">看到结果很有趣，我对吞吐量很满意。3000个虚拟用户上的9.5k/秒——对于一台<code class="fe my mz na mp b">e2-medium</code>机器来说，JSON序列化和反序列化是一个特别好的基准。我注意到的一件事是，CPU使用率是一致的，没有任何峰值。对于3000个虚拟用户同时访问我们的服务，我们的请求延迟或CPU性能没有太大差异。结果是可以预测的。</p><p id="b95c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">铁锈基线对比到此为止。在接下来的文章中，我将使用Golang编写完全相同的程序，并尝试获得这个API的一些基线数据。看看会发生什么会很有趣。我对这一个感到兴奋！</p><blockquote class="kz la lb"><p id="5e3e" class="kb kc lc kd b ke kf kg kh ki kj kk kl ld kn ko kp le kr ks kt lf kv kw kx ky im bi translated"><strong class="kd iu">敬请关注，关注我更多！</strong></p></blockquote></div></div>    
</body>
</html>