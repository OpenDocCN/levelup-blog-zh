<html>
<head>
<title>Diagnosing Breast Cancer Using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习诊断乳腺癌</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/diagnosing-breast-cancer-using-machine-learning-d56e4b1d4364?source=collection_archive---------8-----------------------#2020-04-29">https://levelup.gitconnected.com/diagnosing-breast-cancer-using-machine-learning-d56e4b1d4364?source=collection_archive---------8-----------------------#2020-04-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fb17" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将描述我如何构建一个ML模型来确定乳腺癌数据中的肿瘤是恶性还是良性。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/d29b7cf70be1161c6353634f8348ec33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjsLGG-U9km84AvWLLmK8A.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">来自https://unsplash.com/photos/L7en7Lb-Ovc<a class="ae lc" href="https://unsplash.com/photos/L7en7Lb-Ovc" rel="noopener ugc nofollow" target="_blank">的癌细胞图像</a></figcaption></figure><p id="7252" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在美国，八分之一的女性在她们的一生中将被诊断患有乳腺癌。</p><p id="992c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在所有被诊断的人中，<strong class="jp ir">只有87% </strong>被正确诊断<em class="kl"/>。乍一看，87%似乎是个不错的数字，对吗？这是站在大多数人一边的，但就医学而言，在世界上200万患有乳腺癌的女性中，<strong class="jp ir">只有大约174万女性会得到正确的诊断</strong>——剩下60万人没有关于她们病情的正确信息。</p><p id="244d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了做出诊断，当放射科医生在乳房x光片上发现可疑的形成时，进行乳房活检。通过手术切除肿瘤，并在显微镜下进行研究。无数的研究论文，比如<a class="ae lc" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5064832/" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae lc" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5857941/" rel="noopener ugc nofollow" target="_blank">这个</a>都发现乳腺癌经常被误诊，而且诊断往往<em class="kl">不足</em>或者<em class="kl">过度治疗</em>患者。许多这些论文的主要作者，华盛顿大学的研究人员Joan Elmore博士描述了这个过程非常容易出错:</p><blockquote class="ld le lf"><p id="c030" class="jn jo kl jp b jq jr js jt ju jv jw jx lg jz ka kb lh kd ke kf li kh ki kj kk ij bi translated"><strong class="jp ir">病理学家在大约一半的时间里正确诊断出异常的癌前细胞，这不比扔硬币好多少— </strong>主要作者Joann Elmore博士，华盛顿大学的研究人员。</p></blockquote><p id="4485" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">许多患有乳腺癌的患者经常不得不求助于第二专家对其诊断的意见，以确保他们确实得到了所需的治疗。获得诊断的第二意见通常是昂贵的(T21)，这使得很大一部分人不可能去拜访另一位专家来验证他们的结果。</p><p id="2bc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">机器学习是解决这一问题的成本和时间有效的解决方案，因为它提供了:</p><ul class=""><li id="fde5" class="lj lk iq jp b jq jr ju jv jy ll kc lm kg ln kk lo lp lq lr bi translated"><em class="kl">诊断准确率高</em></li><li id="699a" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><em class="kl">不要求与专家相同薪酬的第二种意见</em></li><li id="22b6" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><em class="kl">方便快捷</em></li></ul><p id="d6de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，ML是一种可行的潜在解决方案，可以用于在为患者决定诊断和治疗时向医生提供第二意见，因此，消除了就诊断咨询第二专业人员的需要。这意味着更多的人将能够获得准确的治疗，而不必花费额外的时间和金钱寻找第二位专家。</p><p id="7a4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我制作了一个机器学习模型，使用定量数据来诊断乳腺癌患者是良性还是恶性肿瘤。使用监督学习和测试三种类型的模型:随机森林分类器、决策树分类器和逻辑回归分类器，我能够选择一个给出96%准确性的模型。</p><h1 id="98c2" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">数据准备:</h1><p id="4a45" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">我使用的测量和数据来自<a class="ae lc" href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank"> Wisconsins乳腺癌(诊断)数据集</a>。<strong class="jp ir">测量描述了乳腺肿块细针抽吸(FNA)图像中细胞核的特征。</strong></p><p id="8d72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用Numpy、Pandas、Matplotlib和Seaborn库来操作数据和构建ML模型。</p><h2 id="97f4" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">理解数据:</h2><p id="696c" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">下图显示了该数据的格式。第一列包含患者的ID，用于代替姓名以保护机密性。第二列包含M或B。<strong class="jp ir">M代表恶性</strong>，这是一个用来描述能够迅速扩散到其他组织的癌性肿瘤的术语，而<strong class="jp ir"> B代表良性</strong>，这是一种尚未癌变的肿瘤，具有更高的患者存活率。其余的列包含每个样品的定性和定量数据。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nm"><img src="../Images/fd13b3ba81ae02f812020464768ba23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51Hm0b9RlgnPVQLariliRw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">所有打印的数据巧合地只显示了恶性肿瘤的“M ”,但是，数据中也有“B”。</figcaption></figure><p id="98cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在总共569个患者行中，这是包含在数据集中的恶性和良性肿瘤数量的图。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nn"><img src="../Images/120b2b1e2ac6f9ffa8a14b85da7838ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01aQQaJ_p7ANLj2g1DKKJg.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">显示数据集中恶性和良性肿瘤的数量。</figcaption></figure><h2 id="9c86" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">清理数据:</h2><p id="48d0" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">现在，我将使用下面的逻辑从我的模型<em class="kl">中删除不必要的数据:</em></p><ol class=""><li id="a0c9" class="lj lk iq jp b jq jr ju jv jy ll kc lm kg ln kk no lp lq lr bi translated">我计算了所有包含空值(NAN，NaN，na)的列。标题为“未命名”的列32包含该数据集中所有患者的空值。显然，它对预测肿瘤是恶性还是良性没有帮助，因此我可以删除这一列。</li><li id="681d" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk no lp lq lr bi translated">包含患者ID的列0对我们的目的也没有帮助，因此从数据集中删除。</li></ol><h2 id="94ec" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">查看变量相关性:</h2><p id="4893" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">为了进一步研究数据，可以查看32个变量中的一个变量如何与另一个变量的值相关联。这将为我们提供进一步的见解，即哪些变量结合在一起导致肿瘤变得恶性，以及机器学习模型将如何做出预测。</p><p id="f291" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用下面的线条，我们构建一个热图来可视化变量之间的相关性。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi np"><img src="../Images/ffc0f8faba62fa2441ba72d43ac617bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Utefr_y5S3rVFFtzfQUlRw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">热图图像，用于显示数据集中变量之间的相关性。</figcaption></figure><h2 id="a6df" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">拆分数据:</h2><p id="b2bc" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">对于这个模型，我将数据分成75%作为训练数据集，另外25%作为测试数据集。我还将数据缩放到，以便将其测量值转换为0-100或0-1的比例，从而进行更精确的比较。</p><h1 id="d3d6" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">机器学习模型:</h1><p id="1408" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">我用下面几行代码创建了一个包含三个模型的函数，我们可以用它来确定病人的肿瘤类型。</p><pre class="kn ko kp kq gt nq nr ns nt aw nu bi"><span id="7e39" class="na ly iq nr b gy nv nw l nx ny">def models(X_train, Y_train)</span><span id="5510" class="na ly iq nr b gy nz nw l nx ny">     from sklearn.linear_model import LogisticRegression</span><span id="589a" class="na ly iq nr b gy nz nw l nx ny">     log = LogisticRegression(random_state=0)</span><span id="127d" class="na ly iq nr b gy nz nw l nx ny">     log.fit(X_train, Y_train)</span><span id="4693" class="na ly iq nr b gy nz nw l nx ny">     from sklearn.tree import DecisionTreeClassifier</span><span id="18e4" class="na ly iq nr b gy nz nw l nx ny">     tree = DecisionTreeClassifier(criterion = ‘entropy’,      random_state=0)</span><span id="1c70" class="na ly iq nr b gy nz nw l nx ny">     tree.fit(X_train, Y_train)</span><span id="8aa8" class="na ly iq nr b gy nz nw l nx ny">     from sklearn.ensemble import RandomForestClassifier</span><span id="605c" class="na ly iq nr b gy nz nw l nx ny">     forest = RandomForestClassifier(n_estimators = 10, criterion = ‘entropy’, random_state = 0)</span><span id="b1e0" class="na ly iq nr b gy nz nw l nx ny">     forest.fit(X_train, Y_train)</span></pre><p id="b99d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所使用的每种类型的分类器对于不同类型的问题都是最佳的，因此在执行这项任务时会有不同的分类精度。我们将在文章中进一步研究每种方法的准确性。</p><h2 id="a616" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">逻辑回归</h2><ul class=""><li id="e189" class="lj lk iq jp b jq mv ju mw jy oa kc ob kg oc kk lo lp lq lr bi translated">用于对某一事件的概率进行建模，在这种情况下，该事件为恶性肿瘤，如转换数据中的“1”所示</li><li id="1b6a" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated">通常用于基于多个属性的分类，因为输出介于0和1之间</li></ul><p id="d0b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种类型的回归类似于线性回归，因为它们都涉及基于训练数据估计预测方程的参数值。然而，线性回归预测的是连续的因变量的值，而逻辑回归预测的是基于多个不同因素的结果的概率。</p><h2 id="ec6f" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">决策树分类器</h2><ul class=""><li id="2dc5" class="lj lk iq jp b jq mv ju mw jy oa kc ob kg oc kk lo lp lq lr bi translated">可以输出分类预测:植物是否属于某一种类</li><li id="ff06" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated">数字预测:房子的价格是多少</li></ul><p id="df7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">决策树包含用于将数据分成特定类别的节点和分支，它是通过递归评估特定特征对数据值的不同影响而构建的。每个节点都是不更新的，直到它能够最好地分割数据，用于分类或数值预测的目的。</p><h2 id="8ed7" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated"><strong class="ak">随机森林分类器</strong></h2><ul class=""><li id="08fd" class="lj lk iq jp b jq mv ju mw jy oa kc ob kg oc kk lo lp lq lr bi translated">由大量独立的决策树组成，因此称为“森林分类器”，它们一起工作来预测输出</li><li id="7828" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated">每棵树都给出了它的答案预测，在这些树中最流行的答案就是模型输出</li></ul><p id="759e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让多数获胜的树“投票”在输出准确预测方面是有效的，因为它确保结果已经由具有不同参数和设置的多个树预测，因此最小化了由我们的模型输出的预测中的可能性或机会和误差。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/94a117f4687e428bc5fdc45fce3d1e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*WUQPiFiid1kSjjyvbA2uGQ.jpeg"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">图片来自<a class="ae lc" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener" target="_blank">https://towards data science . com/understanding-random-forest-58381 e 0602d 2</a></figcaption></figure><h1 id="bbd5" class="lx ly iq bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">测试模型:</h1><p id="9f59" class="pw-post-body-paragraph jn jo iq jp b jq mv js jt ju mw jw jx jy mx ka kb kc my ke kf kg mz ki kj kk ij bi translated">现在，我将建立一个<strong class="jp ir">混淆矩阵</strong>，看看每个模型在测试数据上的表现有多准确。由于模型容易出错，矩阵将向我们展示<em class="kl">在测试数据的分类中有多少真阳性、假阳性、真阴性和假阴性。</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b377bea84bc22315c606876104b944fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*j0rlCUiwjs2DDVJnyzYDKQ.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">每个模型的混淆矩阵。</figcaption></figure><p id="6230" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型0为逻辑回归模型，检验准确率为95.1%。决策树分类器是模型1，其准确率为93.7%。最后，模型2是随机森林分类器，它在测试数据上是最准确的，给出了96.5%的结果。</p><p id="7985" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们可以用来显示模型性能的额外指标的代码:</p><pre class="kn ko kp kq gt nq nr ns nt aw nu bi"><span id="5612" class="na ly iq nr b gy nv nw l nx ny">from sklearn.metrics import classification_report</span><span id="f66d" class="na ly iq nr b gy nz nw l nx ny">from sklearn.metrics import accuracy_score</span><span id="6c5c" class="na ly iq nr b gy nz nw l nx ny">for i in range(len(model)):</span><span id="fed1" class="na ly iq nr b gy nz nw l nx ny">print('Model ', i)</span><span id="9c4b" class="na ly iq nr b gy nz nw l nx ny">print(classification_report(Y_test, model[0].predict(X_test)))</span><span id="b86a" class="na ly iq nr b gy nz nw l nx ny">print(accuracy_score(Y_test, model[0].predict(X_test)))</span></pre><p id="6596" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们得到以下结果:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/a2e9830f712afad352b18dd0f6c1eb5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*inQxk9lV5irLmECyPtHWEA.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk translated">关于每个模型准确性的附加信息。</figcaption></figure><p id="d74e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据结果，<strong class="jp ir">随机森林分类器在所有三个分类器中表现最好。</strong>这意味着它在执行分类时犯的错误最少，并且是确定肿瘤是良性还是恶性时使用的最佳模型。</p><h2 id="433d" class="na ly iq bd lz nb nc dn md nd ne dp mh jy nf ng ml kc nh ni mp kg nj nk mt nl bi translated">感谢您的阅读！请务必留下掌声，并查看:</h2><ol class=""><li id="277f" class="lj lk iq jp b jq mv ju mw jy oa kc ob kg oc kk no lp lq lr bi translated">我的网站:<a class="ae lc" href="http://linanayvelt.com" rel="noopener ugc nofollow" target="_blank">linanayvelt.com</a></li><li id="ee6c" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk no lp lq lr bi translated"><a class="ae lc" href="https://colab.research.google.com/drive/1aRHPHtnDfEJA-1FjsAsKzOkErp0NWyyl" rel="noopener ugc nofollow" target="_blank"> Colab链接到项目！</a></li><li id="a491" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk no lp lq lr bi translated">我的链接https://www.linkedin.com/in/lina-nayvelt</li></ol><p id="c96d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献:</strong></p><p id="c68d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">坦纳大学(2015年3月18日)。乳房组织被误诊的几率比你想象的要高。检索自<a class="ae lc" href="https://www.theglobeandmail.com/life/health-and-fitness/health/breast-tissue-misdiagnosed-more-often-than-you-think/article23522980/" rel="noopener ugc nofollow" target="_blank">https://www . the globe and mail . com/life/health-and-fitness/health/乳腺组织-误诊率比你想象的要高/article23522980/ </a></p><p id="d318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Uci。(2016年9月25日)。乳腺癌威斯康星州(诊断)数据集。从https://www.kaggle.com/uciml/breast-cancer-wisconsin-data<a class="ae lc" href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="2630" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(2019年8月14日)。了解随机森林。检索自<a class="ae lc" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2?gi=855dafade1" rel="noopener" target="_blank">https://towardsdatascience . com/understanding-random-forest-58381 e 0602d 2？gi=855dafade1 </a></p><p id="2355" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(未注明)。利用最大似然法检测乳腺癌。检索于2020年4月28日，来自<a class="ae lc" href="https://www.youtube.com/watch?v=NSSOyhJBmWY&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=NSSOyhJBmWY&amp;feature = youtu . be</a></p><p id="fe10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Zornoza，J. (2020年2月8日)。逻辑回归解释。检索自<a class="ae lc" href="https://towardsdatascience.com/logistic-regression-explained-9ee73cede081" rel="noopener" target="_blank">https://towards data science . com/logistic-regression-explained-9ee 73 cede 081</a></p><p id="5661" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Zornoza，J. (2020年3月8日)。决策树解释道。检索自<a class="ae lc" href="https://towardsdatascience.com/decision-trees-explained-3ec41632ceb6" rel="noopener" target="_blank">https://towards data science . com/decision-trees-explained-3ec 41632 CEB 6</a></p></div></div>    
</body>
</html>