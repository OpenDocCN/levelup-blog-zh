<html>
<head>
<title>Adding Metadata to Media Frames via Insertable Streams API for WebRTC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过WebRTC的可插入流API向媒体帧添加元数据</h1>
<blockquote>原文：<a href="https://levelup.gitconnected.com/adding-metadata-to-media-frames-via-insertable-streams-api-for-webrtc-47f7a740e457?source=collection_archive---------2-----------------------#2020-04-20">https://levelup.gitconnected.com/adding-metadata-to-media-frames-via-insertable-streams-api-for-webrtc-47f7a740e457?source=collection_archive---------2-----------------------#2020-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8066" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">许多WebRTC功能以前只能在原生应用中实现，包括修改了Chromium代码的电子应用。CoSMo多年来一直与多个合作伙伴(包括Symphony Communications、AOMedia、Google或Apple/Webkit)一起引领编解码器(AV1)、音频处理、E2EE和AI等新功能的开发。</p><p id="ba65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如今，多亏了WebRTC NV APIs，其中一些在web应用程序中也成为可能。<a class="ae ko" href="https://webrtcbydralex.com/index.php/2020/03/30/secure-frames-sframes-end-to-end-media-encryption-with-webrtc-now-in-chrome/" rel="noopener ugc nofollow" target="_blank">继上周我们披露了与谷歌合作开发的SFrame E2EE之后</a>，由于Insertable stream，该在网络上实现了部分功能，现在是时候展示另一个以前在网络应用中几乎不可能实现的功能了。</p><p id="b43e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://webrtcbydralex.com/index.php/2020/04/20/around-a-refreshingly-new-approach-to-webrtc-calls-and-meetings/" rel="noopener ugc nofollow" target="_blank">受我们的合作伙伴在其应用中的出色工作的启发，</a>我们将展示如何实现媒体和数据之间的实时、帧完美同步，并将简单的人工智能算法应用于视频内容以改善用户体验。</p><p id="2b44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过能够访问原始编码媒体帧并修改其内容，可插入流API允许在编码之后将定制元数据附加到每个帧，并在解码过程之前在另一端接收到媒体帧时提取它。</p><p id="77f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然您可以通过WebRTC datachannels发送这些元数据，但能够以每帧的精度将元数据附加到媒体流是AR/VR等应用程序的关键要求。</p><p id="64fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了演示这一功能，我们受到了Around应用程序的启发，该应用程序提供了最先进的UI/UX，包括面部识别和自动对焦，可以在一个小圆圈上显示每个参与者的面部，而不必浪费屏幕空间来显示参与者背景。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/45a446f2da2282cd02c7dd0db9f622ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EaAxA-aRf28gJwI-mg7X0Q.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">【https://www.around.co/ T4】</figcaption></figure><p id="a957" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目前，为了实现这一点，您必须捕获媒体流的每个视频帧，将其显示在画布上，适当地裁剪和调整其大小，然后使用<em class="lf"> canvas.captureStream() </em>通过peerconnection发送。</p><p id="5fc3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，这个过程仍然不够高效(直到支持WebRTC NV的“滑稽帽子”用例)，所以我们将尝试使用Insertable Streams API实现它，并将图像处理推送到css上的接收端，以增加性能。</p><p id="8a82" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了将处理逻辑移出主javascript线程，我们将使用两个web workers，一个处理可插入的流，另一个进行面部检测。</p><p id="d11e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主网页将创建web workers和MessageChannel，这样它们可以直接在它们之间发送消息，而不必通过主线程。</p><p id="d669" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主线程将可写和可读的流从RTCRtpSender和RTCRtpReceiver传输到insertable streams worker，并定期(每秒)从本地视频对象中抓取一帧，并将其传输到人脸检测器worker。</p><p id="2dcd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人脸检测器工作器使用<a class="ae ko" href="https://github.com/justadudewhohacks/face-api.js/" rel="noopener ugc nofollow" target="_blank"> face-api.js </a>来检测视频帧中出现的人脸，并向insertable streams工作器发布一条消息，其中包含有关检测到的人脸的位置和大小的信息。</p><p id="31dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可插入流工作器将把检测到的面部元数据附加到接收到的下一个视频帧，该视频帧将被发送到服务器并循环回浏览器，在那里它将由可插入流工作器再次处理，该可插入流工作器将从帧中提取元数据(因此它可再次被解码)并将带有面部信息的消息发布到主线程。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="lg lh l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">Web worker在视频帧上插入和提取人脸元数据</figcaption></figure><p id="aba6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，主线程将在视频元素上应用css转换，以便在查看区域的中心为参与者显示人脸。</p><p id="adc5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://sgmedooze.cosmosoftware.io/insertable-face/index.html" rel="noopener ugc nofollow" target="_blank">T3【https://sgmedooze.cosmosoftware.io/insertable-face】T5</a></p><p id="f846" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以看到被孩子们打断的著名BBC采访的实际结果:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi li"><img src="../Images/b7ce6b28301ee227a074d901ef07fa66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s5oHUYMxeOm3XU8jY35wug.png"/></div></div></figure><p id="0250" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">可插入流API和TransformStream的良好设计还允许该元数据插入/提取过程可以容易地与端到端加密过程链接，因此通过服务器发送的元数据被端到端加密并且对SFU不透明:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="lg lh l"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk translated">端到端元数据加密</figcaption></figure></div><div class="ab cl lj lk hx ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="im in io ip iq"><h1 id="1ce6" class="lq lr it bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">经过思考</h1><p id="1498" class="pw-post-body-paragraph jq jr it js b jt mo jv jw jx mp jz ka kb mq kd ke kf mr kh ki kj ms kl km kn im bi translated">排名不分先后:</p><ul class=""><li id="03ac" class="mt mu it js b jt ju jx jy kb mv kf mw kj mx kn my mz na nb bi translated">WebRTC已经成熟，第二代服务正在推出，重点是改善用户体验，更好地适应他们的主要用例。</li><li id="90f9" class="mt mu it js b jt nc jx nd kb ne kf nf kj ng kn my mz na nb bi translated">WebRTC(或libWebRTC)默认行为已经从您可以达到的最高质量变成了它所要求的基本水平。关于如何超越基本体验的示例，请参见围绕增强音频处理的<a class="ae ko" href="https://www.around.co/" rel="noopener ugc nofollow" target="_blank">或基于包丢失隐藏算法的</a><a class="ae ko" href="https://ai.googleblog.com/2020/04/improving-audio-quality-in-duo-with.html" rel="noopener ugc nofollow" target="_blank"> Google DUO AI。这将需要大量非常具体的专业知识和知识。</a></li><li id="1484" class="mt mu it js b jt nc jx nd kb ne kf nf kj ng kn my mz na nb bi translated">基于WebRTC NV需求的新WebRTC APIs(如可插入流)将是非常强大的工具，开发人员可以利用它们来探索和创造各种各样的创新想法。</li><li id="77d4" class="mt mu it js b jt nc jx nd kb ne kf nf kj ng kn my mz na nb bi translated">客户端开发将比以往更加重要，也更加难以实现。</li><li id="aa17" class="mt mu it js b jt nc jx nd kb ne kf nf kj ng kn my mz na nb bi translated">在不久的将来，WebCodec、WebTransport和WASM将进一步开放网络应用的容量。这将需要大量的WebRTC客户端专业知识，而<a class="ae ko" href="https://www.cosmosoftware.io/" rel="noopener ugc nofollow" target="_blank"> CoSMo </a>可以提供这些专业知识。</li></ul></div></div>    
</body>
</html>